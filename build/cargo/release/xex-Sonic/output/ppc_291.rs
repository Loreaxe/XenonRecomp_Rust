pub fn sub_831E28E8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E28E8 size=240
    let mut pc: u32 = 0x831E28E8;
    'dispatch: loop {
        match pc {
            0x831E28E8 => {
    //   block [0x831E28E8..0x831E29D8)
	// 831E28E8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E28EC: 4BFC5879  bl 0x831a8164
	ctx.lr = 0x831E28F0;
	sub_831A8130(ctx, base);
	// 831E28F0: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E28F4: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E28F8: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E28FC: 7F84E378  mr r4, r28
	ctx.r[4].u64 = ctx.r[28].u64;
	// 831E2900: 806BD59C  lwz r3, -0x2a64(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-10852 as u32) ) } as u64;
	// 831E2904: 4BFFFBD5  bl 0x831e24d8
	ctx.lr = 0x831E2908;
	sub_831E24D8(ctx, base);
	// 831E2908: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 831E290C: 2B1B0000  cmplwi cr6, r27, 0
	ctx.cr[6].compare_u32(ctx.r[27].u32, 0 as u32, &mut ctx.xer);
	// 831E2910: 419A00BC  beq cr6, 0x831e29cc
	if ctx.cr[6].eq {
	pc = 0x831E29CC; continue 'dispatch;
	}
	// 831E2914: 48060849  bl 0x8324315c
	ctx.lr = 0x831E2918;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E2918: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E291C: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831E2920: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831E2924: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831E2928: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E292C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E2930: 419A0010  beq cr6, 0x831e2940
	if ctx.cr[6].eq {
	pc = 0x831E2940; continue 'dispatch;
	}
	// 831E2934: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E2938: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E293C: 419A0018  beq cr6, 0x831e2954
	if ctx.cr[6].eq {
	pc = 0x831E2954; continue 'dispatch;
	}
	// 831E2940: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E2944: 48060139  bl 0x83242a7c
	ctx.lr = 0x831E2948;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E2948: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E294C: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831E2950: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831E2954: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E2958: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E295C: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E2960: 813B0028  lwz r9, 0x28(r27)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(40 as u32) ) } as u64;
	// 831E2964: 81690008  lwz r11, 8(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E2968: 7D6BE214  add r11, r11, r28
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[28].u64;
	// 831E296C: 912B0000  stw r9, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831E2970: 81090004  lwz r8, 4(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E2974: 910B0004  stw r8, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[8].u32 ) };
	// 831E2978: 91690004  stw r11, 4(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E297C: 80EB0004  lwz r7, 4(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E2980: 91670000  stw r11, 0(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831E2984: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E2988: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E298C: 419A0040  beq cr6, 0x831e29cc
	if ctx.cr[6].eq {
	pc = 0x831E29CC; continue 'dispatch;
	}
	// 831E2990: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E2994: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E2998: 409A0034  bne cr6, 0x831e29cc
	if !ctx.cr[6].eq {
	pc = 0x831E29CC; continue 'dispatch;
	}
	// 831E299C: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E29A0: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E29A4: 40820028  bne 0x831e29cc
	if !ctx.cr[0].eq {
	pc = 0x831E29CC; continue 'dispatch;
	}
	// 831E29A8: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E29AC: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E29B0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E29B4: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E29B8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E29BC: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E29C0: 480600AD  bl 0x83242a6c
	ctx.lr = 0x831E29C4;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E29C4: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E29C8: 480607A5  bl 0x8324316c
	ctx.lr = 0x831E29CC;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E29CC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E29D0: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E29D4: 4BFC57E0  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E29D8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E29D8 size=264
    let mut pc: u32 = 0x831E29D8;
    'dispatch: loop {
        match pc {
            0x831E29D8 => {
    //   block [0x831E29D8..0x831E2AE0)
	// 831E29D8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E29DC: 4BFC578D  bl 0x831a8168
	ctx.lr = 0x831E29E0;
	sub_831A8130(ctx, base);
	// 831E29E0: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E29E4: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E29E8: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 831E29EC: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 831E29F0: 38810054  addi r4, r1, 0x54
	ctx.r[4].s64 = ctx.r[1].s64 + 84;
	// 831E29F4: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831E29F8: 4BFFFE59  bl 0x831e2850
	ctx.lr = 0x831E29FC;
	sub_831E2850(ctx, base);
	// 831E29FC: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E2A00: 41980010  blt cr6, 0x831e2a10
	if ctx.cr[6].lt {
	pc = 0x831E2A10; continue 'dispatch;
	}
	// 831E2A04: 81610054  lwz r11, 0x54(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 831E2A08: 388B0048  addi r4, r11, 0x48
	ctx.r[4].s64 = ctx.r[11].s64 + 72;
	// 831E2A0C: 48000008  b 0x831e2a14
	pc = 0x831E2A14; continue 'dispatch;
	// 831E2A10: 80810054  lwz r4, 0x54(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 831E2A14: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831E2A18: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E2A1C: 4198009C  blt cr6, 0x831e2ab8
	if ctx.cr[6].lt {
	pc = 0x831E2AB8; continue 'dispatch;
	}
	// 831E2A20: 3C606182  lis r3, 0x6182
	ctx.r[3].s64 = 1635909632;
	// 831E2A24: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 831E2A28: 60630006  ori r3, r3, 6
	ctx.r[3].u64 = ctx.r[3].u64 | 6;
	// 831E2A2C: 4800053D  bl 0x831e2f68
	ctx.lr = 0x831E2A30;
	sub_831E2F68(ctx, base);
	// 831E2A30: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831E2A34: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 831E2A38: 41980080  blt cr6, 0x831e2ab8
	if ctx.cr[6].lt {
	pc = 0x831E2AB8; continue 'dispatch;
	}
	// 831E2A3C: 80610050  lwz r3, 0x50(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831E2A40: 38800048  li r4, 0x48
	ctx.r[4].s64 = 72;
	// 831E2A44: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E2A48: 814B0014  lwz r10, 0x14(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E2A4C: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E2A50: 4E800421  bctrl
	ctx.lr = 0x831E2A54;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E2A54: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E2A58: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 831E2A5C: 419A003C  beq cr6, 0x831e2a98
	if ctx.cr[6].eq {
	pc = 0x831E2A98; continue 'dispatch;
	}
	// 831E2A60: 38A00002  li r5, 2
	ctx.r[5].s64 = 2;
	// 831E2A64: 80810050  lwz r4, 0x50(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831E2A68: 48001329  bl 0x831e3d90
	ctx.lr = 0x831E2A6C;
	sub_831E3D90(ctx, base);
	// 831E2A6C: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E2A70: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 831E2A74: 394B01F0  addi r10, r11, 0x1f0
	ctx.r[10].s64 = ctx.r[11].s64 + 496;
	// 831E2A78: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E2A7C: 915F0000  stw r10, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E2A80: 4BFFFB09  bl 0x831e2588
	ctx.lr = 0x831E2A84;
	sub_831E2588(ctx, base);
	// 831E2A84: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831E2A88: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 831E2A8C: 41980018  blt cr6, 0x831e2aa4
	if ctx.cr[6].lt {
	pc = 0x831E2AA4; continue 'dispatch;
	}
	// 831E2A90: 93FC0000  stw r31, 0(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(0 as u32), ctx.r[31].u32 ) };
	// 831E2A94: 48000024  b 0x831e2ab8
	pc = 0x831E2AB8; continue 'dispatch;
	// 831E2A98: 3FC08007  lis r30, -0x7ff9
	ctx.r[30].s64 = -2147024896;
	// 831E2A9C: 63DE000E  ori r30, r30, 0xe
	ctx.r[30].u64 = ctx.r[30].u64 | 14;
	// 831E2AA0: 48000018  b 0x831e2ab8
	pc = 0x831E2AB8; continue 'dispatch;
	// 831E2AA4: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E2AA8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E2AAC: 814B000C  lwz r10, 0xc(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E2AB0: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E2AB4: 4E800421  bctrl
	ctx.lr = 0x831E2AB8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E2AB8: 80610050  lwz r3, 0x50(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831E2ABC: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E2AC0: 419A0014  beq cr6, 0x831e2ad4
	if ctx.cr[6].eq {
	pc = 0x831E2AD4; continue 'dispatch;
	}
	// 831E2AC4: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E2AC8: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E2ACC: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E2AD0: 4E800421  bctrl
	ctx.lr = 0x831E2AD4;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E2AD4: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E2AD8: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E2ADC: 4BFC56DC  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E2AE0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E2AE0 size=24
    let mut pc: u32 = 0x831E2AE0;
    'dispatch: loop {
        match pc {
            0x831E2AE0 => {
    //   block [0x831E2AE0..0x831E2AF8)
	// 831E2AE0: 39640003  addi r11, r4, 3
	ctx.r[11].s64 = ctx.r[4].s64 + 3;
	// 831E2AE4: 81430010  lwz r10, 0x10(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E2AE8: 556B003A  rlwinm r11, r11, 0, 0, 0x1d
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831E2AEC: 7D4B5214  add r10, r11, r10
	ctx.r[10].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831E2AF0: 91430010  stw r10, 0x10(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), ctx.r[10].u32 ) };
	// 831E2AF4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E2AF8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E2AF8 size=116
    let mut pc: u32 = 0x831E2AF8;
    'dispatch: loop {
        match pc {
            0x831E2AF8 => {
    //   block [0x831E2AF8..0x831E2B6C)
	// 831E2AF8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E2AFC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E2B00: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E2B04: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E2B08: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E2B0C: 7C852378  mr r5, r4
	ctx.r[5].u64 = ctx.r[4].u64;
	// 831E2B10: 809F0010  lwz r4, 0x10(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E2B14: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 831E2B18: 409A001C  bne cr6, 0x831e2b34
	if !ctx.cr[6].eq {
	pc = 0x831E2B34; continue 'dispatch;
	}
	// 831E2B1C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E2B20: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831E2B24: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E2B28: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E2B2C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E2B30: 4E800020  blr
	return;
	// 831E2B34: 90BF000C  stw r5, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[5].u32 ) };
	// 831E2B38: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E2B3C: 386BD5A4  addi r3, r11, -0x2a5c
	ctx.r[3].s64 = ctx.r[11].s64 + -10844;
	// 831E2B40: 4BFF9B71  bl 0x831dc6b0
	ctx.lr = 0x831E2B44;
	sub_831DC6B0(ctx, base);
	// 831E2B44: 907F0018  stw r3, 0x18(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), ctx.r[3].u32 ) };
	// 831E2B48: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E2B4C: 409AFFD0  bne cr6, 0x831e2b1c
	if !ctx.cr[6].eq {
	pc = 0x831E2B1C; continue 'dispatch;
	}
	// 831E2B50: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 831E2B54: 6063000E  ori r3, r3, 0xe
	ctx.r[3].u64 = ctx.r[3].u64 | 14;
	// 831E2B58: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831E2B5C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E2B60: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E2B64: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E2B68: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E2B70(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E2B70 size=108
    let mut pc: u32 = 0x831E2B70;
    'dispatch: loop {
        match pc {
            0x831E2B70 => {
    //   block [0x831E2B70..0x831E2BDC)
	// 831E2B70: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E2B74: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E2B78: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831E2B7C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E2B80: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E2B84: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E2B88: 39440003  addi r10, r4, 3
	ctx.r[10].s64 = ctx.r[4].s64 + 3;
	// 831E2B8C: 555E003A  rlwinm r30, r10, 0, 0, 0x1d
	ctx.r[30].u64 = ctx.r[10].u32 as u64 & 0xFFFFFFFFu64;
	// 831E2B90: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E2B94: 812B0010  lwz r9, 0x10(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E2B98: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 831E2B9C: 4E800421  bctrl
	ctx.lr = 0x831E2BA0;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E2BA0: 7F1E1840  cmplw cr6, r30, r3
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[3].u32, &mut ctx.xer);
	// 831E2BA4: 4099000C  ble cr6, 0x831e2bb0
	if !ctx.cr[6].gt {
	pc = 0x831E2BB0; continue 'dispatch;
	}
	// 831E2BA8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E2BAC: 48000018  b 0x831e2bc4
	pc = 0x831E2BC4; continue 'dispatch;
	// 831E2BB0: 817F0014  lwz r11, 0x14(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E2BB4: 815F0018  lwz r10, 0x18(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) } as u64;
	// 831E2BB8: 7D2BF214  add r9, r11, r30
	ctx.r[9].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 831E2BBC: 7C6A5A14  add r3, r10, r11
	ctx.r[3].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831E2BC0: 913F0014  stw r9, 0x14(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), ctx.r[9].u32 ) };
	// 831E2BC4: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E2BC8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E2BCC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E2BD0: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831E2BD4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E2BD8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E2BE0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E2BE0 size=124
    let mut pc: u32 = 0x831E2BE0;
    'dispatch: loop {
        match pc {
            0x831E2BE0 => {
    //   block [0x831E2BE0..0x831E2C5C)
	// 831E2BE0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E2BE4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E2BE8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831E2BEC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E2BF0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E2BF4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E2BF8: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E2BFC: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831E2C00: 392B0284  addi r9, r11, 0x284
	ctx.r[9].s64 = ctx.r[11].s64 + 644;
	// 831E2C04: 390A0248  addi r8, r10, 0x248
	ctx.r[8].s64 = ctx.r[10].s64 + 584;
	// 831E2C08: 809F0018  lwz r4, 0x18(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) } as u64;
	// 831E2C0C: 3BDF0004  addi r30, r31, 4
	ctx.r[30].s64 = ctx.r[31].s64 + 4;
	// 831E2C10: 913F0000  stw r9, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831E2C14: 911F0004  stw r8, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[8].u32 ) };
	// 831E2C18: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 831E2C1C: 419A001C  beq cr6, 0x831e2c38
	if ctx.cr[6].eq {
	pc = 0x831E2C38; continue 'dispatch;
	}
	// 831E2C20: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E2C24: 80BF000C  lwz r5, 0xc(r31)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E2C28: 386BD5A4  addi r3, r11, -0x2a5c
	ctx.r[3].s64 = ctx.r[11].s64 + -10844;
	// 831E2C2C: 4BFF9A95  bl 0x831dc6c0
	ctx.lr = 0x831E2C30;
	sub_831DC6C0(ctx, base);
	// 831E2C30: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E2C34: 915F0018  stw r10, 0x18(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), ctx.r[10].u32 ) };
	// 831E2C38: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E2C3C: 394BFF64  addi r10, r11, -0x9c
	ctx.r[10].s64 = ctx.r[11].s64 + -156;
	// 831E2C40: 915E0000  stw r10, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E2C44: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E2C48: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E2C4C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E2C50: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831E2C54: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E2C58: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E2C60(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E2C60 size=8
    let mut pc: u32 = 0x831E2C60;
    'dispatch: loop {
        match pc {
            0x831E2C60 => {
    //   block [0x831E2C60..0x831E2C68)
	// 831E2C60: 3863FFFC  addi r3, r3, -4
	ctx.r[3].s64 = ctx.r[3].s64 + -4;
	// 831E2C64: 4800008C  b 0x831e2cf0
	sub_831E2CF0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E2C68(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E2C68 size=16
    let mut pc: u32 = 0x831E2C68;
    'dispatch: loop {
        match pc {
            0x831E2C68 => {
    //   block [0x831E2C68..0x831E2C78)
	// 831E2C68: 81630010  lwz r11, 0x10(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E2C6C: 81430014  lwz r10, 0x14(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E2C70: 7C6A5850  subf r3, r10, r11
	ctx.r[3].s64 = ctx.r[11].s64 - ctx.r[10].s64;
	// 831E2C74: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E2C78(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E2C78 size=8
    let mut pc: u32 = 0x831E2C78;
    'dispatch: loop {
        match pc {
            0x831E2C78 => {
    //   block [0x831E2C78..0x831E2C80)
	// 831E2C78: 3863FFFC  addi r3, r3, -4
	ctx.r[3].s64 = ctx.r[3].s64 + -4;
	// 831E2C7C: 480000D4  b 0x831e2d50
	sub_831E2D50(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E2C80(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E2C80 size=8
    let mut pc: u32 = 0x831E2C80;
    'dispatch: loop {
        match pc {
            0x831E2C80 => {
    //   block [0x831E2C80..0x831E2C88)
	// 831E2C80: 3863FFFC  addi r3, r3, -4
	ctx.r[3].s64 = ctx.r[3].s64 + -4;
	// 831E2C84: 48000144  b 0x831e2dc8
	sub_831E2DC8(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E2C88(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E2C88 size=100
    let mut pc: u32 = 0x831E2C88;
    'dispatch: loop {
        match pc {
            0x831E2C88 => {
    //   block [0x831E2C88..0x831E2CEC)
	// 831E2C88: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E2C8C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E2C90: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831E2C94: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E2C98: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E2C9C: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E2CA0: 3BE3FFFC  addi r31, r3, -4
	ctx.r[31].s64 = ctx.r[3].s64 + -4;
	// 831E2CA4: 83C30008  lwz r30, 8(r3)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E2CA8: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 831E2CAC: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E2CB0: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E2CB4: 4E800421  bctrl
	ctx.lr = 0x831E2CB8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E2CB8: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 831E2CBC: 419A0018  beq cr6, 0x831e2cd4
	if ctx.cr[6].eq {
	pc = 0x831E2CD4; continue 'dispatch;
	}
	// 831E2CC0: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E2CC4: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 831E2CC8: 386BD5A4  addi r3, r11, -0x2a5c
	ctx.r[3].s64 = ctx.r[11].s64 + -10844;
	// 831E2CCC: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831E2CD0: 4BFF99F1  bl 0x831dc6c0
	ctx.lr = 0x831E2CD4;
	sub_831DC6C0(ctx, base);
	// 831E2CD4: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E2CD8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E2CDC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E2CE0: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831E2CE4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E2CE8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E2CF0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E2CF0 size=92
    let mut pc: u32 = 0x831E2CF0;
    'dispatch: loop {
        match pc {
            0x831E2CF0 => {
    //   block [0x831E2CF0..0x831E2D4C)
	// 831E2CF0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E2CF4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E2CF8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831E2CFC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E2D00: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E2D04: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E2D08: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 831E2D0C: 4BFFFED5  bl 0x831e2be0
	ctx.lr = 0x831E2D10;
	sub_831E2BE0(ctx, base);
	// 831E2D10: 57CB07FE  clrlwi r11, r30, 0x1f
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0x00000001u64;
	// 831E2D14: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E2D18: 419A0018  beq cr6, 0x831e2d30
	if ctx.cr[6].eq {
	pc = 0x831E2D30; continue 'dispatch;
	}
	// 831E2D1C: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E2D20: 3CA06182  lis r5, 0x6182
	ctx.r[5].s64 = 1635909632;
	// 831E2D24: 386BD5A4  addi r3, r11, -0x2a5c
	ctx.r[3].s64 = ctx.r[11].s64 + -10844;
	// 831E2D28: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831E2D2C: 4BFF9995  bl 0x831dc6c0
	ctx.lr = 0x831E2D30;
	sub_831DC6C0(ctx, base);
	// 831E2D30: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E2D34: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E2D38: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E2D3C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E2D40: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831E2D44: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E2D48: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E2D50(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E2D50 size=116
    let mut pc: u32 = 0x831E2D50;
    'dispatch: loop {
        match pc {
            0x831E2D50 => {
    //   block [0x831E2D50..0x831E2DC4)
	// 831E2D50: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E2D54: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E2D58: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831E2D5C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E2D60: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E2D64: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E2D68: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E2D6C: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831E2D70: 392B0284  addi r9, r11, 0x284
	ctx.r[9].s64 = ctx.r[11].s64 + 644;
	// 831E2D74: 390A025C  addi r8, r10, 0x25c
	ctx.r[8].s64 = ctx.r[10].s64 + 604;
	// 831E2D78: 913F0000  stw r9, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831E2D7C: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 831E2D80: 911F0004  stw r8, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[8].u32 ) };
	// 831E2D84: 4BFFFE5D  bl 0x831e2be0
	ctx.lr = 0x831E2D88;
	sub_831E2BE0(ctx, base);
	// 831E2D88: 57C707FE  clrlwi r7, r30, 0x1f
	ctx.r[7].u64 = ctx.r[30].u32 as u64 & 0x00000001u64;
	// 831E2D8C: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 831E2D90: 419A0018  beq cr6, 0x831e2da8
	if ctx.cr[6].eq {
	pc = 0x831E2DA8; continue 'dispatch;
	}
	// 831E2D94: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E2D98: 38A00001  li r5, 1
	ctx.r[5].s64 = 1;
	// 831E2D9C: 386BD5A4  addi r3, r11, -0x2a5c
	ctx.r[3].s64 = ctx.r[11].s64 + -10844;
	// 831E2DA0: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831E2DA4: 4BFF991D  bl 0x831dc6c0
	ctx.lr = 0x831E2DA8;
	sub_831DC6C0(ctx, base);
	// 831E2DA8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E2DAC: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E2DB0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E2DB4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E2DB8: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831E2DBC: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E2DC0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E2DC8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E2DC8 size=80
    let mut pc: u32 = 0x831E2DC8;
    'dispatch: loop {
        match pc {
            0x831E2DC8 => {
    //   block [0x831E2DC8..0x831E2E18)
	// 831E2DC8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E2DCC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E2DD0: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E2DD4: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E2DD8: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E2DDC: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E2DE0: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831E2DE4: 392B0284  addi r9, r11, 0x284
	ctx.r[9].s64 = ctx.r[11].s64 + 644;
	// 831E2DE8: 390A0270  addi r8, r10, 0x270
	ctx.r[8].s64 = ctx.r[10].s64 + 624;
	// 831E2DEC: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 831E2DF0: 913F0000  stw r9, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831E2DF4: 911F0004  stw r8, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[8].u32 ) };
	// 831E2DF8: 90FF0018  stw r7, 0x18(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), ctx.r[7].u32 ) };
	// 831E2DFC: 4BFFFDE5  bl 0x831e2be0
	ctx.lr = 0x831E2E00;
	sub_831E2BE0(ctx, base);
	// 831E2E00: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E2E04: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831E2E08: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E2E0C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E2E10: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E2E14: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E2E18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E2E18 size=176
    let mut pc: u32 = 0x831E2E18;
    'dispatch: loop {
        match pc {
            0x831E2E18 => {
    //   block [0x831E2E18..0x831E2EC8)
	// 831E2E18: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E2E1C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E2E20: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E2E24: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E2E28: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E2E2C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E2E30: 38A00001  li r5, 1
	ctx.r[5].s64 = 1;
	// 831E2E34: 386BD5A4  addi r3, r11, -0x2a5c
	ctx.r[3].s64 = ctx.r[11].s64 + -10844;
	// 831E2E38: 3880001C  li r4, 0x1c
	ctx.r[4].s64 = 28;
	// 831E2E3C: 4BFF9875  bl 0x831dc6b0
	ctx.lr = 0x831E2E40;
	sub_831DC6B0(ctx, base);
	// 831E2E40: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 831E2E44: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E2E48: 419A0064  beq cr6, 0x831e2eac
	if ctx.cr[6].eq {
	pc = 0x831E2EAC; continue 'dispatch;
	}
	// 831E2E4C: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831E2E50: 3D20821A  lis r9, -0x7de6
	ctx.r[9].s64 = -2112225280;
	// 831E2E54: 3D00821A  lis r8, -0x7de6
	ctx.r[8].s64 = -2112225280;
	// 831E2E58: 38EAFF64  addi r7, r10, -0x9c
	ctx.r[7].s64 = ctx.r[10].s64 + -156;
	// 831E2E5C: 38C00001  li r6, 1
	ctx.r[6].s64 = 1;
	// 831E2E60: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E2E64: 90EB0004  stw r7, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[7].u32 ) };
	// 831E2E68: 38A90284  addi r5, r9, 0x284
	ctx.r[5].s64 = ctx.r[9].s64 + 644;
	// 831E2E6C: 90CB0008  stw r6, 8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[6].u32 ) };
	// 831E2E70: 3888025C  addi r4, r8, 0x25c
	ctx.r[4].s64 = ctx.r[8].s64 + 604;
	// 831E2E74: 914B000C  stw r10, 0xc(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[10].u32 ) };
	// 831E2E78: 914B0010  stw r10, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[10].u32 ) };
	// 831E2E7C: 392B0004  addi r9, r11, 4
	ctx.r[9].s64 = ctx.r[11].s64 + 4;
	// 831E2E80: 914B0014  stw r10, 0x14(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), ctx.r[10].u32 ) };
	// 831E2E84: 7D435378  mr r3, r10
	ctx.r[3].u64 = ctx.r[10].u64;
	// 831E2E88: 914B0018  stw r10, 0x18(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), ctx.r[10].u32 ) };
	// 831E2E8C: 90AB0000  stw r5, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[5].u32 ) };
	// 831E2E90: 908B0004  stw r4, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[4].u32 ) };
	// 831E2E94: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831E2E98: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831E2E9C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E2EA0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E2EA4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E2EA8: 4E800020  blr
	return;
	// 831E2EAC: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 831E2EB0: 6063000E  ori r3, r3, 0xe
	ctx.r[3].u64 = ctx.r[3].u64 | 14;
	// 831E2EB4: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831E2EB8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E2EBC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E2EC0: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E2EC4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E2EC8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E2EC8 size=156
    let mut pc: u32 = 0x831E2EC8;
    'dispatch: loop {
        match pc {
            0x831E2EC8 => {
    //   block [0x831E2EC8..0x831E2F64)
	// 831E2EC8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E2ECC: 4BFC52A1  bl 0x831a816c
	ctx.lr = 0x831E2ED0;
	sub_831A8130(ctx, base);
	// 831E2ED0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E2ED4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E2ED8: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 831E2EDC: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E2EE0: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 831E2EE4: 7FE5FB78  mr r5, r31
	ctx.r[5].u64 = ctx.r[31].u64;
	// 831E2EE8: 386BD5A4  addi r3, r11, -0x2a5c
	ctx.r[3].s64 = ctx.r[11].s64 + -10844;
	// 831E2EEC: 389E001C  addi r4, r30, 0x1c
	ctx.r[4].s64 = ctx.r[30].s64 + 28;
	// 831E2EF0: 4BFF97C1  bl 0x831dc6b0
	ctx.lr = 0x831E2EF4;
	sub_831DC6B0(ctx, base);
	// 831E2EF4: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 831E2EF8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E2EFC: 409A0014  bne cr6, 0x831e2f10
	if !ctx.cr[6].eq {
	pc = 0x831E2F10; continue 'dispatch;
	}
	// 831E2F00: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 831E2F04: 6063000E  ori r3, r3, 0xe
	ctx.r[3].u64 = ctx.r[3].u64 | 14;
	// 831E2F08: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E2F0C: 4BFC52B0  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 831E2F10: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831E2F14: 3D20821A  lis r9, -0x7de6
	ctx.r[9].s64 = -2112225280;
	// 831E2F18: 3D00821A  lis r8, -0x7de6
	ctx.r[8].s64 = -2112225280;
	// 831E2F1C: 38EAFF64  addi r7, r10, -0x9c
	ctx.r[7].s64 = ctx.r[10].s64 + -156;
	// 831E2F20: 38A90284  addi r5, r9, 0x284
	ctx.r[5].s64 = ctx.r[9].s64 + 644;
	// 831E2F24: 38C00001  li r6, 1
	ctx.r[6].s64 = 1;
	// 831E2F28: 90EB0004  stw r7, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[7].u32 ) };
	// 831E2F2C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E2F30: 38880270  addi r4, r8, 0x270
	ctx.r[4].s64 = ctx.r[8].s64 + 624;
	// 831E2F34: 90CB0008  stw r6, 8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[6].u32 ) };
	// 831E2F38: 392B001C  addi r9, r11, 0x1c
	ctx.r[9].s64 = ctx.r[11].s64 + 28;
	// 831E2F3C: 906B0014  stw r3, 0x14(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), ctx.r[3].u32 ) };
	// 831E2F40: 90AB0000  stw r5, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[5].u32 ) };
	// 831E2F44: 394B0004  addi r10, r11, 4
	ctx.r[10].s64 = ctx.r[11].s64 + 4;
	// 831E2F48: 908B0004  stw r4, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[4].u32 ) };
	// 831E2F4C: 93EB000C  stw r31, 0xc(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[31].u32 ) };
	// 831E2F50: 93CB0010  stw r30, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[30].u32 ) };
	// 831E2F54: 912B0018  stw r9, 0x18(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), ctx.r[9].u32 ) };
	// 831E2F58: 917D0000  stw r11, 0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831E2F5C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E2F60: 4BFC525C  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E2F68(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E2F68 size=172
    let mut pc: u32 = 0x831E2F68;
    'dispatch: loop {
        match pc {
            0x831E2F68 => {
    //   block [0x831E2F68..0x831E3014)
	// 831E2F68: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E2F6C: 4BFC51FD  bl 0x831a8168
	ctx.lr = 0x831E2F70;
	sub_831A8130(ctx, base);
	// 831E2F70: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E2F74: 7CBC2B78  mr r28, r5
	ctx.r[28].u64 = ctx.r[5].u64;
	// 831E2F78: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831E2F7C: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 831E2F80: 83FC0000  lwz r31, 0(r28)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E2F84: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 831E2F88: 409A0040  bne cr6, 0x831e2fc8
	if !ctx.cr[6].eq {
	pc = 0x831E2FC8; continue 'dispatch;
	}
	// 831E2F8C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E2F90: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 831E2F94: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 831E2F98: 419A0010  beq cr6, 0x831e2fa8
	if ctx.cr[6].eq {
	pc = 0x831E2FA8; continue 'dispatch;
	}
	// 831E2F9C: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 831E2FA0: 4BFFFF29  bl 0x831e2ec8
	ctx.lr = 0x831E2FA4;
	sub_831E2EC8(ctx, base);
	// 831E2FA4: 4800000C  b 0x831e2fb0
	pc = 0x831E2FB0; continue 'dispatch;
	// 831E2FA8: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 831E2FAC: 4BFFFE6D  bl 0x831e2e18
	ctx.lr = 0x831E2FB0;
	sub_831E2E18(ctx, base);
	// 831E2FB0: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E2FB4: 41980058  blt cr6, 0x831e300c
	if ctx.cr[6].lt {
	pc = 0x831E300C; continue 'dispatch;
	}
	// 831E2FB8: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831E2FBC: 917C0000  stw r11, 0(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831E2FC0: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E2FC4: 4BFC51F4  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
	// 831E2FC8: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E2FCC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E2FD0: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E2FD4: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E2FD8: 4E800421  bctrl
	ctx.lr = 0x831E2FDC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E2FDC: 813F0000  lwz r9, 0(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E2FE0: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 831E2FE4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E2FE8: 81090008  lwz r8, 8(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E2FEC: 7D0903A6  mtctr r8
	ctx.ctr.u64 = ctx.r[8].u64;
	// 831E2FF0: 4E800421  bctrl
	ctx.lr = 0x831E2FF4;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E2FF4: 80FF0000  lwz r7, 0(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E2FF8: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 831E2FFC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E3000: 80C7000C  lwz r6, 0xc(r7)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E3004: 7CC903A6  mtctr r6
	ctx.ctr.u64 = ctx.r[6].u64;
	// 831E3008: 4E800421  bctrl
	ctx.lr = 0x831E300C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E300C: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E3010: 4BFC51A8  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E3018(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E3018 size=60
    let mut pc: u32 = 0x831E3018;
    'dispatch: loop {
        match pc {
            0x831E3018 => {
    //   block [0x831E3018..0x831E3054)
	// 831E3018: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E301C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E3020: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E3024: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E3028: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E302C: 48000D65  bl 0x831e3d90
	ctx.lr = 0x831E3030;
	sub_831E3D90(ctx, base);
	// 831E3030: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E3034: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E3038: 394B02A0  addi r10, r11, 0x2a0
	ctx.r[10].s64 = ctx.r[11].s64 + 672;
	// 831E303C: 915F0000  stw r10, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E3040: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831E3044: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E3048: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E304C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E3050: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E3058(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E3058 size=80
    let mut pc: u32 = 0x831E3058;
    'dispatch: loop {
        match pc {
            0x831E3058 => {
    //   block [0x831E3058..0x831E30A8)
	// 831E3058: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E305C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E3060: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831E3064: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E3068: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E306C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E3070: 7CBE2B78  mr r30, r5
	ctx.r[30].u64 = ctx.r[5].u64;
	// 831E3074: 480009B5  bl 0x831e3a28
	ctx.lr = 0x831E3078;
	sub_831E3A28(ctx, base);
	// 831E3078: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E307C: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 831E3080: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E3084: 814B0024  lwz r10, 0x24(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) } as u64;
	// 831E3088: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E308C: 4E800421  bctrl
	ctx.lr = 0x831E3090;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E3090: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E3094: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E3098: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E309C: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831E30A0: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E30A4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E30A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E30A8 size=180
    let mut pc: u32 = 0x831E30A8;
    'dispatch: loop {
        match pc {
            0x831E30A8 => {
    //   block [0x831E30A8..0x831E315C)
	// 831E30A8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E30AC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E30B0: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831E30B4: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E30B8: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E30BC: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 831E30C0: 38810054  addi r4, r1, 0x54
	ctx.r[4].s64 = ctx.r[1].s64 + 84;
	// 831E30C4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E30C8: 48000979  bl 0x831e3a40
	ctx.lr = 0x831E30CC;
	sub_831E3A40(ctx, base);
	// 831E30CC: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E30D0: 41980074  blt cr6, 0x831e3144
	if ctx.cr[6].lt {
	pc = 0x831E3144; continue 'dispatch;
	}
	// 831E30D4: 39410060  addi r10, r1, 0x60
	ctx.r[10].s64 = ctx.r[1].s64 + 96;
	// 831E30D8: 893F0019  lbz r9, 0x19(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(25 as u32) ) } as u64;
	// 831E30DC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E30E0: 39000001  li r8, 1
	ctx.r[8].s64 = 1;
	// 831E30E4: 3CE08343  lis r7, -0x7cbd
	ctx.r[7].s64 = -2092761088;
	// 831E30E8: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 831E30EC: F96A0000  std r11, 0(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[11].u64 ) };
	// 831E30F0: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 831E30F4: F96A0008  std r11, 8(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), ctx.r[11].u64 ) };
	// 831E30F8: 91610064  stw r11, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[11].u32 ) };
	// 831E30FC: 99610069  stb r11, 0x69(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(105 as u32), ctx.r[11].u8 ) };
	// 831E3100: 99210068  stb r9, 0x68(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[9].u8 ) };
	// 831E3104: 99010060  stb r8, 0x60(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[8].u8 ) };
	// 831E3108: 8167D59C  lwz r11, -0x2a64(r7)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(-10852 as u32) ) } as u64;
	// 831E310C: 806B003C  lwz r3, 0x3c(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(60 as u32) ) } as u64;
	// 831E3110: 4BFF7F61  bl 0x831db070
	ctx.lr = 0x831E3114;
	sub_831DB070(ctx, base);
	// 831E3114: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E3118: 4198002C  blt cr6, 0x831e3144
	if ctx.cr[6].lt {
	pc = 0x831E3144; continue 'dispatch;
	}
	// 831E311C: 897F0018  lbz r11, 0x18(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) } as u64;
	// 831E3120: 81410050  lwz r10, 0x50(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831E3124: 5569083E  rotlwi r9, r11, 1
	ctx.r[9].u64 = ((ctx.r[11].u32).rotate_left(1)) as u64;
	// 831E3128: 81010054  lwz r8, 0x54(r1)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 831E312C: 7D4B51D6  mullw r10, r11, r10
	ctx.r[10].s64 = (ctx.r[11].s32 as i64) * (ctx.r[10].s32 as i64);
	// 831E3130: 7CEB4A14  add r7, r11, r9
	ctx.r[7].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 831E3134: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 831E3138: 54EB103A  slwi r11, r7, 2
	ctx.r[11].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831E313C: 7CCB5214  add r6, r11, r10
	ctx.r[6].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831E3140: 90DE0000  stw r6, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[6].u32 ) };
	// 831E3144: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831E3148: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E314C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E3150: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831E3154: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E3158: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E3160(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E3160 size=276
    let mut pc: u32 = 0x831E3160;
    'dispatch: loop {
        match pc {
            0x831E3160 => {
    //   block [0x831E3160..0x831E3274)
	// 831E3160: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E3164: 4BFC5005  bl 0x831a8168
	ctx.lr = 0x831E3168;
	sub_831A8130(ctx, base);
	// 831E3168: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E316C: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 831E3170: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E3174: 897C0018  lbz r11, 0x18(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(24 as u32) ) } as u64;
	// 831E3178: 997F0044  stb r11, 0x44(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), ctx.r[11].u8 ) };
	// 831E317C: 4800148D  bl 0x831e4608
	ctx.lr = 0x831E3180;
	sub_831E4608(ctx, base);
	// 831E3180: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E3184: 419800D8  blt cr6, 0x831e325c
	if ctx.cr[6].lt {
	pc = 0x831E325C; continue 'dispatch;
	}
	// 831E3188: 897F0044  lbz r11, 0x44(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(68 as u32) ) } as u64;
	// 831E318C: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 831E3190: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E3194: 419A0034  beq cr6, 0x831e31c8
	if ctx.cr[6].eq {
	pc = 0x831E31C8; continue 'dispatch;
	}
	// 831E3198: 807F0008  lwz r3, 8(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E319C: 556A083C  slwi r10, r11, 1
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831E31A0: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831E31A4: 5564103A  slwi r4, r11, 2
	ctx.r[4].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 831E31A8: 81430000  lwz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E31AC: 812A0014  lwz r9, 0x14(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E31B0: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 831E31B4: 4E800421  bctrl
	ctx.lr = 0x831E31B8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E31B8: 907F0048  stw r3, 0x48(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(72 as u32), ctx.r[3].u32 ) };
	// 831E31BC: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E31C0: 419A00A4  beq cr6, 0x831e3264
	if ctx.cr[6].eq {
	pc = 0x831E3264; continue 'dispatch;
	}
	// 831E31C4: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E31C8: 897F0044  lbz r11, 0x44(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(68 as u32) ) } as u64;
	// 831E31CC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E31D0: 419A006C  beq cr6, 0x831e323c
	if ctx.cr[6].eq {
	pc = 0x831E323C; continue 'dispatch;
	}
	// 831E31D4: 39410050  addi r10, r1, 0x50
	ctx.r[10].s64 = ctx.r[1].s64 + 80;
	// 831E31D8: 893C0019  lbz r9, 0x19(r28)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(25 as u32) ) } as u64;
	// 831E31DC: 39000001  li r8, 1
	ctx.r[8].s64 = 1;
	// 831E31E0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E31E4: FBCA0000  std r30, 0(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[30].u64 ) };
	// 831E31E8: FBCA0008  std r30, 8(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), ctx.r[30].u64 ) };
	// 831E31EC: 99210058  stb r9, 0x58(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[9].u8 ) };
	// 831E31F0: 99010050  stb r8, 0x50(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[8].u8 ) };
	// 831E31F4: 93E10054  stw r31, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[31].u32 ) };
	// 831E31F8: 9BC10059  stb r30, 0x59(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(89 as u32), ctx.r[30].u8 ) };
	// 831E31FC: 419A0040  beq cr6, 0x831e323c
	if ctx.cr[6].eq {
	pc = 0x831E323C; continue 'dispatch;
	}
	// 831E3200: 7FDDF378  mr r29, r30
	ctx.r[29].u64 = ctx.r[30].u64;
	// 831E3204: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E3208: 41980054  blt cr6, 0x831e325c
	if ctx.cr[6].lt {
	pc = 0x831E325C; continue 'dispatch;
	}
	// 831E320C: 817F0048  lwz r11, 0x48(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(72 as u32) ) } as u64;
	// 831E3210: 38C000FF  li r6, 0xff
	ctx.r[6].s64 = 255;
	// 831E3214: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 831E3218: 7D6BEA14  add r11, r11, r29
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 831E321C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E3220: 388B0004  addi r4, r11, 4
	ctx.r[4].s64 = ctx.r[11].s64 + 4;
	// 831E3224: 480009D5  bl 0x831e3bf8
	ctx.lr = 0x831E3228;
	sub_831E3BF8(ctx, base);
	// 831E3228: 897F0044  lbz r11, 0x44(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(68 as u32) ) } as u64;
	// 831E322C: 3BDE0001  addi r30, r30, 1
	ctx.r[30].s64 = ctx.r[30].s64 + 1;
	// 831E3230: 3BBD000C  addi r29, r29, 0xc
	ctx.r[29].s64 = ctx.r[29].s64 + 12;
	// 831E3234: 7F1E5840  cmplw cr6, r30, r11
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831E3238: 4198FFCC  blt cr6, 0x831e3204
	if ctx.cr[6].lt {
	pc = 0x831E3204; continue 'dispatch;
	}
	// 831E323C: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E3240: 4198001C  blt cr6, 0x831e325c
	if ctx.cr[6].lt {
	pc = 0x831E325C; continue 'dispatch;
	}
	// 831E3244: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E3248: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E324C: 809C001C  lwz r4, 0x1c(r28)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(28 as u32) ) } as u64;
	// 831E3250: 814B0024  lwz r10, 0x24(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) } as u64;
	// 831E3254: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E3258: 4E800421  bctrl
	ctx.lr = 0x831E325C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E325C: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831E3260: 4BFC4F58  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
	// 831E3264: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 831E3268: 6063000E  ori r3, r3, 0xe
	ctx.r[3].u64 = ctx.r[3].u64 | 14;
	// 831E326C: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831E3270: 4BFC4F48  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E3278(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E3278 size=192
    let mut pc: u32 = 0x831E3278;
    'dispatch: loop {
        match pc {
            0x831E3278 => {
    //   block [0x831E3278..0x831E3338)
	// 831E3278: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E327C: 4BFC4EF1  bl 0x831a816c
	ctx.lr = 0x831E3280;
	sub_831A8130(ctx, base);
	// 831E3280: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E3284: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 831E3288: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831E328C: 7CBE2B78  mr r30, r5
	ctx.r[30].u64 = ctx.r[5].u64;
	// 831E3290: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 831E3294: 409A000C  bne cr6, 0x831e32a0
	if !ctx.cr[6].eq {
	pc = 0x831E32A0; continue 'dispatch;
	}
	// 831E3298: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 831E329C: 3BEB0628  addi r31, r11, 0x628
	ctx.r[31].s64 = ctx.r[11].s64 + 1576;
	// 831E32A0: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E32A4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E32A8: 419A000C  beq cr6, 0x831e32b4
	if ctx.cr[6].eq {
	pc = 0x831E32B4; continue 'dispatch;
	}
	// 831E32AC: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831E32B0: 48000014  b 0x831e32c4
	pc = 0x831E32C4; continue 'dispatch;
	// 831E32B4: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E32B8: 816BD59C  lwz r11, -0x2a64(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-10852 as u32) ) } as u64;
	// 831E32BC: 814B0040  lwz r10, 0x40(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(64 as u32) ) } as u64;
	// 831E32C0: 915E0000  stw r10, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E32C4: 807E0000  lwz r3, 0(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E32C8: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E32CC: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E32D0: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E32D4: 4E800421  bctrl
	ctx.lr = 0x831E32D8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E32D8: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E32DC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E32E0: 409A0038  bne cr6, 0x831e3318
	if !ctx.cr[6].eq {
	pc = 0x831E3318; continue 'dispatch;
	}
	// 831E32E4: 807E0000  lwz r3, 0(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E32E8: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831E32EC: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E32F0: 814B0040  lwz r10, 0x40(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(64 as u32) ) } as u64;
	// 831E32F4: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E32F8: 4E800421  bctrl
	ctx.lr = 0x831E32FC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E32FC: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E3300: 41980030  blt cr6, 0x831e3330
	if ctx.cr[6].lt {
	pc = 0x831E3330; continue 'dispatch;
	}
	// 831E3304: 38A10058  addi r5, r1, 0x58
	ctx.r[5].s64 = ctx.r[1].s64 + 88;
	// 831E3308: 88810051  lbz r4, 0x51(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(81 as u32) ) } as u64;
	// 831E330C: 887D0035  lbz r3, 0x35(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(53 as u32) ) } as u64;
	// 831E3310: 4BFF50A1  bl 0x831d83b0
	ctx.lr = 0x831E3314;
	sub_831D83B0(ctx, base);
	// 831E3314: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 831E3318: 807E0004  lwz r3, 4(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E331C: 7D645B78  mr r4, r11
	ctx.r[4].u64 = ctx.r[11].u64;
	// 831E3320: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E3324: 814B0028  lwz r10, 0x28(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(40 as u32) ) } as u64;
	// 831E3328: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E332C: 4E800421  bctrl
	ctx.lr = 0x831E3330;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E3330: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E3334: 4BFC4E88  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E3338(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E3338 size=96
    let mut pc: u32 = 0x831E3338;
    'dispatch: loop {
        match pc {
            0x831E3338 => {
    //   block [0x831E3338..0x831E3398)
	// 831E3338: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E333C: 4BFC4E2D  bl 0x831a8168
	ctx.lr = 0x831E3340;
	sub_831A8130(ctx, base);
	// 831E3340: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E3344: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831E3348: 3B800000  li r28, 0
	ctx.r[28].s64 = 0;
	// 831E334C: 7F9DE378  mr r29, r28
	ctx.r[29].u64 = ctx.r[28].u64;
	// 831E3350: 897E0045  lbz r11, 0x45(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(69 as u32) ) } as u64;
	// 831E3354: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E3358: 419A0034  beq cr6, 0x831e338c
	if ctx.cr[6].eq {
	pc = 0x831E338C; continue 'dispatch;
	}
	// 831E335C: 7F9FE378  mr r31, r28
	ctx.r[31].u64 = ctx.r[28].u64;
	// 831E3360: 817E0048  lwz r11, 0x48(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(72 as u32) ) } as u64;
	// 831E3364: 7C6BF82E  lwzx r3, r11, r31
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[31].u32)) } as u64;
	// 831E3368: 81430000  lwz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E336C: 812A0008  lwz r9, 8(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E3370: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 831E3374: 4E800421  bctrl
	ctx.lr = 0x831E3378;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E3378: 891E0045  lbz r8, 0x45(r30)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(69 as u32) ) } as u64;
	// 831E337C: 3BBD0001  addi r29, r29, 1
	ctx.r[29].s64 = ctx.r[29].s64 + 1;
	// 831E3380: 3BFF000C  addi r31, r31, 0xc
	ctx.r[31].s64 = ctx.r[31].s64 + 12;
	// 831E3384: 7F1D4040  cmplw cr6, r29, r8
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831E3388: 4198FFD8  blt cr6, 0x831e3360
	if ctx.cr[6].lt {
	pc = 0x831E3360; continue 'dispatch;
	}
	// 831E338C: 9B9E0045  stb r28, 0x45(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(69 as u32), ctx.r[28].u8 ) };
	// 831E3390: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E3394: 4BFC4E24  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E3398(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E3398 size=152
    let mut pc: u32 = 0x831E3398;
    'dispatch: loop {
        match pc {
            0x831E3398 => {
    //   block [0x831E3398..0x831E3430)
	// 831E3398: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E339C: 4BFC4DC9  bl 0x831a8164
	ctx.lr = 0x831E33A0;
	sub_831A8130(ctx, base);
	// 831E33A0: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E33A4: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E33A8: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 831E33AC: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 831E33B0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E33B4: 897C003D  lbz r11, 0x3d(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(61 as u32) ) } as u64;
	// 831E33B8: 895D0000  lbz r10, 0(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E33BC: 7D6958F8  nor r9, r11, r11
	ctx.r[9].u64 = !(ctx.r[11].u64 | ctx.r[11].u64);
	// 831E33C0: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E33C4: 553B07FE  clrlwi r27, r9, 0x1f
	ctx.r[27].u64 = ctx.r[9].u32 as u64 & 0x00000001u64;
	// 831E33C8: 419A0060  beq cr6, 0x831e3428
	if ctx.cr[6].eq {
	pc = 0x831E3428; continue 'dispatch;
	}
	// 831E33CC: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 831E33D0: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E33D4: 41980054  blt cr6, 0x831e3428
	if ctx.cr[6].lt {
	pc = 0x831E3428; continue 'dispatch;
	}
	// 831E33D8: 817D0004  lwz r11, 4(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E33DC: 7F65DB78  mr r5, r27
	ctx.r[5].u64 = ctx.r[27].u64;
	// 831E33E0: 813C0048  lwz r9, 0x48(r28)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(72 as u32) ) } as u64;
	// 831E33E4: 7D6BF214  add r11, r11, r30
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 831E33E8: 894B0000  lbz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E33EC: 808B0004  lwz r4, 4(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E33F0: 554B083E  rotlwi r11, r10, 1
	ctx.r[11].u64 = ((ctx.r[10].u32).rotate_left(1)) as u64;
	// 831E33F4: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831E33F8: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831E33FC: 7D4B4A14  add r10, r11, r9
	ctx.r[10].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 831E3400: 806A0004  lwz r3, 4(r10)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E3404: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E3408: 81090038  lwz r8, 0x38(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E340C: 7D0903A6  mtctr r8
	ctx.ctr.u64 = ctx.r[8].u64;
	// 831E3410: 4E800421  bctrl
	ctx.lr = 0x831E3414;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E3414: 88FD0000  lbz r7, 0(r29)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E3418: 3BFF0001  addi r31, r31, 1
	ctx.r[31].s64 = ctx.r[31].s64 + 1;
	// 831E341C: 3BDE0008  addi r30, r30, 8
	ctx.r[30].s64 = ctx.r[30].s64 + 8;
	// 831E3420: 7F1F3840  cmplw cr6, r31, r7
	ctx.cr[6].compare_u32(ctx.r[31].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831E3424: 4198FFAC  blt cr6, 0x831e33d0
	if ctx.cr[6].lt {
	pc = 0x831E33D0; continue 'dispatch;
	}
	// 831E3428: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E342C: 4BFC4D88  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E3430(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E3430 size=156
    let mut pc: u32 = 0x831E3430;
    'dispatch: loop {
        match pc {
            0x831E3430 => {
    //   block [0x831E3430..0x831E34CC)
	// 831E3430: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E3434: 4BFC4D35  bl 0x831a8168
	ctx.lr = 0x831E3438;
	sub_831A8130(ctx, base);
	// 831E3438: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E343C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E3440: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E3444: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 831E3448: 394B02A0  addi r10, r11, 0x2a0
	ctx.r[10].s64 = ctx.r[11].s64 + 672;
	// 831E344C: 915F0000  stw r10, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E3450: 48000DF9  bl 0x831e4248
	ctx.lr = 0x831E3454;
	sub_831E4248(ctx, base);
	// 831E3454: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E3458: 4BFFFEE1  bl 0x831e3338
	ctx.lr = 0x831E345C;
	sub_831E3338(ctx, base);
	// 831E345C: 893F0044  lbz r9, 0x44(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(68 as u32) ) } as u64;
	// 831E3460: 3B800000  li r28, 0
	ctx.r[28].s64 = 0;
	// 831E3464: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831E3468: 7F9DE378  mr r29, r28
	ctx.r[29].u64 = ctx.r[28].u64;
	// 831E346C: 419A0050  beq cr6, 0x831e34bc
	if ctx.cr[6].eq {
	pc = 0x831E34BC; continue 'dispatch;
	}
	// 831E3470: 7F9EE378  mr r30, r28
	ctx.r[30].u64 = ctx.r[28].u64;
	// 831E3474: 817F0048  lwz r11, 0x48(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(72 as u32) ) } as u64;
	// 831E3478: 7D6BF214  add r11, r11, r30
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 831E347C: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E3480: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E3484: 419A0024  beq cr6, 0x831e34a8
	if ctx.cr[6].eq {
	pc = 0x831E34A8; continue 'dispatch;
	}
	// 831E3488: 5543003E  slwi r3, r10, 0
	ctx.r[3].u32 = ctx.r[10].u32.wrapping_shl(0);
	ctx.r[3].u64 = ctx.r[3].u32 as u64;
	// 831E348C: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E3490: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E3494: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E3498: 4E800421  bctrl
	ctx.lr = 0x831E349C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E349C: 817F0048  lwz r11, 0x48(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(72 as u32) ) } as u64;
	// 831E34A0: 7D2BF214  add r9, r11, r30
	ctx.r[9].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 831E34A4: 93890004  stw r28, 4(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), ctx.r[28].u32 ) };
	// 831E34A8: 897F0044  lbz r11, 0x44(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(68 as u32) ) } as u64;
	// 831E34AC: 3BBD0001  addi r29, r29, 1
	ctx.r[29].s64 = ctx.r[29].s64 + 1;
	// 831E34B0: 3BDE000C  addi r30, r30, 0xc
	ctx.r[30].s64 = ctx.r[30].s64 + 12;
	// 831E34B4: 7F1D5840  cmplw cr6, r29, r11
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831E34B8: 4198FFBC  blt cr6, 0x831e3474
	if ctx.cr[6].lt {
	pc = 0x831E3474; continue 'dispatch;
	}
	// 831E34BC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E34C0: 48000669  bl 0x831e3b28
	ctx.lr = 0x831E34C4;
	sub_831E3B28(ctx, base);
	// 831E34C4: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E34C8: 4BFC4CF0  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E34D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E34D0 size=200
    let mut pc: u32 = 0x831E34D0;
    'dispatch: loop {
        match pc {
            0x831E34D0 => {
    //   block [0x831E34D0..0x831E3598)
	// 831E34D0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E34D4: 4BFC4C8D  bl 0x831a8160
	ctx.lr = 0x831E34D8;
	sub_831A8130(ctx, base);
	// 831E34D8: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E34DC: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E34E0: 7C9B2378  mr r27, r4
	ctx.r[27].u64 = ctx.r[4].u64;
	// 831E34E4: 3B400000  li r26, 0
	ctx.r[26].s64 = 0;
	// 831E34E8: 4BFFFE51  bl 0x831e3338
	ctx.lr = 0x831E34EC;
	sub_831E3338(ctx, base);
	// 831E34EC: 2B1B0000  cmplwi cr6, r27, 0
	ctx.cr[6].compare_u32(ctx.r[27].u32, 0 as u32, &mut ctx.xer);
	// 831E34F0: 419A0074  beq cr6, 0x831e3564
	if ctx.cr[6].eq {
	pc = 0x831E3564; continue 'dispatch;
	}
	// 831E34F4: 897B0000  lbz r11, 0(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E34F8: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 831E34FC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E3500: 419A0050  beq cr6, 0x831e3550
	if ctx.cr[6].eq {
	pc = 0x831E3550; continue 'dispatch;
	}
	// 831E3504: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 831E3508: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 831E350C: 2F1A0000  cmpwi cr6, r26, 0
	ctx.cr[6].compare_i32(ctx.r[26].s32, 0, &mut ctx.xer);
	// 831E3510: 41980048  blt cr6, 0x831e3558
	if ctx.cr[6].lt {
	pc = 0x831E3558; continue 'dispatch;
	}
	// 831E3514: 815C0048  lwz r10, 0x48(r28)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(72 as u32) ) } as u64;
	// 831E3518: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 831E351C: 817B0004  lwz r11, 4(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E3520: 7CAAFA14  add r5, r10, r31
	ctx.r[5].u64 = ctx.r[10].u64 + ctx.r[31].u64;
	// 831E3524: 7C8BF214  add r4, r11, r30
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 831E3528: 4BFFFD51  bl 0x831e3278
	ctx.lr = 0x831E352C;
	sub_831E3278(ctx, base);
	// 831E352C: 897B0000  lbz r11, 0(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E3530: 3BBD0001  addi r29, r29, 1
	ctx.r[29].s64 = ctx.r[29].s64 + 1;
	// 831E3534: 7C7A1B78  mr r26, r3
	ctx.r[26].u64 = ctx.r[3].u64;
	// 831E3538: 3BFF000C  addi r31, r31, 0xc
	ctx.r[31].s64 = ctx.r[31].s64 + 12;
	// 831E353C: 3BDE0008  addi r30, r30, 8
	ctx.r[30].s64 = ctx.r[30].s64 + 8;
	// 831E3540: 7F1D5840  cmplw cr6, r29, r11
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831E3544: 4198FFC8  blt cr6, 0x831e350c
	if ctx.cr[6].lt {
	pc = 0x831E350C; continue 'dispatch;
	}
	// 831E3548: 2F1A0000  cmpwi cr6, r26, 0
	ctx.cr[6].compare_i32(ctx.r[26].s32, 0, &mut ctx.xer);
	// 831E354C: 4198000C  blt cr6, 0x831e3558
	if ctx.cr[6].lt {
	pc = 0x831E3558; continue 'dispatch;
	}
	// 831E3550: 897B0000  lbz r11, 0(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E3554: 997C0045  stb r11, 0x45(r28)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[28].u32.wrapping_add(69 as u32), ctx.r[11].u8 ) };
	// 831E3558: 7F43D378  mr r3, r26
	ctx.r[3].u64 = ctx.r[26].u64;
	// 831E355C: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831E3560: 4BFC4C50  b 0x831a81b0
	sub_831A8180(ctx, base);
	return;
	// 831E3564: 897C0044  lbz r11, 0x44(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(68 as u32) ) } as u64;
	// 831E3568: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E356C: 419AFFEC  beq cr6, 0x831e3558
	if ctx.cr[6].eq {
	pc = 0x831E3558; continue 'dispatch;
	}
	// 831E3570: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831E3574: 80BC0048  lwz r5, 0x48(r28)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(72 as u32) ) } as u64;
	// 831E3578: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 831E357C: 4BFFFCFD  bl 0x831e3278
	ctx.lr = 0x831E3580;
	sub_831E3278(ctx, base);
	// 831E3580: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E3584: 4198FFD8  blt cr6, 0x831e355c
	if ctx.cr[6].lt {
	pc = 0x831E355C; continue 'dispatch;
	}
	// 831E3588: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 831E358C: 997C0045  stb r11, 0x45(r28)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[28].u32.wrapping_add(69 as u32), ctx.r[11].u8 ) };
	// 831E3590: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831E3594: 4BFC4C1C  b 0x831a81b0
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E3598(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E3598 size=144
    let mut pc: u32 = 0x831E3598;
    'dispatch: loop {
        match pc {
            0x831E3598 => {
    //   block [0x831E3598..0x831E3628)
	// 831E3598: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E359C: 4BFC4BCD  bl 0x831a8168
	ctx.lr = 0x831E35A0;
	sub_831A8130(ctx, base);
	// 831E35A0: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E35A4: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831E35A8: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 831E35AC: 48001195  bl 0x831e4740
	ctx.lr = 0x831E35B0;
	sub_831E4740(ctx, base);
	// 831E35B0: 897E0045  lbz r11, 0x45(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(69 as u32) ) } as u64;
	// 831E35B4: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 831E35B8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E35BC: 419A0064  beq cr6, 0x831e3620
	if ctx.cr[6].eq {
	pc = 0x831E3620; continue 'dispatch;
	}
	// 831E35C0: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 831E35C4: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E35C8: 41980058  blt cr6, 0x831e3620
	if ctx.cr[6].lt {
	pc = 0x831E3620; continue 'dispatch;
	}
	// 831E35CC: 817E0048  lwz r11, 0x48(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(72 as u32) ) } as u64;
	// 831E35D0: 7D4BF82E  lwzx r10, r11, r31
	ctx.r[10].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[31].u32)) } as u64;
	// 831E35D4: 7D435378  mr r3, r10
	ctx.r[3].u64 = ctx.r[10].u64;
	// 831E35D8: 812A0000  lwz r9, 0(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E35DC: 81090048  lwz r8, 0x48(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(72 as u32) ) } as u64;
	// 831E35E0: 7D0903A6  mtctr r8
	ctx.ctr.u64 = ctx.r[8].u64;
	// 831E35E4: 4E800421  bctrl
	ctx.lr = 0x831E35E8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E35E8: 817E0048  lwz r11, 0x48(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(72 as u32) ) } as u64;
	// 831E35EC: 7C651B78  mr r5, r3
	ctx.r[5].u64 = ctx.r[3].u64;
	// 831E35F0: 809C0000  lwz r4, 0(r28)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E35F4: 7CEBFA14  add r7, r11, r31
	ctx.r[7].u64 = ctx.r[11].u64 + ctx.r[31].u64;
	// 831E35F8: 80670004  lwz r3, 4(r7)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E35FC: 80C30000  lwz r6, 0(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E3600: 81660018  lwz r11, 0x18(r6)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(24 as u32) ) } as u64;
	// 831E3604: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 831E3608: 4E800421  bctrl
	ctx.lr = 0x831E360C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E360C: 895E0045  lbz r10, 0x45(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(69 as u32) ) } as u64;
	// 831E3610: 3BBD0001  addi r29, r29, 1
	ctx.r[29].s64 = ctx.r[29].s64 + 1;
	// 831E3614: 3BFF000C  addi r31, r31, 0xc
	ctx.r[31].s64 = ctx.r[31].s64 + 12;
	// 831E3618: 7F1D5040  cmplw cr6, r29, r10
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E361C: 4198FFA8  blt cr6, 0x831e35c4
	if ctx.cr[6].lt {
	pc = 0x831E35C4; continue 'dispatch;
	}
	// 831E3620: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E3624: 4BFC4B94  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E3628(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E3628 size=324
    let mut pc: u32 = 0x831E3628;
    'dispatch: loop {
        match pc {
            0x831E3628 => {
    //   block [0x831E3628..0x831E376C)
	// 831E3628: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E362C: 4BFC4B3D  bl 0x831a8168
	ctx.lr = 0x831E3630;
	sub_831A8130(ctx, base);
	// 831E3630: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E3634: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E3638: 4805FB25  bl 0x8324315c
	ctx.lr = 0x831E363C;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E363C: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E3640: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831E3644: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831E3648: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831E364C: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E3650: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831E3654: 419A0010  beq cr6, 0x831e3664
	if ctx.cr[6].eq {
	pc = 0x831E3664; continue 'dispatch;
	}
	// 831E3658: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E365C: 7F1E4040  cmplw cr6, r30, r8
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831E3660: 419A001C  beq cr6, 0x831e367c
	if ctx.cr[6].eq {
	pc = 0x831E367C; continue 'dispatch;
	}
	// 831E3664: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E3668: 4805F415  bl 0x83242a7c
	ctx.lr = 0x831E366C;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E366C: 7FC8F378  mr r8, r30
	ctx.r[8].u64 = ctx.r[30].u64;
	// 831E3670: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E3674: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831E3678: 911F0008  stw r8, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 831E367C: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 831E3680: 397C0018  addi r11, r28, 0x18
	ctx.r[11].s64 = ctx.r[28].s64 + 24;
	// 831E3684: 915F0004  stw r10, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831E3688: 813C0018  lwz r9, 0x18(r28)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(24 as u32) ) } as u64;
	// 831E368C: 7F095840  cmplw cr6, r9, r11
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831E3690: 419A0028  beq cr6, 0x831e36b8
	if ctx.cr[6].eq {
	pc = 0x831E36B8; continue 'dispatch;
	}
	// 831E3694: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E3698: 91490004  stw r10, 4(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831E369C: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E36A0: 810B0004  lwz r8, 4(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E36A4: 91280000  stw r9, 0(r8)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831E36A8: 916B0004  stw r11, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E36AC: 916B0000  stw r11, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831E36B0: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E36B4: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E36B8: 7DAB6B78  mr r11, r13
	ctx.r[11].u64 = ctx.r[13].u64;
	// 831E36BC: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831E36C0: 419A003C  beq cr6, 0x831e36fc
	if ctx.cr[6].eq {
	pc = 0x831E36FC; continue 'dispatch;
	}
	// 831E36C4: 7F0B4040  cmplw cr6, r11, r8
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831E36C8: 409A0034  bne cr6, 0x831e36fc
	if !ctx.cr[6].eq {
	pc = 0x831E36FC; continue 'dispatch;
	}
	// 831E36CC: 356AFFFF  addic. r11, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E36D0: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E36D4: 40820028  bne 0x831e36fc
	if !ctx.cr[0].eq {
	pc = 0x831E36FC; continue 'dispatch;
	}
	// 831E36D8: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E36DC: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E36E0: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E36E4: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E36E8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E36EC: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E36F0: 4805F37D  bl 0x83242a6c
	ctx.lr = 0x831E36F4;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E36F4: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E36F8: 4805FA75  bl 0x8324316c
	ctx.lr = 0x831E36FC;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E36FC: 897C0045  lbz r11, 0x45(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(69 as u32) ) } as u64;
	// 831E3700: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E3704: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 831E3708: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E370C: 419A0058  beq cr6, 0x831e3764
	if ctx.cr[6].eq {
	pc = 0x831E3764; continue 'dispatch;
	}
	// 831E3710: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 831E3714: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E3718: 4198004C  blt cr6, 0x831e3764
	if ctx.cr[6].lt {
	pc = 0x831E3764; continue 'dispatch;
	}
	// 831E371C: 817C0048  lwz r11, 0x48(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(72 as u32) ) } as u64;
	// 831E3720: 7C6BF82E  lwzx r3, r11, r31
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[31].u32)) } as u64;
	// 831E3724: 81430028  lwz r10, 0x28(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) } as u64;
	// 831E3728: 356AFFFF  addic. r11, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E372C: 91630028  stw r11, 0x28(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(40 as u32), ctx.r[11].u32 ) };
	// 831E3730: 4182000C  beq 0x831e373c
	if ctx.cr[0].eq {
	pc = 0x831E373C; continue 'dispatch;
	}
	// 831E3734: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E3738: 48000018  b 0x831e3750
	pc = 0x831E3750; continue 'dispatch;
	// 831E373C: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E3740: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831E3744: 814B003C  lwz r10, 0x3c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(60 as u32) ) } as u64;
	// 831E3748: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E374C: 4E800421  bctrl
	ctx.lr = 0x831E3750;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E3750: 897C0045  lbz r11, 0x45(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(69 as u32) ) } as u64;
	// 831E3754: 3BDE0001  addi r30, r30, 1
	ctx.r[30].s64 = ctx.r[30].s64 + 1;
	// 831E3758: 3BFF000C  addi r31, r31, 0xc
	ctx.r[31].s64 = ctx.r[31].s64 + 12;
	// 831E375C: 7F1E5840  cmplw cr6, r30, r11
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831E3760: 4198FFB4  blt cr6, 0x831e3714
	if ctx.cr[6].lt {
	pc = 0x831E3714; continue 'dispatch;
	}
	// 831E3764: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E3768: 4BFC4A50  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E3770(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E3770 size=92
    let mut pc: u32 = 0x831E3770;
    'dispatch: loop {
        match pc {
            0x831E3770 => {
    //   block [0x831E3770..0x831E37CC)
	// 831E3770: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E3774: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E3778: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831E377C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E3780: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E3784: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E3788: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 831E378C: 4BFFFCA5  bl 0x831e3430
	ctx.lr = 0x831E3790;
	sub_831E3430(ctx, base);
	// 831E3790: 57CB07FE  clrlwi r11, r30, 0x1f
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0x00000001u64;
	// 831E3794: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E3798: 419A0018  beq cr6, 0x831e37b0
	if ctx.cr[6].eq {
	pc = 0x831E37B0; continue 'dispatch;
	}
	// 831E379C: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E37A0: 3CA06182  lis r5, 0x6182
	ctx.r[5].s64 = 1635909632;
	// 831E37A4: 386BD5A4  addi r3, r11, -0x2a5c
	ctx.r[3].s64 = ctx.r[11].s64 + -10844;
	// 831E37A8: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831E37AC: 4BFF8F15  bl 0x831dc6c0
	ctx.lr = 0x831E37B0;
	sub_831DC6C0(ctx, base);
	// 831E37B0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E37B4: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E37B8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E37BC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E37C0: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831E37C4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E37C8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E37D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E37D0 size=388
    let mut pc: u32 = 0x831E37D0;
    'dispatch: loop {
        match pc {
            0x831E37D0 => {
    //   block [0x831E37D0..0x831E3954)
	// 831E37D0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E37D4: 4BFC4991  bl 0x831a8164
	ctx.lr = 0x831E37D8;
	sub_831A8130(ctx, base);
	// 831E37D8: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E37DC: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831E37E0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E37E4: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 831E37E8: 897D0045  lbz r11, 0x45(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(69 as u32) ) } as u64;
	// 831E37EC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E37F0: 419A0050  beq cr6, 0x831e3840
	if ctx.cr[6].eq {
	pc = 0x831E3840; continue 'dispatch;
	}
	// 831E37F4: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 831E37F8: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E37FC: 41980150  blt cr6, 0x831e394c
	if ctx.cr[6].lt {
	pc = 0x831E394C; continue 'dispatch;
	}
	// 831E3800: 817D0048  lwz r11, 0x48(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(72 as u32) ) } as u64;
	// 831E3804: 7C6BF02E  lwzx r3, r11, r30
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[30].u32)) } as u64;
	// 831E3808: 81630028  lwz r11, 0x28(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) } as u64;
	// 831E380C: 394B0001  addi r10, r11, 1
	ctx.r[10].s64 = ctx.r[11].s64 + 1;
	// 831E3810: 91430028  stw r10, 0x28(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(40 as u32), ctx.r[10].u32 ) };
	// 831E3814: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E3818: 81090038  lwz r8, 0x38(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E381C: 7D0903A6  mtctr r8
	ctx.ctr.u64 = ctx.r[8].u64;
	// 831E3820: 4E800421  bctrl
	ctx.lr = 0x831E3824;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E3824: 88FD0045  lbz r7, 0x45(r29)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(69 as u32) ) } as u64;
	// 831E3828: 3BFF0001  addi r31, r31, 1
	ctx.r[31].s64 = ctx.r[31].s64 + 1;
	// 831E382C: 3BDE000C  addi r30, r30, 0xc
	ctx.r[30].s64 = ctx.r[30].s64 + 12;
	// 831E3830: 7F1F3840  cmplw cr6, r31, r7
	ctx.cr[6].compare_u32(ctx.r[31].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831E3834: 4198FFC4  blt cr6, 0x831e37f8
	if ctx.cr[6].lt {
	pc = 0x831E37F8; continue 'dispatch;
	}
	// 831E3838: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E383C: 41980110  blt cr6, 0x831e394c
	if ctx.cr[6].lt {
	pc = 0x831E394C; continue 'dispatch;
	}
	// 831E3840: 817D0000  lwz r11, 0(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E3844: 3D408343  lis r10, -0x7cbd
	ctx.r[10].s64 = -2092761088;
	// 831E3848: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831E384C: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831E3850: 83EAD59C  lwz r31, -0x2a64(r10)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-10852 as u32) ) } as u64;
	// 831E3854: 812B0034  lwz r9, 0x34(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(52 as u32) ) } as u64;
	// 831E3858: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 831E385C: 4E800421  bctrl
	ctx.lr = 0x831E3860;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E3860: 89610050  lbz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831E3864: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 831E3868: 4198001C  blt cr6, 0x831e3884
	if ctx.cr[6].lt {
	pc = 0x831E3884; continue 'dispatch;
	}
	// 831E386C: 409A00DC  bne cr6, 0x831e3948
	if !ctx.cr[6].eq {
	pc = 0x831E3948; continue 'dispatch;
	}
	// 831E3870: 895D004C  lbz r10, 0x4c(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(76 as u32) ) } as u64;
	// 831E3874: 817F007C  lwz r11, 0x7c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(124 as u32) ) } as u64;
	// 831E3878: 1D4A002C  mulli r10, r10, 0x2c
	ctx.r[10].s64 = ctx.r[10].s64 * 44;
	// 831E387C: 7F6A5A14  add r27, r10, r11
	ctx.r[27].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831E3880: 48000008  b 0x831e3888
	pc = 0x831E3888; continue 'dispatch;
	// 831E3884: 3B7F0050  addi r27, r31, 0x50
	ctx.r[27].s64 = ctx.r[31].s64 + 80;
	// 831E3888: 2B1B0000  cmplwi cr6, r27, 0
	ctx.cr[6].compare_u32(ctx.r[27].u32, 0 as u32, &mut ctx.xer);
	// 831E388C: 419A00BC  beq cr6, 0x831e3948
	if ctx.cr[6].eq {
	pc = 0x831E3948; continue 'dispatch;
	}
	// 831E3890: 4805F8CD  bl 0x8324315c
	ctx.lr = 0x831E3894;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E3894: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E3898: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E389C: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831E38A0: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831E38A4: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E38A8: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E38AC: 419A0010  beq cr6, 0x831e38bc
	if ctx.cr[6].eq {
	pc = 0x831E38BC; continue 'dispatch;
	}
	// 831E38B0: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E38B4: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E38B8: 419A0018  beq cr6, 0x831e38d0
	if ctx.cr[6].eq {
	pc = 0x831E38D0; continue 'dispatch;
	}
	// 831E38BC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E38C0: 4805F1BD  bl 0x83242a7c
	ctx.lr = 0x831E38C4;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E38C4: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E38C8: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831E38CC: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 831E38D0: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E38D4: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E38D8: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E38DC: 813B0028  lwz r9, 0x28(r27)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(40 as u32) ) } as u64;
	// 831E38E0: 81690008  lwz r11, 8(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E38E4: 7D6BEA14  add r11, r11, r29
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 831E38E8: 912B0000  stw r9, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831E38EC: 81090004  lwz r8, 4(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E38F0: 910B0004  stw r8, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[8].u32 ) };
	// 831E38F4: 91690004  stw r11, 4(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E38F8: 80EB0004  lwz r7, 4(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E38FC: 91670000  stw r11, 0(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831E3900: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E3904: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E3908: 419A0040  beq cr6, 0x831e3948
	if ctx.cr[6].eq {
	pc = 0x831E3948; continue 'dispatch;
	}
	// 831E390C: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E3910: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E3914: 409A0034  bne cr6, 0x831e3948
	if !ctx.cr[6].eq {
	pc = 0x831E3948; continue 'dispatch;
	}
	// 831E3918: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E391C: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E3920: 40820028  bne 0x831e3948
	if !ctx.cr[0].eq {
	pc = 0x831E3948; continue 'dispatch;
	}
	// 831E3924: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E3928: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E392C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E3930: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E3934: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E3938: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E393C: 4805F131  bl 0x83242a6c
	ctx.lr = 0x831E3940;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E3940: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E3944: 4805F829  bl 0x8324316c
	ctx.lr = 0x831E3948;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E3948: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E394C: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831E3950: 4BFC4864  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E3958(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E3958 size=208
    let mut pc: u32 = 0x831E3958;
    'dispatch: loop {
        match pc {
            0x831E3958 => {
    //   block [0x831E3958..0x831E3A28)
	// 831E3958: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E395C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E3960: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E3964: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E3968: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E396C: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E3970: 814B0048  lwz r10, 0x48(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(72 as u32) ) } as u64;
	// 831E3974: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E3978: 4E800421  bctrl
	ctx.lr = 0x831E397C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E397C: 90610054  stw r3, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[3].u32 ) };
	// 831E3980: 38600003  li r3, 3
	ctx.r[3].s64 = 3;
	// 831E3984: 4B5EB855  bl 0x827cf1d8
	ctx.lr = 0x831E3988;
	sub_827CF1D8(ctx, base);
	// 831E3988: 817F002C  lwz r11, 0x2c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(44 as u32) ) } as u64;
	// 831E398C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E3990: 419A0018  beq cr6, 0x831e39a8
	if ctx.cr[6].eq {
	pc = 0x831E39A8; continue 'dispatch;
	}
	// 831E3994: 815F0030  lwz r10, 0x30(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(48 as u32) ) } as u64;
	// 831E3998: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 831E399C: 91410050  stw r10, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[10].u32 ) };
	// 831E39A0: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 831E39A4: 4E800421  bctrl
	ctx.lr = 0x831E39A8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E39A8: 897F003D  lbz r11, 0x3d(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(61 as u32) ) } as u64;
	// 831E39AC: 556A077A  rlwinm r10, r11, 0, 0x1d, 0x1d
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831E39B0: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E39B4: 419A001C  beq cr6, 0x831e39d0
	if ctx.cr[6].eq {
	pc = 0x831E39D0; continue 'dispatch;
	}
	// 831E39B8: A17F0040  lhz r11, 0x40(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(64 as u32) ) } as u64;
	// 831E39BC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E39C0: 419A004C  beq cr6, 0x831e3a0c
	if ctx.cr[6].eq {
	pc = 0x831E3A0C; continue 'dispatch;
	}
	// 831E39C4: 3D6B0001  addis r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 65536;
	// 831E39C8: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 831E39CC: B17F0040  sth r11, 0x40(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(64 as u32), ctx.r[11].u16 ) };
	// 831E39D0: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E39D4: 38810054  addi r4, r1, 0x54
	ctx.r[4].s64 = ctx.r[1].s64 + 84;
	// 831E39D8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E39DC: 814B0054  lwz r10, 0x54(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(84 as u32) ) } as u64;
	// 831E39E0: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E39E4: 4E800421  bctrl
	ctx.lr = 0x831E39E8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E39E8: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E39EC: 38600003  li r3, 3
	ctx.r[3].s64 = 3;
	// 831E39F0: 4B5EB7E9  bl 0x827cf1d8
	ctx.lr = 0x831E39F4;
	sub_827CF1D8(ctx, base);
	// 831E39F4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E39F8: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E39FC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E3A00: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E3A04: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E3A08: 4E800020  blr
	return;
	// 831E3A0C: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E3A10: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 831E3A14: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E3A18: 814B003C  lwz r10, 0x3c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(60 as u32) ) } as u64;
	// 831E3A1C: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E3A20: 4E800421  bctrl
	ctx.lr = 0x831E3A24;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E3A24: 4BFFFFC4  b 0x831e39e8
	pc = 0x831E39E8; continue 'dispatch;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E3A28(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E3A28 size=20
    let mut pc: u32 = 0x831E3A28;
    'dispatch: loop {
        match pc {
            0x831E3A28 => {
    //   block [0x831E3A28..0x831E3A3C)
	// 831E3A28: 81640000  lwz r11, 0(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E3A2C: 91630034  stw r11, 0x34(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), ctx.r[11].u32 ) };
	// 831E3A30: 81440004  lwz r10, 4(r4)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E3A34: 91430038  stw r10, 0x38(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(56 as u32), ctx.r[10].u32 ) };
	// 831E3A38: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E3A40(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E3A40 size=228
    let mut pc: u32 = 0x831E3A40;
    'dispatch: loop {
        match pc {
            0x831E3A40 => {
    //   block [0x831E3A40..0x831E3B24)
	// 831E3A40: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E3A44: 4BFC471D  bl 0x831a8160
	ctx.lr = 0x831E3A48;
	sub_831A8130(ctx, base);
	// 831E3A48: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E3A4C: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E3A50: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 831E3A54: 7C9A2378  mr r26, r4
	ctx.r[26].u64 = ctx.r[4].u64;
	// 831E3A58: 7FFDFB78  mr r29, r31
	ctx.r[29].u64 = ctx.r[31].u64;
	// 831E3A5C: 7FFEFB78  mr r30, r31
	ctx.r[30].u64 = ctx.r[31].u64;
	// 831E3A60: 817C000C  lwz r11, 0xc(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E3A64: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E3A68: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E3A6C: 409A0048  bne cr6, 0x831e3ab4
	if !ctx.cr[6].eq {
	pc = 0x831E3AB4; continue 'dispatch;
	}
	// 831E3A70: 39610060  addi r11, r1, 0x60
	ctx.r[11].s64 = ctx.r[1].s64 + 96;
	// 831E3A74: 895C0001  lbz r10, 1(r28)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(1 as u32) ) } as u64;
	// 831E3A78: 3D200000  lis r9, 0
	ctx.r[9].s64 = 0;
	// 831E3A7C: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831E3A80: 6128BB80  ori r8, r9, 0xbb80
	ctx.r[8].u64 = ctx.r[9].u64 | 48000;
	// 831E3A84: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 831E3A88: FBEB0000  std r31, 0(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[31].u64 ) };
	// 831E3A8C: FBEB0008  std r31, 8(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[31].u64 ) };
	// 831E3A90: 93EB0010  stw r31, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[31].u32 ) };
	// 831E3A94: 9BE10064  stb r31, 0x64(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[31].u8 ) };
	// 831E3A98: 99410065  stb r10, 0x65(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(101 as u32), ctx.r[10].u8 ) };
	// 831E3A9C: 91010068  stw r8, 0x68(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[8].u32 ) };
	// 831E3AA0: 9BE10060  stb r31, 0x60(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[31].u8 ) };
	// 831E3AA4: 4BFFE85D  bl 0x831e2300
	ctx.lr = 0x831E3AA8;
	sub_831E2300(ctx, base);
	// 831E3AA8: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E3AAC: 41980070  blt cr6, 0x831e3b1c
	if ctx.cr[6].lt {
	pc = 0x831E3B1C; continue 'dispatch;
	}
	// 831E3AB0: 83A10050  lwz r29, 0x50(r1)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831E3AB4: 817C0008  lwz r11, 8(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E3AB8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E3ABC: 419A0054  beq cr6, 0x831e3b10
	if ctx.cr[6].eq {
	pc = 0x831E3B10; continue 'dispatch;
	}
	// 831E3AC0: 894B0000  lbz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E3AC4: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E3AC8: 419A0048  beq cr6, 0x831e3b10
	if ctx.cr[6].eq {
	pc = 0x831E3B10; continue 'dispatch;
	}
	// 831E3ACC: 3F608343  lis r27, -0x7cbd
	ctx.r[27].s64 = -2092761088;
	// 831E3AD0: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E3AD4: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 831E3AD8: 817BD59C  lwz r11, -0x2a64(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(-10852 as u32) ) } as u64;
	// 831E3ADC: 7C8AF82E  lwzx r4, r10, r31
	ctx.r[4].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[31].u32)) } as u64;
	// 831E3AE0: 806B003C  lwz r3, 0x3c(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(60 as u32) ) } as u64;
	// 831E3AE4: 4BFF758D  bl 0x831db070
	ctx.lr = 0x831E3AE8;
	sub_831DB070(ctx, base);
	// 831E3AE8: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E3AEC: 41980030  blt cr6, 0x831e3b1c
	if ctx.cr[6].lt {
	pc = 0x831E3B1C; continue 'dispatch;
	}
	// 831E3AF0: 817C0008  lwz r11, 8(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E3AF4: 3BDE0001  addi r30, r30, 1
	ctx.r[30].s64 = ctx.r[30].s64 + 1;
	// 831E3AF8: 81410050  lwz r10, 0x50(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831E3AFC: 3BFF0004  addi r31, r31, 4
	ctx.r[31].s64 = ctx.r[31].s64 + 4;
	// 831E3B00: 7FAAEA14  add r29, r10, r29
	ctx.r[29].u64 = ctx.r[10].u64 + ctx.r[29].u64;
	// 831E3B04: 894B0000  lbz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E3B08: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E3B0C: 4198FFC4  blt cr6, 0x831e3ad0
	if ctx.cr[6].lt {
	pc = 0x831E3AD0; continue 'dispatch;
	}
	// 831E3B10: 57CB1838  slwi r11, r30, 3
	ctx.r[11].u32 = ctx.r[30].u32.wrapping_shl(3);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831E3B14: 7D6BEA14  add r11, r11, r29
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 831E3B18: 917A0000  stw r11, 0(r26)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831E3B1C: 382100B0  addi r1, r1, 0xb0
	ctx.r[1].s64 = ctx.r[1].s64 + 176;
	// 831E3B20: 4BFC4690  b 0x831a81b0
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E3B28(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E3B28 size=204
    let mut pc: u32 = 0x831E3B28;
    'dispatch: loop {
        match pc {
            0x831E3B28 => {
    //   block [0x831E3B28..0x831E3BF4)
	// 831E3B28: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E3B2C: 4BFC463D  bl 0x831a8168
	ctx.lr = 0x831E3B30;
	sub_831A8130(ctx, base);
	// 831E3B30: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E3B34: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E3B38: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E3B3C: 3B800000  li r28, 0
	ctx.r[28].s64 = 0;
	// 831E3B40: 392B0300  addi r9, r11, 0x300
	ctx.r[9].s64 = ctx.r[11].s64 + 768;
	// 831E3B44: 895F003C  lbz r10, 0x3c(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(60 as u32) ) } as u64;
	// 831E3B48: 913F0000  stw r9, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831E3B4C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E3B50: 419A0050  beq cr6, 0x831e3ba0
	if ctx.cr[6].eq {
	pc = 0x831E3BA0; continue 'dispatch;
	}
	// 831E3B54: 7F9DE378  mr r29, r28
	ctx.r[29].u64 = ctx.r[28].u64;
	// 831E3B58: 815F0024  lwz r10, 0x24(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(36 as u32) ) } as u64;
	// 831E3B5C: 57BE1838  slwi r30, r29, 3
	ctx.r[30].u32 = ctx.r[29].u32.wrapping_shl(3);
	ctx.r[30].u64 = ctx.r[30].u32 as u64;
	// 831E3B60: 7D7E502E  lwzx r11, r30, r10
	ctx.r[11].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[30].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 831E3B64: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E3B68: 419A0020  beq cr6, 0x831e3b88
	if ctx.cr[6].eq {
	pc = 0x831E3B88; continue 'dispatch;
	}
	// 831E3B6C: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E3B70: 7C7E502E  lwzx r3, r30, r10
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[30].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 831E3B74: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E3B78: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E3B7C: 4E800421  bctrl
	ctx.lr = 0x831E3B80;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E3B80: 813F0024  lwz r9, 0x24(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(36 as u32) ) } as u64;
	// 831E3B84: 7F9E492E  stwx r28, r30, r9
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[9].u32), ctx.r[28].u32) };
	// 831E3B88: 397D0001  addi r11, r29, 1
	ctx.r[11].s64 = ctx.r[29].s64 + 1;
	// 831E3B8C: 895F003C  lbz r10, 0x3c(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(60 as u32) ) } as u64;
	// 831E3B90: 556B063E  clrlwi r11, r11, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 831E3B94: 7D7D5B78  mr r29, r11
	ctx.r[29].u64 = ctx.r[11].u64;
	// 831E3B98: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E3B9C: 4198FFBC  blt cr6, 0x831e3b58
	if ctx.cr[6].lt {
	pc = 0x831E3B58; continue 'dispatch;
	}
	// 831E3BA0: 807F0020  lwz r3, 0x20(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) } as u64;
	// 831E3BA4: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E3BA8: 419A000C  beq cr6, 0x831e3bb4
	if ctx.cr[6].eq {
	pc = 0x831E3BB4; continue 'dispatch;
	}
	// 831E3BAC: 4BFF74A5  bl 0x831db050
	ctx.lr = 0x831E3BB0;
	sub_831DB050(ctx, base);
	// 831E3BB0: 939F0020  stw r28, 0x20(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[28].u32 ) };
	// 831E3BB4: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E3BB8: 807F0008  lwz r3, 8(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E3BBC: 394BFF78  addi r10, r11, -0x88
	ctx.r[10].s64 = ctx.r[11].s64 + -136;
	// 831E3BC0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E3BC4: 915F0000  stw r10, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E3BC8: 419A0018  beq cr6, 0x831e3be0
	if ctx.cr[6].eq {
	pc = 0x831E3BE0; continue 'dispatch;
	}
	// 831E3BCC: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E3BD0: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E3BD4: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E3BD8: 4E800421  bctrl
	ctx.lr = 0x831E3BDC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E3BDC: 939F0008  stw r28, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[28].u32 ) };
	// 831E3BE0: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E3BE4: 394BFF64  addi r10, r11, -0x9c
	ctx.r[10].s64 = ctx.r[11].s64 + -156;
	// 831E3BE8: 915F0000  stw r10, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E3BEC: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E3BF0: 4BFC45C8  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E3BF8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E3BF8 size=152
    let mut pc: u32 = 0x831E3BF8;
    'dispatch: loop {
        match pc {
            0x831E3BF8 => {
    //   block [0x831E3BF8..0x831E3C90)
	// 831E3BF8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E3BFC: 4BFC4571  bl 0x831a816c
	ctx.lr = 0x831E3C00;
	sub_831A8130(ctx, base);
	// 831E3C00: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E3C04: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E3C08: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 831E3C0C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E3C10: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831E3C14: 7CDD3378  mr r29, r6
	ctx.r[29].u64 = ctx.r[6].u64;
	// 831E3C18: 816BD59C  lwz r11, -0x2a64(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-10852 as u32) ) } as u64;
	// 831E3C1C: 7CA42B78  mr r4, r5
	ctx.r[4].u64 = ctx.r[5].u64;
	// 831E3C20: 7FE6FB78  mr r6, r31
	ctx.r[6].u64 = ctx.r[31].u64;
	// 831E3C24: 806B003C  lwz r3, 0x3c(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(60 as u32) ) } as u64;
	// 831E3C28: 915F0000  stw r10, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E3C2C: 80BE0008  lwz r5, 8(r30)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E3C30: 4BFF7461  bl 0x831db090
	ctx.lr = 0x831E3C34;
	sub_831DB090(ctx, base);
	// 831E3C34: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E3C38: 41980050  blt cr6, 0x831e3c88
	if ctx.cr[6].lt {
	pc = 0x831E3C88; continue 'dispatch;
	}
	// 831E3C3C: 807F0000  lwz r3, 0(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E3C40: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831E3C44: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E3C48: 814B0008  lwz r10, 8(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E3C4C: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E3C50: 4E800421  bctrl
	ctx.lr = 0x831E3C54;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E3C54: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E3C58: 41980030  blt cr6, 0x831e3c88
	if ctx.cr[6].lt {
	pc = 0x831E3C88; continue 'dispatch;
	}
	// 831E3C5C: 89410050  lbz r10, 0x50(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831E3C60: 39200001  li r9, 1
	ctx.r[9].s64 = 1;
	// 831E3C64: A1610052  lhz r11, 0x52(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[1].u32.wrapping_add(82 as u32) ) } as u64;
	// 831E3C68: 9BBF0004  stb r29, 4(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[29].u8 ) };
	// 831E3C6C: 7D685B78  mr r8, r11
	ctx.r[8].u64 = ctx.r[11].u64;
	// 831E3C70: 993F0005  stb r9, 5(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(5 as u32), ctx.r[9].u8 ) };
	// 831E3C74: 995F0006  stb r10, 6(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(6 as u32), ctx.r[10].u8 ) };
	// 831E3C78: A0FE003E  lhz r7, 0x3e(r30)
	ctx.r[7].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(62 as u32) ) } as u64;
	// 831E3C7C: 7F083840  cmplw cr6, r8, r7
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831E3C80: 40990008  ble cr6, 0x831e3c88
	if !ctx.cr[6].gt {
	pc = 0x831E3C88; continue 'dispatch;
	}
	// 831E3C84: B17E003E  sth r11, 0x3e(r30)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[30].u32.wrapping_add(62 as u32), ctx.r[11].u16 ) };
	// 831E3C88: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E3C8C: 4BFC4530  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E3C90(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E3C90 size=36
    let mut pc: u32 = 0x831E3C90;
    'dispatch: loop {
        match pc {
            0x831E3C90 => {
    //   block [0x831E3C90..0x831E3CB4)
	// 831E3C90: 8943003C  lbz r10, 0x3c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(60 as u32) ) } as u64;
	// 831E3C94: 548B063E  clrlwi r11, r4, 0x18
	ctx.r[11].u64 = ctx.r[4].u32 as u64 & 0x000000FFu64;
	// 831E3C98: 7CA92B78  mr r9, r5
	ctx.r[9].u64 = ctx.r[5].u64;
	// 831E3C9C: 7CC53378  mr r5, r6
	ctx.r[5].u64 = ctx.r[6].u64;
	// 831E3CA0: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E3CA4: 41980010  blt cr6, 0x831e3cb4
	if ctx.cr[6].lt {
		sub_831E3CB4(ctx, base);
		return;
	}
	// 831E3CA8: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 831E3CAC: 60630057  ori r3, r3, 0x57
	ctx.r[3].u64 = ctx.r[3].u64 | 87;
	// 831E3CB0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E3CB4(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E3CB4 size=36
    let mut pc: u32 = 0x831E3CB4;
    'dispatch: loop {
        match pc {
            0x831E3CB4 => {
    //   block [0x831E3CB4..0x831E3CD8)
	// 831E3CB4: 81430024  lwz r10, 0x24(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) } as u64;
	// 831E3CB8: 556B1838  slwi r11, r11, 3
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(3);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831E3CBC: 7CE63B78  mr r6, r7
	ctx.r[6].u64 = ctx.r[7].u64;
	// 831E3CC0: 7D244B78  mr r4, r9
	ctx.r[4].u64 = ctx.r[9].u64;
	// 831E3CC4: 7C6B502E  lwzx r3, r11, r10
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 831E3CC8: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E3CCC: 814B000C  lwz r10, 0xc(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E3CD0: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E3CD4: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E3CD8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E3CD8 size=36
    let mut pc: u32 = 0x831E3CD8;
    'dispatch: loop {
        match pc {
            0x831E3CD8 => {
    //   block [0x831E3CD8..0x831E3CFC)
	// 831E3CD8: 8943003C  lbz r10, 0x3c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(60 as u32) ) } as u64;
	// 831E3CDC: 548B063E  clrlwi r11, r4, 0x18
	ctx.r[11].u64 = ctx.r[4].u32 as u64 & 0x000000FFu64;
	// 831E3CE0: 7CA92B78  mr r9, r5
	ctx.r[9].u64 = ctx.r[5].u64;
	// 831E3CE4: 7CC53378  mr r5, r6
	ctx.r[5].u64 = ctx.r[6].u64;
	// 831E3CE8: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E3CEC: 41980010  blt cr6, 0x831e3cfc
	if ctx.cr[6].lt {
		sub_831E3CFC(ctx, base);
		return;
	}
	// 831E3CF0: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 831E3CF4: 60630057  ori r3, r3, 0x57
	ctx.r[3].u64 = ctx.r[3].u64 | 87;
	// 831E3CF8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E3CFC(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E3CFC size=36
    let mut pc: u32 = 0x831E3CFC;
    'dispatch: loop {
        match pc {
            0x831E3CFC => {
    //   block [0x831E3CFC..0x831E3D20)
	// 831E3CFC: 81430024  lwz r10, 0x24(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) } as u64;
	// 831E3D00: 556B1838  slwi r11, r11, 3
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(3);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831E3D04: 7CE63B78  mr r6, r7
	ctx.r[6].u64 = ctx.r[7].u64;
	// 831E3D08: 7D244B78  mr r4, r9
	ctx.r[4].u64 = ctx.r[9].u64;
	// 831E3D0C: 7C6B502E  lwzx r3, r11, r10
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 831E3D10: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E3D14: 814B0010  lwz r10, 0x10(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E3D18: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E3D1C: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E3D20(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E3D20 size=28
    let mut pc: u32 = 0x831E3D20;
    'dispatch: loop {
        match pc {
            0x831E3D20 => {
    //   block [0x831E3D20..0x831E3D3C)
	// 831E3D20: 8943003C  lbz r10, 0x3c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(60 as u32) ) } as u64;
	// 831E3D24: 548B063E  clrlwi r11, r4, 0x18
	ctx.r[11].u64 = ctx.r[4].u32 as u64 & 0x000000FFu64;
	// 831E3D28: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E3D2C: 41980010  blt cr6, 0x831e3d3c
	if ctx.cr[6].lt {
		sub_831E3D3C(ctx, base);
		return;
	}
	// 831E3D30: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 831E3D34: 60630057  ori r3, r3, 0x57
	ctx.r[3].u64 = ctx.r[3].u64 | 87;
	// 831E3D38: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E3D3C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E3D3C size=28
    let mut pc: u32 = 0x831E3D3C;
    'dispatch: loop {
        match pc {
            0x831E3D3C => {
    //   block [0x831E3D3C..0x831E3D58)
	// 831E3D3C: 81430024  lwz r10, 0x24(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) } as u64;
	// 831E3D40: 556B1838  slwi r11, r11, 3
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(3);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831E3D44: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E3D48: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831E3D4C: 896B0005  lbz r11, 5(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(5 as u32) ) } as u64;
	// 831E3D50: 99650000  stb r11, 0(r5)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), ctx.r[11].u8 ) };
	// 831E3D54: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E3D58(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E3D58 size=28
    let mut pc: u32 = 0x831E3D58;
    'dispatch: loop {
        match pc {
            0x831E3D58 => {
    //   block [0x831E3D58..0x831E3D74)
	// 831E3D58: 8943003C  lbz r10, 0x3c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(60 as u32) ) } as u64;
	// 831E3D5C: 548B063E  clrlwi r11, r4, 0x18
	ctx.r[11].u64 = ctx.r[4].u32 as u64 & 0x000000FFu64;
	// 831E3D60: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E3D64: 41980010  blt cr6, 0x831e3d74
	if ctx.cr[6].lt {
		sub_831E3D74(ctx, base);
		return;
	}
	// 831E3D68: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 831E3D6C: 60630057  ori r3, r3, 0x57
	ctx.r[3].u64 = ctx.r[3].u64 | 87;
	// 831E3D70: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E3D74(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E3D74 size=24
    let mut pc: u32 = 0x831E3D74;
    'dispatch: loop {
        match pc {
            0x831E3D74 => {
    //   block [0x831E3D74..0x831E3D8C)
	// 831E3D74: 81430024  lwz r10, 0x24(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) } as u64;
	// 831E3D78: 556B1838  slwi r11, r11, 3
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(3);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831E3D7C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E3D80: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831E3D84: 98AB0005  stb r5, 5(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(5 as u32), ctx.r[5].u8 ) };
	// 831E3D88: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E3D90(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E3D90 size=156
    let mut pc: u32 = 0x831E3D90;
    'dispatch: loop {
        match pc {
            0x831E3D90 => {
    //   block [0x831E3D90..0x831E3E2C)
	// 831E3D90: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E3D94: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E3D98: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831E3D9C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E3DA0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E3DA4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E3DA8: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E3DAC: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 831E3DB0: 392BFF78  addi r9, r11, -0x88
	ctx.r[9].s64 = ctx.r[11].s64 + -136;
	// 831E3DB4: 7CBE2B78  mr r30, r5
	ctx.r[30].u64 = ctx.r[5].u64;
	// 831E3DB8: 909F0008  stw r4, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[4].u32 ) };
	// 831E3DBC: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 831E3DC0: 915F0004  stw r10, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831E3DC4: 913F0000  stw r9, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831E3DC8: 419A0018  beq cr6, 0x831e3de0
	if ctx.cr[6].eq {
	pc = 0x831E3DE0; continue 'dispatch;
	}
	// 831E3DCC: 81640000  lwz r11, 0(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E3DD0: 7C832378  mr r3, r4
	ctx.r[3].u64 = ctx.r[4].u64;
	// 831E3DD4: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E3DD8: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E3DDC: 4E800421  bctrl
	ctx.lr = 0x831E3DE0;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E3DE0: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831E3DE4: 9BDF000C  stb r30, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[30].u8 ) };
	// 831E3DE8: 397F0010  addi r11, r31, 0x10
	ctx.r[11].s64 = ctx.r[31].s64 + 16;
	// 831E3DEC: 392A0300  addi r9, r10, 0x300
	ctx.r[9].s64 = ctx.r[10].s64 + 768;
	// 831E3DF0: 395F0018  addi r10, r31, 0x18
	ctx.r[10].s64 = ctx.r[31].s64 + 24;
	// 831E3DF4: 913F0000  stw r9, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831E3DF8: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 831E3DFC: 917F0010  stw r11, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 831E3E00: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E3E04: 917F0014  stw r11, 0x14(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), ctx.r[11].u32 ) };
	// 831E3E08: 915F0018  stw r10, 0x18(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), ctx.r[10].u32 ) };
	// 831E3E0C: 915F001C  stw r10, 0x1c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), ctx.r[10].u32 ) };
	// 831E3E10: 911F0028  stw r8, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[8].u32 ) };
	// 831E3E14: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E3E18: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E3E1C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E3E20: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831E3E24: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E3E28: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E3E30(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E3E30 size=92
    let mut pc: u32 = 0x831E3E30;
    'dispatch: loop {
        match pc {
            0x831E3E30 => {
    //   block [0x831E3E30..0x831E3E8C)
	// 831E3E30: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E3E34: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E3E38: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831E3E3C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E3E40: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E3E44: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E3E48: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 831E3E4C: 4BFFFCDD  bl 0x831e3b28
	ctx.lr = 0x831E3E50;
	sub_831E3B28(ctx, base);
	// 831E3E50: 57CB07FE  clrlwi r11, r30, 0x1f
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0x00000001u64;
	// 831E3E54: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E3E58: 419A0018  beq cr6, 0x831e3e70
	if ctx.cr[6].eq {
	pc = 0x831E3E70; continue 'dispatch;
	}
	// 831E3E5C: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E3E60: 3CA06182  lis r5, 0x6182
	ctx.r[5].s64 = 1635909632;
	// 831E3E64: 386BD5A4  addi r3, r11, -0x2a5c
	ctx.r[3].s64 = ctx.r[11].s64 + -10844;
	// 831E3E68: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831E3E6C: 4BFF8855  bl 0x831dc6c0
	ctx.lr = 0x831E3E70;
	sub_831DC6C0(ctx, base);
	// 831E3E70: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E3E74: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E3E78: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E3E7C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E3E80: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831E3E84: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E3E88: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E3E90(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E3E90 size=112
    let mut pc: u32 = 0x831E3E90;
    'dispatch: loop {
        match pc {
            0x831E3E90 => {
    //   block [0x831E3E90..0x831E3F00)
	// 831E3E90: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E3E94: 4BFC42D9  bl 0x831a816c
	ctx.lr = 0x831E3E98;
	sub_831A8130(ctx, base);
	// 831E3E98: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E3E9C: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 831E3EA0: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831E3EA4: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E3EA8: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 831E3EAC: 897F0000  lbz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E3EB0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E3EB4: 419A0044  beq cr6, 0x831e3ef8
	if ctx.cr[6].eq {
	pc = 0x831E3EF8; continue 'dispatch;
	}
	// 831E3EB8: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E3EBC: 4198003C  blt cr6, 0x831e3ef8
	if ctx.cr[6].lt {
	pc = 0x831E3EF8; continue 'dispatch;
	}
	// 831E3EC0: 813F0004  lwz r9, 4(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E3EC4: 54C815BA  rlwinm r8, r6, 2, 0x16, 0x1d
	ctx.r[8].u64 = ctx.r[6].u32 as u64 & 0x3FFFFFFFu64;
	// 831E3EC8: 815E0024  lwz r10, 0x24(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(36 as u32) ) } as u64;
	// 831E3ECC: 54CB1D78  rlwinm r11, r6, 3, 0x15, 0x1c
	ctx.r[11].u64 = ctx.r[6].u32 as u64 & 0x1FFFFFFFu64;
	// 831E3ED0: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E3ED4: 7C8B5214  add r4, r11, r10
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831E3ED8: 54DD063E  clrlwi r29, r6, 0x18
	ctx.r[29].u64 = ctx.r[6].u32 as u64 & 0x000000FFu64;
	// 831E3EDC: 7CA8482E  lwzx r5, r8, r9
	ctx.r[5].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[8].u32.wrapping_add(ctx.r[9].u32)) } as u64;
	// 831E3EE0: 4BFFFD19  bl 0x831e3bf8
	ctx.lr = 0x831E3EE4;
	sub_831E3BF8(ctx, base);
	// 831E3EE4: 38FD0001  addi r7, r29, 1
	ctx.r[7].s64 = ctx.r[29].s64 + 1;
	// 831E3EE8: 88BF0000  lbz r5, 0(r31)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E3EEC: 54E6063E  clrlwi r6, r7, 0x18
	ctx.r[6].u64 = ctx.r[7].u32 as u64 & 0x000000FFu64;
	// 831E3EF0: 7F062840  cmplw cr6, r6, r5
	ctx.cr[6].compare_u32(ctx.r[6].u32, ctx.r[5].u32, &mut ctx.xer);
	// 831E3EF4: 4198FFC4  blt cr6, 0x831e3eb8
	if ctx.cr[6].lt {
	pc = 0x831E3EB8; continue 'dispatch;
	}
	// 831E3EF8: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E3EFC: 4BFC42C0  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E3F00(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E3F00 size=288
    let mut pc: u32 = 0x831E3F00;
    'dispatch: loop {
        match pc {
            0x831E3F00 => {
    //   block [0x831E3F00..0x831E4020)
	// 831E3F00: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E3F04: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E3F08: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E3F0C: 89640005  lbz r11, 5(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[4].u32.wrapping_add(5 as u32) ) } as u64;
	// 831E3F10: 556A07FE  clrlwi r10, r11, 0x1f
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0x00000001u64;
	// 831E3F14: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E3F18: 409A0018  bne cr6, 0x831e3f30
	if !ctx.cr[6].eq {
	pc = 0x831E3F30; continue 'dispatch;
	}
	// 831E3F1C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E3F20: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831E3F24: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E3F28: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E3F2C: 4E800020  blr
	return;
	// 831E3F30: 89640006  lbz r11, 6(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[4].u32.wrapping_add(6 as u32) ) } as u64;
	// 831E3F34: 556A077C  rlwinm r10, r11, 0, 0x1d, 0x1e
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831E3F38: 2B0A0006  cmplwi cr6, r10, 6
	ctx.cr[6].compare_u32(ctx.r[10].u32, 6 as u32, &mut ctx.xer);
	// 831E3F3C: 409A0080  bne cr6, 0x831e3fbc
	if !ctx.cr[6].eq {
	pc = 0x831E3FBC; continue 'dispatch;
	}
	// 831E3F40: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E3F44: 80E50000  lwz r7, 0(r5)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E3F48: 892D010C  lbz r9, 0x10c(r13)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[13].u32.wrapping_add(268 as u32) ) } as u64;
	// 831E3F4C: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 831E3F50: 810BD59C  lwz r8, -0x2a64(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-10852 as u32) ) } as u64;
	// 831E3F54: 419A0030  beq cr6, 0x831e3f84
	if ctx.cr[6].eq {
	pc = 0x831E3F84; continue 'dispatch;
	}
	// 831E3F58: 552A1838  slwi r10, r9, 3
	ctx.r[10].u32 = ctx.r[9].u32.wrapping_shl(3);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831E3F5C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E3F60: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 831E3F64: 394A000C  addi r10, r10, 0xc
	ctx.r[10].s64 = ctx.r[10].s64 + 12;
	// 831E3F68: 80CA0000  lwz r6, 0(r10)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E3F6C: 7F073040  cmplw cr6, r7, r6
	ctx.cr[6].compare_u32(ctx.r[7].u32, ctx.r[6].u32, &mut ctx.xer);
	// 831E3F70: 419A0028  beq cr6, 0x831e3f98
	if ctx.cr[6].eq {
	pc = 0x831E3F98; continue 'dispatch;
	}
	// 831E3F74: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E3F78: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 831E3F7C: 2B0B0002  cmplwi cr6, r11, 2
	ctx.cr[6].compare_u32(ctx.r[11].u32, 2 as u32, &mut ctx.xer);
	// 831E3F80: 4198FFE8  blt cr6, 0x831e3f68
	if ctx.cr[6].lt {
	pc = 0x831E3F68; continue 'dispatch;
	}
	// 831E3F84: 552B1838  slwi r11, r9, 3
	ctx.r[11].u32 = ctx.r[9].u32.wrapping_shl(3);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831E3F88: 7D6B4214  add r11, r11, r8
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 831E3F8C: 816B000C  lwz r11, 0xc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E3F90: 91650000  stw r11, 0(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831E3F94: 48000060  b 0x831e3ff4
	pc = 0x831E3FF4; continue 'dispatch;
	// 831E3F98: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 831E3F9C: 552A083C  slwi r10, r9, 1
	ctx.r[10].u32 = ctx.r[9].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831E3FA0: 556B07FE  clrlwi r11, r11, 0x1f
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x00000001u64;
	// 831E3FA4: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831E3FA8: 394B0003  addi r10, r11, 3
	ctx.r[10].s64 = ctx.r[11].s64 + 3;
	// 831E3FAC: 5549103A  slwi r9, r10, 2
	ctx.r[9].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831E3FB0: 7D69402E  lwzx r11, r9, r8
	ctx.r[11].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[8].u32)) } as u64;
	// 831E3FB4: 91650000  stw r11, 0(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831E3FB8: 4800003C  b 0x831e3ff4
	pc = 0x831E3FF4; continue 'dispatch;
	// 831E3FBC: 556A07BE  clrlwi r10, r11, 0x1e
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0x00000003u64;
	// 831E3FC0: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E3FC4: 419A0010  beq cr6, 0x831e3fd4
	if ctx.cr[6].eq {
	pc = 0x831E3FD4; continue 'dispatch;
	}
	// 831E3FC8: 80E50000  lwz r7, 0(r5)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E3FCC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E3FD0: 48000024  b 0x831e3ff4
	pc = 0x831E3FF4; continue 'dispatch;
	// 831E3FD4: 556B077A  rlwinm r11, r11, 0, 0x1d, 0x1d
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831E3FD8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E3FDC: 419A0010  beq cr6, 0x831e3fec
	if ctx.cr[6].eq {
	pc = 0x831E3FEC; continue 'dispatch;
	}
	// 831E3FE0: 81650000  lwz r11, 0(r5)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E3FE4: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 831E3FE8: 4800000C  b 0x831e3ff4
	pc = 0x831E3FF4; continue 'dispatch;
	// 831E3FEC: 80E10050  lwz r7, 0x50(r1)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831E3FF0: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831E3FF4: 80640000  lwz r3, 0(r4)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E3FF8: 7D655B78  mr r5, r11
	ctx.r[5].u64 = ctx.r[11].u64;
	// 831E3FFC: 7CE43B78  mr r4, r7
	ctx.r[4].u64 = ctx.r[7].u64;
	// 831E4000: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E4004: 814B0018  lwz r10, 0x18(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) } as u64;
	// 831E4008: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E400C: 4E800421  bctrl
	ctx.lr = 0x831E4010;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E4010: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831E4014: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E4018: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E401C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E4020(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E4020 size=548
    let mut pc: u32 = 0x831E4020;
    'dispatch: loop {
        match pc {
            0x831E4020 => {
    //   block [0x831E4020..0x831E4244)
	// 831E4020: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E4024: 4BFC4145  bl 0x831a8168
	ctx.lr = 0x831E4028;
	sub_831A8130(ctx, base);
	// 831E4028: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E402C: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E4030: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 831E4034: 4B5EB1A5  bl 0x827cf1d8
	ctx.lr = 0x831E4038;
	sub_827CF1D8(ctx, base);
	// 831E4038: 4805F125  bl 0x8324315c
	ctx.lr = 0x831E403C;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E403C: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E4040: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831E4044: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831E4048: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831E404C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E4050: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E4054: 419A0010  beq cr6, 0x831e4064
	if ctx.cr[6].eq {
	pc = 0x831E4064; continue 'dispatch;
	}
	// 831E4058: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E405C: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E4060: 419A0018  beq cr6, 0x831e4078
	if ctx.cr[6].eq {
	pc = 0x831E4078; continue 'dispatch;
	}
	// 831E4064: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E4068: 4805EA15  bl 0x83242a7c
	ctx.lr = 0x831E406C;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E406C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E4070: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831E4074: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831E4078: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E407C: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E4080: 897C003D  lbz r11, 0x3d(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(61 as u32) ) } as u64;
	// 831E4084: 556A07FE  clrlwi r10, r11, 0x1f
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0x00000001u64;
	// 831E4088: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E408C: 419A00A4  beq cr6, 0x831e4130
	if ctx.cr[6].eq {
	pc = 0x831E4130; continue 'dispatch;
	}
	// 831E4090: 4805F0CD  bl 0x8324315c
	ctx.lr = 0x831E4094;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E4094: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E4098: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831E409C: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831E40A0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E40A4: 419A0010  beq cr6, 0x831e40b4
	if ctx.cr[6].eq {
	pc = 0x831E40B4; continue 'dispatch;
	}
	// 831E40A8: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E40AC: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E40B0: 419A0018  beq cr6, 0x831e40c8
	if ctx.cr[6].eq {
	pc = 0x831E40C8; continue 'dispatch;
	}
	// 831E40B4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E40B8: 4805E9C5  bl 0x83242a7c
	ctx.lr = 0x831E40BC;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E40BC: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E40C0: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831E40C4: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831E40C8: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E40CC: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E40D0: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E40D4: 897C003D  lbz r11, 0x3d(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(61 as u32) ) } as u64;
	// 831E40D8: 5569063E  clrlwi r9, r11, 0x18
	ctx.r[9].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 831E40DC: 552907B8  rlwinm r9, r9, 0, 0x1e, 0x1c
	ctx.r[9].u64 = ctx.r[9].u32 as u64 & 0xFFFFFFFFu64;
	// 831E40E0: 993C003D  stb r9, 0x3d(r28)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[28].u32.wrapping_add(61 as u32), ctx.r[9].u8 ) };
	// 831E40E4: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E40E8: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E40EC: 419A00FC  beq cr6, 0x831e41e8
	if ctx.cr[6].eq {
	pc = 0x831E41E8; continue 'dispatch;
	}
	// 831E40F0: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E40F4: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E40F8: 409A00F0  bne cr6, 0x831e41e8
	if !ctx.cr[6].eq {
	pc = 0x831E41E8; continue 'dispatch;
	}
	// 831E40FC: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E4100: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E4104: 408200E4  bne 0x831e41e8
	if !ctx.cr[0].eq {
	pc = 0x831E41E8; continue 'dispatch;
	}
	// 831E4108: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E410C: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E4110: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E4114: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E4118: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E411C: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E4120: 4805E94D  bl 0x83242a6c
	ctx.lr = 0x831E4124;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E4124: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E4128: 4805F045  bl 0x8324316c
	ctx.lr = 0x831E412C;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E412C: 480000B8  b 0x831e41e4
	pc = 0x831E41E4; continue 'dispatch;
	// 831E4130: 4805F02D  bl 0x8324315c
	ctx.lr = 0x831E4134;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E4134: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E4138: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831E413C: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831E4140: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E4144: 419A0010  beq cr6, 0x831e4154
	if ctx.cr[6].eq {
	pc = 0x831E4154; continue 'dispatch;
	}
	// 831E4148: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E414C: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E4150: 419A0018  beq cr6, 0x831e4168
	if ctx.cr[6].eq {
	pc = 0x831E4168; continue 'dispatch;
	}
	// 831E4154: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E4158: 4805E925  bl 0x83242a7c
	ctx.lr = 0x831E415C;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E415C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E4160: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831E4164: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831E4168: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E416C: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E4170: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E4174: 897C003D  lbz r11, 0x3d(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(61 as u32) ) } as u64;
	// 831E4178: 5569063C  rlwinm r9, r11, 0, 0x18, 0x1e
	ctx.r[9].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831E417C: 552906B0  rlwinm r9, r9, 0, 0x1a, 0x18
	ctx.r[9].u64 = ctx.r[9].u32 as u64 & 0xFFFFFFFFu64;
	// 831E4180: 61280001  ori r8, r9, 1
	ctx.r[8].u64 = ctx.r[9].u64 | 1;
	// 831E4184: 991C003D  stb r8, 0x3d(r28)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[28].u32.wrapping_add(61 as u32), ctx.r[8].u8 ) };
	// 831E4188: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E418C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E4190: 419A0040  beq cr6, 0x831e41d0
	if ctx.cr[6].eq {
	pc = 0x831E41D0; continue 'dispatch;
	}
	// 831E4194: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E4198: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E419C: 409A0034  bne cr6, 0x831e41d0
	if !ctx.cr[6].eq {
	pc = 0x831E41D0; continue 'dispatch;
	}
	// 831E41A0: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E41A4: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E41A8: 40820028  bne 0x831e41d0
	if !ctx.cr[0].eq {
	pc = 0x831E41D0; continue 'dispatch;
	}
	// 831E41AC: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E41B0: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E41B4: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E41B8: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E41BC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E41C0: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E41C4: 4805E8A9  bl 0x83242a6c
	ctx.lr = 0x831E41C8;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E41C8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E41CC: 4805EFA1  bl 0x8324316c
	ctx.lr = 0x831E41D0;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E41D0: 817C0000  lwz r11, 0(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E41D4: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 831E41D8: 814B004C  lwz r10, 0x4c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(76 as u32) ) } as u64;
	// 831E41DC: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E41E0: 4E800421  bctrl
	ctx.lr = 0x831E41E4;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E41E4: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E41E8: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E41EC: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E41F0: 419A0040  beq cr6, 0x831e4230
	if ctx.cr[6].eq {
	pc = 0x831E4230; continue 'dispatch;
	}
	// 831E41F4: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E41F8: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E41FC: 409A0034  bne cr6, 0x831e4230
	if !ctx.cr[6].eq {
	pc = 0x831E4230; continue 'dispatch;
	}
	// 831E4200: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E4204: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E4208: 40820028  bne 0x831e4230
	if !ctx.cr[0].eq {
	pc = 0x831E4230; continue 'dispatch;
	}
	// 831E420C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E4210: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E4214: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E4218: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E421C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E4220: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E4224: 4805E849  bl 0x83242a6c
	ctx.lr = 0x831E4228;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E4228: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E422C: 4805EF41  bl 0x8324316c
	ctx.lr = 0x831E4230;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E4230: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 831E4234: 4B5EAFA5  bl 0x827cf1d8
	ctx.lr = 0x831E4238;
	sub_827CF1D8(ctx, base);
	// 831E4238: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E423C: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E4240: 4BFC3F78  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E4248(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E4248 size=960
    let mut pc: u32 = 0x831E4248;
    'dispatch: loop {
        match pc {
            0x831E4248 => {
    //   block [0x831E4248..0x831E4608)
	// 831E4248: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E424C: 4BFC3F1D  bl 0x831a8168
	ctx.lr = 0x831E4250;
	sub_831A8130(ctx, base);
	// 831E4250: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E4254: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E4258: 38600002  li r3, 2
	ctx.r[3].s64 = 2;
	// 831E425C: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 831E4260: 4B5EAF79  bl 0x827cf1d8
	ctx.lr = 0x831E4264;
	sub_827CF1D8(ctx, base);
	// 831E4264: 57EB07FE  clrlwi r11, r31, 0x1f
	ctx.r[11].u64 = ctx.r[31].u32 as u64 & 0x00000001u64;
	// 831E4268: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E426C: 419A01DC  beq cr6, 0x831e4448
	if ctx.cr[6].eq {
	pc = 0x831E4448; continue 'dispatch;
	}
	// 831E4270: 4805EEED  bl 0x8324315c
	ctx.lr = 0x831E4274;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E4274: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E4278: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831E427C: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831E4280: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831E4284: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E4288: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E428C: 419A0010  beq cr6, 0x831e429c
	if ctx.cr[6].eq {
	pc = 0x831E429C; continue 'dispatch;
	}
	// 831E4290: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E4294: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E4298: 419A0018  beq cr6, 0x831e42b0
	if ctx.cr[6].eq {
	pc = 0x831E42B0; continue 'dispatch;
	}
	// 831E429C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E42A0: 4805E7DD  bl 0x83242a7c
	ctx.lr = 0x831E42A4;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E42A4: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E42A8: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831E42AC: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831E42B0: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E42B4: 3D408343  lis r10, -0x7cbd
	ctx.r[10].s64 = -2092761088;
	// 831E42B8: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E42BC: 7F84E378  mr r4, r28
	ctx.r[4].u64 = ctx.r[28].u64;
	// 831E42C0: 806AD59C  lwz r3, -0x2a64(r10)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-10852 as u32) ) } as u64;
	// 831E42C4: 4BFF4715  bl 0x831d89d8
	ctx.lr = 0x831E42C8;
	sub_831D89D8(ctx, base);
	// 831E42C8: 893C003D  lbz r9, 0x3d(r28)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(61 as u32) ) } as u64;
	// 831E42CC: 552807FE  clrlwi r8, r9, 0x1f
	ctx.r[8].u64 = ctx.r[9].u32 as u64 & 0x00000001u64;
	// 831E42D0: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 831E42D4: 409A0064  bne cr6, 0x831e4338
	if !ctx.cr[6].eq {
	pc = 0x831E4338; continue 'dispatch;
	}
	// 831E42D8: 813F0004  lwz r9, 4(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E42DC: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E42E0: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831E42E4: 419A0310  beq cr6, 0x831e45f4
	if ctx.cr[6].eq {
	pc = 0x831E45F4; continue 'dispatch;
	}
	// 831E42E8: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E42EC: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831E42F0: 409A0304  bne cr6, 0x831e45f4
	if !ctx.cr[6].eq {
	pc = 0x831E45F4; continue 'dispatch;
	}
	// 831E42F4: 3569FFFF  addic. r11, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E42F8: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E42FC: 408202F8  bne 0x831e45f4
	if !ctx.cr[0].eq {
	pc = 0x831E45F4; continue 'dispatch;
	}
	// 831E4300: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E4304: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E4308: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E430C: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E4310: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E4314: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E4318: 4805E755  bl 0x83242a6c
	ctx.lr = 0x831E431C;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E431C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E4320: 4805EE4D  bl 0x8324316c
	ctx.lr = 0x831E4324;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E4324: 38600002  li r3, 2
	ctx.r[3].s64 = 2;
	// 831E4328: 4B5EAEB1  bl 0x827cf1d8
	ctx.lr = 0x831E432C;
	sub_827CF1D8(ctx, base);
	// 831E432C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E4330: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E4334: 4BFC3E84  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
	// 831E4338: 4805EE25  bl 0x8324315c
	ctx.lr = 0x831E433C;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E433C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E4340: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831E4344: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831E4348: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E434C: 419A0010  beq cr6, 0x831e435c
	if ctx.cr[6].eq {
	pc = 0x831E435C; continue 'dispatch;
	}
	// 831E4350: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E4354: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E4358: 419A0018  beq cr6, 0x831e4370
	if ctx.cr[6].eq {
	pc = 0x831E4370; continue 'dispatch;
	}
	// 831E435C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E4360: 4805E71D  bl 0x83242a7c
	ctx.lr = 0x831E4364;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E4364: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E4368: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831E436C: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831E4370: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E4374: 398000BA  li r12, 0xba
	ctx.r[12].s64 = 186;
	// 831E4378: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E437C: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E4380: 897C003D  lbz r11, 0x3d(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(61 as u32) ) } as u64;
	// 831E4384: 7D696038  and r9, r11, r12
	ctx.r[9].u64 = ctx.r[11].u64 & ctx.r[12].u64;
	// 831E4388: 993C003D  stb r9, 0x3d(r28)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[28].u32.wrapping_add(61 as u32), ctx.r[9].u8 ) };
	// 831E438C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E4390: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E4394: 419A0040  beq cr6, 0x831e43d4
	if ctx.cr[6].eq {
	pc = 0x831E43D4; continue 'dispatch;
	}
	// 831E4398: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E439C: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E43A0: 409A0034  bne cr6, 0x831e43d4
	if !ctx.cr[6].eq {
	pc = 0x831E43D4; continue 'dispatch;
	}
	// 831E43A4: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E43A8: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E43AC: 40820028  bne 0x831e43d4
	if !ctx.cr[0].eq {
	pc = 0x831E43D4; continue 'dispatch;
	}
	// 831E43B0: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E43B4: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E43B8: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E43BC: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E43C0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E43C4: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E43C8: 4805E6A5  bl 0x83242a6c
	ctx.lr = 0x831E43CC;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E43CC: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E43D0: 4805ED9D  bl 0x8324316c
	ctx.lr = 0x831E43D4;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E43D4: 817C0000  lwz r11, 0(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E43D8: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 831E43DC: 814B0050  lwz r10, 0x50(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(80 as u32) ) } as u64;
	// 831E43E0: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E43E4: 4E800421  bctrl
	ctx.lr = 0x831E43E8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E43E8: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E43EC: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E43F0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E43F4: 419A0200  beq cr6, 0x831e45f4
	if ctx.cr[6].eq {
	pc = 0x831E45F4; continue 'dispatch;
	}
	// 831E43F8: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E43FC: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E4400: 409A01F4  bne cr6, 0x831e45f4
	if !ctx.cr[6].eq {
	pc = 0x831E45F4; continue 'dispatch;
	}
	// 831E4404: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E4408: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E440C: 408201E8  bne 0x831e45f4
	if !ctx.cr[0].eq {
	pc = 0x831E45F4; continue 'dispatch;
	}
	// 831E4410: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E4414: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E4418: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E441C: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E4420: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E4424: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E4428: 4805E645  bl 0x83242a6c
	ctx.lr = 0x831E442C;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E442C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E4430: 4805ED3D  bl 0x8324316c
	ctx.lr = 0x831E4434;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E4434: 38600002  li r3, 2
	ctx.r[3].s64 = 2;
	// 831E4438: 4B5EADA1  bl 0x827cf1d8
	ctx.lr = 0x831E443C;
	sub_827CF1D8(ctx, base);
	// 831E443C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E4440: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E4444: 4BFC3D74  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
	// 831E4448: 4805ED15  bl 0x8324315c
	ctx.lr = 0x831E444C;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E444C: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E4450: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831E4454: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831E4458: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831E445C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E4460: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E4464: 419A0010  beq cr6, 0x831e4474
	if ctx.cr[6].eq {
	pc = 0x831E4474; continue 'dispatch;
	}
	// 831E4468: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E446C: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E4470: 419A0024  beq cr6, 0x831e4494
	if ctx.cr[6].eq {
	pc = 0x831E4494; continue 'dispatch;
	}
	// 831E4474: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E4478: 4805E605  bl 0x83242a7c
	ctx.lr = 0x831E447C;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E447C: 7FCAF378  mr r10, r30
	ctx.r[10].u64 = ctx.r[30].u64;
	// 831E4480: 7FA9EB78  mr r9, r29
	ctx.r[9].u64 = ctx.r[29].u64;
	// 831E4484: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E4488: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E448C: 993F000C  stb r9, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[9].u8 ) };
	// 831E4490: 48000008  b 0x831e4498
	pc = 0x831E4498; continue 'dispatch;
	// 831E4494: 893F000C  lbz r9, 0xc(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E4498: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E449C: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E44A0: 891C003D  lbz r8, 0x3d(r28)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(61 as u32) ) } as u64;
	// 831E44A4: 550707FE  clrlwi r7, r8, 0x1f
	ctx.r[7].u64 = ctx.r[8].u32 as u64 & 0x00000001u64;
	// 831E44A8: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 831E44AC: 409A005C  bne cr6, 0x831e4508
	if !ctx.cr[6].eq {
	pc = 0x831E4508; continue 'dispatch;
	}
	// 831E44B0: 7DA86B78  mr r8, r13
	ctx.r[8].u64 = ctx.r[13].u64;
	// 831E44B4: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E44B8: 419A013C  beq cr6, 0x831e45f4
	if ctx.cr[6].eq {
	pc = 0x831E45F4; continue 'dispatch;
	}
	// 831E44BC: 7F085040  cmplw cr6, r8, r10
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E44C0: 409A0134  bne cr6, 0x831e45f4
	if !ctx.cr[6].eq {
	pc = 0x831E45F4; continue 'dispatch;
	}
	// 831E44C4: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E44C8: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E44CC: 40820128  bne 0x831e45f4
	if !ctx.cr[0].eq {
	pc = 0x831E45F4; continue 'dispatch;
	}
	// 831E44D0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E44D4: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E44D8: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E44DC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E44E0: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E44E4: 7D3F4B78  mr r31, r9
	ctx.r[31].u64 = ctx.r[9].u64;
	// 831E44E8: 4805E585  bl 0x83242a6c
	ctx.lr = 0x831E44EC;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E44EC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E44F0: 4805EC7D  bl 0x8324316c
	ctx.lr = 0x831E44F4;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E44F4: 38600002  li r3, 2
	ctx.r[3].s64 = 2;
	// 831E44F8: 4B5EACE1  bl 0x827cf1d8
	ctx.lr = 0x831E44FC;
	sub_827CF1D8(ctx, base);
	// 831E44FC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E4500: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E4504: 4BFC3CB4  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
	// 831E4508: 4805EC55  bl 0x8324315c
	ctx.lr = 0x831E450C;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E450C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E4510: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831E4514: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831E4518: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E451C: 419A0010  beq cr6, 0x831e452c
	if ctx.cr[6].eq {
	pc = 0x831E452C; continue 'dispatch;
	}
	// 831E4520: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E4524: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E4528: 419A0018  beq cr6, 0x831e4540
	if ctx.cr[6].eq {
	pc = 0x831E4540; continue 'dispatch;
	}
	// 831E452C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E4530: 4805E54D  bl 0x83242a7c
	ctx.lr = 0x831E4534;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E4534: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E4538: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831E453C: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831E4540: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E4544: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E4548: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E454C: 897C003D  lbz r11, 0x3d(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(61 as u32) ) } as u64;
	// 831E4550: 61690004  ori r9, r11, 4
	ctx.r[9].u64 = ctx.r[11].u64 | 4;
	// 831E4554: 993C003D  stb r9, 0x3d(r28)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[28].u32.wrapping_add(61 as u32), ctx.r[9].u8 ) };
	// 831E4558: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E455C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E4560: 419A0044  beq cr6, 0x831e45a4
	if ctx.cr[6].eq {
	pc = 0x831E45A4; continue 'dispatch;
	}
	// 831E4564: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E4568: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E456C: 409A0038  bne cr6, 0x831e45a4
	if !ctx.cr[6].eq {
	pc = 0x831E45A4; continue 'dispatch;
	}
	// 831E4570: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E4574: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E4578: 4082002C  bne 0x831e45a4
	if !ctx.cr[0].eq {
	pc = 0x831E45A4; continue 'dispatch;
	}
	// 831E457C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E4580: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E4584: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E4588: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E458C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E4590: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E4594: 4805E4D9  bl 0x83242a6c
	ctx.lr = 0x831E4598;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E4598: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E459C: 4805EBD1  bl 0x8324316c
	ctx.lr = 0x831E45A0;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E45A0: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E45A4: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E45A8: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E45AC: 419A0040  beq cr6, 0x831e45ec
	if ctx.cr[6].eq {
	pc = 0x831E45EC; continue 'dispatch;
	}
	// 831E45B0: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E45B4: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E45B8: 409A0034  bne cr6, 0x831e45ec
	if !ctx.cr[6].eq {
	pc = 0x831E45EC; continue 'dispatch;
	}
	// 831E45BC: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E45C0: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E45C4: 40820028  bne 0x831e45ec
	if !ctx.cr[0].eq {
	pc = 0x831E45EC; continue 'dispatch;
	}
	// 831E45C8: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E45CC: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E45D0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E45D4: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E45D8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E45DC: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E45E0: 4805E48D  bl 0x83242a6c
	ctx.lr = 0x831E45E4;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E45E4: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E45E8: 4805EB85  bl 0x8324316c
	ctx.lr = 0x831E45EC;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E45EC: A17C003E  lhz r11, 0x3e(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[28].u32.wrapping_add(62 as u32) ) } as u64;
	// 831E45F0: B17C0040  sth r11, 0x40(r28)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[28].u32.wrapping_add(64 as u32), ctx.r[11].u16 ) };
	// 831E45F4: 38600002  li r3, 2
	ctx.r[3].s64 = 2;
	// 831E45F8: 4B5EABE1  bl 0x827cf1d8
	ctx.lr = 0x831E45FC;
	sub_827CF1D8(ctx, base);
	// 831E45FC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E4600: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E4604: 4BFC3BB4  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E4608(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E4608 size=308
    let mut pc: u32 = 0x831E4608;
    'dispatch: loop {
        match pc {
            0x831E4608 => {
    //   block [0x831E4608..0x831E473C)
	// 831E4608: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E460C: 4BFC3B5D  bl 0x831a8168
	ctx.lr = 0x831E4610;
	sub_831A8130(ctx, base);
	// 831E4610: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E4614: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 831E4618: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E461C: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 831E4620: 7FBCEB78  mr r28, r29
	ctx.r[28].u64 = ctx.r[29].u64;
	// 831E4624: 817E0010  lwz r11, 0x10(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E4628: 917F002C  stw r11, 0x2c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(44 as u32), ctx.r[11].u32 ) };
	// 831E462C: 815E0014  lwz r10, 0x14(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E4630: 915F0030  stw r10, 0x30(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(48 as u32), ctx.r[10].u32 ) };
	// 831E4634: 813E0000  lwz r9, 0(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E4638: 913F0034  stw r9, 0x34(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(52 as u32), ctx.r[9].u32 ) };
	// 831E463C: 811E0004  lwz r8, 4(r30)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E4640: 911F0038  stw r8, 0x38(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(56 as u32), ctx.r[8].u32 ) };
	// 831E4644: 817E0008  lwz r11, 8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E4648: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E464C: 419A000C  beq cr6, 0x831e4658
	if ctx.cr[6].eq {
	pc = 0x831E4658; continue 'dispatch;
	}
	// 831E4650: 896B0000  lbz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E4654: 48000008  b 0x831e465c
	pc = 0x831E465C; continue 'dispatch;
	// 831E4658: 7FABEB78  mr r11, r29
	ctx.r[11].u64 = ctx.r[29].u64;
	// 831E465C: 997F003C  stb r11, 0x3c(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(60 as u32), ctx.r[11].u8 ) };
	// 831E4660: 817E000C  lwz r11, 0xc(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E4664: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E4668: 419A001C  beq cr6, 0x831e4684
	if ctx.cr[6].eq {
	pc = 0x831E4684; continue 'dispatch;
	}
	// 831E466C: 917F0020  stw r11, 0x20(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[11].u32 ) };
	// 831E4670: 807E000C  lwz r3, 0xc(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E4674: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E4678: 419A0054  beq cr6, 0x831e46cc
	if ctx.cr[6].eq {
	pc = 0x831E46CC; continue 'dispatch;
	}
	// 831E467C: 4BFFD9C5  bl 0x831e2040
	ctx.lr = 0x831E4680;
	sub_831E2040(ctx, base);
	// 831E4680: 4800004C  b 0x831e46cc
	pc = 0x831E46CC; continue 'dispatch;
	// 831E4684: 39610050  addi r11, r1, 0x50
	ctx.r[11].s64 = ctx.r[1].s64 + 80;
	// 831E4688: 895E0001  lbz r10, 1(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(1 as u32) ) } as u64;
	// 831E468C: 3D200000  lis r9, 0
	ctx.r[9].s64 = 0;
	// 831E4690: 809F0008  lwz r4, 8(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E4694: 38BF0020  addi r5, r31, 0x20
	ctx.r[5].s64 = ctx.r[31].s64 + 32;
	// 831E4698: 6128BB80  ori r8, r9, 0xbb80
	ctx.r[8].u64 = ctx.r[9].u64 | 48000;
	// 831E469C: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 831E46A0: FBAB0000  std r29, 0(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[29].u64 ) };
	// 831E46A4: FBAB0008  std r29, 8(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[29].u64 ) };
	// 831E46A8: 93AB0010  stw r29, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[29].u32 ) };
	// 831E46AC: 9BA10054  stb r29, 0x54(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[29].u8 ) };
	// 831E46B0: 99410055  stb r10, 0x55(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(85 as u32), ctx.r[10].u8 ) };
	// 831E46B4: 91010058  stw r8, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[8].u32 ) };
	// 831E46B8: 9BA10050  stb r29, 0x50(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[29].u8 ) };
	// 831E46BC: 4BFFDC9D  bl 0x831e2358
	ctx.lr = 0x831E46C0;
	sub_831E2358(ctx, base);
	// 831E46C0: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E46C4: 2F1C0000  cmpwi cr6, r28, 0
	ctx.cr[6].compare_i32(ctx.r[28].s32, 0, &mut ctx.xer);
	// 831E46C8: 41980068  blt cr6, 0x831e4730
	if ctx.cr[6].lt {
	pc = 0x831E4730; continue 'dispatch;
	}
	// 831E46CC: 897F003C  lbz r11, 0x3c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(60 as u32) ) } as u64;
	// 831E46D0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E46D4: 419A002C  beq cr6, 0x831e4700
	if ctx.cr[6].eq {
	pc = 0x831E4700; continue 'dispatch;
	}
	// 831E46D8: 807F0008  lwz r3, 8(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E46DC: 55641838  slwi r4, r11, 3
	ctx.r[4].u32 = ctx.r[11].u32.wrapping_shl(3);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 831E46E0: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E46E4: 814B0014  lwz r10, 0x14(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E46E8: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E46EC: 4E800421  bctrl
	ctx.lr = 0x831E46F0;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E46F0: 907F0024  stw r3, 0x24(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), ctx.r[3].u32 ) };
	// 831E46F4: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E46F8: 419A0028  beq cr6, 0x831e4720
	if ctx.cr[6].eq {
	pc = 0x831E4720; continue 'dispatch;
	}
	// 831E46FC: 7FBCEB78  mr r28, r29
	ctx.r[28].u64 = ctx.r[29].u64;
	// 831E4700: 897F003C  lbz r11, 0x3c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(60 as u32) ) } as u64;
	// 831E4704: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E4708: 419A0028  beq cr6, 0x831e4730
	if ctx.cr[6].eq {
	pc = 0x831E4730; continue 'dispatch;
	}
	// 831E470C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E4710: 809E0008  lwz r4, 8(r30)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E4714: 4BFFF77D  bl 0x831e3e90
	ctx.lr = 0x831E4718;
	sub_831E3E90(ctx, base);
	// 831E4718: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831E471C: 4BFC3A9C  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
	// 831E4720: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 831E4724: 6063000E  ori r3, r3, 0xe
	ctx.r[3].u64 = ctx.r[3].u64 | 14;
	// 831E4728: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831E472C: 4BFC3A8C  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
	// 831E4730: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 831E4734: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831E4738: 4BFC3A80  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E4740(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E4740 size=104
    let mut pc: u32 = 0x831E4740;
    'dispatch: loop {
        match pc {
            0x831E4740 => {
    //   block [0x831E4740..0x831E47A8)
	// 831E4740: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E4744: 4BFC3A29  bl 0x831a816c
	ctx.lr = 0x831E4748;
	sub_831A8130(ctx, base);
	// 831E4748: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E474C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E4750: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 831E4754: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E4758: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E475C: 895F003C  lbz r10, 0x3c(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(60 as u32) ) } as u64;
	// 831E4760: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E4764: 419A003C  beq cr6, 0x831e47a0
	if ctx.cr[6].eq {
	pc = 0x831E47A0; continue 'dispatch;
	}
	// 831E4768: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E476C: 41980034  blt cr6, 0x831e47a0
	if ctx.cr[6].lt {
	pc = 0x831E47A0; continue 'dispatch;
	}
	// 831E4770: 813F0024  lwz r9, 0x24(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(36 as u32) ) } as u64;
	// 831E4774: 556A1D78  rlwinm r10, r11, 3, 0x15, 0x1c
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0x1FFFFFFFu64;
	// 831E4778: 7FA5EB78  mr r5, r29
	ctx.r[5].u64 = ctx.r[29].u64;
	// 831E477C: 7C8A4A14  add r4, r10, r9
	ctx.r[4].u64 = ctx.r[10].u64 + ctx.r[9].u64;
	// 831E4780: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E4784: 557E063E  clrlwi r30, r11, 0x18
	ctx.r[30].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 831E4788: 4BFFF779  bl 0x831e3f00
	ctx.lr = 0x831E478C;
	sub_831E3F00(ctx, base);
	// 831E478C: 397E0001  addi r11, r30, 1
	ctx.r[11].s64 = ctx.r[30].s64 + 1;
	// 831E4790: 895F003C  lbz r10, 0x3c(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(60 as u32) ) } as u64;
	// 831E4794: 556B063E  clrlwi r11, r11, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 831E4798: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E479C: 4198FFCC  blt cr6, 0x831e4768
	if ctx.cr[6].lt {
	pc = 0x831E4768; continue 'dispatch;
	}
	// 831E47A0: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E47A4: 4BFC3A18  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E47A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831E47A8 size=136
    let mut pc: u32 = 0x831E47A8;
    'dispatch: loop {
        match pc {
            0x831E47A8 => {
    //   block [0x831E47A8..0x831E4830)
	// 831E47A8: 3CE0821A  lis r7, -0x7de6
	ctx.r[7].s64 = -2112225280;
	// 831E47AC: 3CC0821A  lis r6, -0x7de6
	ctx.r[6].s64 = -2112225280;
	// 831E47B0: 3CA0821A  lis r5, -0x7de6
	ctx.r[5].s64 = -2112225280;
	// 831E47B4: 3C80821A  lis r4, -0x7de6
	ctx.r[4].s64 = -2112225280;
	// 831E47B8: 39600008  li r11, 8
	ctx.r[11].s64 = 8;
	// 831E47BC: C0070370  lfs f0, 0x370(r7)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(880 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E47C0: 39400005  li r10, 5
	ctx.r[10].s64 = 5;
	// 831E47C4: C1A60378  lfs f13, 0x378(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(888 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E47C8: 39000006  li r8, 6
	ctx.r[8].s64 = 6;
	// 831E47CC: 39200004  li r9, 4
	ctx.r[9].s64 = 4;
	// 831E47D0: D0030038  stfs f0, 0x38(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(56 as u32), tmp.u32 ) };
	// 831E47D4: D003003C  stfs f0, 0x3c(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(60 as u32), tmp.u32 ) };
	// 831E47D8: 91430000  stw r10, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E47DC: D0030040  stfs f0, 0x40(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(64 as u32), tmp.u32 ) };
	// 831E47E0: 91430004  stw r10, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831E47E4: D1A3004C  stfs f13, 0x4c(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(76 as u32), tmp.u32 ) };
	// 831E47E8: 91030008  stw r8, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 831E47EC: C005036C  lfs f0, 0x36c(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(876 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E47F0: 9103000C  stw r8, 0xc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[8].u32 ) };
	// 831E47F4: C1A70370  lfs f13, 0x370(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(880 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E47F8: 91630018  stw r11, 0x18(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(24 as u32), ctx.r[11].u32 ) };
	// 831E47FC: C1840374  lfs f12, 0x374(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(884 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831E4800: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831E4804: C1660378  lfs f11, 0x378(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(888 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831E4808: 91630020  stw r11, 0x20(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(32 as u32), ctx.r[11].u32 ) };
	// 831E480C: D0030034  stfs f0, 0x34(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 831E4810: 91230024  stw r9, 0x24(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), ctx.r[9].u32 ) };
	// 831E4814: D1A30044  stfs f13, 0x44(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(68 as u32), tmp.u32 ) };
	// 831E4818: 91630028  stw r11, 0x28(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(40 as u32), ctx.r[11].u32 ) };
	// 831E481C: D1830048  stfs f12, 0x48(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(72 as u32), tmp.u32 ) };
	// 831E4820: 9123002C  stw r9, 0x2c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(44 as u32), ctx.r[9].u32 ) };
	// 831E4824: D1630050  stfs f11, 0x50(r3)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 831E4828: 91430030  stw r10, 0x30(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(48 as u32), ctx.r[10].u32 ) };
	// 831E482C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E4830(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831E4830 size=356
    let mut pc: u32 = 0x831E4830;
    'dispatch: loop {
        match pc {
            0x831E4830 => {
    //   block [0x831E4830..0x831E4994)
	// 831E4830: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E4834: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E4838: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E483C: 3981FFF0  addi r12, r1, -0x10
	ctx.r[12].s64 = ctx.r[1].s64 + -16;
	// 831E4840: 4BFC4231  bl 0x831a8a70
	ctx.lr = 0x831E4844;
	sub_831A8A40(ctx, base);
	// 831E4844: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E4848: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E484C: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E4850: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831E4854: C01F000C  lfs f0, 0xc(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E4858: C1BF0008  lfs f13, 8(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E485C: EFE0682A  fadds f31, f0, f13
	ctx.f[31].f64 = ((ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64;
	// 831E4860: C34B0370  lfs f26, 0x370(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(880 as u32) ) };
	ctx.f[26].f64 = (tmp.f32 as f64);
	// 831E4864: C00A0374  lfs f0, 0x374(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(884 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E4868: FF1FD000  fcmpu cr6, f31, f26
	ctx.cr[6].compare_f64(ctx.f[31].f64, ctx.f[26].f64);
	// 831E486C: 4098000C  bge cr6, 0x831e4878
	if !ctx.cr[6].lt {
	pc = 0x831E4878; continue 'dispatch;
	}
	// 831E4870: EF8DF824  fdivs f28, f13, f31
	ctx.f[28].f64 = ((ctx.f[13].f64 / ctx.f[31].f64) as f32) as f64;
	// 831E4874: 48000008  b 0x831e487c
	pc = 0x831E487C; continue 'dispatch;
	// 831E4878: FF800090  fmr f28, f0
	ctx.f[28].f64 = ctx.f[0].f64;
	// 831E487C: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E4880: EDA0E028  fsubs f13, f0, f28
	ctx.f[13].f64 = (((ctx.f[0].f64 - ctx.f[28].f64) as f32) as f64);
	// 831E4884: C19F0004  lfs f12, 4(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831E4888: 3D408204  lis r10, -0x7dfc
	ctx.r[10].s64 = -2113667072;
	// 831E488C: C17F0000  lfs f11, 0(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831E4890: 3D208201  lis r9, -0x7dff
	ctx.r[9].s64 = -2113863680;
	// 831E4894: C80B1010  lfd f0, 0x1010(r11)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(4112 as u32) ) };
	// 831E4898: FD4C0032  fmul f10, f12, f0
	ctx.f[10].f64 = ctx.f[12].f64 * ctx.f[0].f64;
	// 831E489C: CBCAD1E0  lfd f30, -0x2e20(r10)
	ctx.f[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[10].u32.wrapping_add(-11808 as u32) ) };
	// 831E48A0: C009964C  lfs f0, -0x69b4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-27060 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E48A4: FC20F090  fmr f1, f30
	ctx.f[1].f64 = ctx.f[30].f64;
	// 831E48A8: ED2D07F2  fmuls f9, f13, f31
	ctx.f[9].f64 = (((ctx.f[13].f64 * ctx.f[31].f64) as f32) as f64);
	// 831E48AC: FD0A5824  fdiv f8, f10, f11
	ctx.f[8].f64 = ctx.f[10].f64 / ctx.f[11].f64;
	// 831E48B0: EC490032  fmuls f2, f9, f0
	ctx.f[2].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E48B4: FF604018  frsp f27, f8
	ctx.f[27].f64 = (ctx.f[8].f64 as f32) as f64;
	// 831E48B8: 4BFC6BF1  bl 0x831ab4a8
	ctx.lr = 0x831E48BC;
	sub_831AB4A8(ctx, base);
	// 831E48BC: 3D00820D  lis r8, -0x7df3
	ctx.r[8].s64 = -2113077248;
	// 831E48C0: FC200818  frsp f1, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[1].f64 = (ctx.f[1].f64 as f32) as f64;
	// 831E48C4: CBA8D760  lfd f29, -0x28a0(r8)
	ctx.f[29].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[8].u32.wrapping_add(-10400 as u32) ) };
	// 831E48C8: FC40E890  fmr f2, f29
	ctx.f[2].f64 = ctx.f[29].f64;
	// 831E48CC: 4BFC6BDD  bl 0x831ab4a8
	ctx.lr = 0x831E48D0;
	sub_831AB4A8(ctx, base);
	// 831E48D0: ECFC07F2  fmuls f7, f28, f31
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[7].f64 = (((ctx.f[28].f64 * ctx.f[31].f64) as f32) as f64);
	// 831E48D4: 3CE08201  lis r7, -0x7dff
	ctx.r[7].s64 = -2113863680;
	// 831E48D8: FFE00818  frsp f31, f1
	ctx.f[31].f64 = (ctx.f[1].f64 as f32) as f64;
	// 831E48DC: FC20F090  fmr f1, f30
	ctx.f[1].f64 = ctx.f[30].f64;
	// 831E48E0: C0079F78  lfs f0, -0x6088(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(-24712 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E48E4: EC470032  fmuls f2, f7, f0
	ctx.f[2].f64 = (((ctx.f[7].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E48E8: 4BFC6BC1  bl 0x831ab4a8
	ctx.lr = 0x831E48EC;
	sub_831AB4A8(ctx, base);
	// 831E48EC: FC200818  frsp f1, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[1].f64 = (ctx.f[1].f64 as f32) as f64;
	// 831E48F0: D03F0018  stfs f1, 0x18(r31)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 831E48F4: FC40E890  fmr f2, f29
	ctx.f[2].f64 = ctx.f[29].f64;
	// 831E48F8: 4BFC6BB1  bl 0x831ab4a8
	ctx.lr = 0x831E48FC;
	sub_831AB4A8(ctx, base);
	// 831E48FC: 3CC0821A  lis r6, -0x7de6
	ctx.r[6].s64 = -2112225280;
	// 831E4900: FCC00818  frsp f6, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[6].f64 = (ctx.f[1].f64 as f32) as f64;
	// 831E4904: D0DF0018  stfs f6, 0x18(r31)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 831E4908: C0061008  lfs f0, 0x1008(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(4104 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E490C: FF1F0000  fcmpu cr6, f31, f0
	ctx.cr[6].compare_f64(ctx.f[31].f64, ctx.f[0].f64);
	// 831E4910: 40980064  bge cr6, 0x831e4974
	if !ctx.cr[6].lt {
	pc = 0x831E4974; continue 'dispatch;
	}
	// 831E4914: FC20D890  fmr f1, f27
	ctx.f[1].f64 = ctx.f[27].f64;
	// 831E4918: 4BFC4591  bl 0x831a8ea8
	ctx.lr = 0x831E491C;
	sub_831A8EA8(ctx, base);
	// 831E491C: FD800818  frsp f12, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[12].f64 = (ctx.f[1].f64 as f32) as f64;
	// 831E4920: 3D608205  lis r11, -0x7dfb
	ctx.r[11].s64 = -2113601536;
	// 831E4924: ED7F07F2  fmuls f11, f31, f31
	ctx.f[11].f64 = (((ctx.f[31].f64 * ctx.f[31].f64) as f32) as f64);
	// 831E4928: 3D408205  lis r10, -0x7dfb
	ctx.r[10].s64 = -2113601536;
	// 831E492C: C80BE3A0  lfd f0, -0x1c60(r11)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(-7264 as u32) ) };
	// 831E4930: C9AAAA10  lfd f13, -0x55f0(r10)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[10].u32.wrapping_add(-22000 as u32) ) };
	// 831E4934: FD40F828  fsub f10, f0, f31
	ctx.f[10].f64 = ctx.f[0].f64 - ctx.f[31].f64;
	// 831E4938: ED2C0332  fmuls f9, f12, f12
	ctx.f[9].f64 = (((ctx.f[12].f64 * ctx.f[12].f64) as f32) as f64);
	// 831E493C: FD006028  fsub f8, f0, f12
	ctx.f[8].f64 = ctx.f[0].f64 - ctx.f[12].f64;
	// 831E4940: ECEC07F2  fmuls f7, f12, f31
	ctx.f[7].f64 = (((ctx.f[12].f64 * ctx.f[31].f64) as f32) as f64);
	// 831E4944: FCC05018  frsp f6, f10
	ctx.f[6].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831E4948: FCA04828  fsub f5, f0, f9
	ctx.f[5].f64 = ctx.f[0].f64 - ctx.f[9].f64;
	// 831E494C: FC8807F2  fmul f4, f8, f31
	ctx.f[4].f64 = ctx.f[8].f64 * ctx.f[31].f64;
	// 831E4950: FC603828  fsub f3, f0, f7
	ctx.f[3].f64 = ctx.f[0].f64 - ctx.f[7].f64;
	// 831E4954: FC4502F2  fmul f2, f5, f11
	ctx.f[2].f64 = ctx.f[5].f64 * ctx.f[11].f64;
	// 831E4958: FC241378  fmsub f1, f4, f13, f2
	ctx.f[1].f64 = ctx.f[4].f64 * ctx.f[13].f64 - ctx.f[2].f64;
	// 831E495C: FC00082C  fsqrt f0, f1
	ctx.f[0].f64 = (ctx.f[1].f64).sqrt();
	// 831E4960: FDA30028  fsub f13, f3, f0
	ctx.f[13].f64 = ctx.f[3].f64 - ctx.f[0].f64;
	// 831E4964: FD806818  frsp f12, f13
	ctx.f[12].f64 = (ctx.f[13].f64 as f32) as f64;
	// 831E4968: ED6C3024  fdivs f11, f12, f6
	ctx.f[11].f64 = ((ctx.f[12].f64 / ctx.f[6].f64) as f32) as f64;
	// 831E496C: D17F001C  stfs f11, 0x1c(r31)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 831E4970: 48000008  b 0x831e4978
	pc = 0x831E4978; continue 'dispatch;
	// 831E4974: D35F001C  stfs f26, 0x1c(r31)
	tmp.f32 = (ctx.f[26].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 831E4978: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831E497C: 3981FFF0  addi r12, r1, -0x10
	ctx.r[12].s64 = ctx.r[1].s64 + -16;
	// 831E4980: 4BFC413D  bl 0x831a8abc
	ctx.lr = 0x831E4984;
	sub_831A8A8C(ctx, base);
	// 831E4984: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E4988: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E498C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E4990: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E4998(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831E4998 size=96
    let mut pc: u32 = 0x831E4998;
    'dispatch: loop {
        match pc {
            0x831E4998 => {
    //   block [0x831E4998..0x831E49F8)
	// 831E4998: 3963000C  addi r11, r3, 0xc
	ctx.r[11].s64 = ctx.r[3].s64 + 12;
	// 831E499C: 39400800  li r10, 0x800
	ctx.r[10].s64 = 2048;
	// 831E49A0: C0030004  lfs f0, 4(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E49A4: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831E49A8: D00BFFFC  stfs f0, -4(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 831E49AC: C1A30004  lfs f13, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E49B0: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831E49B4: C1830004  lfs f12, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831E49B8: D18B0004  stfs f12, 4(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E49BC: C1630004  lfs f11, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831E49C0: D16B0008  stfs f11, 8(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E49C4: C1430004  lfs f10, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831E49C8: D14B000C  stfs f10, 0xc(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E49CC: C1230004  lfs f9, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831E49D0: D12B0010  stfs f9, 0x10(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831E49D4: C1030004  lfs f8, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831E49D8: D10B0014  stfs f8, 0x14(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E49DC: C0E30004  lfs f7, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831E49E0: D0EB0018  stfs f7, 0x18(r11)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 831E49E4: 396B0020  addi r11, r11, 0x20
	ctx.r[11].s64 = ctx.r[11].s64 + 32;
	// 831E49E8: 4082FFB8  bne 0x831e49a0
	if !ctx.cr[0].eq {
	pc = 0x831E49A0; continue 'dispatch;
	}
	// 831E49EC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E49F0: 91630000  stw r11, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831E49F4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E49F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831E49F8 size=96
    let mut pc: u32 = 0x831E49F8;
    'dispatch: loop {
        match pc {
            0x831E49F8 => {
    //   block [0x831E49F8..0x831E4A58)
	// 831E49F8: 3963000C  addi r11, r3, 0xc
	ctx.r[11].s64 = ctx.r[3].s64 + 12;
	// 831E49FC: 39400040  li r10, 0x40
	ctx.r[10].s64 = 64;
	// 831E4A00: C0030004  lfs f0, 4(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E4A04: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831E4A08: D00BFFFC  stfs f0, -4(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 831E4A0C: C1A30004  lfs f13, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E4A10: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831E4A14: C1830004  lfs f12, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831E4A18: D18B0004  stfs f12, 4(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E4A1C: C1630004  lfs f11, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831E4A20: D16B0008  stfs f11, 8(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E4A24: C1430004  lfs f10, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831E4A28: D14B000C  stfs f10, 0xc(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E4A2C: C1230004  lfs f9, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831E4A30: D12B0010  stfs f9, 0x10(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831E4A34: C1030004  lfs f8, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831E4A38: D10B0014  stfs f8, 0x14(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E4A3C: C0E30004  lfs f7, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831E4A40: D0EB0018  stfs f7, 0x18(r11)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 831E4A44: 396B0020  addi r11, r11, 0x20
	ctx.r[11].s64 = ctx.r[11].s64 + 32;
	// 831E4A48: 4082FFB8  bne 0x831e4a00
	if !ctx.cr[0].eq {
	pc = 0x831E4A00; continue 'dispatch;
	}
	// 831E4A4C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E4A50: 91630000  stw r11, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831E4A54: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E4A58(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831E4A58 size=96
    let mut pc: u32 = 0x831E4A58;
    'dispatch: loop {
        match pc {
            0x831E4A58 => {
    //   block [0x831E4A58..0x831E4AB8)
	// 831E4A58: 3963000C  addi r11, r3, 0xc
	ctx.r[11].s64 = ctx.r[3].s64 + 12;
	// 831E4A5C: 39400010  li r10, 0x10
	ctx.r[10].s64 = 16;
	// 831E4A60: C0030004  lfs f0, 4(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E4A64: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831E4A68: D00BFFFC  stfs f0, -4(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 831E4A6C: C1A30004  lfs f13, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E4A70: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831E4A74: C1830004  lfs f12, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831E4A78: D18B0004  stfs f12, 4(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E4A7C: C1630004  lfs f11, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831E4A80: D16B0008  stfs f11, 8(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E4A84: C1430004  lfs f10, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831E4A88: D14B000C  stfs f10, 0xc(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E4A8C: C1230004  lfs f9, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831E4A90: D12B0010  stfs f9, 0x10(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831E4A94: C1030004  lfs f8, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831E4A98: D10B0014  stfs f8, 0x14(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E4A9C: C0E30004  lfs f7, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831E4AA0: D0EB0018  stfs f7, 0x18(r11)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 831E4AA4: 396B0020  addi r11, r11, 0x20
	ctx.r[11].s64 = ctx.r[11].s64 + 32;
	// 831E4AA8: 4082FFB8  bne 0x831e4a60
	if !ctx.cr[0].eq {
	pc = 0x831E4A60; continue 'dispatch;
	}
	// 831E4AAC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E4AB0: 91630000  stw r11, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831E4AB4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E4AB8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831E4AB8 size=96
    let mut pc: u32 = 0x831E4AB8;
    'dispatch: loop {
        match pc {
            0x831E4AB8 => {
    //   block [0x831E4AB8..0x831E4B18)
	// 831E4AB8: 3963000C  addi r11, r3, 0xc
	ctx.r[11].s64 = ctx.r[3].s64 + 12;
	// 831E4ABC: 39400100  li r10, 0x100
	ctx.r[10].s64 = 256;
	// 831E4AC0: C0030004  lfs f0, 4(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E4AC4: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831E4AC8: D00BFFFC  stfs f0, -4(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 831E4ACC: C1A30004  lfs f13, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E4AD0: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831E4AD4: C1830004  lfs f12, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831E4AD8: D18B0004  stfs f12, 4(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E4ADC: C1630004  lfs f11, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831E4AE0: D16B0008  stfs f11, 8(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E4AE4: C1430004  lfs f10, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831E4AE8: D14B000C  stfs f10, 0xc(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E4AEC: C1230004  lfs f9, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831E4AF0: D12B0010  stfs f9, 0x10(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831E4AF4: C1030004  lfs f8, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831E4AF8: D10B0014  stfs f8, 0x14(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E4AFC: C0E30004  lfs f7, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831E4B00: D0EB0018  stfs f7, 0x18(r11)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 831E4B04: 396B0020  addi r11, r11, 0x20
	ctx.r[11].s64 = ctx.r[11].s64 + 32;
	// 831E4B08: 4082FFB8  bne 0x831e4ac0
	if !ctx.cr[0].eq {
	pc = 0x831E4AC0; continue 'dispatch;
	}
	// 831E4B0C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E4B10: 91630000  stw r11, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831E4B14: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E4B18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831E4B18 size=96
    let mut pc: u32 = 0x831E4B18;
    'dispatch: loop {
        match pc {
            0x831E4B18 => {
    //   block [0x831E4B18..0x831E4B78)
	// 831E4B18: 3963000C  addi r11, r3, 0xc
	ctx.r[11].s64 = ctx.r[3].s64 + 12;
	// 831E4B1C: 39400020  li r10, 0x20
	ctx.r[10].s64 = 32;
	// 831E4B20: C0030004  lfs f0, 4(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E4B24: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831E4B28: D00BFFFC  stfs f0, -4(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 831E4B2C: C1A30004  lfs f13, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E4B30: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831E4B34: C1830004  lfs f12, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831E4B38: D18B0004  stfs f12, 4(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E4B3C: C1630004  lfs f11, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831E4B40: D16B0008  stfs f11, 8(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E4B44: C1430004  lfs f10, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831E4B48: D14B000C  stfs f10, 0xc(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E4B4C: C1230004  lfs f9, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831E4B50: D12B0010  stfs f9, 0x10(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831E4B54: C1030004  lfs f8, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831E4B58: D10B0014  stfs f8, 0x14(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E4B5C: C0E30004  lfs f7, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831E4B60: D0EB0018  stfs f7, 0x18(r11)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 831E4B64: 396B0020  addi r11, r11, 0x20
	ctx.r[11].s64 = ctx.r[11].s64 + 32;
	// 831E4B68: 4082FFB8  bne 0x831e4b20
	if !ctx.cr[0].eq {
	pc = 0x831E4B20; continue 'dispatch;
	}
	// 831E4B6C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E4B70: 91630000  stw r11, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831E4B74: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E4B78(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831E4B78 size=96
    let mut pc: u32 = 0x831E4B78;
    'dispatch: loop {
        match pc {
            0x831E4B78 => {
    //   block [0x831E4B78..0x831E4BD8)
	// 831E4B78: 3963000C  addi r11, r3, 0xc
	ctx.r[11].s64 = ctx.r[3].s64 + 12;
	// 831E4B7C: 39400080  li r10, 0x80
	ctx.r[10].s64 = 128;
	// 831E4B80: C0030004  lfs f0, 4(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E4B84: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831E4B88: D00BFFFC  stfs f0, -4(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 831E4B8C: C1A30004  lfs f13, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E4B90: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831E4B94: C1830004  lfs f12, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831E4B98: D18B0004  stfs f12, 4(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E4B9C: C1630004  lfs f11, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831E4BA0: D16B0008  stfs f11, 8(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E4BA4: C1430004  lfs f10, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831E4BA8: D14B000C  stfs f10, 0xc(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E4BAC: C1230004  lfs f9, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831E4BB0: D12B0010  stfs f9, 0x10(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831E4BB4: C1030004  lfs f8, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831E4BB8: D10B0014  stfs f8, 0x14(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E4BBC: C0E30004  lfs f7, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831E4BC0: D0EB0018  stfs f7, 0x18(r11)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 831E4BC4: 396B0020  addi r11, r11, 0x20
	ctx.r[11].s64 = ctx.r[11].s64 + 32;
	// 831E4BC8: 4082FFB8  bne 0x831e4b80
	if !ctx.cr[0].eq {
	pc = 0x831E4B80; continue 'dispatch;
	}
	// 831E4BCC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E4BD0: 91630000  stw r11, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831E4BD4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E4BD8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831E4BD8 size=96
    let mut pc: u32 = 0x831E4BD8;
    'dispatch: loop {
        match pc {
            0x831E4BD8 => {
    //   block [0x831E4BD8..0x831E4C38)
	// 831E4BD8: 3963000C  addi r11, r3, 0xc
	ctx.r[11].s64 = ctx.r[3].s64 + 12;
	// 831E4BDC: 39400200  li r10, 0x200
	ctx.r[10].s64 = 512;
	// 831E4BE0: C0030004  lfs f0, 4(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E4BE4: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831E4BE8: D00BFFFC  stfs f0, -4(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 831E4BEC: C1A30004  lfs f13, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E4BF0: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831E4BF4: C1830004  lfs f12, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831E4BF8: D18B0004  stfs f12, 4(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E4BFC: C1630004  lfs f11, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831E4C00: D16B0008  stfs f11, 8(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E4C04: C1430004  lfs f10, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831E4C08: D14B000C  stfs f10, 0xc(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E4C0C: C1230004  lfs f9, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831E4C10: D12B0010  stfs f9, 0x10(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831E4C14: C1030004  lfs f8, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831E4C18: D10B0014  stfs f8, 0x14(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E4C1C: C0E30004  lfs f7, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831E4C20: D0EB0018  stfs f7, 0x18(r11)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 831E4C24: 396B0020  addi r11, r11, 0x20
	ctx.r[11].s64 = ctx.r[11].s64 + 32;
	// 831E4C28: 4082FFB8  bne 0x831e4be0
	if !ctx.cr[0].eq {
	pc = 0x831E4BE0; continue 'dispatch;
	}
	// 831E4C2C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E4C30: 91630000  stw r11, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831E4C34: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E4C38(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831E4C38 size=20
    let mut pc: u32 = 0x831E4C38;
    'dispatch: loop {
        match pc {
            0x831E4C38 => {
    //   block [0x831E4C38..0x831E4C4C)
	// 831E4C38: 3D608201  lis r11, -0x7dff
	ctx.r[11].s64 = -2113863680;
	// 831E4C3C: C00B9528  lfs f0, -0x6ad8(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-27352 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E4C40: EC010032  fmuls f0, f1, f0
	ctx.f[0].f64 = (((ctx.f[1].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E4C44: D003005C  stfs f0, 0x5c(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 831E4C48: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E4C50(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831E4C50 size=3480
    let mut pc: u32 = 0x831E4C50;
    'dispatch: loop {
        match pc {
            0x831E4C50 => {
    //   block [0x831E4C50..0x831E59E8)
	// 831E4C50: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E4C54: 4BFC34DD  bl 0x831a8130
	ctx.lr = 0x831E4C58;
	sub_831A8130(ctx, base);
	// 831E4C58: 3981FF68  addi r12, r1, -0x98
	ctx.r[12].s64 = ctx.r[1].s64 + -152;
	// 831E4C5C: 4BFC3DE5  bl 0x831a8a40
	ctx.lr = 0x831E4C60;
	sub_831A8A40(ctx, base);
	// 831E4C60: 9421FE60  stwu r1, -0x1a0(r1)
	ea = ctx.r[1].u32.wrapping_add(-416 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E4C64: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831E4C68: 38A00054  li r5, 0x54
	ctx.r[5].s64 = 84;
	// 831E4C6C: 387E0004  addi r3, r30, 4
	ctx.r[3].s64 = ctx.r[30].s64 + 4;
	// 831E4C70: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 831E4C74: 4BFC389D  bl 0x831a8510
	ctx.lr = 0x831E4C78;
	sub_831A8510(ctx, base);
	// 831E4C78: 3D408201  lis r10, -0x7dff
	ctx.r[10].s64 = -2113863680;
	// 831E4C7C: 817D0004  lwz r11, 4(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E4C80: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E4C84: C1CA9F7C  lfs f14, -0x6084(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-24708 as u32) ) };
	ctx.f[14].f64 = (tmp.f32 as f64);
	// 831E4C88: D1C10060  stfs f14, 0x60(r1)
	tmp.f32 = (ctx.f[14].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), tmp.u32 ) };
	// 831E4C8C: 409A000C  bne cr6, 0x831e4c98
	if !ctx.cr[6].eq {
	pc = 0x831E4C98; continue 'dispatch;
	}
	// 831E4C90: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 831E4C94: 48000030  b 0x831e4cc4
	pc = 0x831E4CC4; continue 'dispatch;
	// 831E4C98: 796B0020  clrldi r11, r11, 0x20
	ctx.r[11].u64 = ctx.r[11].u64 & 0x00000000FFFFFFFFu64;
	// 831E4C9C: C01E0058  lfs f0, 0x58(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(88 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E4CA0: F9610058  std r11, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[11].u64 ) };
	// 831E4CA4: C9A10058  lfd f13, 0x58(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 831E4CA8: FD806E9C  fcfid f12, f13
	ctx.f[12].f64 = (ctx.f[13].s64 as f64);
	// 831E4CAC: FD606018  frsp f11, f12
	ctx.f[11].f64 = (ctx.f[12].f64 as f32) as f64;
	// 831E4CB0: ED4002F2  fmuls f10, f0, f11
	ctx.f[10].f64 = (((ctx.f[0].f64 * ctx.f[11].f64) as f32) as f64);
	// 831E4CB4: ED2A03B2  fmuls f9, f10, f14
	ctx.f[9].f64 = (((ctx.f[10].f64 * ctx.f[14].f64) as f32) as f64);
	// 831E4CB8: FD004E5E  fctidz f8, f9
	ctx.f[8].s64 = if ctx.f[9].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[9].f64.trunc() as i64 };
	// 831E4CBC: D9010058  stfd f8, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.f[8].u64 ) };
	// 831E4CC0: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 831E4CC4: 480067E5  bl 0x831eb4a8
	ctx.lr = 0x831E4CC8;
	sub_831EB4A8(ctx, base);
	// 831E4CC8: 2B030FFF  cmplwi cr6, r3, 0xfff
	ctx.cr[6].compare_u32(ctx.r[3].u32, 4095 as u32, &mut ctx.xer);
	// 831E4CCC: 40990008  ble cr6, 0x831e4cd4
	if !ctx.cr[6].gt {
	pc = 0x831E4CD4; continue 'dispatch;
	}
	// 831E4CD0: 38600FFF  li r3, 0xfff
	ctx.r[3].s64 = 4095;
	// 831E4CD4: 3D400002  lis r10, 2
	ctx.r[10].s64 = 131072;
	// 831E4CD8: 3D600002  lis r11, 2
	ctx.r[11].s64 = 131072;
	// 831E4CDC: 3D200003  lis r9, 3
	ctx.r[9].s64 = 196608;
	// 831E4CE0: 3D000004  lis r8, 4
	ctx.r[8].s64 = 262144;
	// 831E4CE4: 6146EFC4  ori r6, r10, 0xefc4
	ctx.r[6].u64 = ctx.r[10].u64 | 61380;
	// 831E4CE8: 61679F08  ori r7, r11, 0x9f08
	ctx.r[7].u64 = ctx.r[11].u64 | 40712;
	// 831E4CEC: 6125A060  ori r5, r9, 0xa060
	ctx.r[5].u64 = ctx.r[9].u64 | 41056;
	// 831E4CF0: 61045100  ori r4, r8, 0x5100
	ctx.r[4].u64 = ctx.r[8].u64 | 20736;
	// 831E4CF4: 3D408200  lis r10, -0x7e00
	ctx.r[10].s64 = -2113929216;
	// 831E4CF8: 3D20821A  lis r9, -0x7de6
	ctx.r[9].s64 = -2112225280;
	// 831E4CFC: 7C7E312E  stwx r3, r30, r6
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[6].u32), ctx.r[3].u32) };
	// 831E4D00: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E4D04: 7C7E392E  stwx r3, r30, r7
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[7].u32), ctx.r[3].u32) };
	// 831E4D08: 7C7E292E  stwx r3, r30, r5
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[5].u32), ctx.r[3].u32) };
	// 831E4D0C: 7C7E212E  stwx r3, r30, r4
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[4].u32), ctx.r[3].u32) };
	// 831E4D10: C01D0050  lfs f0, 0x50(r29)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(80 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E4D14: C16A08AC  lfs f11, 0x8ac(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(2220 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831E4D18: 3BEB0380  addi r31, r11, 0x380
	ctx.r[31].s64 = ctx.r[11].s64 + 896;
	// 831E4D1C: C1E90374  lfs f15, 0x374(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(884 as u32) ) };
	ctx.f[15].f64 = (tmp.f32 as f64);
	// 831E4D20: FF005800  fcmpu cr6, f0, f11
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[11].f64);
	// 831E4D24: D1E10050  stfs f15, 0x50(r1)
	tmp.f32 = (ctx.f[15].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 831E4D28: 41980030  blt cr6, 0x831e4d58
	if ctx.cr[6].lt {
	pc = 0x831E4D58; continue 'dispatch;
	}
	// 831E4D2C: 3D608201  lis r11, -0x7dff
	ctx.r[11].s64 = -2113863680;
	// 831E4D30: C19E0058  lfs f12, 0x58(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(88 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831E4D34: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831E4D38: 3D208203  lis r9, -0x7dfd
	ctx.r[9].s64 = -2113732608;
	// 831E4D3C: C1AB9528  lfs f13, -0x6ad8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-27352 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E4D40: ED400372  fmuls f10, f0, f13
	ctx.f[10].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 831E4D44: C1AA1074  lfs f13, 0x1074(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4212 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E4D48: C0097BC8  lfs f0, 0x7bc8(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(31688 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E4D4C: ED2A0332  fmuls f9, f10, f12
	ctx.f[9].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 831E4D50: EF290372  fmuls f25, f9, f13
	ctx.f[25].f64 = (((ctx.f[9].f64 * ctx.f[13].f64) as f32) as f64);
	// 831E4D54: 4800003C  b 0x831e4d90
	pc = 0x831E4D90; continue 'dispatch;
	// 831E4D58: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 831E4D5C: C1BF0004  lfs f13, 4(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E4D60: 3D408201  lis r10, -0x7dff
	ctx.r[10].s64 = -2113863680;
	// 831E4D64: C15E0058  lfs f10, 0x58(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(88 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831E4D68: 3D20821A  lis r9, -0x7de6
	ctx.r[9].s64 = -2112225280;
	// 831E4D6C: 3D008203  lis r8, -0x7dfd
	ctx.r[8].s64 = -2113732608;
	// 831E4D70: C18B093C  lfs f12, 0x93c(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2364 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831E4D74: ED20637A  fmadds f9, f0, f13, f12
	ctx.f[9].f64 = (((ctx.f[0].f64 * ctx.f[13].f64 + ctx.f[12].f64) as f32) as f64);
	// 831E4D78: C1AA9528  lfs f13, -0x6ad8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-27352 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E4D7C: C1891074  lfs f12, 0x1074(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4212 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831E4D80: C0087BC8  lfs f0, 0x7bc8(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(31688 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E4D84: ED090372  fmuls f8, f9, f13
	ctx.f[8].f64 = (((ctx.f[9].f64 * ctx.f[13].f64) as f32) as f64);
	// 831E4D88: ECE802B2  fmuls f7, f8, f10
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[10].f64) as f32) as f64);
	// 831E4D8C: EF270332  fmuls f25, f7, f12
	ctx.f[25].f64 = (((ctx.f[7].f64 * ctx.f[12].f64) as f32) as f64);
	// 831E4D90: FF190000  fcmpu cr6, f25, f0
	ctx.cr[6].compare_f64(ctx.f[25].f64, ctx.f[0].f64);
	// 831E4D94: 40980008  bge cr6, 0x831e4d9c
	if !ctx.cr[6].lt {
	pc = 0x831E4D9C; continue 'dispatch;
	}
	// 831E4D98: FF200090  fmr f25, f0
	ctx.f[25].f64 = ctx.f[0].f64;
	// 831E4D9C: 3D608201  lis r11, -0x7dff
	ctx.r[11].s64 = -2113863680;
	// 831E4DA0: C1AB9524  lfs f13, -0x6adc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-27356 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E4DA4: EFD90372  fmuls f30, f25, f13
	ctx.f[30].f64 = (((ctx.f[25].f64 * ctx.f[13].f64) as f32) as f64);
	// 831E4DA8: FF1E0000  fcmpu cr6, f30, f0
	ctx.cr[6].compare_f64(ctx.f[30].f64, ctx.f[0].f64);
	// 831E4DAC: 4098000C  bge cr6, 0x831e4db8
	if !ctx.cr[6].lt {
	pc = 0x831E4DB8; continue 'dispatch;
	}
	// 831E4DB0: FFC00090  fmr f30, f0
	ctx.f[30].f64 = ctx.f[0].f64;
	// 831E4DB4: 48000010  b 0x831e4dc4
	pc = 0x831E4DC4; continue 'dispatch;
	// 831E4DB8: FF1E7800  fcmpu cr6, f30, f15
	ctx.cr[6].compare_f64(ctx.f[30].f64, ctx.f[15].f64);
	// 831E4DBC: 40990008  ble cr6, 0x831e4dc4
	if !ctx.cr[6].gt {
	pc = 0x831E4DC4; continue 'dispatch;
	}
	// 831E4DC0: FFC07890  fmr f30, f15
	ctx.f[30].f64 = ctx.f[15].f64;
	// 831E4DC4: 3D608201  lis r11, -0x7dff
	ctx.r[11].s64 = -2113863680;
	// 831E4DC8: C01D004C  lfs f0, 0x4c(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(76 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E4DCC: C1ABEF50  lfs f13, -0x10b0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4272 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E4DD0: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 831E4DD4: 41980024  blt cr6, 0x831e4df8
	if ctx.cr[6].lt {
	pc = 0x831E4DF8; continue 'dispatch;
	}
	// 831E4DD8: EDA06828  fsubs f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 - ctx.f[13].f64) as f32) as f64);
	// 831E4DDC: 3D60820A  lis r11, -0x7df6
	ctx.r[11].s64 = -2113273856;
	// 831E4DE0: FFA07890  fmr f29, f15
	ctx.f[29].f64 = ctx.f[15].f64;
	// 831E4DE4: FF807890  fmr f28, f15
	ctx.f[28].f64 = ctx.f[15].f64;
	// 831E4DE8: FF607890  fmr f27, f15
	ctx.f[27].f64 = ctx.f[15].f64;
	// 831E4DEC: C00B54AC  lfs f0, 0x54ac(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(21676 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E4DF0: EFED0032  fmuls f31, f13, f0
	ctx.f[31].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E4DF4: 4800006C  b 0x831e4e60
	pc = 0x831E4E60; continue 'dispatch;
	// 831E4DF8: FF005800  fcmpu cr6, f0, f11
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[11].f64);
	// 831E4DFC: 3D40820A  lis r10, -0x7df6
	ctx.r[10].s64 = -2113273856;
	// 831E4E00: 41980024  blt cr6, 0x831e4e24
	if ctx.cr[6].lt {
	pc = 0x831E4E24; continue 'dispatch;
	}
	// 831E4E04: EDA05828  fsubs f13, f0, f11
	ctx.f[13].f64 = (((ctx.f[0].f64 - ctx.f[11].f64) as f32) as f64);
	// 831E4E08: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E4E0C: C00A54AC  lfs f0, 0x54ac(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(21676 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E4E10: FF807890  fmr f28, f15
	ctx.f[28].f64 = ctx.f[15].f64;
	// 831E4E14: FF607890  fmr f27, f15
	ctx.f[27].f64 = ctx.f[15].f64;
	// 831E4E18: C3EB0370  lfs f31, 0x370(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(880 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 831E4E1C: EFAD0032  fmuls f29, f13, f0
	ctx.f[29].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E4E20: 48000040  b 0x831e4e60
	pc = 0x831E4E60; continue 'dispatch;
	// 831E4E24: 3D608201  lis r11, -0x7dff
	ctx.r[11].s64 = -2113863680;
	// 831E4E28: C1AB9D1C  lfs f13, -0x62e4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-25316 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E4E2C: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E4E30: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 831E4E34: C3EB0370  lfs f31, 0x370(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(880 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 831E4E38: FFA0F890  fmr f29, f31
	ctx.f[29].f64 = ctx.f[31].f64;
	// 831E4E3C: 41980018  blt cr6, 0x831e4e54
	if ctx.cr[6].lt {
	pc = 0x831E4E54; continue 'dispatch;
	}
	// 831E4E40: EDA06828  fsubs f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 - ctx.f[13].f64) as f32) as f64);
	// 831E4E44: C00A54AC  lfs f0, 0x54ac(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(21676 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E4E48: FF607890  fmr f27, f15
	ctx.f[27].f64 = ctx.f[15].f64;
	// 831E4E4C: EF8D0032  fmuls f28, f13, f0
	ctx.f[28].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E4E50: 48000010  b 0x831e4e60
	pc = 0x831E4E60; continue 'dispatch;
	// 831E4E54: C1AA54AC  lfs f13, 0x54ac(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(21676 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E4E58: FF80F890  fmr f28, f31
	ctx.f[28].f64 = ctx.f[31].f64;
	// 831E4E5C: EF600372  fmuls f27, f0, f13
	ctx.f[27].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 831E4E60: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E4E64: C00B1070  lfs f0, 0x1070(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4208 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E4E68: EC1E0032  fmuls f0, f30, f0
	ctx.f[0].f64 = (((ctx.f[30].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E4E6C: FDA0065E  fctidz f13, f0
	ctx.f[13].s64 = if ctx.f[0].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[0].f64.trunc() as i64 };
	// 831E4E70: D9A10058  stfd f13, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.f[13].u64 ) };
	// 831E4E74: 8381005C  lwz r28, 0x5c(r1)
	ctx.r[28].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 831E4E78: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 831E4E7C: 4800662D  bl 0x831eb4a8
	ctx.lr = 0x831E4E80;
	sub_831EB4A8(ctx, base);
	// 831E4E80: 3D400002  lis r10, 2
	ctx.r[10].s64 = 131072;
	// 831E4E84: 3D200002  lis r9, 2
	ctx.r[9].s64 = 131072;
	// 831E4E88: 614800F0  ori r8, r10, 0xf0
	ctx.r[8].u64 = ctx.r[10].u64 | 240;
	// 831E4E8C: 612700FC  ori r7, r9, 0xfc
	ctx.r[7].u64 = ctx.r[9].u64 | 252;
	// 831E4E90: 38C3FFFF  addi r6, r3, -1
	ctx.r[6].s64 = ctx.r[3].s64 + -1;
	// 831E4E94: 3CA0821A  lis r5, -0x7de6
	ctx.r[5].s64 = -2112225280;
	// 831E4E98: 7C7E412E  stwx r3, r30, r8
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[8].u32), ctx.r[3].u32) };
	// 831E4E9C: 7CDE392E  stwx r6, r30, r7
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[7].u32), ctx.r[6].u32) };
	// 831E4EA0: C005106C  lfs f0, 0x106c(r5)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(4204 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E4EA4: ED9E0032  fmuls f12, f30, f0
	ctx.f[12].f64 = (((ctx.f[30].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E4EA8: FD60665E  fctidz f11, f12
	ctx.f[11].s64 = if ctx.f[12].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[12].f64.trunc() as i64 };
	// 831E4EAC: D9610058  stfd f11, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.f[11].u64 ) };
	// 831E4EB0: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 831E4EB4: 480065F5  bl 0x831eb4a8
	ctx.lr = 0x831E4EB8;
	sub_831EB4A8(ctx, base);
	// 831E4EB8: 3C800002  lis r4, 2
	ctx.r[4].s64 = 131072;
	// 831E4EBC: 3D600002  lis r11, 2
	ctx.r[11].s64 = 131072;
	// 831E4EC0: 608A0B34  ori r10, r4, 0xb34
	ctx.r[10].u64 = ctx.r[4].u64 | 2868;
	// 831E4EC4: 61690B40  ori r9, r11, 0xb40
	ctx.r[9].u64 = ctx.r[11].u64 | 2880;
	// 831E4EC8: 3903FFFF  addi r8, r3, -1
	ctx.r[8].s64 = ctx.r[3].s64 + -1;
	// 831E4ECC: 7C7E512E  stwx r3, r30, r10
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[10].u32), ctx.r[3].u32) };
	// 831E4ED0: 7D1E492E  stwx r8, r30, r9
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[9].u32), ctx.r[8].u32) };
	// 831E4ED4: 80FD0004  lwz r7, 4(r29)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E4ED8: 20C70000  subfic r6, r7, 0
	ctx.xer.ca = ctx.r[7].u32 <= 0 as u32;
	ctx.r[6].s64 = (0 as i64) - ctx.r[7].s64;
	// 831E4EDC: 7CA63110  subfe r5, r6, r6
	let x = (!ctx.r[6].u32);
	let y = ctx.r[6].u32;
	let s = x.wrapping_add(y);
	let res = s.wrapping_add(ctx.xer.ca as u32);
	tmp.u8 = (s < x) as u8 | (res < s) as u8;
	ctx.r[5].u32 = res;
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	ctx.xer.ca = (tmp.u8 != 0);
	// 831E4EE0: 54AB07FA  rlwinm r11, r5, 0, 0x1f, 0x1d
	ctx.r[11].u64 = ctx.r[5].u32 as u64 & 0xFFFFFFFFu64;
	// 831E4EE4: 556B072A  rlwinm r11, r11, 0, 0x1c, 0x15
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831E4EE8: 396B03FC  addi r11, r11, 0x3fc
	ctx.r[11].s64 = ctx.r[11].s64 + 1020;
	// 831E4EEC: 79640020  clrldi r4, r11, 0x20
	ctx.r[4].u64 = ctx.r[11].u64 & 0x00000000FFFFFFFFu64;
	// 831E4EF0: F8810058  std r4, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[4].u64 ) };
	// 831E4EF4: C9410058  lfd f10, 0x58(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 831E4EF8: FD20569C  fcfid f9, f10
	ctx.f[9].f64 = (ctx.f[10].s64 as f64);
	// 831E4EFC: FD004818  frsp f8, f9
	ctx.f[8].f64 = (ctx.f[9].f64 as f32) as f64;
	// 831E4F00: ECE807B2  fmuls f7, f8, f30
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[30].f64) as f32) as f64);
	// 831E4F04: FCC03E5E  fctidz f6, f7
	ctx.f[6].s64 = if ctx.f[7].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[7].f64.trunc() as i64 };
	// 831E4F08: D8C10058  stfd f6, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.f[6].u64 ) };
	// 831E4F0C: 8361005C  lwz r27, 0x5c(r1)
	ctx.r[27].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 831E4F10: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 831E4F14: 48006595  bl 0x831eb4a8
	ctx.lr = 0x831E4F18;
	sub_831EB4A8(ctx, base);
	// 831E4F18: 3D600002  lis r11, 2
	ctx.r[11].s64 = 131072;
	// 831E4F1C: 616A3790  ori r10, r11, 0x3790
	ctx.r[10].u64 = ctx.r[11].u64 | 14224;
	// 831E4F20: 7C7E512E  stwx r3, r30, r10
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[10].u32), ctx.r[3].u32) };
	// 831E4F24: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 831E4F28: 48006581  bl 0x831eb4a8
	ctx.lr = 0x831E4F2C;
	sub_831EB4A8(ctx, base);
	// 831E4F2C: 3D200002  lis r9, 2
	ctx.r[9].s64 = 131072;
	// 831E4F30: 3D000002  lis r8, 2
	ctx.r[8].s64 = 131072;
	// 831E4F34: 612747B8  ori r7, r9, 0x47b8
	ctx.r[7].u64 = ctx.r[9].u64 | 18360;
	// 831E4F38: 610647C4  ori r6, r8, 0x47c4
	ctx.r[6].u64 = ctx.r[8].u64 | 18372;
	// 831E4F3C: 38A3FFFF  addi r5, r3, -1
	ctx.r[5].s64 = ctx.r[3].s64 + -1;
	// 831E4F40: 3C80821A  lis r4, -0x7de6
	ctx.r[4].s64 = -2112225280;
	// 831E4F44: 7C7E392E  stwx r3, r30, r7
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[7].u32), ctx.r[3].u32) };
	// 831E4F48: 7CBE312E  stwx r5, r30, r6
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[6].u32), ctx.r[5].u32) };
	// 831E4F4C: C0041068  lfs f0, 0x1068(r4)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4200 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E4F50: ECBE0032  fmuls f5, f30, f0
	ctx.f[5].f64 = (((ctx.f[30].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E4F54: FC802E5E  fctidz f4, f5
	ctx.f[4].s64 = if ctx.f[5].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[5].f64.trunc() as i64 };
	// 831E4F58: D8810058  stfd f4, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.f[4].u64 ) };
	// 831E4F5C: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 831E4F60: 48006549  bl 0x831eb4a8
	ctx.lr = 0x831E4F64;
	sub_831EB4A8(ctx, base);
	// 831E4F64: 3D400002  lis r10, 2
	ctx.r[10].s64 = 131072;
	// 831E4F68: 3D200002  lis r9, 2
	ctx.r[9].s64 = 131072;
	// 831E4F6C: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 831E4F70: 614851FC  ori r8, r10, 0x51fc
	ctx.r[8].u64 = ctx.r[10].u64 | 20988;
	// 831E4F74: 61275208  ori r7, r9, 0x5208
	ctx.r[7].u64 = ctx.r[9].u64 | 21000;
	// 831E4F78: 38CBFFFF  addi r6, r11, -1
	ctx.r[6].s64 = ctx.r[11].s64 + -1;
	// 831E4F7C: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 831E4F80: 7D7E412E  stwx r11, r30, r8
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[8].u32), ctx.r[11].u32) };
	// 831E4F84: 7CDE392E  stwx r6, r30, r7
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[7].u32), ctx.r[6].u32) };
	// 831E4F88: 48006521  bl 0x831eb4a8
	ctx.lr = 0x831E4F8C;
	sub_831EB4A8(ctx, base);
	// 831E4F8C: 3CA00002  lis r5, 2
	ctx.r[5].s64 = 131072;
	// 831E4F90: 3C80821A  lis r4, -0x7de6
	ctx.r[4].s64 = -2112225280;
	// 831E4F94: EF5F07B2  fmuls f26, f31, f30
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[26].f64 = (((ctx.f[31].f64 * ctx.f[30].f64) as f32) as f64);
	// 831E4F98: 60AB7E58  ori r11, r5, 0x7e58
	ctx.r[11].u64 = ctx.r[5].u64 | 32344;
	// 831E4F9C: C0041064  lfs f0, 0x1064(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4196 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E4FA0: 7C7E592E  stwx r3, r30, r11
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[11].u32), ctx.r[3].u32) };
	// 831E4FA4: EC7A0032  fmuls f3, f26, f0
	ctx.f[3].f64 = (((ctx.f[26].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E4FA8: FC401E5E  fctidz f2, f3
	ctx.f[2].s64 = if ctx.f[3].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[3].f64.trunc() as i64 };
	// 831E4FAC: D8410058  stfd f2, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.f[2].u64 ) };
	// 831E4FB0: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 831E4FB4: 480064F5  bl 0x831eb4a8
	ctx.lr = 0x831E4FB8;
	sub_831EB4A8(ctx, base);
	// 831E4FB8: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E4FBC: 409A0008  bne cr6, 0x831e4fc4
	if !ctx.cr[6].eq {
	pc = 0x831E4FC4; continue 'dispatch;
	}
	// 831E4FC0: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 831E4FC4: 3E1E0003  addis r16, r30, 3
	ctx.r[16].s64 = ctx.r[30].s64 + 196608;
	// 831E4FC8: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E4FCC: 3A108E78  addi r16, r16, -0x7188
	ctx.r[16].s64 = ctx.r[16].s64 + -29064;
	// 831E4FD0: 3DFE0003  addis r15, r30, 3
	ctx.r[15].s64 = ctx.r[30].s64 + 196608;
	// 831E4FD4: 39EF9690  addi r15, r15, -0x6970
	ctx.r[15].s64 = ctx.r[15].s64 + -26992;
	// 831E4FD8: C00B1060  lfs f0, 0x1060(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4192 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E4FDC: 90700000  stw r3, 0(r16)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[16].u32.wrapping_add(0 as u32), ctx.r[3].u32 ) };
	// 831E4FE0: EC1E0032  fmuls f0, f30, f0
	ctx.f[0].f64 = (((ctx.f[30].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E4FE4: FDA0065E  fctidz f13, f0
	ctx.f[13].s64 = if ctx.f[0].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[0].f64.trunc() as i64 };
	// 831E4FE8: D9A10058  stfd f13, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.f[13].u64 ) };
	// 831E4FEC: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 831E4FF0: 480064B9  bl 0x831eb4a8
	ctx.lr = 0x831E4FF4;
	sub_831EB4A8(ctx, base);
	// 831E4FF4: ED9F0672  fmuls f12, f31, f25
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[12].f64 = (((ctx.f[31].f64 * ctx.f[25].f64) as f32) as f64);
	// 831E4FF8: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831E4FFC: 906F0000  stw r3, 0(r15)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[15].u32.wrapping_add(0 as u32), ctx.r[3].u32 ) };
	// 831E5000: C00A105C  lfs f0, 0x105c(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4188 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5004: ED6C0032  fmuls f11, f12, f0
	ctx.f[11].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E5008: FD405E5E  fctidz f10, f11
	ctx.f[10].s64 = if ctx.f[11].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[11].f64.trunc() as i64 };
	// 831E500C: D9410058  stfd f10, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.f[10].u64 ) };
	// 831E5010: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 831E5014: 48006495  bl 0x831eb4a8
	ctx.lr = 0x831E5018;
	sub_831EB4A8(ctx, base);
	// 831E5018: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E501C: 409A0008  bne cr6, 0x831e5024
	if !ctx.cr[6].eq {
	pc = 0x831E5024; continue 'dispatch;
	}
	// 831E5020: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 831E5024: 3DDE0003  addis r14, r30, 3
	ctx.r[14].s64 = ctx.r[30].s64 + 196608;
	// 831E5028: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E502C: 39CE9EFC  addi r14, r14, -0x6104
	ctx.r[14].s64 = ctx.r[14].s64 + -24836;
	// 831E5030: C00B1058  lfs f0, 0x1058(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4184 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5034: 906E0000  stw r3, 0(r14)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[14].u32.wrapping_add(0 as u32), ctx.r[3].u32 ) };
	// 831E5038: EC1A0032  fmuls f0, f26, f0
	ctx.f[0].f64 = (((ctx.f[26].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E503C: FDA0065E  fctidz f13, f0
	ctx.f[13].s64 = if ctx.f[0].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[0].f64.trunc() as i64 };
	// 831E5040: D9A10058  stfd f13, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.f[13].u64 ) };
	// 831E5044: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 831E5048: 48006461  bl 0x831eb4a8
	ctx.lr = 0x831E504C;
	sub_831EB4A8(ctx, base);
	// 831E504C: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E5050: 409A0008  bne cr6, 0x831e5058
	if !ctx.cr[6].eq {
	pc = 0x831E5058; continue 'dispatch;
	}
	// 831E5054: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 831E5058: 3E5E0003  addis r18, r30, 3
	ctx.r[18].s64 = ctx.r[30].s64 + 196608;
	// 831E505C: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E5060: 3A52DF34  addi r18, r18, -0x20cc
	ctx.r[18].s64 = ctx.r[18].s64 + -8396;
	// 831E5064: 3E3E0003  addis r17, r30, 3
	ctx.r[17].s64 = ctx.r[30].s64 + 196608;
	// 831E5068: 3A31E74C  addi r17, r17, -0x18b4
	ctx.r[17].s64 = ctx.r[17].s64 + -6324;
	// 831E506C: C00B1054  lfs f0, 0x1054(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4180 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5070: 90720000  stw r3, 0(r18)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[18].u32.wrapping_add(0 as u32), ctx.r[3].u32 ) };
	// 831E5074: EC1E0032  fmuls f0, f30, f0
	ctx.f[0].f64 = (((ctx.f[30].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E5078: FDA0065E  fctidz f13, f0
	ctx.f[13].s64 = if ctx.f[0].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[0].f64.trunc() as i64 };
	// 831E507C: D9A10058  stfd f13, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.f[13].u64 ) };
	// 831E5080: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 831E5084: 48006425  bl 0x831eb4a8
	ctx.lr = 0x831E5088;
	sub_831EB4A8(ctx, base);
	// 831E5088: ED9D0672  fmuls f12, f29, f25
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[12].f64 = (((ctx.f[29].f64 * ctx.f[25].f64) as f32) as f64);
	// 831E508C: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831E5090: 90710000  stw r3, 0(r17)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[17].u32.wrapping_add(0 as u32), ctx.r[3].u32 ) };
	// 831E5094: C00A1050  lfs f0, 0x1050(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4176 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5098: ED6C0032  fmuls f11, f12, f0
	ctx.f[11].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E509C: FD405E5E  fctidz f10, f11
	ctx.f[10].s64 = if ctx.f[11].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[11].f64.trunc() as i64 };
	// 831E50A0: D9410058  stfd f10, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.f[10].u64 ) };
	// 831E50A4: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 831E50A8: 48006401  bl 0x831eb4a8
	ctx.lr = 0x831E50AC;
	sub_831EB4A8(ctx, base);
	// 831E50AC: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E50B0: 409A0008  bne cr6, 0x831e50b8
	if !ctx.cr[6].eq {
	pc = 0x831E50B8; continue 'dispatch;
	}
	// 831E50B4: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 831E50B8: 3E7E0003  addis r19, r30, 3
	ctx.r[19].s64 = ctx.r[30].s64 + 196608;
	// 831E50BC: EF9C07B2  fmuls f28, f28, f30
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[28].f64 = (((ctx.f[28].f64 * ctx.f[30].f64) as f32) as f64);
	// 831E50C0: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E50C4: 3A73EFB8  addi r19, r19, -0x1048
	ctx.r[19].s64 = ctx.r[19].s64 + -4168;
	// 831E50C8: C00B104C  lfs f0, 0x104c(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4172 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E50CC: 90730000  stw r3, 0(r19)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(0 as u32), ctx.r[3].u32 ) };
	// 831E50D0: EC1C0032  fmuls f0, f28, f0
	ctx.f[0].f64 = (((ctx.f[28].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E50D4: FDA0065E  fctidz f13, f0
	ctx.f[13].s64 = if ctx.f[0].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[0].f64.trunc() as i64 };
	// 831E50D8: D9A10058  stfd f13, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.f[13].u64 ) };
	// 831E50DC: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 831E50E0: 480063C9  bl 0x831eb4a8
	ctx.lr = 0x831E50E4;
	sub_831EB4A8(ctx, base);
	// 831E50E4: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E50E8: 409A0008  bne cr6, 0x831e50f0
	if !ctx.cr[6].eq {
	pc = 0x831E50F0; continue 'dispatch;
	}
	// 831E50EC: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 831E50F0: EFFD07B2  fmuls f31, f29, f30
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].f64 = (((ctx.f[29].f64 * ctx.f[30].f64) as f32) as f64);
	// 831E50F4: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E50F8: 3E9E0003  addis r20, r30, 3
	ctx.r[20].s64 = ctx.r[30].s64 + 196608;
	// 831E50FC: 3A942FF0  addi r20, r20, 0x2ff0
	ctx.r[20].s64 = ctx.r[20].s64 + 12272;
	// 831E5100: C00B1048  lfs f0, 0x1048(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4168 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5104: 90740000  stw r3, 0(r20)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(0 as u32), ctx.r[3].u32 ) };
	// 831E5108: EC1F0032  fmuls f0, f31, f0
	ctx.f[0].f64 = (((ctx.f[31].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E510C: FDA0065E  fctidz f13, f0
	ctx.f[13].s64 = if ctx.f[0].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[0].f64.trunc() as i64 };
	// 831E5110: D9A10058  stfd f13, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.f[13].u64 ) };
	// 831E5114: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 831E5118: 48006391  bl 0x831eb4a8
	ctx.lr = 0x831E511C;
	sub_831EB4A8(ctx, base);
	// 831E511C: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E5120: 409A0008  bne cr6, 0x831e5128
	if !ctx.cr[6].eq {
	pc = 0x831E5128; continue 'dispatch;
	}
	// 831E5124: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 831E5128: 3EDE0003  addis r22, r30, 3
	ctx.r[22].s64 = ctx.r[30].s64 + 196608;
	// 831E512C: 3943FFFF  addi r10, r3, -1
	ctx.r[10].s64 = ctx.r[3].s64 + -1;
	// 831E5130: 3AD65008  addi r22, r22, 0x5008
	ctx.r[22].s64 = ctx.r[22].s64 + 20488;
	// 831E5134: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E5138: 3EBE0003  addis r21, r30, 3
	ctx.r[21].s64 = ctx.r[30].s64 + 196608;
	// 831E513C: 3AB57024  addi r21, r21, 0x7024
	ctx.r[21].s64 = ctx.r[21].s64 + 28708;
	// 831E5140: 91560000  stw r10, 0(r22)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[22].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E5144: C00B1044  lfs f0, 0x1044(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4164 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5148: EC1E0032  fmuls f0, f30, f0
	ctx.f[0].f64 = (((ctx.f[30].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E514C: FDA0065E  fctidz f13, f0
	ctx.f[13].s64 = if ctx.f[0].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[0].f64.trunc() as i64 };
	// 831E5150: D9A10058  stfd f13, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.f[13].u64 ) };
	// 831E5154: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 831E5158: 48006351  bl 0x831eb4a8
	ctx.lr = 0x831E515C;
	sub_831EB4A8(ctx, base);
	// 831E515C: 3D20821A  lis r9, -0x7de6
	ctx.r[9].s64 = -2112225280;
	// 831E5160: 90750000  stw r3, 0(r21)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(0 as u32), ctx.r[3].u32 ) };
	// 831E5164: C0091040  lfs f0, 0x1040(r9)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4160 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5168: ED9A0032  fmuls f12, f26, f0
	ctx.f[12].f64 = (((ctx.f[26].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E516C: FD60665E  fctidz f11, f12
	ctx.f[11].s64 = if ctx.f[12].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[12].f64.trunc() as i64 };
	// 831E5170: D9610058  stfd f11, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.f[11].u64 ) };
	// 831E5174: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 831E5178: 48006331  bl 0x831eb4a8
	ctx.lr = 0x831E517C;
	sub_831EB4A8(ctx, base);
	// 831E517C: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E5180: 409A0008  bne cr6, 0x831e5188
	if !ctx.cr[6].eq {
	pc = 0x831E5188; continue 'dispatch;
	}
	// 831E5184: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 831E5188: EDBB0672  fmuls f13, f27, f25
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[13].f64 = (((ctx.f[27].f64 * ctx.f[25].f64) as f32) as f64);
	// 831E518C: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E5190: 3F3E0004  addis r25, r30, 4
	ctx.r[25].s64 = ctx.r[30].s64 + 262144;
	// 831E5194: 3B39903C  addi r25, r25, -0x6fc4
	ctx.r[25].s64 = ctx.r[25].s64 + -28612;
	// 831E5198: C00B103C  lfs f0, 0x103c(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4156 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E519C: 90790000  stw r3, 0(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(0 as u32), ctx.r[3].u32 ) };
	// 831E51A0: ED8D0032  fmuls f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E51A4: FD60665E  fctidz f11, f12
	ctx.f[11].s64 = if ctx.f[12].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[12].f64.trunc() as i64 };
	// 831E51A8: D9610058  stfd f11, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.f[11].u64 ) };
	// 831E51AC: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 831E51B0: 480062F9  bl 0x831eb4a8
	ctx.lr = 0x831E51B4;
	sub_831EB4A8(ctx, base);
	// 831E51B4: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E51B8: 409A0008  bne cr6, 0x831e51c0
	if !ctx.cr[6].eq {
	pc = 0x831E51C0; continue 'dispatch;
	}
	// 831E51BC: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 831E51C0: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E51C4: 3EFE0004  addis r23, r30, 4
	ctx.r[23].s64 = ctx.r[30].s64 + 262144;
	// 831E51C8: 3AF7A054  addi r23, r23, -0x5fac
	ctx.r[23].s64 = ctx.r[23].s64 + -24492;
	// 831E51CC: C00B1038  lfs f0, 0x1038(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4152 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E51D0: EC1C0032  fmuls f0, f28, f0
	ctx.f[0].f64 = (((ctx.f[28].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E51D4: 90770000  stw r3, 0(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(0 as u32), ctx.r[3].u32 ) };
	// 831E51D8: FDA0065E  fctidz f13, f0
	ctx.f[13].s64 = if ctx.f[0].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[0].f64.trunc() as i64 };
	// 831E51DC: D9A10058  stfd f13, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.f[13].u64 ) };
	// 831E51E0: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 831E51E4: 480062C5  bl 0x831eb4a8
	ctx.lr = 0x831E51E8;
	sub_831EB4A8(ctx, base);
	// 831E51E8: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E51EC: 409A0008  bne cr6, 0x831e51f4
	if !ctx.cr[6].eq {
	pc = 0x831E51F4; continue 'dispatch;
	}
	// 831E51F0: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 831E51F4: 3F1E0004  addis r24, r30, 4
	ctx.r[24].s64 = ctx.r[30].s64 + 262144;
	// 831E51F8: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E51FC: 3B18E090  addi r24, r24, -0x1f70
	ctx.r[24].s64 = ctx.r[24].s64 + -8048;
	// 831E5200: C00B1034  lfs f0, 0x1034(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4148 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5204: 90780000  stw r3, 0(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(0 as u32), ctx.r[3].u32 ) };
	// 831E5208: EC1F0032  fmuls f0, f31, f0
	ctx.f[0].f64 = (((ctx.f[31].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E520C: FDA0065E  fctidz f13, f0
	ctx.f[13].s64 = if ctx.f[0].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[0].f64.trunc() as i64 };
	// 831E5210: D9A10058  stfd f13, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.f[13].u64 ) };
	// 831E5214: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 831E5218: 48006291  bl 0x831eb4a8
	ctx.lr = 0x831E521C;
	sub_831EB4A8(ctx, base);
	// 831E521C: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E5220: 409A0008  bne cr6, 0x831e5228
	if !ctx.cr[6].eq {
	pc = 0x831E5228; continue 'dispatch;
	}
	// 831E5224: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 831E5228: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E522C: 3F5E0004  addis r26, r30, 4
	ctx.r[26].s64 = ctx.r[30].s64 + 262144;
	// 831E5230: 3B5A00A8  addi r26, r26, 0xa8
	ctx.r[26].s64 = ctx.r[26].s64 + 168;
	// 831E5234: C00B1030  lfs f0, 0x1030(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4144 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5238: EC1A0032  fmuls f0, f26, f0
	ctx.f[0].f64 = (((ctx.f[26].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E523C: 907A0000  stw r3, 0(r26)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(0 as u32), ctx.r[3].u32 ) };
	// 831E5240: FDA0065E  fctidz f13, f0
	ctx.f[13].s64 = if ctx.f[0].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[0].f64.trunc() as i64 };
	// 831E5244: D9A10058  stfd f13, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.f[13].u64 ) };
	// 831E5248: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 831E524C: 4800625D  bl 0x831eb4a8
	ctx.lr = 0x831E5250;
	sub_831EB4A8(ctx, base);
	// 831E5250: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E5254: 409A0008  bne cr6, 0x831e525c
	if !ctx.cr[6].eq {
	pc = 0x831E525C; continue 'dispatch;
	}
	// 831E5258: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 831E525C: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E5260: 3F9E0004  addis r28, r30, 4
	ctx.r[28].s64 = ctx.r[30].s64 + 262144;
	// 831E5264: 3F7E0004  addis r27, r30, 4
	ctx.r[27].s64 = ctx.r[30].s64 + 262144;
	// 831E5268: 3B9C20C4  addi r28, r28, 0x20c4
	ctx.r[28].s64 = ctx.r[28].s64 + 8388;
	// 831E526C: 3B7B40DC  addi r27, r27, 0x40dc
	ctx.r[27].s64 = ctx.r[27].s64 + 16604;
	// 831E5270: C00B102C  lfs f0, 0x102c(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4140 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5274: EC1A0032  fmuls f0, f26, f0
	ctx.f[0].f64 = (((ctx.f[26].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E5278: 907C0000  stw r3, 0(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(0 as u32), ctx.r[3].u32 ) };
	// 831E527C: FDA0065E  fctidz f13, f0
	ctx.f[13].s64 = if ctx.f[0].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[0].f64.trunc() as i64 };
	// 831E5280: D9A10058  stfd f13, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.f[13].u64 ) };
	// 831E5284: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 831E5288: 48006221  bl 0x831eb4a8
	ctx.lr = 0x831E528C;
	sub_831EB4A8(ctx, base);
	// 831E528C: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831E5290: 907B0000  stw r3, 0(r27)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(0 as u32), ctx.r[3].u32 ) };
	// 831E5294: C00A1028  lfs f0, 0x1028(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4136 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5298: ED990032  fmuls f12, f25, f0
	ctx.f[12].f64 = (((ctx.f[25].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E529C: FD60665E  fctidz f11, f12
	ctx.f[11].s64 = if ctx.f[12].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[12].f64.trunc() as i64 };
	// 831E52A0: D9610058  stfd f11, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.f[11].u64 ) };
	// 831E52A4: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 831E52A8: 48006201  bl 0x831eb4a8
	ctx.lr = 0x831E52AC;
	sub_831EB4A8(ctx, base);
	// 831E52AC: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E52B0: 409A0008  bne cr6, 0x831e52b8
	if !ctx.cr[6].eq {
	pc = 0x831E52B8; continue 'dispatch;
	}
	// 831E52B4: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 831E52B8: 81510000  lwz r10, 0(r17)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E52BC: 3D000004  lis r8, 4
	ctx.r[8].s64 = 262144;
	// 831E52C0: 81780000  lwz r11, 0(r24)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E52C4: 3C808204  lis r4, -0x7dfc
	ctx.r[4].s64 = -2113667072;
	// 831E52C8: 81320000  lwz r9, 0(r18)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[18].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E52CC: 611850F4  ori r24, r8, 0x50f4
	ctx.r[24].u64 = ctx.r[8].u64 | 20724;
	// 831E52D0: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831E52D4: 815B0000  lwz r10, 0(r27)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E52D8: 811C0000  lwz r8, 0(r28)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E52DC: 3F80821A  lis r28, -0x7de6
	ctx.r[28].s64 = -2112225280;
	// 831E52E0: 7D6B4A14  add r11, r11, r9
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 831E52E4: 81370000  lwz r9, 0(r23)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E52E8: 80EE0000  lwz r7, 0(r14)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[14].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E52EC: CBC4D1E0  lfd f30, -0x2e20(r4)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[4].u32.wrapping_add(-11808 as u32) ) };
	// 831E52F0: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831E52F4: 815A0000  lwz r10, 0(r26)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E52F8: 80D50000  lwz r6, 0(r21)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E52FC: C1BE0058  lfs f13, 0x58(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(88 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E5300: 7D6B4214  add r11, r11, r8
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 831E5304: 81160000  lwz r8, 0(r22)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[22].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E5308: 80AF0000  lwz r5, 0(r15)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[15].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E530C: C81C1020  lfd f0, 0x1020(r28)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[28].u32.wrapping_add(4128 as u32) ) };
	// 831E5310: 7D6B4A14  add r11, r11, r9
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 831E5314: 81390000  lwz r9, 0(r25)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E5318: 80900000  lwz r4, 0(r16)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[16].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E531C: FC20F090  fmr f1, f30
	ctx.f[1].f64 = ctx.f[30].f64;
	// 831E5320: 7D6B3A14  add r11, r11, r7
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[7].u64;
	// 831E5324: 80F40000  lwz r7, 0(r20)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E5328: 83930000  lwz r28, 0(r19)
	ctx.r[28].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E532C: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831E5330: 7C7EC12E  stwx r3, r30, r24
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[24].u32), ctx.r[3].u32) };
	// 831E5334: C19D0048  lfs f12, 0x48(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(72 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831E5338: 7D6B3214  add r11, r11, r6
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[6].u64;
	// 831E533C: 7D6B4214  add r11, r11, r8
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 831E5340: 7D6B2A14  add r11, r11, r5
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[5].u64;
	// 831E5344: 7D6B4A14  add r11, r11, r9
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 831E5348: 7D6B2214  add r11, r11, r4
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[4].u64;
	// 831E534C: 7D6B3A14  add r11, r11, r7
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[7].u64;
	// 831E5350: 7D6B1A14  add r11, r11, r3
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[3].u64;
	// 831E5354: 7C6BE214  add r3, r11, r28
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[28].u64;
	// 831E5358: 546BF87E  srwi r11, r3, 1
	ctx.r[11].u32 = ctx.r[3].u32.wrapping_shr(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831E535C: F9610058  std r11, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[11].u64 ) };
	// 831E5360: C9610058  lfd f11, 0x58(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 831E5364: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831E5368: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831E536C: ED096824  fdivs f8, f9, f13
	ctx.f[8].f64 = ((ctx.f[9].f64 / ctx.f[13].f64) as f32) as f64;
	// 831E5370: FCEC4024  fdiv f7, f12, f8
	ctx.f[7].f64 = ctx.f[12].f64 / ctx.f[8].f64;
	// 831E5374: FC403824  fdiv f2, f0, f7
	ctx.f[2].f64 = ctx.f[0].f64 / ctx.f[7].f64;
	// 831E5378: 4BFC6131  bl 0x831ab4a8
	ctx.lr = 0x831E537C;
	sub_831AB4A8(ctx, base);
	// 831E537C: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 831E5380: 813D0010  lwz r9, 0x10(r29)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E5384: 3CE0821A  lis r7, -0x7de6
	ctx.r[7].s64 = -2112225280;
	// 831E5388: 811D0008  lwz r8, 8(r29)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E538C: 3CA08209  lis r5, -0x7df7
	ctx.r[5].s64 = -2113339392;
	// 831E5390: 80DD000C  lwz r6, 0xc(r29)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E5394: 3C808201  lis r4, -0x7dff
	ctx.r[4].s64 = -2113863680;
	// 831E5398: 5523103A  slwi r3, r9, 2
	ctx.r[3].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[3].u64 = ctx.r[3].u32 as u64;
	// 831E539C: C80AD760  lfd f0, -0x28a0(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[10].u32.wrapping_add(-10400 as u32) ) };
	// 831E53A0: 551C103A  slwi r28, r8, 2
	ctx.r[28].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[28].u64 = ctx.r[28].u32 as u64;
	// 831E53A4: FCC10032  fmul f6, f1, f0
	ctx.f[6].f64 = ctx.f[1].f64 * ctx.f[0].f64;
	// 831E53A8: C0071018  lfs f0, 0x1018(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4120 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E53AC: C1A5A100  lfs f13, -0x5f00(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(-24320 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E53B0: 54C6103A  slwi r6, r6, 2
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831E53B4: C1649450  lfs f11, -0x6bb0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(-27568 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831E53B8: 397F0378  addi r11, r31, 0x378
	ctx.r[11].s64 = ctx.r[31].s64 + 888;
	// 831E53BC: 395F0178  addi r10, r31, 0x178
	ctx.r[10].s64 = ctx.r[31].s64 + 376;
	// 831E53C0: 393F00C0  addi r9, r31, 0xc0
	ctx.r[9].s64 = ctx.r[31].s64 + 192;
	// 831E53C4: 391F01F8  addi r8, r31, 0x1f8
	ctx.r[8].s64 = ctx.r[31].s64 + 504;
	// 831E53C8: 38FF0278  addi r7, r31, 0x278
	ctx.r[7].s64 = ctx.r[31].s64 + 632;
	// 831E53CC: 38BF02F8  addi r5, r31, 0x2f8
	ctx.r[5].s64 = ctx.r[31].s64 + 760;
	// 831E53D0: 7F835C2E  lfsx f28, r3, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[3].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 831E53D4: 389F01F8  addi r4, r31, 0x1f8
	ctx.r[4].s64 = ctx.r[31].s64 + 504;
	// 831E53D8: 7CA3542E  lfsx f5, r3, r10
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[3].u32.wrapping_add(ctx.r[10].u32)) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831E53DC: 7C834C2E  lfsx f4, r3, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[3].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831E53E0: ED80302C  fsqrts f12, f6
	ctx.f[12].f64 = ((ctx.f[6].f64).sqrt() as f32) as f64;
	// 831E53E4: 7C3C442E  lfsx f1, r28, r8
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[28].u32.wrapping_add(ctx.r[8].u32)) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831E53E8: 7F263C2E  lfsx f25, r6, r7
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[7].u32)) };
	ctx.f[25].f64 = (tmp.f32 as f64);
	// 831E53EC: 7F1C2C2E  lfsx f24, r28, r5
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[28].u32.wrapping_add(ctx.r[5].u32)) };
	ctx.f[24].f64 = (tmp.f32 as f64);
	// 831E53F0: 7EE6242E  lfsx f23, r6, r4
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[4].u32)) };
	ctx.f[23].f64 = (tmp.f32 as f64);
	// 831E53F4: EDAC683C  fnmsubs f13, f12, f0, f13
	ctx.f[13].f64 = -(((ctx.f[12].f64 * ctx.f[0].f64 - ctx.f[13].f64) as f32) as f64);
	// 831E53F8: ED6C02F2  fmuls f11, f12, f11
	ctx.f[11].f64 = (((ctx.f[12].f64 * ctx.f[11].f64) as f32) as f64);
	// 831E53FC: 817D0020  lwz r11, 0x20(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(32 as u32) ) } as u64;
	// 831E5400: 38FF0178  addi r7, r31, 0x178
	ctx.r[7].s64 = ctx.r[31].s64 + 376;
	// 831E5404: 807D0014  lwz r3, 0x14(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E5408: 3B1F00C0  addi r24, r31, 0xc0
	ctx.r[24].s64 = ctx.r[31].s64 + 192;
	// 831E540C: 809D0028  lwz r4, 0x28(r29)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(40 as u32) ) } as u64;
	// 831E5410: 5569103A  slwi r9, r11, 2
	ctx.r[9].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831E5414: 5465103A  slwi r5, r3, 2
	ctx.r[5].u32 = ctx.r[3].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831E5418: 815D002C  lwz r10, 0x2c(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(44 as u32) ) } as u64;
	// 831E541C: 54832036  slwi r3, r4, 4
	ctx.r[3].u32 = ctx.r[4].u32.wrapping_shl(4);
	ctx.r[3].u64 = ctx.r[3].u32 as u64;
	// 831E5420: 811D0024  lwz r8, 0x24(r29)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(36 as u32) ) } as u64;
	// 831E5424: 7D6B4A14  add r11, r11, r9
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 831E5428: ED050372  fmuls f8, f5, f13
	ctx.f[8].f64 = (((ctx.f[5].f64 * ctx.f[13].f64) as f32) as f64);
	// 831E542C: 7D241850  subf r9, r4, r3
	ctx.r[9].s64 = ctx.r[3].s64 - ctx.r[4].s64;
	// 831E5430: 835D0018  lwz r26, 0x18(r29)
	ctx.r[26].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(24 as u32) ) } as u64;
	// 831E5434: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831E5438: 809D001C  lwz r4, 0x1c(r29)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(28 as u32) ) } as u64;
	// 831E543C: 7C695214  add r3, r9, r10
	ctx.r[3].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 831E5440: 7D453C2E  lfsx f10, r5, r7
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[5].u32.wrapping_add(ctx.r[7].u32)) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831E5444: 7D2B4214  add r9, r11, r8
	ctx.r[9].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 831E5448: ECEA0372  fmuls f7, f10, f13
	ctx.f[7].f64 = (((ctx.f[10].f64 * ctx.f[13].f64) as f32) as f64);
	// 831E544C: 3D008208  lis r8, -0x7df8
	ctx.r[8].s64 = -2113404928;
	// 831E5450: 7D25C42E  lfsx f9, r5, r24
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[5].u32.wrapping_add(ctx.r[24].u32)) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831E5454: 38FF0378  addi r7, r31, 0x378
	ctx.r[7].s64 = ctx.r[31].s64 + 888;
	// 831E5458: EEA40372  fmuls f21, f4, f13
	ctx.f[21].f64 = (((ctx.f[4].f64 * ctx.f[13].f64) as f32) as f64);
	// 831E545C: 3AFF02F8  addi r23, r31, 0x2f8
	ctx.r[23].s64 = ctx.r[31].s64 + 760;
	// 831E5460: 817D0000  lwz r11, 0(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E5464: 5529103A  slwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831E5468: FCC05850  fneg f6, f11
	ctx.f[6].u64 = ctx.f[11].u64 ^ 0x8000_0000_0000_0000u64;
	// 831E546C: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831E5470: EE290372  fmuls f17, f9, f13
	ctx.f[17].f64 = (((ctx.f[9].f64 * ctx.f[13].f64) as f32) as f64);
	// 831E5474: C008135C  lfs f0, 0x135c(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(4956 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5478: 5468103A  slwi r8, r3, 2
	ctx.r[8].u32 = ctx.r[3].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831E547C: 7F653C2E  lfsx f27, r5, r7
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[5].u32.wrapping_add(ctx.r[7].u32)) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 831E5480: 38FF0278  addi r7, r31, 0x278
	ctx.r[7].s64 = ctx.r[31].s64 + 632;
	// 831E5484: 7D46BC2E  lfsx f10, r6, r23
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[23].u32)) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831E5488: 38BF03F8  addi r5, r31, 0x3f8
	ctx.r[5].s64 = ctx.r[31].s64 + 1016;
	// 831E548C: 387F013C  addi r3, r31, 0x13c
	ctx.r[3].s64 = ctx.r[31].s64 + 316;
	// 831E5490: EEDC0032  fmuls f22, f28, f0
	ctx.f[22].f64 = (((ctx.f[28].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E5494: 38DF0600  addi r6, r31, 0x600
	ctx.r[6].s64 = ctx.r[31].s64 + 1536;
	// 831E5498: EE880032  fmuls f20, f8, f0
	ctx.f[20].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E549C: 3B1F0808  addi r24, r31, 0x808
	ctx.r[24].s64 = ctx.r[31].s64 + 2056;
	// 831E54A0: EE670032  fmuls f19, f7, f0
	ctx.f[19].f64 = (((ctx.f[7].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E54A4: 7E1C3C2E  lfsx f16, r28, r7
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[28].u32.wrapping_add(ctx.r[7].u32)) };
	ctx.f[16].f64 = (tmp.f32 as f64);
	// 831E54A8: 3AFF0A28  addi r23, r31, 0xa28
	ctx.r[23].s64 = ctx.r[31].s64 + 2600;
	// 831E54AC: 7CA92C2E  lfsx f5, r9, r5
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[5].u32)) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831E54B0: 3ADF0084  addi r22, r31, 0x84
	ctx.r[22].s64 = ctx.r[31].s64 + 132;
	// 831E54B4: 7C8A1C2E  lfsx f4, r10, r3
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[3].u32)) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831E54B8: 38FF0C48  addi r7, r31, 0xc48
	ctx.r[7].s64 = ctx.r[31].s64 + 3144;
	// 831E54BC: 7C69342E  lfsx f3, r9, r6
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[6].u32)) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 831E54C0: 38BF0C48  addi r5, r31, 0xc48
	ctx.r[5].s64 = ctx.r[31].s64 + 3144;
	// 831E54C4: 5743103A  slwi r3, r26, 2
	ctx.r[3].u32 = ctx.r[26].u32.wrapping_shl(2);
	ctx.r[3].u64 = ctx.r[3].u32 as u64;
	// 831E54C8: EE5B0032  fmuls f18, f27, f0
	ctx.f[18].f64 = (((ctx.f[27].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E54CC: 5489103A  slwi r9, r4, 2
	ctx.r[9].u32 = ctx.r[4].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831E54D0: 7C48C42E  lfsx f2, r8, r24
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[8].u32.wrapping_add(ctx.r[24].u32)) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 831E54D4: 7FA8BC2E  lfsx f29, r8, r23
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[8].u32.wrapping_add(ctx.r[23].u32)) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 831E54D8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E54DC: 7F4AB42E  lfsx f26, r10, r22
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[22].u32)) };
	ctx.f[26].f64 = (tmp.f32 as f64);
	// 831E54E0: D1410058  stfs f10, 0x58(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 831E54E4: 7C033C2E  lfsx f0, r3, r7
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[3].u32.wrapping_add(ctx.r[7].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E54E8: 7FE92C2E  lfsx f31, r9, r5
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[5].u32)) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 831E54EC: 409A000C  bne cr6, 0x831e54f8
	if !ctx.cr[6].eq {
	pc = 0x831E54F8; continue 'dispatch;
	}
	// 831E54F0: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 831E54F4: 48000030  b 0x831e5524
	pc = 0x831E5524; continue 'dispatch;
	// 831E54F8: 796B0020  clrldi r11, r11, 0x20
	ctx.r[11].u64 = ctx.r[11].u64 & 0x00000000FFFFFFFFu64;
	// 831E54FC: C1BE0058  lfs f13, 0x58(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(88 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E5500: F9610068  std r11, 0x68(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[11].u64 ) };
	// 831E5504: C9410068  lfd f10, 0x68(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) };
	// 831E5508: FD20569C  fcfid f9, f10
	ctx.f[9].f64 = (ctx.f[10].s64 as f64);
	// 831E550C: FD404818  frsp f10, f9
	ctx.f[10].f64 = (ctx.f[9].f64 as f32) as f64;
	// 831E5510: ED2A0372  fmuls f9, f10, f13
	ctx.f[9].f64 = (((ctx.f[10].f64 * ctx.f[13].f64) as f32) as f64);
	// 831E5514: EDA903B2  fmuls f13, f9, f14
	ctx.f[13].f64 = (((ctx.f[9].f64 * ctx.f[14].f64) as f32) as f64);
	// 831E5518: FD406E5E  fctidz f10, f13
	ctx.f[10].s64 = if ctx.f[13].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[13].f64.trunc() as i64 };
	// 831E551C: D9410068  stfd f10, 0x68(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.f[10].u64 ) };
	// 831E5520: 8141006C  lwz r10, 0x6c(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(108 as u32) ) } as u64;
	// 831E5524: 397E0068  addi r11, r30, 0x68
	ctx.r[11].s64 = ctx.r[30].s64 + 104;
	// 831E5528: 813E0074  lwz r9, 0x74(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(116 as u32) ) } as u64;
	// 831E552C: 811E0070  lwz r8, 0x70(r30)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(112 as u32) ) } as u64;
	// 831E5530: 7F094040  cmplw cr6, r9, r8
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831E5534: 914B0010  stw r10, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[10].u32 ) };
	// 831E5538: 409A000C  bne cr6, 0x831e5544
	if !ctx.cr[6].eq {
	pc = 0x831E5544; continue 'dispatch;
	}
	// 831E553C: D1EB0004  stfs f15, 4(r11)
	tmp.f32 = (ctx.f[15].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E5540: 914B0008  stw r10, 8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E5544: 3D7E0001  addis r11, r30, 1
	ctx.r[11].s64 = ctx.r[30].s64 + 65536;
	// 831E5548: 396B0088  addi r11, r11, 0x88
	ctx.r[11].s64 = ctx.r[11].s64 + 136;
	// 831E554C: 812B000C  lwz r9, 0xc(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E5550: 810B0008  lwz r8, 8(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E5554: 914B0010  stw r10, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[10].u32 ) };
	// 831E5558: 7F094040  cmplw cr6, r9, r8
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831E555C: 409A000C  bne cr6, 0x831e5568
	if !ctx.cr[6].eq {
	pc = 0x831E5568; continue 'dispatch;
	}
	// 831E5560: D1EB0004  stfs f15, 4(r11)
	tmp.f32 = (ctx.f[15].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E5564: 914B0008  stw r10, 8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E5568: 3D600002  lis r11, 2
	ctx.r[11].s64 = 131072;
	// 831E556C: C1BF0000  lfs f13, 0(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E5570: 3D400002  lis r10, 2
	ctx.r[10].s64 = 131072;
	// 831E5574: C15F0004  lfs f10, 4(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831E5578: 616500F4  ori r5, r11, 0xf4
	ctx.r[5].u64 = ctx.r[11].u64 | 244;
	// 831E557C: FDE00050  fneg f15, f0
	ctx.f[15].u64 = ctx.f[0].u64 ^ 0x8000_0000_0000_0000u64;
	// 831E5580: 3D200002  lis r9, 2
	ctx.r[9].s64 = 131072;
	// 831E5584: C13F0014  lfs f9, 0x14(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831E5588: 3D7E0002  addis r11, r30, 2
	ctx.r[11].s64 = ctx.r[30].s64 + 131072;
	// 831E558C: FDC0F850  fneg f14, f31
	ctx.f[14].u64 = ctx.f[31].u64 ^ 0x8000_0000_0000_0000u64;
	// 831E5590: 3CE00002  lis r7, 2
	ctx.r[7].s64 = 131072;
	// 831E5594: 6123010C  ori r3, r9, 0x10c
	ctx.r[3].u64 = ctx.r[9].u64 | 268;
	// 831E5598: 61440100  ori r4, r10, 0x100
	ctx.r[4].u64 = ctx.r[10].u64 | 256;
	// 831E559C: 7DBE2D2E  stfsx f13, r30, r5
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[5].u32), tmp.u32) };
	// 831E55A0: 396B091C  addi r11, r11, 0x91c
	ctx.r[11].s64 = ctx.r[11].s64 + 2332;
	// 831E55A4: 60E90B44  ori r9, r7, 0xb44
	ctx.r[9].u64 = ctx.r[7].u64 | 2884;
	// 831E55A8: 3D000002  lis r8, 2
	ctx.r[8].s64 = 131072;
	// 831E55AC: 3CC00002  lis r6, 2
	ctx.r[6].s64 = 131072;
	// 831E55B0: 7C3E1D2E  stfsx f1, r30, r3
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[3].u32), tmp.u32) };
	// 831E55B4: 610A0B38  ori r10, r8, 0xb38
	ctx.r[10].u64 = ctx.r[8].u64 | 2872;
	// 831E55B8: 7D5E252E  stfsx f10, r30, r4
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[4].u32), tmp.u32) };
	// 831E55BC: 60C80B50  ori r8, r6, 0xb50
	ctx.r[8].u64 = ctx.r[6].u64 | 2896;
	// 831E55C0: D00B0008  stfs f0, 8(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E55C4: D1EB0004  stfs f15, 4(r11)
	tmp.f32 = (ctx.f[15].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E55C8: 3CA00002  lis r5, 2
	ctx.r[5].s64 = 131072;
	// 831E55CC: 7D3E4D2E  stfsx f9, r30, r9
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[9].u32), tmp.u32) };
	// 831E55D0: 3D3E0002  addis r9, r30, 2
	ctx.r[9].s64 = ctx.r[30].s64 + 131072;
	// 831E55D4: 3CE00002  lis r7, 2
	ctx.r[7].s64 = 131072;
	// 831E55D8: 39292B60  addi r9, r9, 0x2b60
	ctx.r[9].s64 = ctx.r[9].s64 + 11104;
	// 831E55DC: 7DBE552E  stfsx f13, r30, r10
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[10].u32), tmp.u32) };
	// 831E55E0: 7EDE452E  stfsx f22, r30, r8
	tmp.f32 = (ctx.f[22].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[8].u32), tmp.u32) };
	// 831E55E4: 3D1E0002  addis r8, r30, 2
	ctx.r[8].s64 = ctx.r[30].s64 + 131072;
	// 831E55E8: 3CC00002  lis r6, 2
	ctx.r[6].s64 = 131072;
	// 831E55EC: 39082F78  addi r8, r8, 0x2f78
	ctx.r[8].s64 = ctx.r[8].s64 + 12152;
	// 831E55F0: 60A500E8  ori r5, r5, 0xe8
	ctx.r[5].u64 = ctx.r[5].u64 | 232;
	// 831E55F4: D0090008  stfs f0, 8(r9)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E55F8: 3C800002  lis r4, 2
	ctx.r[4].s64 = 131072;
	// 831E55FC: D1E90004  stfs f15, 4(r9)
	tmp.f32 = (ctx.f[15].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E5600: 3C600002  lis r3, 2
	ctx.r[3].s64 = 131072;
	// 831E5604: 3D600002  lis r11, 2
	ctx.r[11].s64 = 131072;
	// 831E5608: 3D400002  lis r10, 2
	ctx.r[10].s64 = 131072;
	// 831E560C: D0080008  stfs f0, 8(r8)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E5610: 60E73794  ori r7, r7, 0x3794
	ctx.r[7].u64 = ctx.r[7].u64 | 14228;
	// 831E5614: D1E80004  stfs f15, 4(r8)
	tmp.f32 = (ctx.f[15].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E5618: 60C637A0  ori r6, r6, 0x37a0
	ctx.r[6].u64 = ctx.r[6].u64 | 14240;
	// 831E561C: 7F3E2D2E  stfsx f25, r30, r5
	tmp.f32 = (ctx.f[25].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[5].u32), tmp.u32) };
	// 831E5620: 3D3E0002  addis r9, r30, 2
	ctx.r[9].s64 = ctx.r[30].s64 + 131072;
	// 831E5624: 3F800002  lis r28, 2
	ctx.r[28].s64 = 131072;
	// 831E5628: 608400EC  ori r4, r4, 0xec
	ctx.r[4].u64 = ctx.r[4].u64 | 236;
	// 831E562C: 606347BC  ori r3, r3, 0x47bc
	ctx.r[3].u64 = ctx.r[3].u64 | 18364;
	// 831E5630: 7EBE3D2E  stfsx f21, r30, r7
	tmp.f32 = (ctx.f[21].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[7].u32), tmp.u32) };
	// 831E5634: 616B47C8  ori r11, r11, 0x47c8
	ctx.r[11].u64 = ctx.r[11].u64 | 18376;
	// 831E5638: 7D1E352E  stfsx f8, r30, r6
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[6].u32), tmp.u32) };
	// 831E563C: 614A47D4  ori r10, r10, 0x47d4
	ctx.r[10].u64 = ctx.r[10].u64 | 18388;
	// 831E5640: 39294FE4  addi r9, r9, 0x4fe4
	ctx.r[9].s64 = ctx.r[9].s64 + 20452;
	// 831E5644: 63885200  ori r8, r28, 0x5200
	ctx.r[8].u64 = ctx.r[28].u64 | 20992;
	// 831E5648: 7F1E252E  stfsx f24, r30, r4
	tmp.f32 = (ctx.f[24].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[4].u32), tmp.u32) };
	// 831E564C: 3F400002  lis r26, 2
	ctx.r[26].s64 = 131072;
	// 831E5650: 7DBE1D2E  stfsx f13, r30, r3
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[3].u32), tmp.u32) };
	// 831E5654: 3F000002  lis r24, 2
	ctx.r[24].s64 = 131072;
	// 831E5658: 7D5E5D2E  stfsx f10, r30, r11
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 831E565C: 3CBE0002  addis r5, r30, 2
	ctx.r[5].s64 = ctx.r[30].s64 + 131072;
	// 831E5660: 7EFE552E  stfsx f23, r30, r10
	tmp.f32 = (ctx.f[23].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[10].u32), tmp.u32) };
	// 831E5664: 6347520C  ori r7, r26, 0x520c
	ctx.r[7].u64 = ctx.r[26].u64 | 21004;
	// 831E5668: D0090008  stfs f0, 8(r9)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E566C: 63065218  ori r6, r24, 0x5218
	ctx.r[6].u64 = ctx.r[24].u64 | 21016;
	// 831E5670: D1E90004  stfs f15, 4(r9)
	tmp.f32 = (ctx.f[15].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E5674: 38A57228  addi r5, r5, 0x7228
	ctx.r[5].s64 = ctx.r[5].s64 + 29224;
	// 831E5678: 7DBE452E  stfsx f13, r30, r8
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[8].u32), tmp.u32) };
	// 831E567C: 3C800002  lis r4, 2
	ctx.r[4].s64 = 131072;
	// 831E5680: 3D1E0002  addis r8, r30, 2
	ctx.r[8].s64 = ctx.r[30].s64 + 131072;
	// 831E5684: 7D3E3D2E  stfsx f9, r30, r7
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[7].u32), tmp.u32) };
	// 831E5688: 3C600002  lis r3, 2
	ctx.r[3].s64 = 131072;
	// 831E568C: 7E5E352E  stfsx f18, r30, r6
	tmp.f32 = (ctx.f[18].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[6].u32), tmp.u32) };
	// 831E5690: 3D600002  lis r11, 2
	ctx.r[11].s64 = 131072;
	// 831E5694: D0050008  stfs f0, 8(r5)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E5698: 3D400002  lis r10, 2
	ctx.r[10].s64 = 131072;
	// 831E569C: D1E50004  stfs f15, 4(r5)
	tmp.f32 = (ctx.f[15].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E56A0: 3D200002  lis r9, 2
	ctx.r[9].s64 = 131072;
	// 831E56A4: 39087640  addi r8, r8, 0x7640
	ctx.r[8].s64 = ctx.r[8].s64 + 30272;
	// 831E56A8: 60877E5C  ori r7, r4, 0x7e5c
	ctx.r[7].u64 = ctx.r[4].u64 | 32348;
	// 831E56AC: 616547B0  ori r5, r11, 0x47b0
	ctx.r[5].u64 = ctx.r[11].u64 | 18352;
	// 831E56B0: D0080008  stfs f0, 8(r8)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E56B4: 60667E68  ori r6, r3, 0x7e68
	ctx.r[6].u64 = ctx.r[3].u64 | 32360;
	// 831E56B8: D1E80004  stfs f15, 4(r8)
	tmp.f32 = (ctx.f[15].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E56BC: 614447B4  ori r4, r10, 0x47b4
	ctx.r[4].u64 = ctx.r[10].u64 | 18356;
	// 831E56C0: 7E3E3D2E  stfsx f17, r30, r7
	tmp.f32 = (ctx.f[17].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[7].u32), tmp.u32) };
	// 831E56C4: 3D600002  lis r11, 2
	ctx.r[11].s64 = 131072;
	// 831E56C8: C0010058  lfs f0, 0x58(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E56CC: 61239EAC  ori r3, r9, 0x9eac
	ctx.r[3].u64 = ctx.r[9].u64 | 40620;
	// 831E56D0: FC20F090  fmr f1, f30
	ctx.f[1].f64 = ctx.f[30].f64;
	// 831E56D4: 7E1E2D2E  stfsx f16, r30, r5
	tmp.f32 = (ctx.f[16].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[5].u32), tmp.u32) };
	// 831E56D8: 3D200002  lis r9, 2
	ctx.r[9].s64 = 131072;
	// 831E56DC: 61659EC4  ori r5, r11, 0x9ec4
	ctx.r[5].u64 = ctx.r[11].u64 | 40644;
	// 831E56E0: 7CFE352E  stfsx f7, r30, r6
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[6].u32), tmp.u32) };
	// 831E56E4: 3D400002  lis r10, 2
	ctx.r[10].s64 = 131072;
	// 831E56E8: 7C1E252E  stfsx f0, r30, r4
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[4].u32), tmp.u32) };
	// 831E56EC: 3D000002  lis r8, 2
	ctx.r[8].s64 = 131072;
	// 831E56F0: D3F00008  stfs f31, 8(r16)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[16].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E56F4: 612B9ECC  ori r11, r9, 0x9ecc
	ctx.r[11].u64 = ctx.r[9].u64 | 40652;
	// 831E56F8: D1D00004  stfs f14, 4(r16)
	tmp.f32 = (ctx.f[14].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[16].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E56FC: 3CE00002  lis r7, 2
	ctx.r[7].s64 = 131072;
	// 831E5700: D3EF0008  stfs f31, 8(r15)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[15].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E5704: 3CC00002  lis r6, 2
	ctx.r[6].s64 = 131072;
	// 831E5708: D1CF0004  stfs f14, 4(r15)
	tmp.f32 = (ctx.f[14].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[15].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E570C: 61449EC8  ori r4, r10, 0x9ec8
	ctx.r[4].u64 = ctx.r[10].u64 | 40648;
	// 831E5710: 7C9E2D2E  stfsx f4, r30, r5
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[5].u32), tmp.u32) };
	// 831E5714: 610A9EE8  ori r10, r8, 0x9ee8
	ctx.r[10].u64 = ctx.r[8].u64 | 40680;
	// 831E5718: 7CBE1D2E  stfsx f5, r30, r3
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[3].u32), tmp.u32) };
	// 831E571C: 60E99EEC  ori r9, r7, 0x9eec
	ctx.r[9].u64 = ctx.r[7].u64 | 40684;
	// 831E5720: 7C5E5D2E  stfsx f2, r30, r11
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 831E5724: 60C8DF20  ori r8, r6, 0xdf20
	ctx.r[8].u64 = ctx.r[6].u64 | 57120;
	// 831E5728: 3CE00002  lis r7, 2
	ctx.r[7].s64 = 131072;
	// 831E572C: 3CC00002  lis r6, 2
	ctx.r[6].s64 = 131072;
	// 831E5730: 7C7E252E  stfsx f3, r30, r4
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[4].u32), tmp.u32) };
	// 831E5734: 3CA00002  lis r5, 2
	ctx.r[5].s64 = 131072;
	// 831E5738: 7FBE552E  stfsx f29, r30, r10
	tmp.f32 = (ctx.f[29].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[10].u32), tmp.u32) };
	// 831E573C: 60E7EF68  ori r7, r7, 0xef68
	ctx.r[7].u64 = ctx.r[7].u64 | 61288;
	// 831E5740: 7F5E4D2E  stfsx f26, r30, r9
	tmp.f32 = (ctx.f[26].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[9].u32), tmp.u32) };
	// 831E5744: 60C6EF80  ori r6, r6, 0xef80
	ctx.r[6].u64 = ctx.r[6].u64 | 61312;
	// 831E5748: 7D9E452E  stfsx f12, r30, r8
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[8].u32), tmp.u32) };
	// 831E574C: 3C600002  lis r3, 2
	ctx.r[3].s64 = 131072;
	// 831E5750: D3F20008  stfs f31, 8(r18)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[18].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E5754: 3D600002  lis r11, 2
	ctx.r[11].s64 = 131072;
	// 831E5758: D1D20004  stfs f14, 4(r18)
	tmp.f32 = (ctx.f[14].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[18].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E575C: 60A5EF84  ori r5, r5, 0xef84
	ctx.r[5].u64 = ctx.r[5].u64 | 61316;
	// 831E5760: D3F10008  stfs f31, 8(r17)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[17].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E5764: 6063EF88  ori r3, r3, 0xef88
	ctx.r[3].u64 = ctx.r[3].u64 | 61320;
	// 831E5768: D1D10004  stfs f14, 4(r17)
	tmp.f32 = (ctx.f[14].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[17].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E576C: 616BEFA4  ori r11, r11, 0xefa4
	ctx.r[11].u64 = ctx.r[11].u64 | 61348;
	// 831E5770: 7CBE3D2E  stfsx f5, r30, r7
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[7].u32), tmp.u32) };
	// 831E5774: 3D400002  lis r10, 2
	ctx.r[10].s64 = 131072;
	// 831E5778: 7C9E352E  stfsx f4, r30, r6
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[6].u32), tmp.u32) };
	// 831E577C: 3D200003  lis r9, 3
	ctx.r[9].s64 = 196608;
	// 831E5780: 3D000003  lis r8, 3
	ctx.r[8].s64 = 196608;
	// 831E5784: 7C7E2D2E  stfsx f3, r30, r5
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[5].u32), tmp.u32) };
	// 831E5788: 3C800003  lis r4, 3
	ctx.r[4].s64 = 196608;
	// 831E578C: 7C5E1D2E  stfsx f2, r30, r3
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[3].u32), tmp.u32) };
	// 831E5790: 614AEFA8  ori r10, r10, 0xefa8
	ctx.r[10].u64 = ctx.r[10].u64 | 61352;
	// 831E5794: 7FBE5D2E  stfsx f29, r30, r11
	tmp.f32 = (ctx.f[29].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 831E5798: 61292FDC  ori r9, r9, 0x2fdc
	ctx.r[9].u64 = ctx.r[9].u64 | 12252;
	// 831E579C: 3CE00004  lis r7, 4
	ctx.r[7].s64 = 262144;
	// 831E57A0: 3CC00004  lis r6, 4
	ctx.r[6].s64 = 262144;
	// 831E57A4: 6105E07C  ori r5, r8, 0xe07c
	ctx.r[5].u64 = ctx.r[8].u64 | 57468;
	// 831E57A8: 6084E080  ori r4, r4, 0xe080
	ctx.r[4].u64 = ctx.r[4].u64 | 57472;
	// 831E57AC: 7F5E552E  stfsx f26, r30, r10
	tmp.f32 = (ctx.f[26].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[10].u32), tmp.u32) };
	// 831E57B0: 60E3911C  ori r3, r7, 0x911c
	ctx.r[3].u64 = ctx.r[7].u64 | 37148;
	// 831E57B4: 7D9E4D2E  stfsx f12, r30, r9
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[9].u32), tmp.u32) };
	// 831E57B8: 60CB9120  ori r11, r6, 0x9120
	ctx.r[11].u64 = ctx.r[6].u64 | 37152;
	// 831E57BC: D3F90008  stfs f31, 8(r25)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E57C0: D1D90004  stfs f14, 4(r25)
	tmp.f32 = (ctx.f[14].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E57C4: 3D40820E  lis r10, -0x7df2
	ctx.r[10].s64 = -2113011712;
	// 831E57C8: 7D7E2D2E  stfsx f11, r30, r5
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[5].u32), tmp.u32) };
	// 831E57CC: 7D7E252E  stfsx f11, r30, r4
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[4].u32), tmp.u32) };
	// 831E57D0: D3FB0008  stfs f31, 8(r27)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E57D4: D1DB0004  stfs f14, 4(r27)
	tmp.f32 = (ctx.f[14].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E57D8: 7CDE1D2E  stfsx f6, r30, r3
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[3].u32), tmp.u32) };
	// 831E57DC: 7CDE5D2E  stfsx f6, r30, r11
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 831E57E0: CBAAC4D8  lfd f29, -0x3b28(r10)
	ctx.f[29].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[10].u32.wrapping_add(-15144 as u32) ) };
	// 831E57E4: C1BD0044  lfs f13, 0x44(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(68 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E57E8: FC4D0772  fmul f2, f13, f29
	ctx.f[2].f64 = ctx.f[13].f64 * ctx.f[29].f64;
	// 831E57EC: 4BFC5CBD  bl 0x831ab4a8
	ctx.lr = 0x831E57F0;
	sub_831AB4A8(ctx, base);
	// 831E57F0: FD800818  frsp f12, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[12].f64 = (ctx.f[1].f64 as f32) as f64;
	// 831E57F4: 3D200002  lis r9, 2
	ctx.r[9].s64 = 131072;
	// 831E57F8: FC20F090  fmr f1, f30
	ctx.f[1].f64 = ctx.f[30].f64;
	// 831E57FC: 61289F0C  ori r8, r9, 0x9f0c
	ctx.r[8].u64 = ctx.r[9].u64 | 40716;
	// 831E5800: ED6C0732  fmuls f11, f12, f28
	ctx.f[11].f64 = (((ctx.f[12].f64 * ctx.f[28].f64) as f32) as f64);
	// 831E5804: 7D7E452E  stfsx f11, r30, r8
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[8].u32), tmp.u32) };
	// 831E5808: C15D0044  lfs f10, 0x44(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(68 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831E580C: FC4A0772  fmul f2, f10, f29
	ctx.f[2].f64 = ctx.f[10].f64 * ctx.f[29].f64;
	// 831E5810: 4BFC5C99  bl 0x831ab4a8
	ctx.lr = 0x831E5814;
	sub_831AB4A8(ctx, base);
	// 831E5814: FD200818  frsp f9, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[9].f64 = (ctx.f[1].f64 as f32) as f64;
	// 831E5818: 3CE00002  lis r7, 2
	ctx.r[7].s64 = 131072;
	// 831E581C: FC20F090  fmr f1, f30
	ctx.f[1].f64 = ctx.f[30].f64;
	// 831E5820: 60E6EFC8  ori r6, r7, 0xefc8
	ctx.r[6].u64 = ctx.r[7].u64 | 61384;
	// 831E5824: ED0906F2  fmuls f8, f9, f27
	ctx.f[8].f64 = (((ctx.f[9].f64 * ctx.f[27].f64) as f32) as f64);
	// 831E5828: 7D1E352E  stfsx f8, r30, r6
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[6].u32), tmp.u32) };
	// 831E582C: C0FD0044  lfs f7, 0x44(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(68 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831E5830: FC470772  fmul f2, f7, f29
	ctx.f[2].f64 = ctx.f[7].f64 * ctx.f[29].f64;
	// 831E5834: 4BFC5C75  bl 0x831ab4a8
	ctx.lr = 0x831E5838;
	sub_831AB4A8(ctx, base);
	// 831E5838: FCC00818  frsp f6, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[6].f64 = (ctx.f[1].f64 as f32) as f64;
	// 831E583C: 3CA00003  lis r5, 3
	ctx.r[5].s64 = 196608;
	// 831E5840: FC20F090  fmr f1, f30
	ctx.f[1].f64 = ctx.f[30].f64;
	// 831E5844: 60A4A064  ori r4, r5, 0xa064
	ctx.r[4].u64 = ctx.r[5].u64 | 41060;
	// 831E5848: ECA60532  fmuls f5, f6, f20
	ctx.f[5].f64 = (((ctx.f[6].f64 * ctx.f[20].f64) as f32) as f64);
	// 831E584C: 7CBE252E  stfsx f5, r30, r4
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[4].u32), tmp.u32) };
	// 831E5850: C09D0044  lfs f4, 0x44(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(68 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831E5854: FC440772  fmul f2, f4, f29
	ctx.f[2].f64 = ctx.f[4].f64 * ctx.f[29].f64;
	// 831E5858: 4BFC5C51  bl 0x831ab4a8
	ctx.lr = 0x831E585C;
	sub_831AB4A8(ctx, base);
	// 831E585C: FC600818  frsp f3, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[3].f64 = (ctx.f[1].f64 as f32) as f64;
	// 831E5860: 3C600004  lis r3, 4
	ctx.r[3].s64 = 262144;
	// 831E5864: FC20F090  fmr f1, f30
	ctx.f[1].f64 = ctx.f[30].f64;
	// 831E5868: 606B5104  ori r11, r3, 0x5104
	ctx.r[11].u64 = ctx.r[3].u64 | 20740;
	// 831E586C: EC4304F2  fmuls f2, f3, f19
	ctx.f[2].f64 = (((ctx.f[3].f64 * ctx.f[19].f64) as f32) as f64);
	// 831E5870: 7C5E5D2E  stfsx f2, r30, r11
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 831E5874: C01D0040  lfs f0, 0x40(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(64 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5878: FC400772  fmul f2, f0, f29
	ctx.f[2].f64 = ctx.f[0].f64 * ctx.f[29].f64;
	// 831E587C: 4BFC5C2D  bl 0x831ab4a8
	ctx.lr = 0x831E5880;
	sub_831AB4A8(ctx, base);
	// 831E5880: C01F0014  lfs f0, 0x14(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5884: ED9F0032  fmuls f12, f31, f0
	ctx.f[12].f64 = (((ctx.f[31].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E5888: 3D5E0005  addis r10, r30, 5
	ctx.r[10].s64 = ctx.r[30].s64 + 327680;
	// 831E588C: FDA00818  frsp f13, f1
	ctx.f[13].f64 = (ctx.f[1].f64 as f32) as f64;
	// 831E5890: D1BE0060  stfs f13, 0x60(r30)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(96 as u32), tmp.u32 ) };
	// 831E5894: 394A9130  addi r10, r10, -0x6ed0
	ctx.r[10].s64 = ctx.r[10].s64 + -28368;
	// 831E5898: 3D3E0005  addis r9, r30, 5
	ctx.r[9].s64 = ctx.r[30].s64 + 327680;
	// 831E589C: 3D1E0005  addis r8, r30, 5
	ctx.r[8].s64 = ctx.r[30].s64 + 327680;
	// 831E58A0: 3CFE0005  addis r7, r30, 5
	ctx.r[7].s64 = ctx.r[30].s64 + 327680;
	// 831E58A4: 39299948  addi r9, r9, -0x66b8
	ctx.r[9].s64 = ctx.r[9].s64 + -26296;
	// 831E58A8: 3908A160  addi r8, r8, -0x5ea0
	ctx.r[8].s64 = ctx.r[8].s64 + -24224;
	// 831E58AC: D18A0008  stfs f12, 8(r10)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E58B0: 3FFE0002  addis r31, r30, 2
	ctx.r[31].s64 = ctx.r[30].s64 + 131072;
	// 831E58B4: 38E7A978  addi r7, r7, -0x5688
	ctx.r[7].s64 = ctx.r[7].s64 + -22152;
	// 831E58B8: FD606050  fneg f11, f12
	ctx.f[11].u64 = ctx.f[12].u64 ^ 0x8000_0000_0000_0000u64;
	// 831E58BC: D16A0004  stfs f11, 4(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E58C0: 3BFF00A8  addi r31, r31, 0xa8
	ctx.r[31].s64 = ctx.r[31].s64 + 168;
	// 831E58C4: D1890008  stfs f12, 8(r9)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E58C8: D1690004  stfs f11, 4(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E58CC: D1880008  stfs f12, 8(r8)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E58D0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E58D4: D1680004  stfs f11, 4(r8)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E58D8: D1670004  stfs f11, 4(r7)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E58DC: D1870008  stfs f12, 8(r7)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E58E0: C15D0034  lfs f10, 0x34(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(52 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831E58E4: D15F0004  stfs f10, 4(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E58E8: 4BFFEF49  bl 0x831e4830
	ctx.lr = 0x831E58EC;
	sub_831E4830(ctx, base);
	// 831E58EC: C13D0038  lfs f9, 0x38(r29)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(56 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831E58F0: D13F0008  stfs f9, 8(r31)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E58F4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E58F8: 4BFFEF39  bl 0x831e4830
	ctx.lr = 0x831E58FC;
	sub_831E4830(ctx, base);
	// 831E58FC: C11D003C  lfs f8, 0x3c(r29)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(60 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831E5900: D11F000C  stfs f8, 0xc(r31)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E5904: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E5908: 4BFFEF29  bl 0x831e4830
	ctx.lr = 0x831E590C;
	sub_831E4830(ctx, base);
	// 831E590C: 3FFE0002  addis r31, r30, 2
	ctx.r[31].s64 = ctx.r[30].s64 + 131072;
	// 831E5910: C0FD0034  lfs f7, 0x34(r29)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(52 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831E5914: 3BFF00C8  addi r31, r31, 0xc8
	ctx.r[31].s64 = ctx.r[31].s64 + 200;
	// 831E5918: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E591C: D0FF0004  stfs f7, 4(r31)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E5920: 4BFFEF11  bl 0x831e4830
	ctx.lr = 0x831E5924;
	sub_831E4830(ctx, base);
	// 831E5924: C0DD0038  lfs f6, 0x38(r29)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(56 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 831E5928: D0DF0008  stfs f6, 8(r31)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E592C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E5930: 4BFFEF01  bl 0x831e4830
	ctx.lr = 0x831E5934;
	sub_831E4830(ctx, base);
	// 831E5934: C0BD003C  lfs f5, 0x3c(r29)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(60 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831E5938: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E593C: D0BF000C  stfs f5, 0xc(r31)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E5940: 4BFFEEF1  bl 0x831e4830
	ctx.lr = 0x831E5944;
	sub_831E4830(ctx, base);
	// 831E5944: 817D0030  lwz r11, 0x30(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(48 as u32) ) } as u64;
	// 831E5948: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E594C: 409A000C  bne cr6, 0x831e5958
	if !ctx.cr[6].eq {
	pc = 0x831E5958; continue 'dispatch;
	}
	// 831E5950: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 831E5954: 48000034  b 0x831e5988
	pc = 0x831E5988; continue 'dispatch;
	// 831E5958: 796B0020  clrldi r11, r11, 0x20
	ctx.r[11].u64 = ctx.r[11].u64 & 0x00000000FFFFFFFFu64;
	// 831E595C: C01E0058  lfs f0, 0x58(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(88 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5960: C1A10060  lfs f13, 0x60(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E5964: F9610068  std r11, 0x68(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[11].u64 ) };
	// 831E5968: C9810068  lfd f12, 0x68(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) };
	// 831E596C: FD60669C  fcfid f11, f12
	ctx.f[11].f64 = (ctx.f[12].s64 as f64);
	// 831E5970: FD405818  frsp f10, f11
	ctx.f[10].f64 = (ctx.f[11].f64 as f32) as f64;
	// 831E5974: ED2A0032  fmuls f9, f10, f0
	ctx.f[9].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E5978: ED090372  fmuls f8, f9, f13
	ctx.f[8].f64 = (((ctx.f[9].f64 * ctx.f[13].f64) as f32) as f64);
	// 831E597C: FCE0465E  fctidz f7, f8
	ctx.f[7].s64 = if ctx.f[8].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[8].f64.trunc() as i64 };
	// 831E5980: D8E10068  stfd f7, 0x68(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.f[7].u64 ) };
	// 831E5984: 8141006C  lwz r10, 0x6c(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(108 as u32) ) } as u64;
	// 831E5988: 3D7E0005  addis r11, r30, 5
	ctx.r[11].s64 = ctx.r[30].s64 + 327680;
	// 831E598C: 396BB190  addi r11, r11, -0x4e70
	ctx.r[11].s64 = ctx.r[11].s64 + -20080;
	// 831E5990: 812B000C  lwz r9, 0xc(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E5994: 810B0008  lwz r8, 8(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E5998: 914B0010  stw r10, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[10].u32 ) };
	// 831E599C: 7F094040  cmplw cr6, r9, r8
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831E59A0: 409A0010  bne cr6, 0x831e59b0
	if !ctx.cr[6].eq {
	pc = 0x831E59B0; continue 'dispatch;
	}
	// 831E59A4: C0010050  lfs f0, 0x50(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E59A8: 914B0008  stw r10, 8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E59AC: D00B0004  stfs f0, 4(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E59B0: 3D7E0005  addis r11, r30, 5
	ctx.r[11].s64 = ctx.r[30].s64 + 327680;
	// 831E59B4: 396BB5B0  addi r11, r11, -0x4a50
	ctx.r[11].s64 = ctx.r[11].s64 + -19024;
	// 831E59B8: 812B000C  lwz r9, 0xc(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E59BC: 810B0008  lwz r8, 8(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E59C0: 914B0010  stw r10, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[10].u32 ) };
	// 831E59C4: 7F094040  cmplw cr6, r9, r8
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831E59C8: 409A0010  bne cr6, 0x831e59d8
	if !ctx.cr[6].eq {
	pc = 0x831E59D8; continue 'dispatch;
	}
	// 831E59CC: C0010050  lfs f0, 0x50(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E59D0: 914B0008  stw r10, 8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E59D4: D00B0004  stfs f0, 4(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E59D8: 382101A0  addi r1, r1, 0x1a0
	ctx.r[1].s64 = ctx.r[1].s64 + 416;
	// 831E59DC: 3981FF68  addi r12, r1, -0x98
	ctx.r[12].s64 = ctx.r[1].s64 + -152;
	// 831E59E0: 4BFC30AD  bl 0x831a8a8c
	ctx.lr = 0x831E59E4;
	sub_831A8A8C(ctx, base);
	// 831E59E4: 4BFC279C  b 0x831a8180
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E59E8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831E59E8 size=3036
    let mut pc: u32 = 0x831E59E8;
    'dispatch: loop {
        match pc {
            0x831E59E8 => {
    //   block [0x831E59E8..0x831E65C4)
	// 831E59E8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E59EC: 4BFC275D  bl 0x831a8148
	ctx.lr = 0x831E59F0;
	sub_831A8130(ctx, base);
	// 831E59F0: 3981FF98  addi r12, r1, -0x68
	ctx.r[12].s64 = ctx.r[1].s64 + -104;
	// 831E59F4: 4BFC3059  bl 0x831a8a4c
	ctx.lr = 0x831E59F8;
	sub_831A8A40(ctx, base);
	// 831E59F8: 9421FED0  stwu r1, -0x130(r1)
	ea = ctx.r[1].u32.wrapping_add(-304 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E59FC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E5A00: 3CE0821A  lis r7, -0x7de6
	ctx.r[7].s64 = -2112225280;
	// 831E5A04: 3F00821A  lis r24, -0x7de6
	ctx.r[24].s64 = -2112225280;
	// 831E5A08: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E5A0C: 3EE0821A  lis r23, -0x7de6
	ctx.r[23].s64 = -2112225280;
	// 831E5A10: 3CA0821A  lis r5, -0x7de6
	ctx.r[5].s64 = -2112225280;
	// 831E5A14: 38CBFF60  addi r6, r11, -0xa0
	ctx.r[6].s64 = ctx.r[11].s64 + -160;
	// 831E5A18: C1A70378  lfs f13, 0x378(r7)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(888 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E5A1C: 3EC0821A  lis r22, -0x7de6
	ctx.r[22].s64 = -2112225280;
	// 831E5A20: C0180370  lfs f0, 0x370(r24)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5A24: 90DF0000  stw r6, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[6].u32 ) };
	// 831E5A28: 39600008  li r11, 8
	ctx.r[11].s64 = 8;
	// 831E5A2C: 39400005  li r10, 5
	ctx.r[10].s64 = 5;
	// 831E5A30: C1970374  lfs f12, 0x374(r23)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(884 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831E5A34: 39000006  li r8, 6
	ctx.r[8].s64 = 6;
	// 831E5A38: D01F003C  stfs f0, 0x3c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(60 as u32), tmp.u32 ) };
	// 831E5A3C: 39200004  li r9, 4
	ctx.r[9].s64 = 4;
	// 831E5A40: D01F0040  stfs f0, 0x40(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(64 as u32), tmp.u32 ) };
	// 831E5A44: D01F0044  stfs f0, 0x44(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), tmp.u32 ) };
	// 831E5A48: 915F0004  stw r10, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831E5A4C: D1BF0050  stfs f13, 0x50(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 831E5A50: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E5A54: C005036C  lfs f0, 0x36c(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(876 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5A58: 911F000C  stw r8, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[8].u32 ) };
	// 831E5A5C: C1B80370  lfs f13, 0x370(r24)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E5A60: 911F0010  stw r8, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[8].u32 ) };
	// 831E5A64: C1670378  lfs f11, 0x378(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(888 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831E5A68: 917F001C  stw r11, 0x1c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831E5A6C: D19F004C  stfs f12, 0x4c(r31)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(76 as u32), tmp.u32 ) };
	// 831E5A70: 917F0020  stw r11, 0x20(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[11].u32 ) };
	// 831E5A74: C196037C  lfs f12, 0x37c(r22)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[22].u32.wrapping_add(892 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831E5A78: 917F0024  stw r11, 0x24(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), ctx.r[11].u32 ) };
	// 831E5A7C: C1570374  lfs f10, 0x374(r23)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(884 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831E5A80: 913F0028  stw r9, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[9].u32 ) };
	// 831E5A84: D01F0038  stfs f0, 0x38(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(56 as u32), tmp.u32 ) };
	// 831E5A88: 917F002C  stw r11, 0x2c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(44 as u32), ctx.r[11].u32 ) };
	// 831E5A8C: D1BF0048  stfs f13, 0x48(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(72 as u32), tmp.u32 ) };
	// 831E5A90: 913F0030  stw r9, 0x30(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(48 as u32), ctx.r[9].u32 ) };
	// 831E5A94: D17F0054  stfs f11, 0x54(r31)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 831E5A98: 915F0034  stw r10, 0x34(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(52 as u32), ctx.r[10].u32 ) };
	// 831E5A9C: D19F0058  stfs f12, 0x58(r31)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 831E5AA0: 3C808202  lis r4, -0x7dfe
	ctx.r[4].s64 = -2113798144;
	// 831E5AA4: D15F005C  stfs f10, 0x5c(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 831E5AA8: 3C608204  lis r3, -0x7dfc
	ctx.r[3].s64 = -2113667072;
	// 831E5AAC: CBA4D228  lfd f29, -0x2dd8(r4)
	ctx.f[29].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[4].u32.wrapping_add(-11736 as u32) ) };
	// 831E5AB0: CB83D1E0  lfd f28, -0x2e20(r3)
	ctx.f[28].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[3].u32.wrapping_add(-11808 as u32) ) };
	// 831E5AB4: FC40E890  fmr f2, f29
	ctx.f[2].f64 = ctx.f[29].f64;
	// 831E5AB8: FC20E090  fmr f1, f28
	ctx.f[1].f64 = ctx.f[28].f64;
	// 831E5ABC: 4BFC59ED  bl 0x831ab4a8
	ctx.lr = 0x831E5AC0;
	sub_831AB4A8(ctx, base);
	// 831E5AC0: FC000818  frsp f0, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].f64 = (ctx.f[1].f64 as f32) as f64;
	// 831E5AC4: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 831E5AC8: D01F0060  stfs f0, 0x60(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(96 as u32), tmp.u32 ) };
	// 831E5ACC: C0180370  lfs f0, 0x370(r24)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5AD0: 3BA00028  li r29, 0x28
	ctx.r[29].s64 = 40;
	// 831E5AD4: 93DF0064  stw r30, 0x64(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(100 as u32), ctx.r[30].u32 ) };
	// 831E5AD8: D01F006C  stfs f0, 0x6c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(108 as u32), tmp.u32 ) };
	// 831E5ADC: FDA00090  fmr f13, f0
	ctx.f[13].f64 = ctx.f[0].f64;
	// 831E5AE0: C016037C  lfs f0, 0x37c(r22)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[22].u32.wrapping_add(892 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5AE4: D1BF007C  stfs f13, 0x7c(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(124 as u32), tmp.u32 ) };
	// 831E5AE8: 93BF0070  stw r29, 0x70(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(112 as u32), ctx.r[29].u32 ) };
	// 831E5AEC: D01F0068  stfs f0, 0x68(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(104 as u32), tmp.u32 ) };
	// 831E5AF0: 93BF0074  stw r29, 0x74(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(116 as u32), ctx.r[29].u32 ) };
	// 831E5AF4: 93BF0078  stw r29, 0x78(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(120 as u32), ctx.r[29].u32 ) };
	// 831E5AF8: D1BF0084  stfs f13, 0x84(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(132 as u32), tmp.u32 ) };
	// 831E5AFC: 93DF0080  stw r30, 0x80(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(128 as u32), ctx.r[30].u32 ) };
	// 831E5B00: 397F0068  addi r11, r31, 0x68
	ctx.r[11].s64 = ctx.r[31].s64 + 104;
	// 831E5B04: 386B0018  addi r3, r11, 0x18
	ctx.r[3].s64 = ctx.r[11].s64 + 24;
	// 831E5B08: 4BFFEE91  bl 0x831e4998
	ctx.lr = 0x831E5B0C;
	sub_831E4998(ctx, base);
	// 831E5B0C: 3D7F0001  addis r11, r31, 1
	ctx.r[11].s64 = ctx.r[31].s64 + 65536;
	// 831E5B10: C1B80370  lfs f13, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E5B14: 396B0088  addi r11, r11, 0x88
	ctx.r[11].s64 = ctx.r[11].s64 + 136;
	// 831E5B18: C016037C  lfs f0, 0x37c(r22)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[22].u32.wrapping_add(892 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5B1C: 386B0018  addi r3, r11, 0x18
	ctx.r[3].s64 = ctx.r[11].s64 + 24;
	// 831E5B20: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E5B24: 93AB0008  stw r29, 8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 831E5B28: D1AB0014  stfs f13, 0x14(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E5B2C: 93AB000C  stw r29, 0xc(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[29].u32 ) };
	// 831E5B30: D00B0000  stfs f0, 0(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831E5B34: 93AB0010  stw r29, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[29].u32 ) };
	// 831E5B38: D1AB001C  stfs f13, 0x1c(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 831E5B3C: 93CB0018  stw r30, 0x18(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), ctx.r[30].u32 ) };
	// 831E5B40: 4BFFEE59  bl 0x831e4998
	ctx.lr = 0x831E5B44;
	sub_831E4998(ctx, base);
	// 831E5B44: 3EA08201  lis r21, -0x7dff
	ctx.r[21].s64 = -2113863680;
	// 831E5B48: 3C7F0002  addis r3, r31, 2
	ctx.r[3].s64 = ctx.r[31].s64 + 131072;
	// 831E5B4C: C19F0058  lfs f12, 0x58(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(88 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831E5B50: C1B80370  lfs f13, 0x370(r24)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E5B54: 386300A8  addi r3, r3, 0xa8
	ctx.r[3].s64 = ctx.r[3].s64 + 168;
	// 831E5B58: C0159450  lfs f0, -0x6bb0(r21)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(-27568 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5B5C: ED6C0032  fmuls f11, f12, f0
	ctx.f[11].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E5B60: FC006890  fmr f0, f13
	ctx.f[0].f64 = ctx.f[13].f64;
	// 831E5B64: D003000C  stfs f0, 0xc(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E5B68: D0030018  stfs f0, 0x18(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 831E5B6C: D1A30008  stfs f13, 8(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E5B70: D1830000  stfs f12, 0(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831E5B74: D1630004  stfs f11, 4(r3)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E5B78: D003001C  stfs f0, 0x1c(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 831E5B7C: 4BFFECB5  bl 0x831e4830
	ctx.lr = 0x831E5B80;
	sub_831E4830(ctx, base);
	// 831E5B80: 3C7F0002  addis r3, r31, 2
	ctx.r[3].s64 = ctx.r[31].s64 + 131072;
	// 831E5B84: C15F0058  lfs f10, 0x58(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(88 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831E5B88: 386300C8  addi r3, r3, 0xc8
	ctx.r[3].s64 = ctx.r[3].s64 + 200;
	// 831E5B8C: C0159450  lfs f0, -0x6bb0(r21)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(-27568 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5B90: C1B80370  lfs f13, 0x370(r24)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E5B94: ED2A0032  fmuls f9, f10, f0
	ctx.f[9].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E5B98: FC006890  fmr f0, f13
	ctx.f[0].f64 = ctx.f[13].f64;
	// 831E5B9C: D003000C  stfs f0, 0xc(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E5BA0: D0030018  stfs f0, 0x18(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 831E5BA4: D1A30008  stfs f13, 8(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E5BA8: D1430000  stfs f10, 0(r3)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831E5BAC: D1230004  stfs f9, 4(r3)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E5BB0: D003001C  stfs f0, 0x1c(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 831E5BB4: 4BFFEC7D  bl 0x831e4830
	ctx.lr = 0x831E5BB8;
	sub_831E4830(ctx, base);
	// 831E5BB8: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E5BBC: 3D400002  lis r10, 2
	ctx.r[10].s64 = 131072;
	// 831E5BC0: C0180370  lfs f0, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5BC4: 3A8B0380  addi r20, r11, 0x380
	ctx.r[20].s64 = ctx.r[11].s64 + 896;
	// 831E5BC8: 3D200002  lis r9, 2
	ctx.r[9].s64 = 131072;
	// 831E5BCC: 614800E8  ori r8, r10, 0xe8
	ctx.r[8].u64 = ctx.r[10].u64 | 232;
	// 831E5BD0: C3CB0380  lfs f30, 0x380(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(896 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 831E5BD4: 3D7F0002  addis r11, r31, 2
	ctx.r[11].s64 = ctx.r[31].s64 + 131072;
	// 831E5BD8: 612700EC  ori r7, r9, 0xec
	ctx.r[7].u64 = ctx.r[9].u64 | 236;
	// 831E5BDC: 396B00F0  addi r11, r11, 0xf0
	ctx.r[11].s64 = ctx.r[11].s64 + 240;
	// 831E5BE0: C354002C  lfs f26, 0x2c(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(44 as u32) ) };
	ctx.f[26].f64 = (tmp.f32 as f64);
	// 831E5BE4: 3B2001FD  li r25, 0x1fd
	ctx.r[25].s64 = 509;
	// 831E5BE8: C3340030  lfs f25, 0x30(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(48 as u32) ) };
	ctx.f[25].f64 = (tmp.f32 as f64);
	// 831E5BEC: 3B4001FC  li r26, 0x1fc
	ctx.r[26].s64 = 508;
	// 831E5BF0: 7F5F452E  stfsx f26, r31, r8
	tmp.f32 = (ctx.f[26].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[31].u32.wrapping_add(ctx.r[8].u32), tmp.u32) };
	// 831E5BF4: 3BA00001  li r29, 1
	ctx.r[29].s64 = 1;
	// 831E5BF8: C3140004  lfs f24, 4(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) };
	ctx.f[24].f64 = (tmp.f32 as f64);
	// 831E5BFC: 7F3F3D2E  stfsx f25, r31, r7
	tmp.f32 = (ctx.f[25].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[31].u32.wrapping_add(ctx.r[7].u32), tmp.u32) };
	// 831E5C00: 386B0024  addi r3, r11, 0x24
	ctx.r[3].s64 = ctx.r[11].s64 + 36;
	// 831E5C04: C2F40008  lfs f23, 8(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(8 as u32) ) };
	ctx.f[23].f64 = (tmp.f32 as f64);
	// 831E5C08: 932B0000  stw r25, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[25].u32 ) };
	// 831E5C0C: D00B0008  stfs f0, 8(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E5C10: 934B000C  stw r26, 0xc(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[26].u32 ) };
	// 831E5C14: D00B0014  stfs f0, 0x14(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E5C18: 93AB0018  stw r29, 0x18(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), ctx.r[29].u32 ) };
	// 831E5C1C: D00B0020  stfs f0, 0x20(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(32 as u32), tmp.u32 ) };
	// 831E5C20: D3CB0004  stfs f30, 4(r11)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E5C24: D30B0010  stfs f24, 0x10(r11)
	tmp.f32 = (ctx.f[24].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831E5C28: D2EB001C  stfs f23, 0x1c(r11)
	tmp.f32 = (ctx.f[23].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 831E5C2C: 93CB0024  stw r30, 0x24(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(36 as u32), ctx.r[30].u32 ) };
	// 831E5C30: D00B0028  stfs f0, 0x28(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(40 as u32), tmp.u32 ) };
	// 831E5C34: 4BFFEDC5  bl 0x831e49f8
	ctx.lr = 0x831E5C38;
	sub_831E49F8(ctx, base);
	// 831E5C38: 3D7F0002  addis r11, r31, 2
	ctx.r[11].s64 = ctx.r[31].s64 + 131072;
	// 831E5C3C: 3CC08213  lis r6, -0x7ded
	ctx.r[6].s64 = -2112684032;
	// 831E5C40: C0180370  lfs f0, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5C44: 396B091C  addi r11, r11, 0x91c
	ctx.r[11].s64 = ctx.r[11].s64 + 2332;
	// 831E5C48: C2B4000C  lfs f21, 0xc(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(12 as u32) ) };
	ctx.f[21].f64 = (tmp.f32 as f64);
	// 831E5C4C: 38A00053  li r5, 0x53
	ctx.r[5].s64 = 83;
	// 831E5C50: 386B0010  addi r3, r11, 0x10
	ctx.r[3].s64 = ctx.r[11].s64 + 16;
	// 831E5C54: C2C614D0  lfs f22, 0x14d0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(5328 as u32) ) };
	ctx.f[22].f64 = (tmp.f32 as f64);
	// 831E5C58: D00B000C  stfs f0, 0xc(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E5C5C: 90AB0000  stw r5, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[5].u32 ) };
	// 831E5C60: D2CB0004  stfs f22, 4(r11)
	tmp.f32 = (ctx.f[22].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E5C64: D2AB0008  stfs f21, 8(r11)
	tmp.f32 = (ctx.f[21].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E5C68: 93CB0010  stw r30, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[30].u32 ) };
	// 831E5C6C: D00B0014  stfs f0, 0x14(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E5C70: 4BFFEDE9  bl 0x831e4a58
	ctx.lr = 0x831E5C74;
	sub_831E4A58(ctx, base);
	// 831E5C74: 3D7F0002  addis r11, r31, 2
	ctx.r[11].s64 = ctx.r[31].s64 + 131072;
	// 831E5C78: C0180370  lfs f0, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5C7C: 3C808201  lis r4, -0x7dff
	ctx.r[4].s64 = -2113863680;
	// 831E5C80: 396B0B34  addi r11, r11, 0xb34
	ctx.r[11].s64 = ctx.r[11].s64 + 2868;
	// 831E5C84: 386007F7  li r3, 0x7f7
	ctx.r[3].s64 = 2039;
	// 831E5C88: C2649F78  lfs f19, -0x6088(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(-24712 as u32) ) };
	ctx.f[19].f64 = (tmp.f32 as f64);
	// 831E5C8C: 394007F6  li r10, 0x7f6
	ctx.r[10].s64 = 2038;
	// 831E5C90: C2940014  lfs f20, 0x14(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(20 as u32) ) };
	ctx.f[20].f64 = (tmp.f32 as f64);
	// 831E5C94: 3B600258  li r27, 0x258
	ctx.r[27].s64 = 600;
	// 831E5C98: 906B0000  stw r3, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[3].u32 ) };
	// 831E5C9C: D00B0008  stfs f0, 8(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E5CA0: 914B000C  stw r10, 0xc(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[10].u32 ) };
	// 831E5CA4: D00B0014  stfs f0, 0x14(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E5CA8: 936B0018  stw r27, 0x18(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), ctx.r[27].u32 ) };
	// 831E5CAC: D00B0020  stfs f0, 0x20(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(32 as u32), tmp.u32 ) };
	// 831E5CB0: 386B0024  addi r3, r11, 0x24
	ctx.r[3].s64 = ctx.r[11].s64 + 36;
	// 831E5CB4: D3CB0004  stfs f30, 4(r11)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E5CB8: D28B0010  stfs f20, 0x10(r11)
	tmp.f32 = (ctx.f[20].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831E5CBC: D26B001C  stfs f19, 0x1c(r11)
	tmp.f32 = (ctx.f[19].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 831E5CC0: 93CB0024  stw r30, 0x24(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(36 as u32), ctx.r[30].u32 ) };
	// 831E5CC4: D00B0028  stfs f0, 0x28(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(40 as u32), tmp.u32 ) };
	// 831E5CC8: 4BFFEDF1  bl 0x831e4ab8
	ctx.lr = 0x831E5CCC;
	sub_831E4AB8(ctx, base);
	// 831E5CCC: 3D7F0002  addis r11, r31, 2
	ctx.r[11].s64 = ctx.r[31].s64 + 131072;
	// 831E5CD0: 3D208201  lis r9, -0x7dff
	ctx.r[9].s64 = -2113863680;
	// 831E5CD4: C0180370  lfs f0, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5CD8: 396B2B60  addi r11, r11, 0x2b60
	ctx.r[11].s64 = ctx.r[11].s64 + 11104;
	// 831E5CDC: C3759450  lfs f27, -0x6bb0(r21)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(-27568 as u32) ) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 831E5CE0: 390000D3  li r8, 0xd3
	ctx.r[8].s64 = 211;
	// 831E5CE4: 386B0010  addi r3, r11, 0x10
	ctx.r[3].s64 = ctx.r[11].s64 + 16;
	// 831E5CE8: C3E99530  lfs f31, -0x6ad0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-27344 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 831E5CEC: D00B000C  stfs f0, 0xc(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E5CF0: 910B0000  stw r8, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 831E5CF4: D3EB0004  stfs f31, 4(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E5CF8: D36B0008  stfs f27, 8(r11)
	tmp.f32 = (ctx.f[27].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E5CFC: 93CB0010  stw r30, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[30].u32 ) };
	// 831E5D00: D00B0014  stfs f0, 0x14(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E5D04: 4BFFEE15  bl 0x831e4b18
	ctx.lr = 0x831E5D08;
	sub_831E4B18(ctx, base);
	// 831E5D08: 3D7F0002  addis r11, r31, 2
	ctx.r[11].s64 = ctx.r[31].s64 + 131072;
	// 831E5D0C: 38E00137  li r7, 0x137
	ctx.r[7].s64 = 311;
	// 831E5D10: C0180370  lfs f0, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5D14: 396B2F78  addi r11, r11, 0x2f78
	ctx.r[11].s64 = ctx.r[11].s64 + 12152;
	// 831E5D18: 386B0010  addi r3, r11, 0x10
	ctx.r[3].s64 = ctx.r[11].s64 + 16;
	// 831E5D1C: D00B000C  stfs f0, 0xc(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E5D20: 90EB0000  stw r7, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[7].u32 ) };
	// 831E5D24: D3EB0004  stfs f31, 4(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E5D28: D36B0008  stfs f27, 8(r11)
	tmp.f32 = (ctx.f[27].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E5D2C: 93CB0010  stw r30, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[30].u32 ) };
	// 831E5D30: D00B0014  stfs f0, 0x14(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E5D34: 4BFFECC5  bl 0x831e49f8
	ctx.lr = 0x831E5D38;
	sub_831E49F8(ctx, base);
	// 831E5D38: 3D7F0002  addis r11, r31, 2
	ctx.r[11].s64 = ctx.r[31].s64 + 131072;
	// 831E5D3C: 3B8003FC  li r28, 0x3fc
	ctx.r[28].s64 = 1020;
	// 831E5D40: C0180370  lfs f0, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5D44: 396B3790  addi r11, r11, 0x3790
	ctx.r[11].s64 = ctx.r[11].s64 + 14224;
	// 831E5D48: C2540024  lfs f18, 0x24(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(36 as u32) ) };
	ctx.f[18].f64 = (tmp.f32 as f64);
	// 831E5D4C: C2340028  lfs f17, 0x28(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(40 as u32) ) };
	ctx.f[17].f64 = (tmp.f32 as f64);
	// 831E5D50: 386B0018  addi r3, r11, 0x18
	ctx.r[3].s64 = ctx.r[11].s64 + 24;
	// 831E5D54: D00B0008  stfs f0, 8(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E5D58: 938B0000  stw r28, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[28].u32 ) };
	// 831E5D5C: D00B0014  stfs f0, 0x14(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E5D60: 93AB000C  stw r29, 0xc(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[29].u32 ) };
	// 831E5D64: D24B0004  stfs f18, 4(r11)
	tmp.f32 = (ctx.f[18].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E5D68: D22B0010  stfs f17, 0x10(r11)
	tmp.f32 = (ctx.f[17].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831E5D6C: 93CB0018  stw r30, 0x18(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), ctx.r[30].u32 ) };
	// 831E5D70: D00B001C  stfs f0, 0x1c(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 831E5D74: 4BFFEE05  bl 0x831e4b78
	ctx.lr = 0x831E5D78;
	sub_831E4B78(ctx, base);
	// 831E5D78: 3CC00002  lis r6, 2
	ctx.r[6].s64 = 131072;
	// 831E5D7C: 3CA00002  lis r5, 2
	ctx.r[5].s64 = 131072;
	// 831E5D80: C0180370  lfs f0, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5D84: 3D7F0002  addis r11, r31, 2
	ctx.r[11].s64 = ctx.r[31].s64 + 131072;
	// 831E5D88: 60C447B0  ori r4, r6, 0x47b0
	ctx.r[4].u64 = ctx.r[6].u64 | 18352;
	// 831E5D8C: 60AA47B4  ori r10, r5, 0x47b4
	ctx.r[10].u64 = ctx.r[5].u64 | 18356;
	// 831E5D90: 396B47B8  addi r11, r11, 0x47b8
	ctx.r[11].s64 = ctx.r[11].s64 + 18360;
	// 831E5D94: 386B0024  addi r3, r11, 0x24
	ctx.r[3].s64 = ctx.r[11].s64 + 36;
	// 831E5D98: 7F5F252E  stfsx f26, r31, r4
	tmp.f32 = (ctx.f[26].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[31].u32.wrapping_add(ctx.r[4].u32), tmp.u32) };
	// 831E5D9C: 7F3F552E  stfsx f25, r31, r10
	tmp.f32 = (ctx.f[25].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[31].u32.wrapping_add(ctx.r[10].u32), tmp.u32) };
	// 831E5DA0: D00B0008  stfs f0, 8(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E5DA4: 932B0000  stw r25, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[25].u32 ) };
	// 831E5DA8: D00B0014  stfs f0, 0x14(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E5DAC: 934B000C  stw r26, 0xc(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[26].u32 ) };
	// 831E5DB0: D00B0020  stfs f0, 0x20(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(32 as u32), tmp.u32 ) };
	// 831E5DB4: 93AB0018  stw r29, 0x18(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), ctx.r[29].u32 ) };
	// 831E5DB8: D3CB0004  stfs f30, 4(r11)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E5DBC: D30B0010  stfs f24, 0x10(r11)
	tmp.f32 = (ctx.f[24].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831E5DC0: D2EB001C  stfs f23, 0x1c(r11)
	tmp.f32 = (ctx.f[23].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 831E5DC4: 93CB0024  stw r30, 0x24(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(36 as u32), ctx.r[30].u32 ) };
	// 831E5DC8: D00B0028  stfs f0, 0x28(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(40 as u32), tmp.u32 ) };
	// 831E5DCC: 4BFFEC2D  bl 0x831e49f8
	ctx.lr = 0x831E5DD0;
	sub_831E49F8(ctx, base);
	// 831E5DD0: 3D7F0002  addis r11, r31, 2
	ctx.r[11].s64 = ctx.r[31].s64 + 131072;
	// 831E5DD4: 39200061  li r9, 0x61
	ctx.r[9].s64 = 97;
	// 831E5DD8: C0180370  lfs f0, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5DDC: 396B4FE4  addi r11, r11, 0x4fe4
	ctx.r[11].s64 = ctx.r[11].s64 + 20452;
	// 831E5DE0: 386B0010  addi r3, r11, 0x10
	ctx.r[3].s64 = ctx.r[11].s64 + 16;
	// 831E5DE4: D00B000C  stfs f0, 0xc(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E5DE8: 912B0000  stw r9, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831E5DEC: D2CB0004  stfs f22, 4(r11)
	tmp.f32 = (ctx.f[22].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E5DF0: D2AB0008  stfs f21, 8(r11)
	tmp.f32 = (ctx.f[21].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E5DF4: 93CB0010  stw r30, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[30].u32 ) };
	// 831E5DF8: D00B0014  stfs f0, 0x14(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E5DFC: 4BFFEC5D  bl 0x831e4a58
	ctx.lr = 0x831E5E00;
	sub_831E4A58(ctx, base);
	// 831E5E00: 3D7F0002  addis r11, r31, 2
	ctx.r[11].s64 = ctx.r[31].s64 + 131072;
	// 831E5E04: 39000511  li r8, 0x511
	ctx.r[8].s64 = 1297;
	// 831E5E08: C0180370  lfs f0, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5E0C: 396B51FC  addi r11, r11, 0x51fc
	ctx.r[11].s64 = ctx.r[11].s64 + 20988;
	// 831E5E10: 38E00510  li r7, 0x510
	ctx.r[7].s64 = 1296;
	// 831E5E14: 386B0024  addi r3, r11, 0x24
	ctx.r[3].s64 = ctx.r[11].s64 + 36;
	// 831E5E18: D00B0008  stfs f0, 8(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E5E1C: 910B0000  stw r8, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 831E5E20: D00B0014  stfs f0, 0x14(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E5E24: 90EB000C  stw r7, 0xc(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[7].u32 ) };
	// 831E5E28: D00B0020  stfs f0, 0x20(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(32 as u32), tmp.u32 ) };
	// 831E5E2C: 936B0018  stw r27, 0x18(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), ctx.r[27].u32 ) };
	// 831E5E30: D3CB0004  stfs f30, 4(r11)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E5E34: D28B0010  stfs f20, 0x10(r11)
	tmp.f32 = (ctx.f[20].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831E5E38: D26B001C  stfs f19, 0x1c(r11)
	tmp.f32 = (ctx.f[19].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 831E5E3C: 93CB0024  stw r30, 0x24(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(36 as u32), ctx.r[30].u32 ) };
	// 831E5E40: D00B0028  stfs f0, 0x28(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(40 as u32), tmp.u32 ) };
	// 831E5E44: 4BFFEC75  bl 0x831e4ab8
	ctx.lr = 0x831E5E48;
	sub_831E4AB8(ctx, base);
	// 831E5E48: 3D7F0002  addis r11, r31, 2
	ctx.r[11].s64 = ctx.r[31].s64 + 131072;
	// 831E5E4C: 38C000DF  li r6, 0xdf
	ctx.r[6].s64 = 223;
	// 831E5E50: C0180370  lfs f0, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5E54: 396B7228  addi r11, r11, 0x7228
	ctx.r[11].s64 = ctx.r[11].s64 + 29224;
	// 831E5E58: 386B0010  addi r3, r11, 0x10
	ctx.r[3].s64 = ctx.r[11].s64 + 16;
	// 831E5E5C: D00B000C  stfs f0, 0xc(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E5E60: 90CB0000  stw r6, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[6].u32 ) };
	// 831E5E64: D3EB0004  stfs f31, 4(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E5E68: D36B0008  stfs f27, 8(r11)
	tmp.f32 = (ctx.f[27].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E5E6C: 93CB0010  stw r30, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[30].u32 ) };
	// 831E5E70: D00B0014  stfs f0, 0x14(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E5E74: 4BFFECA5  bl 0x831e4b18
	ctx.lr = 0x831E5E78;
	sub_831E4B18(ctx, base);
	// 831E5E78: 3D7F0002  addis r11, r31, 2
	ctx.r[11].s64 = ctx.r[31].s64 + 131072;
	// 831E5E7C: 38A00125  li r5, 0x125
	ctx.r[5].s64 = 293;
	// 831E5E80: C0180370  lfs f0, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5E84: 396B7640  addi r11, r11, 0x7640
	ctx.r[11].s64 = ctx.r[11].s64 + 30272;
	// 831E5E88: 386B0010  addi r3, r11, 0x10
	ctx.r[3].s64 = ctx.r[11].s64 + 16;
	// 831E5E8C: D00B000C  stfs f0, 0xc(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E5E90: 90AB0000  stw r5, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[5].u32 ) };
	// 831E5E94: D3EB0004  stfs f31, 4(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E5E98: D36B0008  stfs f27, 8(r11)
	tmp.f32 = (ctx.f[27].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E5E9C: 93CB0010  stw r30, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[30].u32 ) };
	// 831E5EA0: D00B0014  stfs f0, 0x14(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E5EA4: 4BFFEB55  bl 0x831e49f8
	ctx.lr = 0x831E5EA8;
	sub_831E49F8(ctx, base);
	// 831E5EA8: 3D7F0002  addis r11, r31, 2
	ctx.r[11].s64 = ctx.r[31].s64 + 131072;
	// 831E5EAC: C0180370  lfs f0, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5EB0: 396B7E58  addi r11, r11, 0x7e58
	ctx.r[11].s64 = ctx.r[11].s64 + 32344;
	// 831E5EB4: 386B0018  addi r3, r11, 0x18
	ctx.r[3].s64 = ctx.r[11].s64 + 24;
	// 831E5EB8: D00B0008  stfs f0, 8(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E5EBC: 938B0000  stw r28, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[28].u32 ) };
	// 831E5EC0: D00B0014  stfs f0, 0x14(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E5EC4: 93AB000C  stw r29, 0xc(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[29].u32 ) };
	// 831E5EC8: D24B0004  stfs f18, 4(r11)
	tmp.f32 = (ctx.f[18].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E5ECC: D22B0010  stfs f17, 0x10(r11)
	tmp.f32 = (ctx.f[17].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831E5ED0: 93CB0018  stw r30, 0x18(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), ctx.r[30].u32 ) };
	// 831E5ED4: D00B001C  stfs f0, 0x1c(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 831E5ED8: 4BFFECA1  bl 0x831e4b78
	ctx.lr = 0x831E5EDC;
	sub_831E4B78(ctx, base);
	// 831E5EDC: 3D7F0003  addis r11, r31, 3
	ctx.r[11].s64 = ctx.r[31].s64 + 196608;
	// 831E5EE0: 3C80821A  lis r4, -0x7de6
	ctx.r[4].s64 = -2112225280;
	// 831E5EE4: C1B80370  lfs f13, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E5EE8: 396B8E78  addi r11, r11, -0x7188
	ctx.r[11].s64 = ctx.r[11].s64 + -29064;
	// 831E5EEC: C014004C  lfs f0, 0x4c(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(76 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5EF0: 39400199  li r10, 0x199
	ctx.r[10].s64 = 409;
	// 831E5EF4: 386B0010  addi r3, r11, 0x10
	ctx.r[3].s64 = ctx.r[11].s64 + 16;
	// 831E5EF8: C3C4107C  lfs f30, 0x107c(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4220 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 831E5EFC: D1AB000C  stfs f13, 0xc(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E5F00: 914B0000  stw r10, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E5F04: D3CB0004  stfs f30, 4(r11)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E5F08: D00B0008  stfs f0, 8(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E5F0C: D1AB0014  stfs f13, 0x14(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E5F10: 93CB0010  stw r30, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[30].u32 ) };
	// 831E5F14: 4BFFEAE5  bl 0x831e49f8
	ctx.lr = 0x831E5F18;
	sub_831E49F8(ctx, base);
	// 831E5F18: 3D7F0003  addis r11, r31, 3
	ctx.r[11].s64 = ctx.r[31].s64 + 196608;
	// 831E5F1C: 39200101  li r9, 0x101
	ctx.r[9].s64 = 257;
	// 831E5F20: C0180370  lfs f0, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5F24: 396B9690  addi r11, r11, -0x6970
	ctx.r[11].s64 = ctx.r[11].s64 + -26992;
	// 831E5F28: 386B0010  addi r3, r11, 0x10
	ctx.r[3].s64 = ctx.r[11].s64 + 16;
	// 831E5F2C: D00B000C  stfs f0, 0xc(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E5F30: 912B0000  stw r9, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831E5F34: D3EB0004  stfs f31, 4(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E5F38: D36B0008  stfs f27, 8(r11)
	tmp.f32 = (ctx.f[27].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E5F3C: 93CB0010  stw r30, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[30].u32 ) };
	// 831E5F40: D00B0014  stfs f0, 0x14(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E5F44: 4BFFEAB5  bl 0x831e49f8
	ctx.lr = 0x831E5F48;
	sub_831E49F8(ctx, base);
	// 831E5F48: 3D1F0003  addis r8, r31, 3
	ctx.r[8].s64 = ctx.r[31].s64 + 196608;
	// 831E5F4C: 3CFF0003  addis r7, r31, 3
	ctx.r[7].s64 = ctx.r[31].s64 + 196608;
	// 831E5F50: C1B80370  lfs f13, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E5F54: 39089EA8  addi r8, r8, -0x6158
	ctx.r[8].s64 = ctx.r[8].s64 + -24920;
	// 831E5F58: C0140034  lfs f0, 0x34(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(52 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5F5C: 3CDF0003  addis r6, r31, 3
	ctx.r[6].s64 = ctx.r[31].s64 + 196608;
	// 831E5F60: C1940038  lfs f12, 0x38(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(56 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831E5F64: 38E79EC0  addi r7, r7, -0x6140
	ctx.r[7].s64 = ctx.r[7].s64 + -24896;
	// 831E5F68: C174003C  lfs f11, 0x3c(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(60 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831E5F6C: 38C69EE0  addi r6, r6, -0x6120
	ctx.r[6].s64 = ctx.r[6].s64 + -24864;
	// 831E5F70: C1540040  lfs f10, 0x40(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(64 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831E5F74: C1340044  lfs f9, 0x44(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(68 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831E5F78: FC40E890  fmr f2, f29
	ctx.f[2].f64 = ctx.f[29].f64;
	// 831E5F7C: D0080004  stfs f0, 4(r8)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E5F80: 93A80000  stw r29, 0(r8)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), ctx.r[29].u32 ) };
	// 831E5F84: D1A80008  stfs f13, 8(r8)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E5F88: FC006890  fmr f0, f13
	ctx.f[0].f64 = ctx.f[13].f64;
	// 831E5F8C: D008000C  stfs f0, 0xc(r8)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E5F90: FC20E090  fmr f1, f28
	ctx.f[1].f64 = ctx.f[28].f64;
	// 831E5F94: D0080010  stfs f0, 0x10(r8)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831E5F98: D0080014  stfs f0, 0x14(r8)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E5F9C: 93A70000  stw r29, 0(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), ctx.r[29].u32 ) };
	// 831E5FA0: D0070010  stfs f0, 0x10(r7)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831E5FA4: D1870004  stfs f12, 4(r7)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E5FA8: D1670008  stfs f11, 8(r7)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E5FAC: D147000C  stfs f10, 0xc(r7)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E5FB0: D0070014  stfs f0, 0x14(r7)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E5FB4: D0070018  stfs f0, 0x18(r7)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 831E5FB8: D007001C  stfs f0, 0x1c(r7)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 831E5FBC: 93A60000  stw r29, 0(r6)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(0 as u32), ctx.r[29].u32 ) };
	// 831E5FC0: D0060004  stfs f0, 4(r6)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E5FC4: C0140048  lfs f0, 0x48(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(72 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E5FC8: D006000C  stfs f0, 0xc(r6)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E5FCC: FC006890  fmr f0, f13
	ctx.f[0].f64 = ctx.f[13].f64;
	// 831E5FD0: D1260008  stfs f9, 8(r6)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E5FD4: D0060014  stfs f0, 0x14(r6)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E5FD8: D1A60010  stfs f13, 0x10(r6)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831E5FDC: D0060018  stfs f0, 0x18(r6)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 831E5FE0: 4BFC54C9  bl 0x831ab4a8
	ctx.lr = 0x831E5FE4;
	sub_831AB4A8(ctx, base);
	// 831E5FE4: FD000818  frsp f8, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[8].f64 = (ctx.f[1].f64 as f32) as f64;
	// 831E5FE8: 3D7F0003  addis r11, r31, 3
	ctx.r[11].s64 = ctx.r[31].s64 + 196608;
	// 831E5FEC: C1940054  lfs f12, 0x54(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(84 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831E5FF0: 39400D68  li r10, 0xd68
	ctx.r[10].s64 = 3432;
	// 831E5FF4: C1B80370  lfs f13, 0x370(r24)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E5FF8: 396B9EFC  addi r11, r11, -0x6104
	ctx.r[11].s64 = ctx.r[11].s64 + -24836;
	// 831E5FFC: C0170374  lfs f0, 0x374(r23)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(884 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E6000: 386B0018  addi r3, r11, 0x18
	ctx.r[3].s64 = ctx.r[11].s64 + 24;
	// 831E6004: D1AB0008  stfs f13, 8(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E6008: 914B0000  stw r10, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E600C: D1AB0014  stfs f13, 0x14(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E6010: 914B000C  stw r10, 0xc(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[10].u32 ) };
	// 831E6014: ECE80332  fmuls f7, f8, f12
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[12].f64) as f32) as f64);
	// 831E6018: D00B0004  stfs f0, 4(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E601C: D0EB0010  stfs f7, 0x10(r11)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831E6020: 93CB0018  stw r30, 0x18(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), ctx.r[30].u32 ) };
	// 831E6024: D1AB001C  stfs f13, 0x1c(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 831E6028: 4BFFEBB1  bl 0x831e4bd8
	ctx.lr = 0x831E602C;
	sub_831E4BD8(ctx, base);
	// 831E602C: 3D7F0003  addis r11, r31, 3
	ctx.r[11].s64 = ctx.r[31].s64 + 196608;
	// 831E6030: 3CBF0003  addis r5, r31, 3
	ctx.r[5].s64 = ctx.r[31].s64 + 196608;
	// 831E6034: C1B80370  lfs f13, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E6038: 396BDF34  addi r11, r11, -0x20cc
	ctx.r[11].s64 = ctx.r[11].s64 + -8396;
	// 831E603C: C194004C  lfs f12, 0x4c(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(76 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831E6040: 38A5DF1C  addi r5, r5, -0x20e4
	ctx.r[5].s64 = ctx.r[5].s64 + -8420;
	// 831E6044: FC00A090  fmr f0, f20
	ctx.f[0].f64 = ctx.f[20].f64;
	// 831E6048: 3880017F  li r4, 0x17f
	ctx.r[4].s64 = 383;
	// 831E604C: 386B0010  addi r3, r11, 0x10
	ctx.r[3].s64 = ctx.r[11].s64 + 16;
	// 831E6050: D0050004  stfs f0, 4(r5)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E6054: 93A50000  stw r29, 0(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), ctx.r[29].u32 ) };
	// 831E6058: D1A50008  stfs f13, 8(r5)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E605C: FC006890  fmr f0, f13
	ctx.f[0].f64 = ctx.f[13].f64;
	// 831E6060: D005000C  stfs f0, 0xc(r5)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E6064: D0050010  stfs f0, 0x10(r5)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831E6068: D0050014  stfs f0, 0x14(r5)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E606C: 908B0000  stw r4, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[4].u32 ) };
	// 831E6070: D00B000C  stfs f0, 0xc(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E6074: D3CB0004  stfs f30, 4(r11)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E6078: D18B0008  stfs f12, 8(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E607C: 93CB0010  stw r30, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[30].u32 ) };
	// 831E6080: D00B0014  stfs f0, 0x14(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E6084: 4BFFE975  bl 0x831e49f8
	ctx.lr = 0x831E6088;
	sub_831E49F8(ctx, base);
	// 831E6088: 3D7F0003  addis r11, r31, 3
	ctx.r[11].s64 = ctx.r[31].s64 + 196608;
	// 831E608C: 394000E9  li r10, 0xe9
	ctx.r[10].s64 = 233;
	// 831E6090: C1B80370  lfs f13, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E6094: 396BE74C  addi r11, r11, -0x18b4
	ctx.r[11].s64 = ctx.r[11].s64 + -6324;
	// 831E6098: FC00D890  fmr f0, f27
	ctx.f[0].f64 = ctx.f[27].f64;
	// 831E609C: 386B0010  addi r3, r11, 0x10
	ctx.r[3].s64 = ctx.r[11].s64 + 16;
	// 831E60A0: D1AB000C  stfs f13, 0xc(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E60A4: 914B0000  stw r10, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E60A8: D3EB0004  stfs f31, 4(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E60AC: D00B0008  stfs f0, 8(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E60B0: 93CB0010  stw r30, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[30].u32 ) };
	// 831E60B4: D1AB0014  stfs f13, 0x14(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E60B8: 4BFFE941  bl 0x831e49f8
	ctx.lr = 0x831E60BC;
	sub_831E49F8(ctx, base);
	// 831E60BC: 3D3F0003  addis r9, r31, 3
	ctx.r[9].s64 = ctx.r[31].s64 + 196608;
	// 831E60C0: 3D1F0003  addis r8, r31, 3
	ctx.r[8].s64 = ctx.r[31].s64 + 196608;
	// 831E60C4: C1B80370  lfs f13, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E60C8: 3929EF64  addi r9, r9, -0x109c
	ctx.r[9].s64 = ctx.r[9].s64 + -4252;
	// 831E60CC: C0140034  lfs f0, 0x34(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(52 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E60D0: 3908EF7C  addi r8, r8, -0x1084
	ctx.r[8].s64 = ctx.r[8].s64 + -4228;
	// 831E60D4: C1940040  lfs f12, 0x40(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(64 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831E60D8: 3CFF0003  addis r7, r31, 3
	ctx.r[7].s64 = ctx.r[31].s64 + 196608;
	// 831E60DC: FC40E890  fmr f2, f29
	ctx.f[2].f64 = ctx.f[29].f64;
	// 831E60E0: FC20E090  fmr f1, f28
	ctx.f[1].f64 = ctx.f[28].f64;
	// 831E60E4: 38E7EF9C  addi r7, r7, -0x1064
	ctx.r[7].s64 = ctx.r[7].s64 + -4196;
	// 831E60E8: D0090004  stfs f0, 4(r9)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E60EC: 93A90000  stw r29, 0(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[29].u32 ) };
	// 831E60F0: D1A90008  stfs f13, 8(r9)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E60F4: FC006890  fmr f0, f13
	ctx.f[0].f64 = ctx.f[13].f64;
	// 831E60F8: D009000C  stfs f0, 0xc(r9)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E60FC: D0090010  stfs f0, 0x10(r9)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831E6100: D0090014  stfs f0, 0x14(r9)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E6104: 93A80000  stw r29, 0(r8)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), ctx.r[29].u32 ) };
	// 831E6108: D0080010  stfs f0, 0x10(r8)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831E610C: C0140038  lfs f0, 0x38(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(56 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E6110: D0080004  stfs f0, 4(r8)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E6114: C1B4003C  lfs f13, 0x3c(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(60 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E6118: D1A80008  stfs f13, 8(r8)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E611C: D188000C  stfs f12, 0xc(r8)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E6120: C0180370  lfs f0, 0x370(r24)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E6124: D0080014  stfs f0, 0x14(r8)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E6128: D0080018  stfs f0, 0x18(r8)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 831E612C: D008001C  stfs f0, 0x1c(r8)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 831E6130: 93A70000  stw r29, 0(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), ctx.r[29].u32 ) };
	// 831E6134: D0070004  stfs f0, 4(r7)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E6138: C0140044  lfs f0, 0x44(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(68 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E613C: D0070008  stfs f0, 8(r7)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E6140: C0180370  lfs f0, 0x370(r24)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E6144: C1B40048  lfs f13, 0x48(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(72 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E6148: FD800090  fmr f12, f0
	ctx.f[12].f64 = ctx.f[0].f64;
	// 831E614C: D1A7000C  stfs f13, 0xc(r7)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E6150: D0070014  stfs f0, 0x14(r7)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E6154: D1870010  stfs f12, 0x10(r7)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831E6158: D0070018  stfs f0, 0x18(r7)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 831E615C: 4BFC534D  bl 0x831ab4a8
	ctx.lr = 0x831E6160;
	sub_831AB4A8(ctx, base);
	// 831E6160: FCC00818  frsp f6, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[6].f64 = (ctx.f[1].f64 as f32) as f64;
	// 831E6164: 3D7F0003  addis r11, r31, 3
	ctx.r[11].s64 = ctx.r[31].s64 + 196608;
	// 831E6168: C1940054  lfs f12, 0x54(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(84 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831E616C: 39400EEC  li r10, 0xeec
	ctx.r[10].s64 = 3820;
	// 831E6170: C1B80370  lfs f13, 0x370(r24)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E6174: 396BEFB8  addi r11, r11, -0x1048
	ctx.r[11].s64 = ctx.r[11].s64 + -4168;
	// 831E6178: C0170374  lfs f0, 0x374(r23)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(884 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E617C: 386B0018  addi r3, r11, 0x18
	ctx.r[3].s64 = ctx.r[11].s64 + 24;
	// 831E6180: D1AB0008  stfs f13, 8(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E6184: 914B0000  stw r10, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E6188: D1AB0014  stfs f13, 0x14(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E618C: 914B000C  stw r10, 0xc(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[10].u32 ) };
	// 831E6190: ECA60332  fmuls f5, f6, f12
	ctx.f[5].f64 = (((ctx.f[6].f64 * ctx.f[12].f64) as f32) as f64);
	// 831E6194: D00B0004  stfs f0, 4(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E6198: D0AB0010  stfs f5, 0x10(r11)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831E619C: 93CB0018  stw r30, 0x18(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), ctx.r[30].u32 ) };
	// 831E61A0: D1AB001C  stfs f13, 0x1c(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 831E61A4: 4BFFEA35  bl 0x831e4bd8
	ctx.lr = 0x831E61A8;
	sub_831E4BD8(ctx, base);
	// 831E61A8: 3CDF0003  addis r6, r31, 3
	ctx.r[6].s64 = ctx.r[31].s64 + 196608;
	// 831E61AC: 3D7F0003  addis r11, r31, 3
	ctx.r[11].s64 = ctx.r[31].s64 + 196608;
	// 831E61B0: C1B80370  lfs f13, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E61B4: 38C62FD8  addi r6, r6, 0x2fd8
	ctx.r[6].s64 = ctx.r[6].s64 + 12248;
	// 831E61B8: FC00A090  fmr f0, f20
	ctx.f[0].f64 = ctx.f[20].f64;
	// 831E61BC: 396B2FF0  addi r11, r11, 0x2ff0
	ctx.r[11].s64 = ctx.r[11].s64 + 12272;
	// 831E61C0: C374004C  lfs f27, 0x4c(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(76 as u32) ) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 831E61C4: 38A005E7  li r5, 0x5e7
	ctx.r[5].s64 = 1511;
	// 831E61C8: 386B0010  addi r3, r11, 0x10
	ctx.r[3].s64 = ctx.r[11].s64 + 16;
	// 831E61CC: D0060004  stfs f0, 4(r6)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E61D0: 93A60000  stw r29, 0(r6)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(0 as u32), ctx.r[29].u32 ) };
	// 831E61D4: D1A60008  stfs f13, 8(r6)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E61D8: FC006890  fmr f0, f13
	ctx.f[0].f64 = ctx.f[13].f64;
	// 831E61DC: D0060010  stfs f0, 0x10(r6)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831E61E0: D0060014  stfs f0, 0x14(r6)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E61E4: D1A6000C  stfs f13, 0xc(r6)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E61E8: 90AB0000  stw r5, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[5].u32 ) };
	// 831E61EC: D00B000C  stfs f0, 0xc(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E61F0: D3CB0004  stfs f30, 4(r11)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E61F4: D36B0008  stfs f27, 8(r11)
	tmp.f32 = (ctx.f[27].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E61F8: 93CB0010  stw r30, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[30].u32 ) };
	// 831E61FC: D00B0014  stfs f0, 0x14(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E6200: 4BFFE8B9  bl 0x831e4ab8
	ctx.lr = 0x831E6204;
	sub_831E4AB8(ctx, base);
	// 831E6204: 3D7F0003  addis r11, r31, 3
	ctx.r[11].s64 = ctx.r[31].s64 + 196608;
	// 831E6208: 38800425  li r4, 0x425
	ctx.r[4].s64 = 1061;
	// 831E620C: C0180370  lfs f0, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E6210: 396B5008  addi r11, r11, 0x5008
	ctx.r[11].s64 = ctx.r[11].s64 + 20488;
	// 831E6214: 386B0014  addi r3, r11, 0x14
	ctx.r[3].s64 = ctx.r[11].s64 + 20;
	// 831E6218: D00B0010  stfs f0, 0x10(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831E621C: 908B0000  stw r4, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[4].u32 ) };
	// 831E6220: D36B0004  stfs f27, 4(r11)
	tmp.f32 = (ctx.f[27].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E6224: D36B0008  stfs f27, 8(r11)
	tmp.f32 = (ctx.f[27].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E6228: D3CB000C  stfs f30, 0xc(r11)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E622C: 93CB0014  stw r30, 0x14(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), ctx.r[30].u32 ) };
	// 831E6230: D00B0018  stfs f0, 0x18(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 831E6234: 4BFFE885  bl 0x831e4ab8
	ctx.lr = 0x831E6238;
	sub_831E4AB8(ctx, base);
	// 831E6238: 3D7F0003  addis r11, r31, 3
	ctx.r[11].s64 = ctx.r[31].s64 + 196608;
	// 831E623C: 39400355  li r10, 0x355
	ctx.r[10].s64 = 853;
	// 831E6240: C0180370  lfs f0, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E6244: 396B7024  addi r11, r11, 0x7024
	ctx.r[11].s64 = ctx.r[11].s64 + 28708;
	// 831E6248: 386B0010  addi r3, r11, 0x10
	ctx.r[3].s64 = ctx.r[11].s64 + 16;
	// 831E624C: D00B000C  stfs f0, 0xc(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E6250: 914B0000  stw r10, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E6254: D3CB0004  stfs f30, 4(r11)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E6258: D36B0008  stfs f27, 8(r11)
	tmp.f32 = (ctx.f[27].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E625C: 93CB0010  stw r30, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[30].u32 ) };
	// 831E6260: D00B0014  stfs f0, 0x14(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E6264: 4BFFE855  bl 0x831e4ab8
	ctx.lr = 0x831E6268;
	sub_831E4AB8(ctx, base);
	// 831E6268: 3D7F0004  addis r11, r31, 4
	ctx.r[11].s64 = ctx.r[31].s64 + 262144;
	// 831E626C: 3920021D  li r9, 0x21d
	ctx.r[9].s64 = 541;
	// 831E6270: C1B80370  lfs f13, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E6274: 396B903C  addi r11, r11, -0x6fc4
	ctx.r[11].s64 = ctx.r[11].s64 + -28612;
	// 831E6278: C0159450  lfs f0, -0x6bb0(r21)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(-27568 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E627C: 386B0010  addi r3, r11, 0x10
	ctx.r[3].s64 = ctx.r[11].s64 + 16;
	// 831E6280: D1AB000C  stfs f13, 0xc(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E6284: 912B0000  stw r9, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831E6288: D3EB0004  stfs f31, 4(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E628C: D00B0008  stfs f0, 8(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E6290: 93CB0010  stw r30, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[30].u32 ) };
	// 831E6294: D1AB0014  stfs f13, 0x14(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E6298: 4BFFE8E1  bl 0x831e4b78
	ctx.lr = 0x831E629C;
	sub_831E4B78(ctx, base);
	// 831E629C: FC40E890  fmr f2, f29
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[2].f64 = ctx.f[29].f64;
	// 831E62A0: FC20E090  fmr f1, f28
	ctx.f[1].f64 = ctx.f[28].f64;
	// 831E62A4: 4BFC5205  bl 0x831ab4a8
	ctx.lr = 0x831E62A8;
	sub_831AB4A8(ctx, base);
	// 831E62A8: 3D7F0004  addis r11, r31, 4
	ctx.r[11].s64 = ctx.r[31].s64 + 262144;
	// 831E62AC: C1B80370  lfs f13, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E62B0: 394005E6  li r10, 0x5e6
	ctx.r[10].s64 = 1510;
	// 831E62B4: C0170374  lfs f0, 0x374(r23)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(884 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E62B8: 396BA054  addi r11, r11, -0x5fac
	ctx.r[11].s64 = ctx.r[11].s64 + -24492;
	// 831E62BC: C1940054  lfs f12, 0x54(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(84 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831E62C0: FC800818  frsp f4, f1
	ctx.f[4].f64 = (ctx.f[1].f64 as f32) as f64;
	// 831E62C4: 386B0018  addi r3, r11, 0x18
	ctx.r[3].s64 = ctx.r[11].s64 + 24;
	// 831E62C8: D1AB0008  stfs f13, 8(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E62CC: 914B0000  stw r10, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E62D0: D00B0004  stfs f0, 4(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E62D4: 914B000C  stw r10, 0xc(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[10].u32 ) };
	// 831E62D8: EC640332  fmuls f3, f4, f12
	ctx.f[3].f64 = (((ctx.f[4].f64 * ctx.f[12].f64) as f32) as f64);
	// 831E62DC: D1AB0014  stfs f13, 0x14(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E62E0: D06B0010  stfs f3, 0x10(r11)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831E62E4: FC006890  fmr f0, f13
	ctx.f[0].f64 = ctx.f[13].f64;
	// 831E62E8: D00B001C  stfs f0, 0x1c(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 831E62EC: 93CB0018  stw r30, 0x18(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), ctx.r[30].u32 ) };
	// 831E62F0: 4BFFE8E9  bl 0x831e4bd8
	ctx.lr = 0x831E62F4;
	sub_831E4BD8(ctx, base);
	// 831E62F4: 3CFF0004  addis r7, r31, 4
	ctx.r[7].s64 = ctx.r[31].s64 + 262144;
	// 831E62F8: 3D008203  lis r8, -0x7dfd
	ctx.r[8].s64 = -2113732608;
	// 831E62FC: C1B80370  lfs f13, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E6300: 38E7E074  addi r7, r7, -0x1f8c
	ctx.r[7].s64 = ctx.r[7].s64 + -8076;
	// 831E6304: 3D7F0004  addis r11, r31, 4
	ctx.r[11].s64 = ctx.r[31].s64 + 262144;
	// 831E6308: 38C00679  li r6, 0x679
	ctx.r[6].s64 = 1657;
	// 831E630C: 396BE090  addi r11, r11, -0x1f70
	ctx.r[11].s64 = ctx.r[11].s64 + -8048;
	// 831E6310: C0087BC8  lfs f0, 0x7bc8(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(31688 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E6314: D0070008  stfs f0, 8(r7)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E6318: 93A70000  stw r29, 0(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), ctx.r[29].u32 ) };
	// 831E631C: D007000C  stfs f0, 0xc(r7)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E6320: FC006890  fmr f0, f13
	ctx.f[0].f64 = ctx.f[13].f64;
	// 831E6324: D1A70004  stfs f13, 4(r7)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E6328: 386B0010  addi r3, r11, 0x10
	ctx.r[3].s64 = ctx.r[11].s64 + 16;
	// 831E632C: D0070010  stfs f0, 0x10(r7)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831E6330: D0070014  stfs f0, 0x14(r7)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E6334: D0070018  stfs f0, 0x18(r7)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 831E6338: 90CB0000  stw r6, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[6].u32 ) };
	// 831E633C: D00B000C  stfs f0, 0xc(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E6340: D3CB0004  stfs f30, 4(r11)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E6344: D36B0008  stfs f27, 8(r11)
	tmp.f32 = (ctx.f[27].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E6348: 93CB0010  stw r30, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[30].u32 ) };
	// 831E634C: D00B0014  stfs f0, 0x14(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E6350: 4BFFE769  bl 0x831e4ab8
	ctx.lr = 0x831E6354;
	sub_831E4AB8(ctx, base);
	// 831E6354: 3D7F0004  addis r11, r31, 4
	ctx.r[11].s64 = ctx.r[31].s64 + 262144;
	// 831E6358: 38A0044F  li r5, 0x44f
	ctx.r[5].s64 = 1103;
	// 831E635C: C0180370  lfs f0, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E6360: 396B00A8  addi r11, r11, 0xa8
	ctx.r[11].s64 = ctx.r[11].s64 + 168;
	// 831E6364: 386B0014  addi r3, r11, 0x14
	ctx.r[3].s64 = ctx.r[11].s64 + 20;
	// 831E6368: D00B0010  stfs f0, 0x10(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831E636C: 90AB0000  stw r5, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[5].u32 ) };
	// 831E6370: D36B0004  stfs f27, 4(r11)
	tmp.f32 = (ctx.f[27].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E6374: D36B0008  stfs f27, 8(r11)
	tmp.f32 = (ctx.f[27].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E6378: D3CB000C  stfs f30, 0xc(r11)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E637C: 93CB0014  stw r30, 0x14(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), ctx.r[30].u32 ) };
	// 831E6380: D00B0018  stfs f0, 0x18(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 831E6384: 4BFFE735  bl 0x831e4ab8
	ctx.lr = 0x831E6388;
	sub_831E4AB8(ctx, base);
	// 831E6388: 3D7F0004  addis r11, r31, 4
	ctx.r[11].s64 = ctx.r[31].s64 + 262144;
	// 831E638C: 38800377  li r4, 0x377
	ctx.r[4].s64 = 887;
	// 831E6390: C0180370  lfs f0, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E6394: 396B20C4  addi r11, r11, 0x20c4
	ctx.r[11].s64 = ctx.r[11].s64 + 8388;
	// 831E6398: 386B0010  addi r3, r11, 0x10
	ctx.r[3].s64 = ctx.r[11].s64 + 16;
	// 831E639C: D00B000C  stfs f0, 0xc(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E63A0: 908B0000  stw r4, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[4].u32 ) };
	// 831E63A4: D3CB0004  stfs f30, 4(r11)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E63A8: D36B0008  stfs f27, 8(r11)
	tmp.f32 = (ctx.f[27].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E63AC: 93CB0010  stw r30, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[30].u32 ) };
	// 831E63B0: D00B0014  stfs f0, 0x14(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E63B4: 4BFFE705  bl 0x831e4ab8
	ctx.lr = 0x831E63B8;
	sub_831E4AB8(ctx, base);
	// 831E63B8: 3D7F0004  addis r11, r31, 4
	ctx.r[11].s64 = ctx.r[31].s64 + 262144;
	// 831E63BC: 394001EB  li r10, 0x1eb
	ctx.r[10].s64 = 491;
	// 831E63C0: C1B80370  lfs f13, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E63C4: 396B40DC  addi r11, r11, 0x40dc
	ctx.r[11].s64 = ctx.r[11].s64 + 16604;
	// 831E63C8: C0159450  lfs f0, -0x6bb0(r21)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(-27568 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E63CC: 386B0010  addi r3, r11, 0x10
	ctx.r[3].s64 = ctx.r[11].s64 + 16;
	// 831E63D0: D00B0008  stfs f0, 8(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E63D4: 914B0000  stw r10, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E63D8: D3EB0004  stfs f31, 4(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E63DC: FC006890  fmr f0, f13
	ctx.f[0].f64 = ctx.f[13].f64;
	// 831E63E0: D1AB000C  stfs f13, 0xc(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E63E4: 93CB0010  stw r30, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[30].u32 ) };
	// 831E63E8: D00B0014  stfs f0, 0x14(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E63EC: 4BFFE78D  bl 0x831e4b78
	ctx.lr = 0x831E63F0;
	sub_831E4B78(ctx, base);
	// 831E63F0: FC40E890  fmr f2, f29
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[2].f64 = ctx.f[29].f64;
	// 831E63F4: FC20E090  fmr f1, f28
	ctx.f[1].f64 = ctx.f[28].f64;
	// 831E63F8: 4BFC50B1  bl 0x831ab4a8
	ctx.lr = 0x831E63FC;
	sub_831AB4A8(ctx, base);
	// 831E63FC: 3D7F0004  addis r11, r31, 4
	ctx.r[11].s64 = ctx.r[31].s64 + 262144;
	// 831E6400: C1B80370  lfs f13, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E6404: C1940054  lfs f12, 0x54(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(84 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831E6408: FC400818  frsp f2, f1
	ctx.f[2].f64 = (ctx.f[1].f64 as f32) as f64;
	// 831E640C: 396B50F4  addi r11, r11, 0x50f4
	ctx.r[11].s64 = ctx.r[11].s64 + 20724;
	// 831E6410: C0170374  lfs f0, 0x374(r23)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(884 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E6414: 3940059E  li r10, 0x59e
	ctx.r[10].s64 = 1438;
	// 831E6418: 386B0018  addi r3, r11, 0x18
	ctx.r[3].s64 = ctx.r[11].s64 + 24;
	// 831E641C: EC220332  fmuls f1, f2, f12
	ctx.f[1].f64 = (((ctx.f[2].f64 * ctx.f[12].f64) as f32) as f64);
	// 831E6420: D1AB0008  stfs f13, 8(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E6424: D1AB0014  stfs f13, 0x14(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E6428: 914B0000  stw r10, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E642C: D00B0004  stfs f0, 4(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E6430: 914B000C  stw r10, 0xc(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[10].u32 ) };
	// 831E6434: D02B0010  stfs f1, 0x10(r11)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831E6438: 93CB0018  stw r30, 0x18(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), ctx.r[30].u32 ) };
	// 831E643C: D1AB001C  stfs f13, 0x1c(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 831E6440: 4BFFE799  bl 0x831e4bd8
	ctx.lr = 0x831E6444;
	sub_831E4BD8(ctx, base);
	// 831E6444: 3D3F0005  addis r9, r31, 5
	ctx.r[9].s64 = ctx.r[31].s64 + 327680;
	// 831E6448: 3D7F0005  addis r11, r31, 5
	ctx.r[11].s64 = ctx.r[31].s64 + 327680;
	// 831E644C: C1B80370  lfs f13, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E6450: 39299114  addi r9, r9, -0x6eec
	ctx.r[9].s64 = ctx.r[9].s64 + -28396;
	// 831E6454: C0140078  lfs f0, 0x78(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(120 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E6458: 3D00821A  lis r8, -0x7de6
	ctx.r[8].s64 = -2112225280;
	// 831E645C: C3D4007C  lfs f30, 0x7c(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(124 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 831E6460: 396B9130  addi r11, r11, -0x6ed0
	ctx.r[11].s64 = ctx.r[11].s64 + -28368;
	// 831E6464: 38E00083  li r7, 0x83
	ctx.r[7].s64 = 131;
	// 831E6468: 386B0010  addi r3, r11, 0x10
	ctx.r[3].s64 = ctx.r[11].s64 + 16;
	// 831E646C: D0090008  stfs f0, 8(r9)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E6470: 93A90000  stw r29, 0(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[29].u32 ) };
	// 831E6474: D009000C  stfs f0, 0xc(r9)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E6478: FC006890  fmr f0, f13
	ctx.f[0].f64 = ctx.f[13].f64;
	// 831E647C: D1A90004  stfs f13, 4(r9)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E6480: D0090010  stfs f0, 0x10(r9)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831E6484: D0090014  stfs f0, 0x14(r9)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E6488: D0090018  stfs f0, 0x18(r9)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 831E648C: 90EB0000  stw r7, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[7].u32 ) };
	// 831E6490: C3E81078  lfs f31, 0x1078(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(4216 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 831E6494: D00B000C  stfs f0, 0xc(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E6498: D3EB0004  stfs f31, 4(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E649C: D3CB0008  stfs f30, 8(r11)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E64A0: 93CB0010  stw r30, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[30].u32 ) };
	// 831E64A4: D00B0014  stfs f0, 0x14(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E64A8: 4BFFE551  bl 0x831e49f8
	ctx.lr = 0x831E64AC;
	sub_831E49F8(ctx, base);
	// 831E64AC: 3D7F0005  addis r11, r31, 5
	ctx.r[11].s64 = ctx.r[31].s64 + 327680;
	// 831E64B0: 38C00071  li r6, 0x71
	ctx.r[6].s64 = 113;
	// 831E64B4: C0180370  lfs f0, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E64B8: 396B9948  addi r11, r11, -0x66b8
	ctx.r[11].s64 = ctx.r[11].s64 + -26296;
	// 831E64BC: 386B0010  addi r3, r11, 0x10
	ctx.r[3].s64 = ctx.r[11].s64 + 16;
	// 831E64C0: D00B000C  stfs f0, 0xc(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E64C4: 90CB0000  stw r6, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[6].u32 ) };
	// 831E64C8: D3EB0004  stfs f31, 4(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E64CC: D3CB0008  stfs f30, 8(r11)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E64D0: 93CB0010  stw r30, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[30].u32 ) };
	// 831E64D4: D00B0014  stfs f0, 0x14(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E64D8: 4BFFE521  bl 0x831e49f8
	ctx.lr = 0x831E64DC;
	sub_831E49F8(ctx, base);
	// 831E64DC: 3D7F0005  addis r11, r31, 5
	ctx.r[11].s64 = ctx.r[31].s64 + 327680;
	// 831E64E0: 38A0006B  li r5, 0x6b
	ctx.r[5].s64 = 107;
	// 831E64E4: C0180370  lfs f0, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E64E8: 396BA160  addi r11, r11, -0x5ea0
	ctx.r[11].s64 = ctx.r[11].s64 + -24224;
	// 831E64EC: 386B0010  addi r3, r11, 0x10
	ctx.r[3].s64 = ctx.r[11].s64 + 16;
	// 831E64F0: D00B000C  stfs f0, 0xc(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E64F4: 90AB0000  stw r5, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[5].u32 ) };
	// 831E64F8: D3EB0004  stfs f31, 4(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E64FC: D3CB0008  stfs f30, 8(r11)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E6500: 93CB0010  stw r30, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[30].u32 ) };
	// 831E6504: D00B0014  stfs f0, 0x14(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E6508: 4BFFE4F1  bl 0x831e49f8
	ctx.lr = 0x831E650C;
	sub_831E49F8(ctx, base);
	// 831E650C: 3D7F0005  addis r11, r31, 5
	ctx.r[11].s64 = ctx.r[31].s64 + 327680;
	// 831E6510: 3880007F  li r4, 0x7f
	ctx.r[4].s64 = 127;
	// 831E6514: C0180370  lfs f0, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E6518: 396BA978  addi r11, r11, -0x5688
	ctx.r[11].s64 = ctx.r[11].s64 + -22152;
	// 831E651C: 386B0010  addi r3, r11, 0x10
	ctx.r[3].s64 = ctx.r[11].s64 + 16;
	// 831E6520: D00B000C  stfs f0, 0xc(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E6524: 908B0000  stw r4, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[4].u32 ) };
	// 831E6528: D3EB0004  stfs f31, 4(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E652C: D3CB0008  stfs f30, 8(r11)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E6530: 93CB0010  stw r30, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[30].u32 ) };
	// 831E6534: D00B0014  stfs f0, 0x14(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E6538: 4BFFE4C1  bl 0x831e49f8
	ctx.lr = 0x831E653C;
	sub_831E49F8(ctx, base);
	// 831E653C: 3D7F0005  addis r11, r31, 5
	ctx.r[11].s64 = ctx.r[31].s64 + 327680;
	// 831E6540: 3BA00014  li r29, 0x14
	ctx.r[29].s64 = 20;
	// 831E6544: C1B80370  lfs f13, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E6548: 396BB190  addi r11, r11, -0x4e70
	ctx.r[11].s64 = ctx.r[11].s64 + -20080;
	// 831E654C: C016037C  lfs f0, 0x37c(r22)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[22].u32.wrapping_add(892 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E6550: 386B0018  addi r3, r11, 0x18
	ctx.r[3].s64 = ctx.r[11].s64 + 24;
	// 831E6554: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E6558: 93AB0008  stw r29, 8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 831E655C: 93AB000C  stw r29, 0xc(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[29].u32 ) };
	// 831E6560: D1AB0014  stfs f13, 0x14(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E6564: 93AB0010  stw r29, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[29].u32 ) };
	// 831E6568: D00B0000  stfs f0, 0(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831E656C: 93CB0018  stw r30, 0x18(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), ctx.r[30].u32 ) };
	// 831E6570: D1AB001C  stfs f13, 0x1c(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 831E6574: 4BFFE5A5  bl 0x831e4b18
	ctx.lr = 0x831E6578;
	sub_831E4B18(ctx, base);
	// 831E6578: 3D7F0005  addis r11, r31, 5
	ctx.r[11].s64 = ctx.r[31].s64 + 327680;
	// 831E657C: C1B80370  lfs f13, 0x370(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(880 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E6580: 396BB5B0  addi r11, r11, -0x4a50
	ctx.r[11].s64 = ctx.r[11].s64 + -19024;
	// 831E6584: C016037C  lfs f0, 0x37c(r22)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[22].u32.wrapping_add(892 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E6588: 386B0018  addi r3, r11, 0x18
	ctx.r[3].s64 = ctx.r[11].s64 + 24;
	// 831E658C: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E6590: 93AB0008  stw r29, 8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 831E6594: D1AB0014  stfs f13, 0x14(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E6598: 93AB000C  stw r29, 0xc(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[29].u32 ) };
	// 831E659C: D00B0000  stfs f0, 0(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831E65A0: 93AB0010  stw r29, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[29].u32 ) };
	// 831E65A4: D1AB001C  stfs f13, 0x1c(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 831E65A8: 93CB0018  stw r30, 0x18(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), ctx.r[30].u32 ) };
	// 831E65AC: 4BFFE56D  bl 0x831e4b18
	ctx.lr = 0x831E65B0;
	sub_831E4B18(ctx, base);
	// 831E65B0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E65B4: 38210130  addi r1, r1, 0x130
	ctx.r[1].s64 = ctx.r[1].s64 + 304;
	// 831E65B8: 3981FF98  addi r12, r1, -0x68
	ctx.r[12].s64 = ctx.r[1].s64 + -104;
	// 831E65BC: 4BFC24DD  bl 0x831a8a98
	ctx.lr = 0x831E65C0;
	sub_831A8A8C(ctx, base);
	// 831E65C0: 4BFC1BD8  b 0x831a8198
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E65C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831E65C8 size=656
    let mut pc: u32 = 0x831E65C8;
    'dispatch: loop {
        match pc {
            0x831E65C8 => {
    //   block [0x831E65C8..0x831E6858)
	// 831E65C8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E65CC: 4BFC1BA1  bl 0x831a816c
	ctx.lr = 0x831E65D0;
	sub_831A8130(ctx, base);
	// 831E65D0: DBC1FFD0  stfd f30, -0x30(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.f[30].u64 ) };
	// 831E65D4: DBE1FFD8  stfd f31, -0x28(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), ctx.f[31].u64 ) };
	// 831E65D8: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E65DC: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E65E0: 7CBF2B78  mr r31, r5
	ctx.r[31].u64 = ctx.r[5].u64;
	// 831E65E4: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831E65E8: 3D20821A  lis r9, -0x7de6
	ctx.r[9].s64 = -2112225280;
	// 831E65EC: 3D00821A  lis r8, -0x7de6
	ctx.r[8].s64 = -2112225280;
	// 831E65F0: 816B0368  lwz r11, 0x368(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(872 as u32) ) } as u64;
	// 831E65F4: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 831E65F8: 3CE08201  lis r7, -0x7dff
	ctx.r[7].s64 = -2113863680;
	// 831E65FC: 3CC08200  lis r6, -0x7e00
	ctx.r[6].s64 = -2113929216;
	// 831E6600: 3BA00004  li r29, 4
	ctx.r[29].s64 = 4;
	// 831E6604: 38A00006  li r5, 6
	ctx.r[5].s64 = 6;
	// 831E6608: 917F0030  stw r11, 0x30(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(48 as u32), ctx.r[11].u32 ) };
	// 831E660C: 816A0360  lwz r11, 0x360(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(864 as u32) ) } as u64;
	// 831E6610: C3E79528  lfs f31, -0x6ad8(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(-27352 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 831E6614: 917F0008  stw r11, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 831E6618: C3C608A8  lfs f30, 0x8a8(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(2216 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 831E661C: 816A0360  lwz r11, 0x360(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(864 as u32) ) } as u64;
	// 831E6620: 917F000C  stw r11, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u32 ) };
	// 831E6624: 81690364  lwz r11, 0x364(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(868 as u32) ) } as u64;
	// 831E6628: 917F0010  stw r11, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 831E662C: 81690364  lwz r11, 0x364(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(868 as u32) ) } as u64;
	// 831E6630: 917F0014  stw r11, 0x14(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), ctx.r[11].u32 ) };
	// 831E6634: C0080378  lfs f0, 0x378(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(888 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E6638: D01F0050  stfs f0, 0x50(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 831E663C: 809E0000  lwz r4, 0(r30)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E6640: 7C8307B4  extsw r3, r4
	ctx.r[3].s64 = ctx.r[4].s32 as i64;
	// 831E6644: F8610050  std r3, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[3].u64 ) };
	// 831E6648: C8010050  lfd f0, 0x50(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 831E664C: FDA0069C  fcfid f13, f0
	ctx.f[13].f64 = (ctx.f[0].s64 as f64);
	// 831E6650: FD806818  frsp f12, f13
	ctx.f[12].f64 = (ctx.f[13].f64 as f32) as f64;
	// 831E6654: ED6C07F2  fmuls f11, f12, f31
	ctx.f[11].f64 = (((ctx.f[12].f64 * ctx.f[31].f64) as f32) as f64);
	// 831E6658: D17F0038  stfs f11, 0x38(r31)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(56 as u32), tmp.u32 ) };
	// 831E665C: 817E0004  lwz r11, 4(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E6660: 7D6A07B4  extsw r10, r11
	ctx.r[10].s64 = ctx.r[11].s32 as i64;
	// 831E6664: F9410050  std r10, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[10].u64 ) };
	// 831E6668: C9410050  lfd f10, 0x50(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 831E666C: FD20569C  fcfid f9, f10
	ctx.f[9].f64 = (ctx.f[10].s64 as f64);
	// 831E6670: 93BF0024  stw r29, 0x24(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), ctx.r[29].u32 ) };
	// 831E6674: FD004818  frsp f8, f9
	ctx.f[8].f64 = (ctx.f[9].f64 as f32) as f64;
	// 831E6678: 90BF002C  stw r5, 0x2c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(44 as u32), ctx.r[5].u32 ) };
	// 831E667C: 39600008  li r11, 8
	ctx.r[11].s64 = 8;
	// 831E6680: ECE807F2  fmuls f7, f8, f31
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[31].f64) as f32) as f64);
	// 831E6684: D0FF003C  stfs f7, 0x3c(r31)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(60 as u32), tmp.u32 ) };
	// 831E6688: C0DE0010  lfs f6, 0x10(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 831E668C: FF06F000  fcmpu cr6, f6, f30
	ctx.cr[6].compare_f64(ctx.f[6].f64, ctx.f[30].f64);
	// 831E6690: 4198006C  blt cr6, 0x831e66fc
	if ctx.cr[6].lt {
	pc = 0x831E66FC; continue 'dispatch;
	}
	// 831E6694: 917F0028  stw r11, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[11].u32 ) };
	// 831E6698: C03E0010  lfs f1, 0x10(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831E669C: 4BFC7DC5  bl 0x831ae460
	ctx.lr = 0x831E66A0;
	sub_831AE460(ctx, base);
	// 831E66A0: FDA00818  frsp f13, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[13].f64 = (ctx.f[1].f64 as f32) as f64;
	// 831E66A4: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831E66A8: C80A1080  lfd f0, 0x1080(r10)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[10].u32.wrapping_add(4224 as u32) ) };
	// 831E66AC: FD8D0032  fmul f12, f13, f0
	ctx.f[12].f64 = ctx.f[13].f64 * ctx.f[0].f64;
	// 831E66B0: FD60601E  fctiwz f11, f12
	ctx.f[11].s64 = if ctx.f[12].f64 > (i32::MAX as f64) { i32::MAX as i64 } else { ctx.f[12].f64.trunc() as i32 as i64 };
	// 831E66B4: D9610050  stfd f11, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.f[11].u64 ) };
	// 831E66B8: 81610054  lwz r11, 0x54(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 831E66BC: 2F0BFFF8  cmpwi cr6, r11, -8
	ctx.cr[6].compare_i32(ctx.r[11].s32, -8, &mut ctx.xer);
	// 831E66C0: 40980010  bge cr6, 0x831e66d0
	if !ctx.cr[6].lt {
	pc = 0x831E66D0; continue 'dispatch;
	}
	// 831E66C4: 3960FFF8  li r11, -8
	ctx.r[11].s64 = -8;
	// 831E66C8: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 831E66CC: 48000018  b 0x831e66e4
	pc = 0x831E66E4; continue 'dispatch;
	// 831E66D0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E66D4: 4098000C  bge cr6, 0x831e66e0
	if !ctx.cr[6].lt {
	pc = 0x831E66E0; continue 'dispatch;
	}
	// 831E66D8: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 831E66DC: 48000008  b 0x831e66e4
	pc = 0x831E66E4; continue 'dispatch;
	// 831E66E0: 39600008  li r11, 8
	ctx.r[11].s64 = 8;
	// 831E66E4: 917F0020  stw r11, 0x20(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[11].u32 ) };
	// 831E66E8: C1BE0010  lfs f13, 0x10(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E66EC: C01E000C  lfs f0, 0xc(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E66F0: ED800372  fmuls f12, f0, f13
	ctx.f[12].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 831E66F4: D19F0048  stfs f12, 0x48(r31)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(72 as u32), tmp.u32 ) };
	// 831E66F8: 48000060  b 0x831e6758
	pc = 0x831E6758; continue 'dispatch;
	// 831E66FC: 917F0020  stw r11, 0x20(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[11].u32 ) };
	// 831E6700: C03E0010  lfs f1, 0x10(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831E6704: 4BFC7D5D  bl 0x831ae460
	ctx.lr = 0x831E6708;
	sub_831AE460(ctx, base);
	// 831E6708: FDA00818  frsp f13, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[13].f64 = (ctx.f[1].f64 as f32) as f64;
	// 831E670C: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 831E6710: C80AA928  lfd f0, -0x56d8(r10)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[10].u32.wrapping_add(-22232 as u32) ) };
	// 831E6714: FD8D0032  fmul f12, f13, f0
	ctx.f[12].f64 = ctx.f[13].f64 * ctx.f[0].f64;
	// 831E6718: FD60601E  fctiwz f11, f12
	ctx.f[11].s64 = if ctx.f[12].f64 > (i32::MAX as f64) { i32::MAX as i64 } else { ctx.f[12].f64.trunc() as i32 as i64 };
	// 831E671C: D9610050  stfd f11, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.f[11].u64 ) };
	// 831E6720: 81610054  lwz r11, 0x54(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 831E6724: 2F0BFFF8  cmpwi cr6, r11, -8
	ctx.cr[6].compare_i32(ctx.r[11].s32, -8, &mut ctx.xer);
	// 831E6728: 40980010  bge cr6, 0x831e6738
	if !ctx.cr[6].lt {
	pc = 0x831E6738; continue 'dispatch;
	}
	// 831E672C: 3960FFF8  li r11, -8
	ctx.r[11].s64 = -8;
	// 831E6730: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 831E6734: 48000018  b 0x831e674c
	pc = 0x831E674C; continue 'dispatch;
	// 831E6738: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E673C: 4098000C  bge cr6, 0x831e6748
	if !ctx.cr[6].lt {
	pc = 0x831E6748; continue 'dispatch;
	}
	// 831E6740: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 831E6744: 48000008  b 0x831e674c
	pc = 0x831E674C; continue 'dispatch;
	// 831E6748: 39600008  li r11, 8
	ctx.r[11].s64 = 8;
	// 831E674C: 917F0028  stw r11, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[11].u32 ) };
	// 831E6750: C01E000C  lfs f0, 0xc(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E6754: D01F0048  stfs f0, 0x48(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(72 as u32), tmp.u32 ) };
	// 831E6758: 817E0014  lwz r11, 0x14(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E675C: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831E6760: 3D208204  lis r9, -0x7dfc
	ctx.r[9].s64 = -2113667072;
	// 831E6764: 7D6807B4  extsw r8, r11
	ctx.r[8].s64 = ctx.r[11].s32 as i64;
	// 831E6768: F9010050  std r8, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[8].u64 ) };
	// 831E676C: C8010050  lfd f0, 0x50(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 831E6770: FDA0069C  fcfid f13, f0
	ctx.f[13].f64 = (ctx.f[0].s64 as f64);
	// 831E6774: FD606818  frsp f11, f13
	ctx.f[11].f64 = (ctx.f[13].f64 as f32) as f64;
	// 831E6778: C189DD6C  lfs f12, -0x2294(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-8852 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831E677C: ED4B07F2  fmuls f10, f11, f31
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[31].f64) as f32) as f64);
	// 831E6780: D15F0040  stfs f10, 0x40(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(64 as u32), tmp.u32 ) };
	// 831E6784: C13E0018  lfs f9, 0x18(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(24 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831E6788: 80EA0358  lwz r7, 0x358(r10)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(856 as u32) ) } as u64;
	// 831E678C: F8E10050  std r7, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[7].u64 ) };
	// 831E6790: C9010050  lfd f8, 0x50(r1)
	ctx.f[8].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 831E6794: EC090332  fmuls f0, f9, f12
	ctx.f[0].f64 = (((ctx.f[9].f64 * ctx.f[12].f64) as f32) as f64);
	// 831E6798: FCE0469C  fcfid f7, f8
	ctx.f[7].f64 = (ctx.f[8].s64 as f64);
	// 831E679C: FDA03818  frsp f13, f7
	ctx.f[13].f64 = (ctx.f[7].f64 as f32) as f64;
	// 831E67A0: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 831E67A4: 41980008  blt cr6, 0x831e67ac
	if ctx.cr[6].lt {
	pc = 0x831E67AC; continue 'dispatch;
	}
	// 831E67A8: EC0DF028  fsubs f0, f13, f30
	ctx.f[0].f64 = (((ctx.f[13].f64 - ctx.f[30].f64) as f32) as f64);
	// 831E67AC: FF00F000  fcmpu cr6, f0, f30
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[30].f64);
	// 831E67B0: 41990008  bgt cr6, 0x831e67b8
	if ctx.cr[6].gt {
	pc = 0x831E67B8; continue 'dispatch;
	}
	// 831E67B4: FC00F090  fmr f0, f30
	ctx.f[0].f64 = ctx.f[30].f64;
	// 831E67B8: FC00065E  fctidz f0, f0
	ctx.f[0].s64 = if ctx.f[0].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[0].f64.trunc() as i64 };
	// 831E67BC: 7C00FFAE  stfiwx f0, 0, r31
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[31].u32, tmp.u32) };
	// 831E67C0: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E67C4: 815E001C  lwz r10, 0x1c(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(28 as u32) ) } as u64;
	// 831E67C8: 7D4907B4  extsw r9, r10
	ctx.r[9].s64 = ctx.r[10].s32 as i64;
	// 831E67CC: F9210050  std r9, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[9].u64 ) };
	// 831E67D0: C9A10050  lfd f13, 0x50(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 831E67D4: FD606E9C  fcfid f11, f13
	ctx.f[11].f64 = (ctx.f[13].s64 as f64);
	// 831E67D8: FD405818  frsp f10, f11
	ctx.f[10].f64 = (ctx.f[11].f64 as f32) as f64;
	// 831E67DC: ED2A07F2  fmuls f9, f10, f31
	ctx.f[9].f64 = (((ctx.f[10].f64 * ctx.f[31].f64) as f32) as f64);
	// 831E67E0: D13F0044  stfs f9, 0x44(r31)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), tmp.u32 ) };
	// 831E67E4: 810B035C  lwz r8, 0x35c(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(860 as u32) ) } as u64;
	// 831E67E8: C11E0020  lfs f8, 0x20(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831E67EC: EC080332  fmuls f0, f8, f12
	ctx.f[0].f64 = (((ctx.f[8].f64 * ctx.f[12].f64) as f32) as f64);
	// 831E67F0: F9010050  std r8, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[8].u64 ) };
	// 831E67F4: C8E10050  lfd f7, 0x50(r1)
	ctx.f[7].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 831E67F8: FCC03E9C  fcfid f6, f7
	ctx.f[6].f64 = (ctx.f[7].s64 as f64);
	// 831E67FC: FDA03018  frsp f13, f6
	ctx.f[13].f64 = (ctx.f[6].f64 as f32) as f64;
	// 831E6800: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 831E6804: 41980008  blt cr6, 0x831e680c
	if ctx.cr[6].lt {
	pc = 0x831E680C; continue 'dispatch;
	}
	// 831E6808: EC0DF028  fsubs f0, f13, f30
	ctx.f[0].f64 = (((ctx.f[13].f64 - ctx.f[30].f64) as f32) as f64);
	// 831E680C: FC00065E  fctidz f0, f0
	ctx.f[0].s64 = if ctx.f[0].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[0].f64.trunc() as i64 };
	// 831E6810: 7C1FEFAE  stfiwx f0, r31, r29
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[31].u32.wrapping_add(ctx.r[29].u32), tmp.u32) };
	// 831E6814: 3D608201  lis r11, -0x7dff
	ctx.r[11].s64 = -2113863680;
	// 831E6818: C00B0140  lfs f0, 0x140(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(320 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E681C: C1BE0024  lfs f13, 0x24(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(36 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E6820: ED8D0032  fmuls f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E6824: FD60665E  fctidz f11, f12
	ctx.f[11].s64 = if ctx.f[12].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[12].f64.trunc() as i64 };
	// 831E6828: D9610050  stfd f11, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.f[11].u64 ) };
	// 831E682C: 81410054  lwz r10, 0x54(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 831E6830: 915F001C  stw r10, 0x1c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), ctx.r[10].u32 ) };
	// 831E6834: 915F0018  stw r10, 0x18(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), ctx.r[10].u32 ) };
	// 831E6838: C15E0028  lfs f10, 0x28(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(40 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831E683C: D15F004C  stfs f10, 0x4c(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(76 as u32), tmp.u32 ) };
	// 831E6840: C13E002C  lfs f9, 0x2c(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(44 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831E6844: D13F0034  stfs f9, 0x34(r31)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 831E6848: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831E684C: CBC1FFD0  lfd f30, -0x30(r1)
	ctx.f[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 831E6850: CBE1FFD8  lfd f31, -0x28(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-40 as u32) ) };
	// 831E6854: 4BFC1968  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E6858(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831E6858 size=344
    let mut pc: u32 = 0x831E6858;
    'dispatch: loop {
        match pc {
            0x831E6858 => {
    //   block [0x831E6858..0x831E68C4)
	// 831E6858: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E685C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E6860: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E6864: 9421FF40  stwu r1, -0xc0(r1)
	ea = ctx.r[1].u32.wrapping_add(-192 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E6868: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E686C: 7CAB2B78  mr r11, r5
	ctx.r[11].u64 = ctx.r[5].u64;
	// 831E6870: 2B04000C  cmplwi cr6, r4, 0xc
	ctx.cr[6].compare_u32(ctx.r[4].u32, 12 as u32, &mut ctx.xer);
	// 831E6874: 419900F0  bgt cr6, 0x831e6964
	if ctx.cr[6].gt {
	pc = 0x831E6964; continue 'dispatch;
	}
	// 831E6878: 3D80831E  lis r12, -0x7ce2
	ctx.r[12].s64 = -2095185920;
	// 831E687C: 398C6890  addi r12, r12, 0x6890
	ctx.r[12].s64 = ctx.r[12].s64 + 26768;
	// 831E6880: 5480103A  slwi r0, r4, 2
	ctx.r[0].u32 = ctx.r[4].u32.wrapping_shl(2);
	ctx.r[0].u64 = ctx.r[0].u32 as u64;
	// 831E6884: 7C0C002E  lwzx r0, r12, r0
	ctx.r[0].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[12].u32.wrapping_add(ctx.r[0].u32)) } as u64;
	// 831E6888: 7C0903A6  mtctr r0
	ctx.ctr.u64 = ctx.r[0].u64;
	// 831E688C: 4E800420  bctr
	match ctx.r[4].u64 {
		0 => {
	pc = 0x831E68C4; continue 'dispatch;
		},
		1 => {
	pc = 0x831E68D8; continue 'dispatch;
		},
		2 => {
	pc = 0x831E68E4; continue 'dispatch;
		},
		3 => {
	pc = 0x831E68F0; continue 'dispatch;
		},
		4 => {
	pc = 0x831E68FC; continue 'dispatch;
		},
		5 => {
	pc = 0x831E6908; continue 'dispatch;
		},
		6 => {
	pc = 0x831E6914; continue 'dispatch;
		},
		7 => {
	pc = 0x831E6920; continue 'dispatch;
		},
		8 => {
	pc = 0x831E692C; continue 'dispatch;
		},
		9 => {
	pc = 0x831E6938; continue 'dispatch;
		},
		10 => {
	pc = 0x831E6944; continue 'dispatch;
		},
		11 => {
	pc = 0x831E6950; continue 'dispatch;
		},
		12 => {
	pc = 0x831E695C; continue 'dispatch;
		},
		_ => unsafe { core::hint::unreachable_unchecked() },
	}
	// 831E6890: 831E68C4  lwz r24, 0x68c4(r30)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(26820 as u32) ) } as u64;
	// 831E6894: 831E68D8  lwz r24, 0x68d8(r30)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(26840 as u32) ) } as u64;
	// 831E6898: 831E68E4  lwz r24, 0x68e4(r30)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(26852 as u32) ) } as u64;
	// 831E689C: 831E68F0  lwz r24, 0x68f0(r30)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(26864 as u32) ) } as u64;
	// 831E68A0: 831E68FC  lwz r24, 0x68fc(r30)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(26876 as u32) ) } as u64;
	// 831E68A4: 831E6908  lwz r24, 0x6908(r30)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(26888 as u32) ) } as u64;
	// 831E68A8: 831E6914  lwz r24, 0x6914(r30)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(26900 as u32) ) } as u64;
	// 831E68AC: 831E6920  lwz r24, 0x6920(r30)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(26912 as u32) ) } as u64;
	// 831E68B0: 831E692C  lwz r24, 0x692c(r30)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(26924 as u32) ) } as u64;
	// 831E68B4: 831E6938  lwz r24, 0x6938(r30)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(26936 as u32) ) } as u64;
	// 831E68B8: 831E6944  lwz r24, 0x6944(r30)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(26948 as u32) ) } as u64;
	// 831E68BC: 831E6950  lwz r24, 0x6950(r30)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(26960 as u32) ) } as u64;
	// 831E68C0: 831E695C  lwz r24, 0x695c(r30)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(26972 as u32) ) } as u64;
            }
            0x831E68C4 => {
    //   block [0x831E68C4..0x831E68D8)
	// 831E68C4: 387F0004  addi r3, r31, 4
	ctx.r[3].s64 = ctx.r[31].s64 + 4;
	// 831E68C8: 38A00030  li r5, 0x30
	ctx.r[5].s64 = 48;
	// 831E68CC: 7D645B78  mr r4, r11
	ctx.r[4].u64 = ctx.r[11].u64;
	// 831E68D0: 4BFC1C41  bl 0x831a8510
	ctx.lr = 0x831E68D4;
	sub_831A8510(ctx, base);
	// 831E68D4: 48000090  b 0x831e6964
	pc = 0x831E6964; continue 'dispatch;
            }
            0x831E68D8 => {
    //   block [0x831E68D8..0x831E68E4)
	// 831E68D8: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E68DC: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E68E0: 48000084  b 0x831e6964
	pc = 0x831E6964; continue 'dispatch;
            }
            0x831E68E4 => {
    //   block [0x831E68E4..0x831E68F0)
	// 831E68E4: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E68E8: 917F0008  stw r11, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 831E68EC: 48000078  b 0x831e6964
	pc = 0x831E6964; continue 'dispatch;
            }
            0x831E68F0 => {
    //   block [0x831E68F0..0x831E68FC)
	// 831E68F0: C00B0008  lfs f0, 8(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E68F4: D01F000C  stfs f0, 0xc(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E68F8: 4800006C  b 0x831e6964
	pc = 0x831E6964; continue 'dispatch;
            }
            0x831E68FC => {
    //   block [0x831E68FC..0x831E6908)
	// 831E68FC: C00B000C  lfs f0, 0xc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E6900: D01F0010  stfs f0, 0x10(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831E6904: 48000060  b 0x831e6964
	pc = 0x831E6964; continue 'dispatch;
            }
            0x831E6908 => {
    //   block [0x831E6908..0x831E6914)
	// 831E6908: C00B0010  lfs f0, 0x10(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E690C: D01F0014  stfs f0, 0x14(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E6910: 48000054  b 0x831e6964
	pc = 0x831E6964; continue 'dispatch;
            }
            0x831E6914 => {
    //   block [0x831E6914..0x831E6920)
	// 831E6914: 816B0014  lwz r11, 0x14(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E6918: 917F0018  stw r11, 0x18(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), ctx.r[11].u32 ) };
	// 831E691C: 48000048  b 0x831e6964
	pc = 0x831E6964; continue 'dispatch;
            }
            0x831E6920 => {
    //   block [0x831E6920..0x831E692C)
	// 831E6920: C00B0018  lfs f0, 0x18(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E6924: D01F001C  stfs f0, 0x1c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 831E6928: 4800003C  b 0x831e6964
	pc = 0x831E6964; continue 'dispatch;
            }
            0x831E692C => {
    //   block [0x831E692C..0x831E6938)
	// 831E692C: 816B001C  lwz r11, 0x1c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) } as u64;
	// 831E6930: 917F0020  stw r11, 0x20(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[11].u32 ) };
	// 831E6934: 48000030  b 0x831e6964
	pc = 0x831E6964; continue 'dispatch;
            }
            0x831E6938 => {
    //   block [0x831E6938..0x831E6944)
	// 831E6938: C00B0020  lfs f0, 0x20(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(32 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E693C: D01F0024  stfs f0, 0x24(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831E6940: 48000024  b 0x831e6964
	pc = 0x831E6964; continue 'dispatch;
            }
            0x831E6944 => {
    //   block [0x831E6944..0x831E6950)
	// 831E6944: C00B0024  lfs f0, 0x24(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E6948: D01F0028  stfs f0, 0x28(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), tmp.u32 ) };
	// 831E694C: 48000018  b 0x831e6964
	pc = 0x831E6964; continue 'dispatch;
            }
            0x831E6950 => {
    //   block [0x831E6950..0x831E695C)
	// 831E6950: C00B0028  lfs f0, 0x28(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(40 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E6954: D01F002C  stfs f0, 0x2c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(44 as u32), tmp.u32 ) };
	// 831E6958: 4800000C  b 0x831e6964
	pc = 0x831E6964; continue 'dispatch;
            }
            0x831E695C => {
    //   block [0x831E695C..0x831E69B0)
	// 831E695C: C00B002C  lfs f0, 0x2c(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(44 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E6960: D01F0030  stfs f0, 0x30(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(48 as u32), tmp.u32 ) };
	// 831E6964: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 831E6968: 4BFFDE41  bl 0x831e47a8
	ctx.lr = 0x831E696C;
	sub_831E47A8(ctx, base);
	// 831E696C: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E6970: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 831E6974: 389F0004  addi r4, r31, 4
	ctx.r[4].s64 = ctx.r[31].s64 + 4;
	// 831E6978: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E697C: 7D4BFA14  add r10, r11, r31
	ctx.r[10].u64 = ctx.r[11].u64 + ctx.r[31].u64;
	// 831E6980: C02A0058  lfs f1, 0x58(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(88 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831E6984: 4BFFFC45  bl 0x831e65c8
	ctx.lr = 0x831E6988;
	sub_831E65C8(ctx, base);
	// 831E6988: 813F0000  lwz r9, 0(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E698C: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831E6990: 81690004  lwz r11, 4(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E6994: 7C6BFA14  add r3, r11, r31
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[31].u64;
	// 831E6998: 4BFFE2B9  bl 0x831e4c50
	ctx.lr = 0x831E699C;
	sub_831E4C50(ctx, base);
	// 831E699C: 382100C0  addi r1, r1, 0xc0
	ctx.r[1].s64 = ctx.r[1].s64 + 192;
	// 831E69A0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E69A4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E69A8: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E69AC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E69B0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831E69B0 size=212
    let mut pc: u32 = 0x831E69B0;
    'dispatch: loop {
        match pc {
            0x831E69B0 => {
    //   block [0x831E69B0..0x831E6A84)
	// 831E69B0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E69B4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E69B8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831E69BC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E69C0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E69C4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E69C8: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 831E69CC: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 831E69D0: 419A0018  beq cr6, 0x831e69e8
	if ctx.cr[6].eq {
	pc = 0x831E69E8; continue 'dispatch;
	}
	// 831E69D4: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E69D8: 387F0034  addi r3, r31, 0x34
	ctx.r[3].s64 = ctx.r[31].s64 + 52;
	// 831E69DC: 394B1088  addi r10, r11, 0x1088
	ctx.r[10].s64 = ctx.r[11].s64 + 4232;
	// 831E69E0: 915F0000  stw r10, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E69E4: 4BFFF005  bl 0x831e59e8
	ctx.lr = 0x831E69E8;
	sub_831E59E8(ctx, base);
	// 831E69E8: 3D208200  lis r9, -0x7e00
	ctx.r[9].s64 = -2113929216;
	// 831E69EC: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E69F0: 3D008200  lis r8, -0x7e00
	ctx.r[8].s64 = -2113929216;
	// 831E69F4: 3C608202  lis r3, -0x7dfe
	ctx.r[3].s64 = -2113798144;
	// 831E69F8: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831E69FC: 3CE08201  lis r7, -0x7dff
	ctx.r[7].s64 = -2113863680;
	// 831E6A00: C1A908A4  lfs f13, 0x8a4(r9)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(2212 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E6A04: 80AB0004  lwz r5, 4(r11)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E6A08: 3CC08201  lis r6, -0x7dff
	ctx.r[6].s64 = -2113863680;
	// 831E6A0C: C18808A8  lfs f12, 0x8a8(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(2216 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831E6A10: 3C80820A  lis r4, -0x7df6
	ctx.r[4].s64 = -2113273856;
	// 831E6A14: C0036218  lfs f0, 0x6218(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(25112 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E6A18: 3D208201  lis r9, -0x7dff
	ctx.r[9].s64 = -2113863680;
	// 831E6A1C: 390A0044  addi r8, r10, 0x44
	ctx.r[8].s64 = ctx.r[10].s64 + 68;
	// 831E6A20: C1679450  lfs f11, -0x6bb0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(-27568 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831E6A24: 3960D8F0  li r11, -0x2710
	ctx.r[11].s64 = -10000;
	// 831E6A28: 7D05F92E  stwx r8, r5, r31
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[5].u32.wrapping_add(ctx.r[31].u32), ctx.r[8].u32) };
	// 831E6A2C: C146CFC8  lfs f10, -0x3038(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(-12344 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831E6A30: C12454AC  lfs f9, 0x54ac(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(21676 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831E6A34: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E6A38: C109BBE8  lfs f8, -0x4418(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-17432 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831E6A3C: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E6A40: D1BF000C  stfs f13, 0xc(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831E6A44: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831E6A48: D19F0010  stfs f12, 0x10(r31)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831E6A4C: 917F0018  stw r11, 0x18(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), ctx.r[11].u32 ) };
	// 831E6A50: D17F0014  stfs f11, 0x14(r31)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831E6A54: 917F0020  stw r11, 0x20(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[11].u32 ) };
	// 831E6A58: D15F001C  stfs f10, 0x1c(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 831E6A5C: D13F0024  stfs f9, 0x24(r31)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831E6A60: D01F0028  stfs f0, 0x28(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), tmp.u32 ) };
	// 831E6A64: D01F002C  stfs f0, 0x2c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(44 as u32), tmp.u32 ) };
	// 831E6A68: D11F0030  stfs f8, 0x30(r31)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(48 as u32), tmp.u32 ) };
	// 831E6A6C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E6A70: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E6A74: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E6A78: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831E6A7C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E6A80: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E6A88(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E6A88 size=64
    let mut pc: u32 = 0x831E6A88;
    'dispatch: loop {
        match pc {
            0x831E6A88 => {
    //   block [0x831E6A88..0x831E6AC8)
	// 831E6A88: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E6A8C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E6A90: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E6A94: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E6A98: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E6A9C: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E6AA0: 387F0004  addi r3, r31, 4
	ctx.r[3].s64 = ctx.r[31].s64 + 4;
	// 831E6AA4: 394B1098  addi r10, r11, 0x1098
	ctx.r[10].s64 = ctx.r[11].s64 + 4248;
	// 831E6AA8: 915F0000  stw r10, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E6AAC: 48004B6D  bl 0x831eb618
	ctx.lr = 0x831E6AB0;
	sub_831EB618(ctx, base);
	// 831E6AB0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E6AB4: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831E6AB8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E6ABC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E6AC0: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E6AC4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E6AC8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E6AC8 size=24
    let mut pc: u32 = 0x831E6AC8;
    'dispatch: loop {
        match pc {
            0x831E6AC8 => {
    //   block [0x831E6AC8..0x831E6AE0)
	// 831E6AC8: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 831E6ACC: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831E6AD0: 386B0004  addi r3, r11, 4
	ctx.r[3].s64 = ctx.r[11].s64 + 4;
	// 831E6AD4: 392A1098  addi r9, r10, 0x1098
	ctx.r[9].s64 = ctx.r[10].s64 + 4248;
	// 831E6AD8: 912B0000  stw r9, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831E6ADC: 48004A44  b 0x831eb520
	sub_831EB520(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E6AE0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831E6AE0 size=104
    let mut pc: u32 = 0x831E6AE0;
    'dispatch: loop {
        match pc {
            0x831E6AE0 => {
    //   block [0x831E6AE0..0x831E6B48)
	// 831E6AE0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E6AE4: 4BFC1689  bl 0x831a816c
	ctx.lr = 0x831E6AE8;
	sub_831A8130(ctx, base);
	// 831E6AE8: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E6AEC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E6AF0: 7CBE2B78  mr r30, r5
	ctx.r[30].u64 = ctx.r[5].u64;
	// 831E6AF4: 387F0024  addi r3, r31, 0x24
	ctx.r[3].s64 = ctx.r[31].s64 + 36;
	// 831E6AF8: 38A00038  li r5, 0x38
	ctx.r[5].s64 = 56;
	// 831E6AFC: 7CFD3B78  mr r29, r7
	ctx.r[29].u64 = ctx.r[7].u64;
	// 831E6B00: 4BFC1A11  bl 0x831a8510
	ctx.lr = 0x831E6B04;
	sub_831A8510(ctx, base);
	// 831E6B04: 3D408200  lis r10, -0x7e00
	ctx.r[10].s64 = -2113929216;
	// 831E6B08: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 831E6B0C: 39200020  li r9, 0x20
	ctx.r[9].s64 = 32;
	// 831E6B10: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 831E6B14: B17F005C  sth r11, 0x5c(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(92 as u32), ctx.r[11].u16 ) };
	// 831E6B18: 993F009C  stb r9, 0x9c(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(156 as u32), ctx.r[9].u8 ) };
	// 831E6B1C: 7FA5EB78  mr r5, r29
	ctx.r[5].u64 = ctx.r[29].u64;
	// 831E6B20: C00A08A8  lfs f0, 0x8a8(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E6B24: B17F005E  sth r11, 0x5e(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(94 as u32), ctx.r[11].u16 ) };
	// 831E6B28: D01F0060  stfs f0, 0x60(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(96 as u32), tmp.u32 ) };
	// 831E6B2C: 911F0098  stw r8, 0x98(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(152 as u32), ctx.r[8].u32 ) };
	// 831E6B30: D01F0064  stfs f0, 0x64(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(100 as u32), tmp.u32 ) };
	// 831E6B34: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 831E6B38: 387F0004  addi r3, r31, 4
	ctx.r[3].s64 = ctx.r[31].s64 + 4;
	// 831E6B3C: 48004A1D  bl 0x831eb558
	ctx.lr = 0x831E6B40;
	sub_831EB558(ctx, base);
	// 831E6B40: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E6B44: 4BFC1678  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E6B48(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E6B48 size=164
    let mut pc: u32 = 0x831E6B48;
    'dispatch: loop {
        match pc {
            0x831E6B48 => {
    //   block [0x831E6B48..0x831E6BEC)
	// 831E6B48: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E6B4C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E6B50: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E6B54: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E6B58: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E6B5C: 897F009C  lbz r11, 0x9c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(156 as u32) ) } as u64;
	// 831E6B60: 556A07FE  clrlwi r10, r11, 0x1f
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0x00000001u64;
	// 831E6B64: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E6B68: 419A0020  beq cr6, 0x831e6b88
	if ctx.cr[6].eq {
	pc = 0x831E6B88; continue 'dispatch;
	}
	// 831E6B6C: 3C608000  lis r3, -0x8000
	ctx.r[3].s64 = -2147483648;
	// 831E6B70: 6063FFFF  ori r3, r3, 0xffff
	ctx.r[3].u64 = ctx.r[3].u64 | 65535;
	// 831E6B74: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831E6B78: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E6B7C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E6B80: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E6B84: 4E800020  blr
	return;
	// 831E6B88: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E6B8C: 3CA08000  lis r5, -0x8000
	ctx.r[5].s64 = -2147483648;
	// 831E6B90: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831E6B94: 60A54004  ori r5, r5, 0x4004
	ctx.r[5].u64 = ctx.r[5].u64 | 16388;
	// 831E6B98: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E6B9C: 814B005C  lwz r10, 0x5c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(92 as u32) ) } as u64;
	// 831E6BA0: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E6BA4: 4E800421  bctrl
	ctx.lr = 0x831E6BA8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E6BA8: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E6BAC: 409AFFDC  bne cr6, 0x831e6b88
	if !ctx.cr[6].eq {
	pc = 0x831E6B88; continue 'dispatch;
	}
	// 831E6BB0: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E6BB4: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 831E6BB8: 38800018  li r4, 0x18
	ctx.r[4].s64 = 24;
	// 831E6BBC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E6BC0: 814B0054  lwz r10, 0x54(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(84 as u32) ) } as u64;
	// 831E6BC4: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E6BC8: 4E800421  bctrl
	ctx.lr = 0x831E6BCC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E6BCC: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 831E6BD0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E6BD4: 913F0098  stw r9, 0x98(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(152 as u32), ctx.r[9].u32 ) };
	// 831E6BD8: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831E6BDC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E6BE0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E6BE4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E6BE8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E6BF0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E6BF0 size=108
    let mut pc: u32 = 0x831E6BF0;
    'dispatch: loop {
        match pc {
            0x831E6BF0 => {
    //   block [0x831E6BF0..0x831E6C5C)
	// 831E6BF0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E6BF4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E6BF8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831E6BFC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E6C00: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E6C04: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E6C08: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E6C0C: 387F0004  addi r3, r31, 4
	ctx.r[3].s64 = ctx.r[31].s64 + 4;
	// 831E6C10: 394B1098  addi r10, r11, 0x1098
	ctx.r[10].s64 = ctx.r[11].s64 + 4248;
	// 831E6C14: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 831E6C18: 915F0000  stw r10, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E6C1C: 48004905  bl 0x831eb520
	ctx.lr = 0x831E6C20;
	sub_831EB520(ctx, base);
	// 831E6C20: 57C907FE  clrlwi r9, r30, 0x1f
	ctx.r[9].u64 = ctx.r[30].u32 as u64 & 0x00000001u64;
	// 831E6C24: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831E6C28: 419A0018  beq cr6, 0x831e6c40
	if ctx.cr[6].eq {
	pc = 0x831E6C40; continue 'dispatch;
	}
	// 831E6C2C: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E6C30: 3CA06182  lis r5, 0x6182
	ctx.r[5].s64 = 1635909632;
	// 831E6C34: 386BD5A4  addi r3, r11, -0x2a5c
	ctx.r[3].s64 = ctx.r[11].s64 + -10844;
	// 831E6C38: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831E6C3C: 4BFF5A85  bl 0x831dc6c0
	ctx.lr = 0x831E6C40;
	sub_831DC6C0(ctx, base);
	// 831E6C40: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E6C44: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E6C48: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E6C4C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E6C50: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831E6C54: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E6C58: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E6C60(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E6C60 size=888
    let mut pc: u32 = 0x831E6C60;
    'dispatch: loop {
        match pc {
            0x831E6C60 => {
    //   block [0x831E6C60..0x831E6FD8)
	// 831E6C60: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E6C64: 4BFC1501  bl 0x831a8164
	ctx.lr = 0x831E6C68;
	sub_831A8130(ctx, base);
	// 831E6C68: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E6C6C: 54AA06F6  rlwinm r10, r5, 0, 0x1b, 0x1b
	ctx.r[10].u64 = ctx.r[5].u32 as u64 & 0xFFFFFFFFu64;
	// 831E6C70: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E6C74: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831E6C78: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 831E6C7C: 54BC063E  clrlwi r28, r5, 0x18
	ctx.r[28].u64 = ctx.r[5].u32 as u64 & 0x000000FFu64;
	// 831E6C80: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E6C84: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831E6C88: 409A0194  bne cr6, 0x831e6e1c
	if !ctx.cr[6].eq {
	pc = 0x831E6E1C; continue 'dispatch;
	}
	// 831E6C8C: 817E0020  lwz r11, 0x20(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) } as u64;
	// 831E6C90: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E6C94: 409A000C  bne cr6, 0x831e6ca0
	if !ctx.cr[6].eq {
	pc = 0x831E6CA0; continue 'dispatch;
	}
	// 831E6C98: 817E000C  lwz r11, 0xc(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E6C9C: 917E0020  stw r11, 0x20(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(32 as u32), ctx.r[11].u32 ) };
	// 831E6CA0: 817E0010  lwz r11, 0x10(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E6CA4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E6CA8: 419A00BC  beq cr6, 0x831e6d64
	if ctx.cr[6].eq {
	pc = 0x831E6D64; continue 'dispatch;
	}
	// 831E6CAC: 817E0014  lwz r11, 0x14(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E6CB0: 815E000C  lwz r10, 0xc(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E6CB4: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E6CB8: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E6CBC: 41980050  blt cr6, 0x831e6d0c
	if ctx.cr[6].lt {
	pc = 0x831E6D0C; continue 'dispatch;
	}
	// 831E6CC0: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E6CC4: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E6CC8: 419A0044  beq cr6, 0x831e6d0c
	if ctx.cr[6].eq {
	pc = 0x831E6D0C; continue 'dispatch;
	}
	// 831E6CCC: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E6CD0: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E6CD4: 409A0038  bne cr6, 0x831e6d0c
	if !ctx.cr[6].eq {
	pc = 0x831E6D0C; continue 'dispatch;
	}
	// 831E6CD8: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E6CDC: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E6CE0: 4082002C  bne 0x831e6d0c
	if !ctx.cr[0].eq {
	pc = 0x831E6D0C; continue 'dispatch;
	}
	// 831E6CE4: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E6CE8: 8B7F000C  lbz r27, 0xc(r31)
	ctx.r[27].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E6CEC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E6CF0: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E6CF4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E6CF8: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E6CFC: 4805BD71  bl 0x83242a6c
	ctx.lr = 0x831E6D00;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E6D00: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 831E6D04: 4805C469  bl 0x8324316c
	ctx.lr = 0x831E6D08;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E6D08: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E6D0C: 815E0018  lwz r10, 0x18(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(24 as u32) ) } as u64;
	// 831E6D10: 813E000C  lwz r9, 0xc(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E6D14: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E6D18: 40990050  ble cr6, 0x831e6d68
	if !ctx.cr[6].gt {
	pc = 0x831E6D68; continue 'dispatch;
	}
	// 831E6D1C: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E6D20: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E6D24: 419A0044  beq cr6, 0x831e6d68
	if ctx.cr[6].eq {
	pc = 0x831E6D68; continue 'dispatch;
	}
	// 831E6D28: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E6D2C: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E6D30: 409A0038  bne cr6, 0x831e6d68
	if !ctx.cr[6].eq {
	pc = 0x831E6D68; continue 'dispatch;
	}
	// 831E6D34: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E6D38: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E6D3C: 4082002C  bne 0x831e6d68
	if !ctx.cr[0].eq {
	pc = 0x831E6D68; continue 'dispatch;
	}
	// 831E6D40: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E6D44: 8B7F000C  lbz r27, 0xc(r31)
	ctx.r[27].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E6D48: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E6D4C: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E6D50: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E6D54: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E6D58: 4805BD15  bl 0x83242a6c
	ctx.lr = 0x831E6D5C;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E6D5C: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 831E6D60: 4805C40D  bl 0x8324316c
	ctx.lr = 0x831E6D64;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E6D64: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E6D68: 815E001C  lwz r10, 0x1c(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(28 as u32) ) } as u64;
	// 831E6D6C: 813E000C  lwz r9, 0xc(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E6D70: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E6D74: 41980050  blt cr6, 0x831e6dc4
	if ctx.cr[6].lt {
	pc = 0x831E6DC4; continue 'dispatch;
	}
	// 831E6D78: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E6D7C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E6D80: 419A0044  beq cr6, 0x831e6dc4
	if ctx.cr[6].eq {
	pc = 0x831E6DC4; continue 'dispatch;
	}
	// 831E6D84: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E6D88: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E6D8C: 409A0038  bne cr6, 0x831e6dc4
	if !ctx.cr[6].eq {
	pc = 0x831E6DC4; continue 'dispatch;
	}
	// 831E6D90: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E6D94: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E6D98: 4082002C  bne 0x831e6dc4
	if !ctx.cr[0].eq {
	pc = 0x831E6DC4; continue 'dispatch;
	}
	// 831E6D9C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E6DA0: 8B7F000C  lbz r27, 0xc(r31)
	ctx.r[27].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E6DA4: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E6DA8: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E6DAC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E6DB0: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E6DB4: 4805BCB9  bl 0x83242a6c
	ctx.lr = 0x831E6DB8;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E6DB8: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 831E6DBC: 4805C3B1  bl 0x8324316c
	ctx.lr = 0x831E6DC0;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E6DC0: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E6DC4: 815E0020  lwz r10, 0x20(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) } as u64;
	// 831E6DC8: 813E000C  lwz r9, 0xc(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E6DCC: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E6DD0: 40990050  ble cr6, 0x831e6e20
	if !ctx.cr[6].gt {
	pc = 0x831E6E20; continue 'dispatch;
	}
	// 831E6DD4: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E6DD8: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E6DDC: 419A0044  beq cr6, 0x831e6e20
	if ctx.cr[6].eq {
	pc = 0x831E6E20; continue 'dispatch;
	}
	// 831E6DE0: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E6DE4: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E6DE8: 409A0038  bne cr6, 0x831e6e20
	if !ctx.cr[6].eq {
	pc = 0x831E6E20; continue 'dispatch;
	}
	// 831E6DEC: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E6DF0: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E6DF4: 4082002C  bne 0x831e6e20
	if !ctx.cr[0].eq {
	pc = 0x831E6E20; continue 'dispatch;
	}
	// 831E6DF8: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E6DFC: 8B7F000C  lbz r27, 0xc(r31)
	ctx.r[27].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E6E00: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E6E04: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E6E08: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E6E0C: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E6E10: 4805BC5D  bl 0x83242a6c
	ctx.lr = 0x831E6E14;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E6E14: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 831E6E18: 4805C355  bl 0x8324316c
	ctx.lr = 0x831E6E1C;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E6E1C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E6E20: 815E0010  lwz r10, 0x10(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E6E24: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E6E28: 419A00C8  beq cr6, 0x831e6ef0
	if ctx.cr[6].eq {
	pc = 0x831E6EF0; continue 'dispatch;
	}
	// 831E6E2C: 578A06B4  rlwinm r10, r28, 0, 0x1a, 0x1a
	ctx.r[10].u64 = ctx.r[28].u32 as u64 & 0xFFFFFFFFu64;
	// 831E6E30: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E6E34: 409A00BC  bne cr6, 0x831e6ef0
	if !ctx.cr[6].eq {
	pc = 0x831E6EF0; continue 'dispatch;
	}
	// 831E6E38: 815E0014  lwz r10, 0x14(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E6E3C: 813E0018  lwz r9, 0x18(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(24 as u32) ) } as u64;
	// 831E6E40: 7F095040  cmplw cr6, r9, r10
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E6E44: 41990050  bgt cr6, 0x831e6e94
	if ctx.cr[6].gt {
	pc = 0x831E6E94; continue 'dispatch;
	}
	// 831E6E48: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E6E4C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E6E50: 419A0044  beq cr6, 0x831e6e94
	if ctx.cr[6].eq {
	pc = 0x831E6E94; continue 'dispatch;
	}
	// 831E6E54: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E6E58: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E6E5C: 409A0038  bne cr6, 0x831e6e94
	if !ctx.cr[6].eq {
	pc = 0x831E6E94; continue 'dispatch;
	}
	// 831E6E60: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E6E64: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E6E68: 4082002C  bne 0x831e6e94
	if !ctx.cr[0].eq {
	pc = 0x831E6E94; continue 'dispatch;
	}
	// 831E6E6C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E6E70: 8B7F000C  lbz r27, 0xc(r31)
	ctx.r[27].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E6E74: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E6E78: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E6E7C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E6E80: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E6E84: 4805BBE9  bl 0x83242a6c
	ctx.lr = 0x831E6E88;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E6E88: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 831E6E8C: 4805C2E1  bl 0x8324316c
	ctx.lr = 0x831E6E90;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E6E90: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E6E94: 815E001C  lwz r10, 0x1c(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(28 as u32) ) } as u64;
	// 831E6E98: 813E0018  lwz r9, 0x18(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(24 as u32) ) } as u64;
	// 831E6E9C: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E6EA0: 41980050  blt cr6, 0x831e6ef0
	if ctx.cr[6].lt {
	pc = 0x831E6EF0; continue 'dispatch;
	}
	// 831E6EA4: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E6EA8: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E6EAC: 419A0044  beq cr6, 0x831e6ef0
	if ctx.cr[6].eq {
	pc = 0x831E6EF0; continue 'dispatch;
	}
	// 831E6EB0: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E6EB4: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E6EB8: 409A0038  bne cr6, 0x831e6ef0
	if !ctx.cr[6].eq {
	pc = 0x831E6EF0; continue 'dispatch;
	}
	// 831E6EBC: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E6EC0: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E6EC4: 4082002C  bne 0x831e6ef0
	if !ctx.cr[0].eq {
	pc = 0x831E6EF0; continue 'dispatch;
	}
	// 831E6EC8: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E6ECC: 8B7F000C  lbz r27, 0xc(r31)
	ctx.r[27].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E6ED0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E6ED4: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E6ED8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E6EDC: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E6EE0: 4805BB8D  bl 0x83242a6c
	ctx.lr = 0x831E6EE4;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E6EE4: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 831E6EE8: 4805C285  bl 0x8324316c
	ctx.lr = 0x831E6EEC;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E6EEC: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E6EF0: 815E0020  lwz r10, 0x20(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) } as u64;
	// 831E6EF4: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E6EF8: 419A006C  beq cr6, 0x831e6f64
	if ctx.cr[6].eq {
	pc = 0x831E6F64; continue 'dispatch;
	}
	// 831E6EFC: 813E0010  lwz r9, 0x10(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E6F00: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831E6F04: 419A000C  beq cr6, 0x831e6f10
	if ctx.cr[6].eq {
	pc = 0x831E6F10; continue 'dispatch;
	}
	// 831E6F08: 813E0014  lwz r9, 0x14(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E6F0C: 48000008  b 0x831e6f14
	pc = 0x831E6F14; continue 'dispatch;
	// 831E6F10: 813E001C  lwz r9, 0x1c(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(28 as u32) ) } as u64;
	// 831E6F14: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E6F18: 4199004C  bgt cr6, 0x831e6f64
	if ctx.cr[6].gt {
	pc = 0x831E6F64; continue 'dispatch;
	}
	// 831E6F1C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E6F20: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E6F24: 419A0040  beq cr6, 0x831e6f64
	if ctx.cr[6].eq {
	pc = 0x831E6F64; continue 'dispatch;
	}
	// 831E6F28: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E6F2C: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E6F30: 409A0034  bne cr6, 0x831e6f64
	if !ctx.cr[6].eq {
	pc = 0x831E6F64; continue 'dispatch;
	}
	// 831E6F34: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E6F38: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E6F3C: 40820028  bne 0x831e6f64
	if !ctx.cr[0].eq {
	pc = 0x831E6F64; continue 'dispatch;
	}
	// 831E6F40: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E6F44: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E6F48: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E6F4C: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E6F50: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E6F54: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E6F58: 4805BB15  bl 0x83242a6c
	ctx.lr = 0x831E6F5C;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E6F5C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E6F60: 4805C20D  bl 0x8324316c
	ctx.lr = 0x831E6F64;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E6F64: 578B07FE  clrlwi r11, r28, 0x1f
	ctx.r[11].u64 = ctx.r[28].u32 as u64 & 0x00000001u64;
	// 831E6F68: 38800018  li r4, 0x18
	ctx.r[4].s64 = 24;
	// 831E6F6C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E6F70: 817D0000  lwz r11, 0(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E6F74: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831E6F78: 38A00008  li r5, 8
	ctx.r[5].s64 = 8;
	// 831E6F7C: 814B0054  lwz r10, 0x54(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(84 as u32) ) } as u64;
	// 831E6F80: 409A0008  bne cr6, 0x831e6f88
	if !ctx.cr[6].eq {
	pc = 0x831E6F88; continue 'dispatch;
	}
	// 831E6F84: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 831E6F88: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E6F8C: 4E800421  bctrl
	ctx.lr = 0x831E6F90;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E6F90: 815D0010  lwz r10, 0x10(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E6F94: 397D0010  addi r11, r29, 0x10
	ctx.r[11].s64 = ctx.r[29].s64 + 16;
	// 831E6F98: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E6F9C: 419A0014  beq cr6, 0x831e6fb0
	if ctx.cr[6].eq {
	pc = 0x831E6FB0; continue 'dispatch;
	}
	// 831E6FA0: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E6FA4: 7D4B5050  subf r10, r11, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 831E6FA8: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E6FAC: 409A0020  bne cr6, 0x831e6fcc
	if !ctx.cr[6].eq {
	pc = 0x831E6FCC; continue 'dispatch;
	}
	// 831E6FB0: 817D0000  lwz r11, 0(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E6FB4: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 831E6FB8: 38800020  li r4, 0x20
	ctx.r[4].s64 = 32;
	// 831E6FBC: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831E6FC0: 814B0054  lwz r10, 0x54(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(84 as u32) ) } as u64;
	// 831E6FC4: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E6FC8: 4E800421  bctrl
	ctx.lr = 0x831E6FCC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E6FCC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E6FD0: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E6FD4: 4BFC11E0  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E6FD8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831E6FD8 size=156
    let mut pc: u32 = 0x831E6FD8;
    'dispatch: loop {
        match pc {
            0x831E6FD8 => {
    //   block [0x831E6FD8..0x831E7074)
	// 831E6FD8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E6FDC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E6FE0: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831E6FE4: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E6FE8: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E6FEC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E6FF0: 7CBE2B78  mr r30, r5
	ctx.r[30].u64 = ctx.r[5].u64;
	// 831E6FF4: 897F009C  lbz r11, 0x9c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(156 as u32) ) } as u64;
	// 831E6FF8: 556A07FE  clrlwi r10, r11, 0x1f
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0x00000001u64;
	// 831E6FFC: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E7000: 409A0054  bne cr6, 0x831e7054
	if !ctx.cr[6].eq {
	pc = 0x831E7054; continue 'dispatch;
	}
	// 831E7004: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E7008: 397F0004  addi r11, r31, 4
	ctx.r[11].s64 = ctx.r[31].s64 + 4;
	// 831E700C: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E7010: 419A0014  beq cr6, 0x831e7024
	if ctx.cr[6].eq {
	pc = 0x831E7024; continue 'dispatch;
	}
	// 831E7014: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E7018: 7D4B5050  subf r10, r11, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 831E701C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E7020: 409A0034  bne cr6, 0x831e7054
	if !ctx.cr[6].eq {
	pc = 0x831E7054; continue 'dispatch;
	}
	// 831E7024: 387F0024  addi r3, r31, 0x24
	ctx.r[3].s64 = ctx.r[31].s64 + 36;
	// 831E7028: 38A00038  li r5, 0x38
	ctx.r[5].s64 = 56;
	// 831E702C: 4BFC14E5  bl 0x831a8510
	ctx.lr = 0x831E7030;
	sub_831A8510(ctx, base);
	// 831E7030: 815F0000  lwz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E7034: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 831E7038: 9BDF009D  stb r30, 0x9d(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(157 as u32), ctx.r[30].u8 ) };
	// 831E703C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E7040: 812A0050  lwz r9, 0x50(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(80 as u32) ) } as u64;
	// 831E7044: C02B08A8  lfs f1, 0x8a8(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2216 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831E7048: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 831E704C: 4E800421  bctrl
	ctx.lr = 0x831E7050;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E7050: 4800000C  b 0x831e705c
	pc = 0x831E705C; continue 'dispatch;
	// 831E7054: 3C608000  lis r3, -0x8000
	ctx.r[3].s64 = -2147483648;
	// 831E7058: 6063FFFF  ori r3, r3, 0xffff
	ctx.r[3].u64 = ctx.r[3].u64 | 65535;
	// 831E705C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E7060: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E7064: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E7068: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831E706C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E7070: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E7078(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E7078 size=696
    let mut pc: u32 = 0x831E7078;
    'dispatch: loop {
        match pc {
            0x831E7078 => {
    //   block [0x831E7078..0x831E7330)
	// 831E7078: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E707C: 4BFC10E1  bl 0x831a815c
	ctx.lr = 0x831E7080;
	sub_831A8130(ctx, base);
	// 831E7080: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E7084: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E7088: 7C9A2378  mr r26, r4
	ctx.r[26].u64 = ctx.r[4].u64;
	// 831E708C: 7CB92B78  mr r25, r5
	ctx.r[25].u64 = ctx.r[5].u64;
	// 831E7090: 4805C0CD  bl 0x8324315c
	ctx.lr = 0x831E7094;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E7094: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E7098: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831E709C: 3BCBD530  addi r30, r11, -0x2ad0
	ctx.r[30].s64 = ctx.r[11].s64 + -10960;
	// 831E70A0: 7DBF6B78  mr r31, r13
	ctx.r[31].u64 = ctx.r[13].u64;
	// 831E70A4: 815E0004  lwz r10, 4(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E70A8: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831E70AC: 419A0010  beq cr6, 0x831e70bc
	if ctx.cr[6].eq {
	pc = 0x831E70BC; continue 'dispatch;
	}
	// 831E70B0: 80FE0008  lwz r7, 8(r30)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E70B4: 7F1F3840  cmplw cr6, r31, r7
	ctx.cr[6].compare_u32(ctx.r[31].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831E70B8: 419A0020  beq cr6, 0x831e70d8
	if ctx.cr[6].eq {
	pc = 0x831E70D8; continue 'dispatch;
	}
	// 831E70BC: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E70C0: 4805B9BD  bl 0x83242a7c
	ctx.lr = 0x831E70C4;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E70C4: 7FE7FB78  mr r7, r31
	ctx.r[7].u64 = ctx.r[31].u64;
	// 831E70C8: 815E0004  lwz r10, 4(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E70CC: 90FE0008  stw r7, 8(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(8 as u32), ctx.r[7].u32 ) };
	// 831E70D0: 9BBE000C  stb r29, 0xc(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831E70D4: 48000008  b 0x831e70dc
	pc = 0x831E70DC; continue 'dispatch;
	// 831E70D8: 8BBE000C  lbz r29, 0xc(r30)
	ctx.r[29].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E70DC: 397C0004  addi r11, r28, 4
	ctx.r[11].s64 = ctx.r[28].s64 + 4;
	// 831E70E0: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 831E70E4: 392B000C  addi r9, r11, 0xc
	ctx.r[9].s64 = ctx.r[11].s64 + 12;
	// 831E70E8: 915E0004  stw r10, 4(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831E70EC: 811C0010  lwz r8, 0x10(r28)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E70F0: 7F094040  cmplw cr6, r9, r8
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831E70F4: 419A00E0  beq cr6, 0x831e71d4
	if ctx.cr[6].eq {
	pc = 0x831E71D4; continue 'dispatch;
	}
	// 831E70F8: 81290008  lwz r9, 8(r9)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E70FC: 7FE94050  subf r31, r9, r8
	ctx.r[31].s64 = ctx.r[8].s64 - ctx.r[9].s64;
	// 831E7100: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 831E7104: 419A00D0  beq cr6, 0x831e71d4
	if ctx.cr[6].eq {
	pc = 0x831E71D4; continue 'dispatch;
	}
	// 831E7108: 7D49FA14  add r10, r9, r31
	ctx.r[10].u64 = ctx.r[9].u64 + ctx.r[31].u64;
	// 831E710C: 7D29F82E  lwzx r9, r9, r31
	ctx.r[9].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[31].u32)) } as u64;
	// 831E7110: 7F095040  cmplw cr6, r9, r10
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E7114: 419A0020  beq cr6, 0x831e7134
	if ctx.cr[6].eq {
	pc = 0x831E7134; continue 'dispatch;
	}
	// 831E7118: 810A0004  lwz r8, 4(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E711C: 91090004  stw r8, 4(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), ctx.r[8].u32 ) };
	// 831E7120: 80EA0000  lwz r7, 0(r10)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E7124: 80CA0004  lwz r6, 4(r10)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E7128: 90E60000  stw r7, 0(r6)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(0 as u32), ctx.r[7].u32 ) };
	// 831E712C: 914A0004  stw r10, 4(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831E7130: 914A0000  stw r10, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E7134: 814B0008  lwz r10, 8(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E7138: 7D4AFA14  add r10, r10, r31
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[31].u64;
	// 831E713C: 916A0000  stw r11, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831E7140: 812B0004  lwz r9, 4(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E7144: 912A0004  stw r9, 4(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 831E7148: 914B0004  stw r10, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831E714C: 810A0004  lwz r8, 4(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E7150: 91480000  stw r10, 0(r8)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E7154: 80EB001C  lwz r7, 0x1c(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) } as u64;
	// 831E7158: 35470001  addic. r10, r7, 1
	ctx.xer.ca = (ctx.r[7].u32 > (!(1 as u32)));
	ctx.r[10].s64 = ctx.r[7].s64 + 1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831E715C: 914B001C  stw r10, 0x1c(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(28 as u32), ctx.r[10].u32 ) };
	// 831E7160: 915F0070  stw r10, 0x70(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(112 as u32), ctx.r[10].u32 ) };
	// 831E7164: 40820014  bne 0x831e7178
	if !ctx.cr[0].eq {
	pc = 0x831E7178; continue 'dispatch;
	}
	// 831E7168: 814B001C  lwz r10, 0x1c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) } as u64;
	// 831E716C: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 831E7170: 914B001C  stw r10, 0x1c(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(28 as u32), ctx.r[10].u32 ) };
	// 831E7174: 915F0070  stw r10, 0x70(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(112 as u32), ctx.r[10].u32 ) };
	// 831E7178: 3B600000  li r27, 0
	ctx.r[27].s64 = 0;
	// 831E717C: 572A06B4  rlwinm r10, r25, 0, 0x1a, 0x1a
	ctx.r[10].u64 = ctx.r[25].u32 as u64 & 0xFFFFFFFFu64;
	// 831E7180: 9B7F0075  stb r27, 0x75(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(117 as u32), ctx.r[27].u8 ) };
	// 831E7184: 9B7F0076  stb r27, 0x76(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(118 as u32), ctx.r[27].u8 ) };
	// 831E7188: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E718C: 9B7F0077  stb r27, 0x77(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(119 as u32), ctx.r[27].u8 ) };
	// 831E7190: 817A0000  lwz r11, 0(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E7194: 917F0008  stw r11, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 831E7198: 813A0004  lwz r9, 4(r26)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E719C: A11C005C  lhz r8, 0x5c(r28)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[28].u32.wrapping_add(92 as u32) ) } as u64;
	// 831E71A0: 0CC80000  twi 6, r8, 0
	// 831E71A4: 7CE94396  divwu r7, r9, r8
	ctx.r[7].u32 = ctx.r[9].u32 / ctx.r[8].u32;
	// 831E71A8: 90FF000C  stw r7, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[7].u32 ) };
	// 831E71AC: 80DA0008  lwz r6, 8(r26)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E71B0: 90DF0010  stw r6, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[6].u32 ) };
	// 831E71B4: 419A00C0  beq cr6, 0x831e7274
	if ctx.cr[6].eq {
	pc = 0x831E7274; continue 'dispatch;
	}
	// 831E71B8: 937F0014  stw r27, 0x14(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), ctx.r[27].u32 ) };
	// 831E71BC: 387F0028  addi r3, r31, 0x28
	ctx.r[3].s64 = ctx.r[31].s64 + 40;
	// 831E71C0: 937F0018  stw r27, 0x18(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), ctx.r[27].u32 ) };
	// 831E71C4: 389A000C  addi r4, r26, 0xc
	ctx.r[4].s64 = ctx.r[26].s64 + 12;
	// 831E71C8: 38A00048  li r5, 0x48
	ctx.r[5].s64 = 72;
	// 831E71CC: 4BFC1345  bl 0x831a8510
	ctx.lr = 0x831E71D0;
	sub_831A8510(ctx, base);
	// 831E71D0: 480000E4  b 0x831e72b4
	pc = 0x831E72B4; continue 'dispatch;
	// 831E71D4: 7DAB6B78  mr r11, r13
	ctx.r[11].u64 = ctx.r[13].u64;
	// 831E71D8: 3B600000  li r27, 0
	ctx.r[27].s64 = 0;
	// 831E71DC: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831E71E0: 419A0044  beq cr6, 0x831e7224
	if ctx.cr[6].eq {
	pc = 0x831E7224; continue 'dispatch;
	}
	// 831E71E4: 7F0B3840  cmplw cr6, r11, r7
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831E71E8: 409A003C  bne cr6, 0x831e7224
	if !ctx.cr[6].eq {
	pc = 0x831E7224; continue 'dispatch;
	}
	// 831E71EC: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831E71F0: 915E0004  stw r10, 4(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831E71F4: 40820030  bne 0x831e7224
	if !ctx.cr[0].eq {
	pc = 0x831E7224; continue 'dispatch;
	}
	// 831E71F8: 7F6BDB78  mr r11, r27
	ctx.r[11].u64 = ctx.r[27].u64;
	// 831E71FC: 7F6ADB78  mr r10, r27
	ctx.r[10].u64 = ctx.r[27].u64;
	// 831E7200: 997E000C  stb r11, 0xc(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E7204: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E7208: 915E0008  stw r10, 8(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E720C: 4805B861  bl 0x83242a6c
	ctx.lr = 0x831E7210;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E7210: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831E7214: 4805BF59  bl 0x8324316c
	ctx.lr = 0x831E7218;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E7218: 80FE0008  lwz r7, 8(r30)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E721C: 815E0004  lwz r10, 4(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E7220: 8BBE000C  lbz r29, 0xc(r30)
	ctx.r[29].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E7224: 7DAB6B78  mr r11, r13
	ctx.r[11].u64 = ctx.r[13].u64;
	// 831E7228: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831E722C: 419A0038  beq cr6, 0x831e7264
	if ctx.cr[6].eq {
	pc = 0x831E7264; continue 'dispatch;
	}
	// 831E7230: 7F0B3840  cmplw cr6, r11, r7
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831E7234: 409A0030  bne cr6, 0x831e7264
	if !ctx.cr[6].eq {
	pc = 0x831E7264; continue 'dispatch;
	}
	// 831E7238: 356AFFFF  addic. r11, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E723C: 917E0004  stw r11, 4(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E7240: 40820024  bne 0x831e7264
	if !ctx.cr[0].eq {
	pc = 0x831E7264; continue 'dispatch;
	}
	// 831E7244: 7F6BDB78  mr r11, r27
	ctx.r[11].u64 = ctx.r[27].u64;
	// 831E7248: 7F6ADB78  mr r10, r27
	ctx.r[10].u64 = ctx.r[27].u64;
	// 831E724C: 997E000C  stb r11, 0xc(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E7250: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E7254: 915E0008  stw r10, 8(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E7258: 4805B815  bl 0x83242a6c
	ctx.lr = 0x831E725C;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E725C: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831E7260: 4805BF0D  bl 0x8324316c
	ctx.lr = 0x831E7264;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E7264: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 831E7268: 6063000E  ori r3, r3, 0xe
	ctx.r[3].u64 = ctx.r[3].u64 | 14;
	// 831E726C: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831E7270: 4BFC0F3C  b 0x831a81ac
	sub_831A8180(ctx, base);
	return;
	// 831E7274: A17C005C  lhz r11, 0x5c(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[28].u32.wrapping_add(92 as u32) ) } as u64;
	// 831E7278: 815A000C  lwz r10, 0xc(r26)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E727C: 0CCB0000  twi 6, r11, 0
	// 831E7280: 7D2A5B96  divwu r9, r10, r11
	ctx.r[9].u32 = ctx.r[10].u32 / ctx.r[11].u32;
	// 831E7284: 913F0014  stw r9, 0x14(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), ctx.r[9].u32 ) };
	// 831E7288: 817A0010  lwz r11, 0x10(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E728C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E7290: 419A001C  beq cr6, 0x831e72ac
	if ctx.cr[6].eq {
	pc = 0x831E72AC; continue 'dispatch;
	}
	// 831E7294: A13C005C  lhz r9, 0x5c(r28)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[28].u32.wrapping_add(92 as u32) ) } as u64;
	// 831E7298: 815F0014  lwz r10, 0x14(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E729C: 7D6B4B96  divwu r11, r11, r9
	ctx.r[11].u32 = ctx.r[11].u32 / ctx.r[9].u32;
	// 831E72A0: 0CC90000  twi 6, r9, 0
	// 831E72A4: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831E72A8: 48000008  b 0x831e72b0
	pc = 0x831E72B0; continue 'dispatch;
	// 831E72AC: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E72B0: 917F0018  stw r11, 0x18(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), ctx.r[11].u32 ) };
	// 831E72B4: 937F001C  stw r27, 0x1c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), ctx.r[27].u32 ) };
	// 831E72B8: 7F25CB78  mr r5, r25
	ctx.r[5].u64 = ctx.r[25].u64;
	// 831E72BC: 937F0020  stw r27, 0x20(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[27].u32 ) };
	// 831E72C0: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831E72C4: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 831E72C8: 817A0054  lwz r11, 0x54(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(84 as u32) ) } as u64;
	// 831E72CC: 917F0024  stw r11, 0x24(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), ctx.r[11].u32 ) };
	// 831E72D0: 4BFFF991  bl 0x831e6c60
	ctx.lr = 0x831E72D4;
	sub_831E6C60(ctx, base);
	// 831E72D4: 817E0004  lwz r11, 4(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E72D8: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E72DC: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E72E0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E72E4: 419A0040  beq cr6, 0x831e7324
	if ctx.cr[6].eq {
	pc = 0x831E7324; continue 'dispatch;
	}
	// 831E72E8: 813E0008  lwz r9, 8(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E72EC: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E72F0: 409A0034  bne cr6, 0x831e7324
	if !ctx.cr[6].eq {
	pc = 0x831E7324; continue 'dispatch;
	}
	// 831E72F4: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E72F8: 917E0004  stw r11, 4(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E72FC: 40820028  bne 0x831e7324
	if !ctx.cr[0].eq {
	pc = 0x831E7324; continue 'dispatch;
	}
	// 831E7300: 7F6ADB78  mr r10, r27
	ctx.r[10].u64 = ctx.r[27].u64;
	// 831E7304: 8BBE000C  lbz r29, 0xc(r30)
	ctx.r[29].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E7308: 7F6BDB78  mr r11, r27
	ctx.r[11].u64 = ctx.r[27].u64;
	// 831E730C: 915E0008  stw r10, 8(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E7310: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E7314: 997E000C  stb r11, 0xc(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E7318: 4805B755  bl 0x83242a6c
	ctx.lr = 0x831E731C;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E731C: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831E7320: 4805BE4D  bl 0x8324316c
	ctx.lr = 0x831E7324;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E7324: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E7328: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831E732C: 4BFC0E80  b 0x831a81ac
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E7330(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E7330 size=612
    let mut pc: u32 = 0x831E7330;
    'dispatch: loop {
        match pc {
            0x831E7330 => {
    //   block [0x831E7330..0x831E7594)
	// 831E7330: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E7334: 4BFC0E2D  bl 0x831a8160
	ctx.lr = 0x831E7338;
	sub_831A8130(ctx, base);
	// 831E7338: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E733C: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 831E7340: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 831E7344: 7CBA2B78  mr r26, r5
	ctx.r[26].u64 = ctx.r[5].u64;
	// 831E7348: 4805BE15  bl 0x8324315c
	ctx.lr = 0x831E734C;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E734C: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E7350: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E7354: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831E7358: 7DBD6B78  mr r29, r13
	ctx.r[29].u64 = ctx.r[13].u64;
	// 831E735C: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E7360: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831E7364: 419A0010  beq cr6, 0x831e7374
	if ctx.cr[6].eq {
	pc = 0x831E7374; continue 'dispatch;
	}
	// 831E7368: 80FF0008  lwz r7, 8(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E736C: 7F1D3840  cmplw cr6, r29, r7
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831E7370: 419A0020  beq cr6, 0x831e7390
	if ctx.cr[6].eq {
	pc = 0x831E7390; continue 'dispatch;
	}
	// 831E7374: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E7378: 4805B705  bl 0x83242a7c
	ctx.lr = 0x831E737C;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E737C: 7FA7EB78  mr r7, r29
	ctx.r[7].u64 = ctx.r[29].u64;
	// 831E7380: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E7384: 90FF0008  stw r7, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[7].u32 ) };
	// 831E7388: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 831E738C: 48000008  b 0x831e7394
	pc = 0x831E7394; continue 'dispatch;
	// 831E7390: 8B9F000C  lbz r28, 0xc(r31)
	ctx.r[28].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E7394: 397B0004  addi r11, r27, 4
	ctx.r[11].s64 = ctx.r[27].s64 + 4;
	// 831E7398: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 831E739C: 392B000C  addi r9, r11, 0xc
	ctx.r[9].s64 = ctx.r[11].s64 + 12;
	// 831E73A0: 915F0004  stw r10, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831E73A4: 811B0010  lwz r8, 0x10(r27)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E73A8: 7F094040  cmplw cr6, r9, r8
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831E73AC: 419A0148  beq cr6, 0x831e74f4
	if ctx.cr[6].eq {
	pc = 0x831E74F4; continue 'dispatch;
	}
	// 831E73B0: 81290008  lwz r9, 8(r9)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E73B4: 7C894050  subf r4, r9, r8
	ctx.r[4].s64 = ctx.r[8].s64 - ctx.r[9].s64;
	// 831E73B8: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 831E73BC: 419A0138  beq cr6, 0x831e74f4
	if ctx.cr[6].eq {
	pc = 0x831E74F4; continue 'dispatch;
	}
	// 831E73C0: 7D492214  add r10, r9, r4
	ctx.r[10].u64 = ctx.r[9].u64 + ctx.r[4].u64;
	// 831E73C4: 7D29202E  lwzx r9, r9, r4
	ctx.r[9].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[4].u32)) } as u64;
	// 831E73C8: 7F095040  cmplw cr6, r9, r10
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E73CC: 419A0020  beq cr6, 0x831e73ec
	if ctx.cr[6].eq {
	pc = 0x831E73EC; continue 'dispatch;
	}
	// 831E73D0: 810A0004  lwz r8, 4(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E73D4: 91090004  stw r8, 4(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), ctx.r[8].u32 ) };
	// 831E73D8: 80EA0000  lwz r7, 0(r10)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E73DC: 80CA0004  lwz r6, 4(r10)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E73E0: 90E60000  stw r7, 0(r6)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(0 as u32), ctx.r[7].u32 ) };
	// 831E73E4: 914A0004  stw r10, 4(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831E73E8: 914A0000  stw r10, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E73EC: 814B0008  lwz r10, 8(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E73F0: 7D4A2214  add r10, r10, r4
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[4].u64;
	// 831E73F4: 916A0000  stw r11, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831E73F8: 812B0004  lwz r9, 4(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E73FC: 912A0004  stw r9, 4(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 831E7400: 914B0004  stw r10, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831E7404: 810A0004  lwz r8, 4(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E7408: 91480000  stw r10, 0(r8)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E740C: 80EB001C  lwz r7, 0x1c(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) } as u64;
	// 831E7410: 35470001  addic. r10, r7, 1
	ctx.xer.ca = (ctx.r[7].u32 > (!(1 as u32)));
	ctx.r[10].s64 = ctx.r[7].s64 + 1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831E7414: 914B001C  stw r10, 0x1c(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(28 as u32), ctx.r[10].u32 ) };
	// 831E7418: 91440070  stw r10, 0x70(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(112 as u32), ctx.r[10].u32 ) };
	// 831E741C: 40820014  bne 0x831e7430
	if !ctx.cr[0].eq {
	pc = 0x831E7430; continue 'dispatch;
	}
	// 831E7420: 814B001C  lwz r10, 0x1c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) } as u64;
	// 831E7424: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 831E7428: 914B001C  stw r10, 0x1c(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(28 as u32), ctx.r[10].u32 ) };
	// 831E742C: 91440070  stw r10, 0x70(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(112 as u32), ctx.r[10].u32 ) };
	// 831E7430: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 831E7434: 7F45D378  mr r5, r26
	ctx.r[5].u64 = ctx.r[26].u64;
	// 831E7438: 9BA40075  stb r29, 0x75(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(117 as u32), ctx.r[29].u8 ) };
	// 831E743C: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 831E7440: 9BA40076  stb r29, 0x76(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(118 as u32), ctx.r[29].u8 ) };
	// 831E7444: 9BA40077  stb r29, 0x77(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(119 as u32), ctx.r[29].u8 ) };
	// 831E7448: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E744C: 91640008  stw r11, 8(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 831E7450: 813E0004  lwz r9, 4(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E7454: A15B005C  lhz r10, 0x5c(r27)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[27].u32.wrapping_add(92 as u32) ) } as u64;
	// 831E7458: 0CCA0000  twi 6, r10, 0
	// 831E745C: 7D095396  divwu r8, r9, r10
	ctx.r[8].u32 = ctx.r[9].u32 / ctx.r[10].u32;
	// 831E7460: 9104000C  stw r8, 0xc(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(12 as u32), ctx.r[8].u32 ) };
	// 831E7464: 80FE0008  lwz r7, 8(r30)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E7468: 90E40010  stw r7, 0x10(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(16 as u32), ctx.r[7].u32 ) };
	// 831E746C: 80DE000C  lwz r6, 0xc(r30)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E7470: 90C40014  stw r6, 0x14(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(20 as u32), ctx.r[6].u32 ) };
	// 831E7474: 817E0010  lwz r11, 0x10(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E7478: 91640018  stw r11, 0x18(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(24 as u32), ctx.r[11].u32 ) };
	// 831E747C: 815E0014  lwz r10, 0x14(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E7480: 9144001C  stw r10, 0x1c(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(28 as u32), ctx.r[10].u32 ) };
	// 831E7484: 813E0018  lwz r9, 0x18(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(24 as u32) ) } as u64;
	// 831E7488: 91240020  stw r9, 0x20(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(32 as u32), ctx.r[9].u32 ) };
	// 831E748C: 811E001C  lwz r8, 0x1c(r30)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(28 as u32) ) } as u64;
	// 831E7490: 91040024  stw r8, 0x24(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(36 as u32), ctx.r[8].u32 ) };
	// 831E7494: 4BFFF7CD  bl 0x831e6c60
	ctx.lr = 0x831E7498;
	sub_831E6C60(ctx, base);
	// 831E7498: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E749C: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831E74A0: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E74A4: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E74A8: 419A0040  beq cr6, 0x831e74e8
	if ctx.cr[6].eq {
	pc = 0x831E74E8; continue 'dispatch;
	}
	// 831E74AC: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E74B0: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E74B4: 409A0034  bne cr6, 0x831e74e8
	if !ctx.cr[6].eq {
	pc = 0x831E74E8; continue 'dispatch;
	}
	// 831E74B8: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E74BC: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E74C0: 40820028  bne 0x831e74e8
	if !ctx.cr[0].eq {
	pc = 0x831E74E8; continue 'dispatch;
	}
	// 831E74C4: 7FAAEB78  mr r10, r29
	ctx.r[10].u64 = ctx.r[29].u64;
	// 831E74C8: 8B9F000C  lbz r28, 0xc(r31)
	ctx.r[28].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E74CC: 7FABEB78  mr r11, r29
	ctx.r[11].u64 = ctx.r[29].u64;
	// 831E74D0: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E74D4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E74D8: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E74DC: 4805B591  bl 0x83242a6c
	ctx.lr = 0x831E74E0;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E74E0: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 831E74E4: 4805BC89  bl 0x8324316c
	ctx.lr = 0x831E74E8;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E74E8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E74EC: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831E74F0: 4BFC0CC0  b 0x831a81b0
	sub_831A8180(ctx, base);
	return;
	// 831E74F4: 7DAB6B78  mr r11, r13
	ctx.r[11].u64 = ctx.r[13].u64;
	// 831E74F8: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 831E74FC: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831E7500: 419A0044  beq cr6, 0x831e7544
	if ctx.cr[6].eq {
	pc = 0x831E7544; continue 'dispatch;
	}
	// 831E7504: 7F0B3840  cmplw cr6, r11, r7
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831E7508: 409A003C  bne cr6, 0x831e7544
	if !ctx.cr[6].eq {
	pc = 0x831E7544; continue 'dispatch;
	}
	// 831E750C: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831E7510: 915F0004  stw r10, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831E7514: 40820030  bne 0x831e7544
	if !ctx.cr[0].eq {
	pc = 0x831E7544; continue 'dispatch;
	}
	// 831E7518: 7FABEB78  mr r11, r29
	ctx.r[11].u64 = ctx.r[29].u64;
	// 831E751C: 7FAAEB78  mr r10, r29
	ctx.r[10].u64 = ctx.r[29].u64;
	// 831E7520: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E7524: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E7528: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E752C: 4805B541  bl 0x83242a6c
	ctx.lr = 0x831E7530;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E7530: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 831E7534: 4805BC39  bl 0x8324316c
	ctx.lr = 0x831E7538;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E7538: 80FF0008  lwz r7, 8(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E753C: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E7540: 8B9F000C  lbz r28, 0xc(r31)
	ctx.r[28].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E7544: 7DAB6B78  mr r11, r13
	ctx.r[11].u64 = ctx.r[13].u64;
	// 831E7548: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831E754C: 419A0038  beq cr6, 0x831e7584
	if ctx.cr[6].eq {
	pc = 0x831E7584; continue 'dispatch;
	}
	// 831E7550: 7F0B3840  cmplw cr6, r11, r7
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831E7554: 409A0030  bne cr6, 0x831e7584
	if !ctx.cr[6].eq {
	pc = 0x831E7584; continue 'dispatch;
	}
	// 831E7558: 356AFFFF  addic. r11, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E755C: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E7560: 40820024  bne 0x831e7584
	if !ctx.cr[0].eq {
	pc = 0x831E7584; continue 'dispatch;
	}
	// 831E7564: 7FABEB78  mr r11, r29
	ctx.r[11].u64 = ctx.r[29].u64;
	// 831E7568: 7FAAEB78  mr r10, r29
	ctx.r[10].u64 = ctx.r[29].u64;
	// 831E756C: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E7570: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E7574: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E7578: 4805B4F5  bl 0x83242a6c
	ctx.lr = 0x831E757C;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E757C: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 831E7580: 4805BBED  bl 0x8324316c
	ctx.lr = 0x831E7584;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E7584: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 831E7588: 6063000E  ori r3, r3, 0xe
	ctx.r[3].u64 = ctx.r[3].u64 | 14;
	// 831E758C: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831E7590: 4BFC0C20  b 0x831a81b0
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E7598(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E7598 size=456
    let mut pc: u32 = 0x831E7598;
    'dispatch: loop {
        match pc {
            0x831E7598 => {
    //   block [0x831E7598..0x831E7760)
	// 831E7598: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E759C: 4BFC0BC9  bl 0x831a8164
	ctx.lr = 0x831E75A0;
	sub_831A8130(ctx, base);
	// 831E75A0: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E75A4: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831E75A8: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 831E75AC: 4805BBB1  bl 0x8324315c
	ctx.lr = 0x831E75B0;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E75B0: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E75B4: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 831E75B8: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831E75BC: 7DBC6B78  mr r28, r13
	ctx.r[28].u64 = ctx.r[13].u64;
	// 831E75C0: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E75C4: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E75C8: 419A0010  beq cr6, 0x831e75d8
	if ctx.cr[6].eq {
	pc = 0x831E75D8; continue 'dispatch;
	}
	// 831E75CC: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E75D0: 7F1C4040  cmplw cr6, r28, r8
	ctx.cr[6].compare_u32(ctx.r[28].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831E75D4: 419A0020  beq cr6, 0x831e75f4
	if ctx.cr[6].eq {
	pc = 0x831E75F4; continue 'dispatch;
	}
	// 831E75D8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E75DC: 4805B4A1  bl 0x83242a7c
	ctx.lr = 0x831E75E0;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E75E0: 7F88E378  mr r8, r28
	ctx.r[8].u64 = ctx.r[28].u64;
	// 831E75E4: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E75E8: 911F0008  stw r8, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 831E75EC: 9B7F000C  stb r27, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[27].u8 ) };
	// 831E75F0: 48000008  b 0x831e75f8
	pc = 0x831E75F8; continue 'dispatch;
	// 831E75F4: 8B7F000C  lbz r27, 0xc(r31)
	ctx.r[27].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E75F8: 392B0001  addi r9, r11, 1
	ctx.r[9].s64 = ctx.r[11].s64 + 1;
	// 831E75FC: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 831E7600: 913F0004  stw r9, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 831E7604: 409A0078  bne cr6, 0x831e767c
	if !ctx.cr[6].eq {
	pc = 0x831E767C; continue 'dispatch;
	}
	// 831E7608: 815E0004  lwz r10, 4(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E760C: 397E0004  addi r11, r30, 4
	ctx.r[11].s64 = ctx.r[30].s64 + 4;
	// 831E7610: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E7614: 419A0010  beq cr6, 0x831e7624
	if ctx.cr[6].eq {
	pc = 0x831E7624; continue 'dispatch;
	}
	// 831E7618: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E761C: 7FAB5050  subf r29, r11, r10
	ctx.r[29].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 831E7620: 48000008  b 0x831e7628
	pc = 0x831E7628; continue 'dispatch;
	// 831E7624: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 831E7628: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 831E762C: 409A0050  bne cr6, 0x831e767c
	if !ctx.cr[6].eq {
	pc = 0x831E767C; continue 'dispatch;
	}
	// 831E7630: 7DAB6B78  mr r11, r13
	ctx.r[11].u64 = ctx.r[13].u64;
	// 831E7634: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831E7638: 419A0038  beq cr6, 0x831e7670
	if ctx.cr[6].eq {
	pc = 0x831E7670; continue 'dispatch;
	}
	// 831E763C: 7F0B4040  cmplw cr6, r11, r8
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831E7640: 409A0030  bne cr6, 0x831e7670
	if !ctx.cr[6].eq {
	pc = 0x831E7670; continue 'dispatch;
	}
	// 831E7644: 3569FFFF  addic. r11, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E7648: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E764C: 40820024  bne 0x831e7670
	if !ctx.cr[0].eq {
	pc = 0x831E7670; continue 'dispatch;
	}
	// 831E7650: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E7654: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E7658: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E765C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E7660: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E7664: 4805B409  bl 0x83242a6c
	ctx.lr = 0x831E7668;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E7668: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 831E766C: 4805BB01  bl 0x8324316c
	ctx.lr = 0x831E7670;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E7670: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E7674: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E7678: 4BFC0B3C  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
	// 831E767C: 817E000C  lwz r11, 0xc(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E7680: 395E0004  addi r10, r30, 4
	ctx.r[10].s64 = ctx.r[30].s64 + 4;
	// 831E7684: 7D6BEA14  add r11, r11, r29
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 831E7688: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E768C: 7F095840  cmplw cr6, r9, r11
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831E7690: 419A0020  beq cr6, 0x831e76b0
	if ctx.cr[6].eq {
	pc = 0x831E76B0; continue 'dispatch;
	}
	// 831E7694: 810B0004  lwz r8, 4(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E7698: 91090004  stw r8, 4(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), ctx.r[8].u32 ) };
	// 831E769C: 80EB0004  lwz r7, 4(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E76A0: 80CB0000  lwz r6, 0(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E76A4: 90C70000  stw r6, 0(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), ctx.r[6].u32 ) };
	// 831E76A8: 916B0004  stw r11, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E76AC: 916B0000  stw r11, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831E76B0: 816A0014  lwz r11, 0x14(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E76B4: 392A000C  addi r9, r10, 0xc
	ctx.r[9].s64 = ctx.r[10].s64 + 12;
	// 831E76B8: 38A00030  li r5, 0x30
	ctx.r[5].s64 = 48;
	// 831E76BC: 7D6BEA14  add r11, r11, r29
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 831E76C0: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831E76C4: 387E0068  addi r3, r30, 0x68
	ctx.r[3].s64 = ctx.r[30].s64 + 104;
	// 831E76C8: 912B0000  stw r9, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831E76CC: 812A0010  lwz r9, 0x10(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E76D0: 912B0004  stw r9, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 831E76D4: 916A0010  stw r11, 0x10(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 831E76D8: 810B0004  lwz r8, 4(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E76DC: 91680000  stw r11, 0(r8)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831E76E0: 4BFC0B01  bl 0x831a81e0
	ctx.lr = 0x831E76E4;
	sub_831A81E0(ctx, base);
	// 831E76E4: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 831E76E8: 38A00020  li r5, 0x20
	ctx.r[5].s64 = 32;
	// 831E76EC: 98FD0074  stb r7, 0x74(r29)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[29].u32.wrapping_add(116 as u32), ctx.r[7].u8 ) };
	// 831E76F0: 38800020  li r4, 0x20
	ctx.r[4].s64 = 32;
	// 831E76F4: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E76F8: 80DE0000  lwz r6, 0(r30)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E76FC: 81660054  lwz r11, 0x54(r6)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(84 as u32) ) } as u64;
	// 831E7700: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 831E7704: 4E800421  bctrl
	ctx.lr = 0x831E7708;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E7708: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E770C: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E7710: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E7714: 419A0040  beq cr6, 0x831e7754
	if ctx.cr[6].eq {
	pc = 0x831E7754; continue 'dispatch;
	}
	// 831E7718: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E771C: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E7720: 409A0034  bne cr6, 0x831e7754
	if !ctx.cr[6].eq {
	pc = 0x831E7754; continue 'dispatch;
	}
	// 831E7724: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E7728: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E772C: 40820028  bne 0x831e7754
	if !ctx.cr[0].eq {
	pc = 0x831E7754; continue 'dispatch;
	}
	// 831E7730: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E7734: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E7738: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E773C: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E7740: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E7744: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E7748: 4805B325  bl 0x83242a6c
	ctx.lr = 0x831E774C;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E774C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E7750: 4805BA1D  bl 0x8324316c
	ctx.lr = 0x831E7754;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E7754: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831E7758: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E775C: 4BFC0A58  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E7760(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E7760 size=200
    let mut pc: u32 = 0x831E7760;
    'dispatch: loop {
        match pc {
            0x831E7760 => {
    //   block [0x831E7760..0x831E7828)
	// 831E7760: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 831E7764: 54AB5828  slwi r11, r5, 0xb
	ctx.r[11].u32 = ctx.r[5].u32.wrapping_shl(11);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831E7768: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 831E776C: 7C832214  add r4, r3, r4
	ctx.r[4].u64 = ctx.r[3].u64 + ctx.r[4].u64;
	// 831E7770: 7D4B1A14  add r10, r11, r3
	ctx.r[10].u64 = ctx.r[11].u64 + ctx.r[3].u64;
	// 831E7774: 54A57022  slwi r5, r5, 0xe
	ctx.r[5].u32 = ctx.r[5].u32.wrapping_shl(14);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831E7778: 54C6BA7E  srwi r6, r6, 9
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shr(9);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831E777C: 7FE8FB78  mr r8, r31
	ctx.r[8].u64 = ctx.r[31].u64;
	// 831E7780: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 831E7784: 7F0A2040  cmplw cr6, r10, r4
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[4].u32, &mut ctx.xer);
	// 831E7788: 40980048  bge cr6, 0x831e77d0
	if !ctx.cr[6].lt {
	pc = 0x831E77D0; continue 'dispatch;
	}
	// 831E778C: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 831E7790: 419A0008  beq cr6, 0x831e7798
	if ctx.cr[6].eq {
	pc = 0x831E7798; continue 'dispatch;
	}
	// 831E7794: 90670000  stw r3, 0(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), ctx.r[3].u32 ) };
	// 831E7798: 812A0000  lwz r9, 0(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E779C: 552B36BE  srwi r11, r9, 0x1a
	ctx.r[11].u32 = ctx.r[9].u32.wrapping_shr(26);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831E77A0: 7D6B4214  add r11, r11, r8
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 831E77A4: 7F065840  cmplw cr6, r6, r11
	ctx.cr[6].compare_u32(ctx.r[6].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831E77A8: 41980034  blt cr6, 0x831e77dc
	if ctx.cr[6].lt {
	pc = 0x831E77DC; continue 'dispatch;
	}
	// 831E77AC: 5529063E  clrlwi r9, r9, 0x18
	ctx.r[9].u64 = ctx.r[9].u32 as u64 & 0x000000FFu64;
	// 831E77B0: 7D685B78  mr r8, r11
	ctx.r[8].u64 = ctx.r[11].u64;
	// 831E77B4: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 831E77B8: 7F0B3040  cmplw cr6, r11, r6
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[6].u32, &mut ctx.xer);
	// 831E77BC: 552B5828  slwi r11, r9, 0xb
	ctx.r[11].u32 = ctx.r[9].u32.wrapping_shl(11);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831E77C0: 55691838  slwi r9, r11, 3
	ctx.r[9].u32 = ctx.r[11].u32.wrapping_shl(3);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831E77C4: 7D4B5214  add r10, r11, r10
	ctx.r[10].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831E77C8: 7CA92A14  add r5, r9, r5
	ctx.r[5].u64 = ctx.r[9].u64 + ctx.r[5].u64;
	// 831E77CC: 4099FFB8  ble cr6, 0x831e7784
	if !ctx.cr[6].gt {
	pc = 0x831E7784; continue 'dispatch;
	}
	// 831E77D0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E77D4: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831E77D8: 4E800020  blr
	return;
	// 831E77DC: 552BAC7E  rlwinm r11, r9, 0x15, 0x11, 0x1f
	ctx.r[11].u64 = ctx.r[9].u32 as u64 & 0x000007FFu64;
	// 831E77E0: 7F064040  cmplw cr6, r6, r8
	ctx.cr[6].compare_u32(ctx.r[6].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831E77E4: 396B0020  addi r11, r11, 0x20
	ctx.r[11].s64 = ctx.r[11].s64 + 32;
	// 831E77E8: 419A0034  beq cr6, 0x831e781c
	if ctx.cr[6].eq {
	pc = 0x831E781C; continue 'dispatch;
	}
	// 831E77EC: 7D283050  subf r9, r8, r6
	ctx.r[9].s64 = ctx.r[6].s64 - ctx.r[8].s64;
	// 831E77F0: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 831E77F4: 419A0008  beq cr6, 0x831e77fc
	if ctx.cr[6].eq {
	pc = 0x831E77FC; continue 'dispatch;
	}
	// 831E77F8: 93E70000  stw r31, 0(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), ctx.r[31].u32 ) };
	// 831E77FC: 5568E8FE  srwi r8, r11, 3
	ctx.r[8].u32 = ctx.r[11].u32.wrapping_shr(3);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831E7800: 5566077E  clrlwi r6, r11, 0x1d
	ctx.r[6].u64 = ctx.r[11].u32 as u64 & 0x00000007u64;
	// 831E7804: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831E7808: 7C88502E  lwzx r4, r8, r10
	ctx.r[4].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[8].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 831E780C: 7C833030  slw r3, r4, r6
	if (ctx.r[6].u8 & 0x20) != 0 {
		ctx.r[3].u64 = 0;
	} else {
		ctx.r[3].u64 = ((ctx.r[4].u32) << ((ctx.r[6].u8 & 0x1F) as u32)) as u64;
	}
	// 831E7810: 54687C7E  srwi r8, r3, 0x11
	ctx.r[8].u32 = ctx.r[3].u32.wrapping_shr(17);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831E7814: 7D685A14  add r11, r8, r11
	ctx.r[11].u64 = ctx.r[8].u64 + ctx.r[11].u64;
	// 831E7818: 4082FFD8  bne 0x831e77f0
	if !ctx.cr[0].eq {
	pc = 0x831E77F0; continue 'dispatch;
	}
	// 831E781C: 7C6B2A14  add r3, r11, r5
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[5].u64;
	// 831E7820: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831E7824: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E7828(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E7828 size=188
    let mut pc: u32 = 0x831E7828;
    'dispatch: loop {
        match pc {
            0x831E7828 => {
    //   block [0x831E7828..0x831E78E4)
	// 831E7828: 54AB5828  slwi r11, r5, 0xb
	ctx.r[11].u32 = ctx.r[5].u32.wrapping_shl(11);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831E782C: 7CC32214  add r6, r3, r4
	ctx.r[6].u64 = ctx.r[3].u64 + ctx.r[4].u64;
	// 831E7830: 7D4B1A14  add r10, r11, r3
	ctx.r[10].u64 = ctx.r[11].u64 + ctx.r[3].u64;
	// 831E7834: 54A87022  slwi r8, r5, 0xe
	ctx.r[8].u32 = ctx.r[5].u32.wrapping_shl(14);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831E7838: 7D445378  mr r4, r10
	ctx.r[4].u64 = ctx.r[10].u64;
	// 831E783C: 7D034378  mr r3, r8
	ctx.r[3].u64 = ctx.r[8].u64;
	// 831E7840: 80EA0000  lwz r7, 0(r10)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E7844: 54EB063E  clrlwi r11, r7, 0x18
	ctx.r[11].u64 = ctx.r[7].u32 as u64 & 0x000000FFu64;
	// 831E7848: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E784C: 55695828  slwi r9, r11, 0xb
	ctx.r[9].u32 = ctx.r[11].u32.wrapping_shl(11);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831E7850: 7D695214  add r11, r9, r10
	ctx.r[11].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 831E7854: 7F0B3040  cmplw cr6, r11, r6
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[6].u32, &mut ctx.xer);
	// 831E7858: 40980034  bge cr6, 0x831e788c
	if !ctx.cr[6].lt {
	pc = 0x831E788C; continue 'dispatch;
	}
	// 831E785C: 80EB0000  lwz r7, 0(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E7860: 55251838  slwi r5, r9, 3
	ctx.r[5].u32 = ctx.r[9].u32.wrapping_shl(3);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831E7864: 7D445378  mr r4, r10
	ctx.r[4].u64 = ctx.r[10].u64;
	// 831E7868: 54E9063E  clrlwi r9, r7, 0x18
	ctx.r[9].u64 = ctx.r[7].u32 as u64 & 0x000000FFu64;
	// 831E786C: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 831E7870: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 831E7874: 7D034378  mr r3, r8
	ctx.r[3].u64 = ctx.r[8].u64;
	// 831E7878: 55295828  slwi r9, r9, 0xb
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(11);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831E787C: 7D054214  add r8, r5, r8
	ctx.r[8].u64 = ctx.r[5].u64 + ctx.r[8].u64;
	// 831E7880: 7D6B4A14  add r11, r11, r9
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 831E7884: 7F0B3040  cmplw cr6, r11, r6
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[6].u32, &mut ctx.xer);
	// 831E7888: 4198FFD4  blt cr6, 0x831e785c
	if ctx.cr[6].lt {
	pc = 0x831E785C; continue 'dispatch;
	}
	// 831E788C: 54EB000A  rlwinm r11, r7, 0, 0, 5
	ctx.r[11].u64 = ctx.r[7].u32 as u64 & 0xFFFFFFFFu64;
	// 831E7890: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E7894: 409A000C  bne cr6, 0x831e78a0
	if !ctx.cr[6].eq {
	pc = 0x831E78A0; continue 'dispatch;
	}
	// 831E7898: 7C8A2378  mr r10, r4
	ctx.r[10].u64 = ctx.r[4].u64;
	// 831E789C: 7C681B78  mr r8, r3
	ctx.r[8].u64 = ctx.r[3].u64;
	// 831E78A0: 816A0000  lwz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E78A4: 556936BE  srwi r9, r11, 0x1a
	ctx.r[9].u32 = ctx.r[11].u32.wrapping_shr(26);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831E78A8: 556BAC7E  rlwinm r11, r11, 0x15, 0x11, 0x1f
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000007FFu64;
	// 831E78AC: 2B090001  cmplwi cr6, r9, 1
	ctx.cr[6].compare_u32(ctx.r[9].u32, 1 as u32, &mut ctx.xer);
	// 831E78B0: 396B0020  addi r11, r11, 0x20
	ctx.r[11].s64 = ctx.r[11].s64 + 32;
	// 831E78B4: 40990028  ble cr6, 0x831e78dc
	if !ctx.cr[6].gt {
	pc = 0x831E78DC; continue 'dispatch;
	}
	// 831E78B8: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 831E78BC: 5567E8FE  srwi r7, r11, 3
	ctx.r[7].u32 = ctx.r[11].u32.wrapping_shr(3);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831E78C0: 5566077E  clrlwi r6, r11, 0x1d
	ctx.r[6].u64 = ctx.r[11].u32 as u64 & 0x00000007u64;
	// 831E78C4: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831E78C8: 7CA7502E  lwzx r5, r7, r10
	ctx.r[5].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[7].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 831E78CC: 7CA43030  slw r4, r5, r6
	if (ctx.r[6].u8 & 0x20) != 0 {
		ctx.r[4].u64 = 0;
	} else {
		ctx.r[4].u64 = ((ctx.r[5].u32) << ((ctx.r[6].u8 & 0x1F) as u32)) as u64;
	}
	// 831E78D0: 54877C7E  srwi r7, r4, 0x11
	ctx.r[7].u32 = ctx.r[4].u32.wrapping_shr(17);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831E78D4: 7D675A14  add r11, r7, r11
	ctx.r[11].u64 = ctx.r[7].u64 + ctx.r[11].u64;
	// 831E78D8: 4082FFE4  bne 0x831e78bc
	if !ctx.cr[0].eq {
	pc = 0x831E78BC; continue 'dispatch;
	}
	// 831E78DC: 7C6B4214  add r3, r11, r8
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 831E78E0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E78E8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E78E8 size=120
    let mut pc: u32 = 0x831E78E8;
    'dispatch: loop {
        match pc {
            0x831E78E8 => {
    //   block [0x831E78E8..0x831E7960)
	// 831E78E8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E78EC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E78F0: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831E78F4: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E78F8: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E78FC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E7900: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E7904: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831E7908: 3D20821A  lis r9, -0x7de6
	ctx.r[9].s64 = -2112225280;
	// 831E790C: 390B1180  addi r8, r11, 0x1180
	ctx.r[8].s64 = ctx.r[11].s64 + 4480;
	// 831E7910: 807F00B8  lwz r3, 0xb8(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E7914: 38EA1158  addi r7, r10, 0x1158
	ctx.r[7].s64 = ctx.r[10].s64 + 4440;
	// 831E7918: 38C910F8  addi r6, r9, 0x10f8
	ctx.r[6].s64 = ctx.r[9].s64 + 4344;
	// 831E791C: 911F0000  stw r8, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 831E7920: 3BDF0004  addi r30, r31, 4
	ctx.r[30].s64 = ctx.r[31].s64 + 4;
	// 831E7924: 90FF0004  stw r7, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[7].u32 ) };
	// 831E7928: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E792C: 90DF0010  stw r6, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[6].u32 ) };
	// 831E7930: 419A0010  beq cr6, 0x831e7940
	if ctx.cr[6].eq {
	pc = 0x831E7940; continue 'dispatch;
	}
	// 831E7934: 4BFF28C5  bl 0x831da1f8
	ctx.lr = 0x831E7938;
	sub_831DA1F8(ctx, base);
	// 831E7938: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E793C: 917F00B8  stw r11, 0xb8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(184 as u32), ctx.r[11].u32 ) };
	// 831E7940: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E7944: 4BFFA08D  bl 0x831e19d0
	ctx.lr = 0x831E7948;
	sub_831E19D0(ctx, base);
	// 831E7948: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E794C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E7950: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E7954: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831E7958: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E795C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E7960(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E7960 size=144
    let mut pc: u32 = 0x831E7960;
    'dispatch: loop {
        match pc {
            0x831E7960 => {
    //   block [0x831E7960..0x831E79F0)
	// 831E7960: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E7964: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E7968: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831E796C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E7970: 9421FF40  stwu r1, -0xc0(r1)
	ea = ctx.r[1].u32.wrapping_add(-192 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E7974: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E7978: 7CBE2B78  mr r30, r5
	ctx.r[30].u64 = ctx.r[5].u64;
	// 831E797C: 897F0124  lbz r11, 0x124(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(292 as u32) ) } as u64;
	// 831E7980: 2B0B0002  cmplwi cr6, r11, 2
	ctx.cr[6].compare_u32(ctx.r[11].u32, 2 as u32, &mut ctx.xer);
	// 831E7984: 409A0010  bne cr6, 0x831e7994
	if !ctx.cr[6].eq {
	pc = 0x831E7994; continue 'dispatch;
	}
	// 831E7988: 3C608000  lis r3, -0x8000
	ctx.r[3].s64 = -2147483648;
	// 831E798C: 60634001  ori r3, r3, 0x4001
	ctx.r[3].u64 = ctx.r[3].u64 | 16385;
	// 831E7990: 48000048  b 0x831e79d8
	pc = 0x831E79D8; continue 'dispatch;
	// 831E7994: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 831E7998: 997F0124  stb r11, 0x124(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(292 as u32), ctx.r[11].u8 ) };
	// 831E799C: 81640008  lwz r11, 8(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E79A0: 2B0B00FF  cmplwi cr6, r11, 0xff
	ctx.cr[6].compare_u32(ctx.r[11].u32, 255 as u32, &mut ctx.xer);
	// 831E79A4: 40990024  ble cr6, 0x831e79c8
	if !ctx.cr[6].gt {
	pc = 0x831E79C8; continue 'dispatch;
	}
	// 831E79A8: 2F0BFFFF  cmpwi cr6, r11, -1
	ctx.cr[6].compare_i32(ctx.r[11].s32, -1, &mut ctx.xer);
	// 831E79AC: 419A001C  beq cr6, 0x831e79c8
	if ctx.cr[6].eq {
	pc = 0x831E79C8; continue 'dispatch;
	}
	// 831E79B0: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 831E79B4: 38A00058  li r5, 0x58
	ctx.r[5].s64 = 88;
	// 831E79B8: 4BFC0B59  bl 0x831a8510
	ctx.lr = 0x831E79BC;
	sub_831A8510(ctx, base);
	// 831E79BC: 3960FFFF  li r11, -1
	ctx.r[11].s64 = -1;
	// 831E79C0: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831E79C4: 91610058  stw r11, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[11].u32 ) };
	// 831E79C8: 57CB063E  clrlwi r11, r30, 0x18
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0x000000FFu64;
	// 831E79CC: 387F0010  addi r3, r31, 0x10
	ctx.r[3].s64 = ctx.r[31].s64 + 16;
	// 831E79D0: 61650030  ori r5, r11, 0x30
	ctx.r[5].u64 = ctx.r[11].u64 | 48;
	// 831E79D4: 4BFFF6A5  bl 0x831e7078
	ctx.lr = 0x831E79D8;
	sub_831E7078(ctx, base);
	// 831E79D8: 382100C0  addi r1, r1, 0xc0
	ctx.r[1].s64 = ctx.r[1].s64 + 192;
	// 831E79DC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E79E0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E79E4: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831E79E8: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E79EC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E79F0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E79F0 size=192
    let mut pc: u32 = 0x831E79F0;
    'dispatch: loop {
        match pc {
            0x831E79F0 => {
    //   block [0x831E79F0..0x831E7AB0)
	// 831E79F0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E79F4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E79F8: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E79FC: 89630124  lbz r11, 0x124(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(292 as u32) ) } as u64;
	// 831E7A00: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 831E7A04: 409A001C  bne cr6, 0x831e7a20
	if !ctx.cr[6].eq {
	pc = 0x831E7A20; continue 'dispatch;
	}
	// 831E7A08: 3C608000  lis r3, -0x8000
	ctx.r[3].s64 = -2147483648;
	// 831E7A0C: 60634001  ori r3, r3, 0x4001
	ctx.r[3].u64 = ctx.r[3].u64 | 16385;
	// 831E7A10: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E7A14: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E7A18: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E7A1C: 4E800020  blr
	return;
	// 831E7A20: 39600002  li r11, 2
	ctx.r[11].s64 = 2;
	// 831E7A24: 3900FFFF  li r8, -1
	ctx.r[8].s64 = -1;
	// 831E7A28: 99630124  stb r11, 0x124(r3)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[3].u32.wrapping_add(292 as u32), ctx.r[11].u8 ) };
	// 831E7A2C: 81640008  lwz r11, 8(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E7A30: 2B0B00FF  cmplwi cr6, r11, 0xff
	ctx.cr[6].compare_u32(ctx.r[11].u32, 255 as u32, &mut ctx.xer);
	// 831E7A34: 40990038  ble cr6, 0x831e7a6c
	if !ctx.cr[6].gt {
	pc = 0x831E7A6C; continue 'dispatch;
	}
	// 831E7A38: 2F0BFFFF  cmpwi cr6, r11, -1
	ctx.cr[6].compare_i32(ctx.r[11].s32, -1, &mut ctx.xer);
	// 831E7A3C: 419A0030  beq cr6, 0x831e7a6c
	if ctx.cr[6].eq {
	pc = 0x831E7A6C; continue 'dispatch;
	}
	// 831E7A40: 39410050  addi r10, r1, 0x50
	ctx.r[10].s64 = ctx.r[1].s64 + 80;
	// 831E7A44: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 831E7A48: 39200008  li r9, 8
	ctx.r[9].s64 = 8;
	// 831E7A4C: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 831E7A50: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E7A54: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 831E7A58: 912A0000  stw r9, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831E7A5C: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 831E7A60: 4200FFF0  bdnz 0x831e7a50
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x831E7A50; continue 'dispatch;
	}
	// 831E7A64: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831E7A68: 91010058  stw r8, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[8].u32 ) };
	// 831E7A6C: 81640008  lwz r11, 8(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E7A70: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E7A74: 419A001C  beq cr6, 0x831e7a90
	if ctx.cr[6].eq {
	pc = 0x831E7A90; continue 'dispatch;
	}
	// 831E7A78: 2F0BFFFF  cmpwi cr6, r11, -1
	ctx.cr[6].compare_i32(ctx.r[11].s32, -1, &mut ctx.xer);
	// 831E7A7C: 409A0008  bne cr6, 0x831e7a84
	if !ctx.cr[6].eq {
	pc = 0x831E7A84; continue 'dispatch;
	}
	// 831E7A80: 7D0B4378  mr r11, r8
	ctx.r[11].u64 = ctx.r[8].u64;
	// 831E7A84: 91630110  stw r11, 0x110(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(272 as u32), ctx.r[11].u32 ) };
	// 831E7A88: 81640010  lwz r11, 0x10(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E7A8C: 9163010C  stw r11, 0x10c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(268 as u32), ctx.r[11].u32 ) };
	// 831E7A90: 54AB063E  clrlwi r11, r5, 0x18
	ctx.r[11].u64 = ctx.r[5].u32 as u64 & 0x000000FFu64;
	// 831E7A94: 38630010  addi r3, r3, 0x10
	ctx.r[3].s64 = ctx.r[3].s64 + 16;
	// 831E7A98: 61650010  ori r5, r11, 0x10
	ctx.r[5].u64 = ctx.r[11].u64 | 16;
	// 831E7A9C: 4BFFF895  bl 0x831e7330
	ctx.lr = 0x831E7AA0;
	sub_831E7330(ctx, base);
	// 831E7AA0: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E7AA4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E7AA8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E7AAC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E7AB0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E7AB0 size=172
    let mut pc: u32 = 0x831E7AB0;
    'dispatch: loop {
        match pc {
            0x831E7AB0 => {
    //   block [0x831E7AB0..0x831E7B5C)
	// 831E7AB0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E7AB4: 4BFC06B5  bl 0x831a8168
	ctx.lr = 0x831E7AB8;
	sub_831A8130(ctx, base);
	// 831E7AB8: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E7ABC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E7AC0: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 831E7AC4: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 831E7AC8: 897F0028  lbz r11, 0x28(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(40 as u32) ) } as u64;
	// 831E7ACC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E7AD0: 419A0074  beq cr6, 0x831e7b44
	if ctx.cr[6].eq {
	pc = 0x831E7B44; continue 'dispatch;
	}
	// 831E7AD4: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 831E7AD8: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 831E7ADC: 807F00A8  lwz r3, 0xa8(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(168 as u32) ) } as u64;
	// 831E7AE0: 4BFF2ED9  bl 0x831da9b8
	ctx.lr = 0x831E7AE4;
	sub_831DA9B8(ctx, base);
	// 831E7AE4: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E7AE8: 419A000C  beq cr6, 0x831e7af4
	if ctx.cr[6].eq {
	pc = 0x831E7AF4; continue 'dispatch;
	}
	// 831E7AEC: 3FA08004  lis r29, -0x7ffc
	ctx.r[29].s64 = -2147221504;
	// 831E7AF0: 63BD0002  ori r29, r29, 2
	ctx.r[29].u64 = ctx.r[29].u64 | 2;
	// 831E7AF4: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 831E7AF8: 807F00A8  lwz r3, 0xa8(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(168 as u32) ) } as u64;
	// 831E7AFC: 4BFF2E7D  bl 0x831da978
	ctx.lr = 0x831E7B00;
	sub_831DA978(ctx, base);
	// 831E7B00: 817F00A8  lwz r11, 0xa8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(168 as u32) ) } as u64;
	// 831E7B04: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E7B08: 55490318  rlwinm r9, r10, 0, 0xc, 0xc
	ctx.r[9].u64 = ctx.r[10].u32 as u64 & 0xFFFFFFFFu64;
	// 831E7B0C: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831E7B10: 419A001C  beq cr6, 0x831e7b2c
	if ctx.cr[6].eq {
	pc = 0x831E7B2C; continue 'dispatch;
	}
	// 831E7B14: 556B003E  slwi r11, r11, 0
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(0);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831E7B18: 3FA08004  lis r29, -0x7ffc
	ctx.r[29].s64 = -2147221504;
	// 831E7B1C: 63BD0003  ori r29, r29, 3
	ctx.r[29].u64 = ctx.r[29].u64 | 3;
	// 831E7B20: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E7B24: 55490356  rlwinm r9, r10, 0, 0xd, 0xb
	ctx.r[9].u64 = ctx.r[10].u32 as u64 & 0xFFFFFFFFu64;
	// 831E7B28: 912B0004  stw r9, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 831E7B2C: 397E0001  addi r11, r30, 1
	ctx.r[11].s64 = ctx.r[30].s64 + 1;
	// 831E7B30: 895F0028  lbz r10, 0x28(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(40 as u32) ) } as u64;
	// 831E7B34: 556B063E  clrlwi r11, r11, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 831E7B38: 7D7E5B78  mr r30, r11
	ctx.r[30].u64 = ctx.r[11].u64;
	// 831E7B3C: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E7B40: 4198FF98  blt cr6, 0x831e7ad8
	if ctx.cr[6].lt {
	pc = 0x831E7AD8; continue 'dispatch;
	}
	// 831E7B44: 7FA5EB78  mr r5, r29
	ctx.r[5].u64 = ctx.r[29].u64;
	// 831E7B48: 7F84E378  mr r4, r28
	ctx.r[4].u64 = ctx.r[28].u64;
	// 831E7B4C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E7B50: 4BFFA491  bl 0x831e1fe0
	ctx.lr = 0x831E7B54;
	sub_831E1FE0(ctx, base);
	// 831E7B54: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E7B58: 4BFC0660  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E7B60(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E7B60 size=8
    let mut pc: u32 = 0x831E7B60;
    'dispatch: loop {
        match pc {
            0x831E7B60 => {
    //   block [0x831E7B60..0x831E7B68)
	// 831E7B60: 3863FFF0  addi r3, r3, -0x10
	ctx.r[3].s64 = ctx.r[3].s64 + -16;
	// 831E7B64: 4BFFFE8C  b 0x831e79f0
	sub_831E79F0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E7B68(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E7B68 size=8
    let mut pc: u32 = 0x831E7B68;
    'dispatch: loop {
        match pc {
            0x831E7B68 => {
    //   block [0x831E7B68..0x831E7B70)
	// 831E7B68: 3863FFF0  addi r3, r3, -0x10
	ctx.r[3].s64 = ctx.r[3].s64 + -16;
	// 831E7B6C: 4BFFFDF4  b 0x831e7960
	sub_831E7960(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E7B70(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E7B70 size=8
    let mut pc: u32 = 0x831E7B70;
    'dispatch: loop {
        match pc {
            0x831E7B70 => {
    //   block [0x831E7B70..0x831E7B78)
	// 831E7B70: 3863FFFC  addi r3, r3, -4
	ctx.r[3].s64 = ctx.r[3].s64 + -4;
	// 831E7B74: 4800016C  b 0x831e7ce0
	sub_831E7CE0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E7B78(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E7B78 size=8
    let mut pc: u32 = 0x831E7B78;
    'dispatch: loop {
        match pc {
            0x831E7B78 => {
    //   block [0x831E7B78..0x831E7B80)
	// 831E7B78: 3863FFF0  addi r3, r3, -0x10
	ctx.r[3].s64 = ctx.r[3].s64 + -16;
	// 831E7B7C: 48000164  b 0x831e7ce0
	sub_831E7CE0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E7B80(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E7B80 size=16
    let mut pc: u32 = 0x831E7B80;
    'dispatch: loop {
        match pc {
            0x831E7B80 => {
    //   block [0x831E7B80..0x831E7B90)
	// 831E7B80: 896300AC  lbz r11, 0xac(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(172 as u32) ) } as u64;
	// 831E7B84: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E7B88: 99640000  stb r11, 0(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[11].u8 ) };
	// 831E7B8C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E7B90(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831E7B90 size=16
    let mut pc: u32 = 0x831E7B90;
    'dispatch: loop {
        match pc {
            0x831E7B90 => {
    //   block [0x831E7B90..0x831E7BA0)
	// 831E7B90: C0030070  lfs f0, 0x70(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(112 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E7B94: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E7B98: D0040000  stfs f0, 0(r4)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831E7B9C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E7BA0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E7BA0 size=84
    let mut pc: u32 = 0x831E7BA0;
    'dispatch: loop {
        match pc {
            0x831E7BA0 => {
    //   block [0x831E7BA0..0x831E7BF4)
	// 831E7BA0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E7BA4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E7BA8: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E7BAC: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E7BB0: 81630010  lwz r11, 0x10(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E7BB4: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 831E7BB8: 38630010  addi r3, r3, 0x10
	ctx.r[3].s64 = ctx.r[3].s64 + 16;
	// 831E7BBC: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831E7BC0: 814B0058  lwz r10, 0x58(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(88 as u32) ) } as u64;
	// 831E7BC4: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E7BC8: 4E800421  bctrl
	ctx.lr = 0x831E7BCC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E7BCC: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E7BD0: 41980010  blt cr6, 0x831e7be0
	if ctx.cr[6].lt {
	pc = 0x831E7BE0; continue 'dispatch;
	}
	// 831E7BD4: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831E7BD8: 814B0010  lwz r10, 0x10(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E7BDC: 915F0000  stw r10, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E7BE0: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E7BE4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E7BE8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E7BEC: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E7BF0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E7BF8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E7BF8 size=120
    let mut pc: u32 = 0x831E7BF8;
    'dispatch: loop {
        match pc {
            0x831E7BF8 => {
    //   block [0x831E7BF8..0x831E7C70)
	// 831E7BF8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E7BFC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E7C00: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E7C04: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E7C08: 896300C6  lbz r11, 0xc6(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(198 as u32) ) } as u64;
	// 831E7C0C: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 831E7C10: 7F0BF840  cmplw cr6, r11, r31
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[31].u32, &mut ctx.xer);
	// 831E7C14: 419A0020  beq cr6, 0x831e7c34
	if ctx.cr[6].eq {
	pc = 0x831E7C34; continue 'dispatch;
	}
	// 831E7C18: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 831E7C1C: 2B1F00FF  cmplwi cr6, r31, 0xff
	ctx.cr[6].compare_u32(ctx.r[31].u32, 255 as u32, &mut ctx.xer);
	// 831E7C20: 91630120  stw r11, 0x120(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(288 as u32), ctx.r[11].u32 ) };
	// 831E7C24: 396000FF  li r11, 0xff
	ctx.r[11].s64 = 255;
	// 831E7C28: 41990008  bgt cr6, 0x831e7c30
	if ctx.cr[6].gt {
	pc = 0x831E7C30; continue 'dispatch;
	}
	// 831E7C2C: 57EB063E  clrlwi r11, r31, 0x18
	ctx.r[11].u64 = ctx.r[31].u32 as u64 & 0x000000FFu64;
	// 831E7C30: 996300C6  stb r11, 0xc6(r3)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[3].u32.wrapping_add(198 as u32), ctx.r[11].u8 ) };
	// 831E7C34: 81630010  lwz r11, 0x10(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E7C38: 38630010  addi r3, r3, 0x10
	ctx.r[3].s64 = ctx.r[3].s64 + 16;
	// 831E7C3C: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831E7C40: 814B0058  lwz r10, 0x58(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(88 as u32) ) } as u64;
	// 831E7C44: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E7C48: 4E800421  bctrl
	ctx.lr = 0x831E7C4C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E7C4C: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E7C50: 4198000C  blt cr6, 0x831e7c5c
	if ctx.cr[6].lt {
	pc = 0x831E7C5C; continue 'dispatch;
	}
	// 831E7C54: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831E7C58: 93EB0010  stw r31, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[31].u32 ) };
	// 831E7C5C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E7C60: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E7C64: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E7C68: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E7C6C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E7C70(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E7C70 size=100
    let mut pc: u32 = 0x831E7C70;
    'dispatch: loop {
        match pc {
            0x831E7C70 => {
    //   block [0x831E7C70..0x831E7CD4)
	// 831E7C70: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E7C74: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E7C78: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831E7C7C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E7C80: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E7C84: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 831E7C88: 7CBE2B78  mr r30, r5
	ctx.r[30].u64 = ctx.r[5].u64;
	// 831E7C8C: 3BE30010  addi r31, r3, 0x10
	ctx.r[31].s64 = ctx.r[3].s64 + 16;
	// 831E7C90: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E7C94: 419A0014  beq cr6, 0x831e7ca8
	if ctx.cr[6].eq {
	pc = 0x831E7CA8; continue 'dispatch;
	}
	// 831E7C98: 389F0024  addi r4, r31, 0x24
	ctx.r[4].s64 = ctx.r[31].s64 + 36;
	// 831E7C9C: 38A00038  li r5, 0x38
	ctx.r[5].s64 = 56;
	// 831E7CA0: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 831E7CA4: 4BFC086D  bl 0x831a8510
	ctx.lr = 0x831E7CA8;
	sub_831A8510(ctx, base);
	// 831E7CA8: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 831E7CAC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E7CB0: 419A000C  beq cr6, 0x831e7cbc
	if ctx.cr[6].eq {
	pc = 0x831E7CBC; continue 'dispatch;
	}
	// 831E7CB4: 897F009D  lbz r11, 0x9d(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(157 as u32) ) } as u64;
	// 831E7CB8: 997E0000  stb r11, 0(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u8 ) };
	// 831E7CBC: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E7CC0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E7CC4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E7CC8: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831E7CCC: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E7CD0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E7CD8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E7CD8 size=8
    let mut pc: u32 = 0x831E7CD8;
    'dispatch: loop {
        match pc {
            0x831E7CD8 => {
    //   block [0x831E7CD8..0x831E7CE0)
	// 831E7CD8: 38630004  addi r3, r3, 4
	ctx.r[3].s64 = ctx.r[3].s64 + 4;
	// 831E7CDC: 4BFF989C  b 0x831e1578
	sub_831E1578(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E7CE0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E7CE0 size=48
    let mut pc: u32 = 0x831E7CE0;
    'dispatch: loop {
        match pc {
            0x831E7CE0 => {
    //   block [0x831E7CE0..0x831E7D10)
	// 831E7CE0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E7CE4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E7CE8: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E7CEC: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E7CF0: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E7CF4: 4BFFFBF5  bl 0x831e78e8
	ctx.lr = 0x831E7CF8;
	sub_831E78E8(ctx, base);
	// 831E7CF8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E7CFC: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831E7D00: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E7D04: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E7D08: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E7D0C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E7D10(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E7D10 size=68
    let mut pc: u32 = 0x831E7D10;
    'dispatch: loop {
        match pc {
            0x831E7D10 => {
    //   block [0x831E7D10..0x831E7D54)
	// 831E7D10: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E7D14: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E7D18: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E7D1C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E7D20: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E7D24: 387F0010  addi r3, r31, 0x10
	ctx.r[3].s64 = ctx.r[31].s64 + 16;
	// 831E7D28: 4BFFF2B1  bl 0x831e6fd8
	ctx.lr = 0x831E7D2C;
	sub_831E6FD8(ctx, base);
	// 831E7D2C: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E7D30: 41980010  blt cr6, 0x831e7d40
	if ctx.cr[6].lt {
	pc = 0x831E7D40; continue 'dispatch;
	}
	// 831E7D34: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 831E7D38: B17F006C  sth r11, 0x6c(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(108 as u32), ctx.r[11].u16 ) };
	// 831E7D3C: B17F006E  sth r11, 0x6e(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(110 as u32), ctx.r[11].u16 ) };
	// 831E7D40: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831E7D44: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E7D48: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E7D4C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E7D50: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E7D58(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831E7D58 size=248
    let mut pc: u32 = 0x831E7D58;
    'dispatch: loop {
        match pc {
            0x831E7D58 => {
    //   block [0x831E7D58..0x831E7E50)
	// 831E7D58: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E7D5C: 4BFC040D  bl 0x831a8168
	ctx.lr = 0x831E7D60;
	sub_831A8130(ctx, base);
	// 831E7D60: DBE1FFD0  stfd f31, -0x30(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.f[31].u64 ) };
	// 831E7D64: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E7D68: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831E7D6C: FFE00890  fmr f31, f1
	ctx.f[31].f64 = ctx.f[1].f64;
	// 831E7D70: 4805B3ED  bl 0x8324315c
	ctx.lr = 0x831E7D74;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E7D74: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E7D78: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E7D7C: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831E7D80: 7DBD6B78  mr r29, r13
	ctx.r[29].u64 = ctx.r[13].u64;
	// 831E7D84: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E7D88: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E7D8C: 419A0010  beq cr6, 0x831e7d9c
	if ctx.cr[6].eq {
	pc = 0x831E7D9C; continue 'dispatch;
	}
	// 831E7D90: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E7D94: 7F1D5040  cmplw cr6, r29, r10
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E7D98: 419A0018  beq cr6, 0x831e7db0
	if ctx.cr[6].eq {
	pc = 0x831E7DB0; continue 'dispatch;
	}
	// 831E7D9C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E7DA0: 4805ACDD  bl 0x83242a7c
	ctx.lr = 0x831E7DA4;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E7DA4: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E7DA8: 93BF0008  stw r29, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 831E7DAC: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 831E7DB0: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E7DB4: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E7DB8: D3FE0070  stfs f31, 0x70(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(112 as u32), tmp.u32 ) };
	// 831E7DBC: 897E0038  lbz r11, 0x38(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E7DC0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E7DC4: 419A0030  beq cr6, 0x831e7df4
	if ctx.cr[6].eq {
	pc = 0x831E7DF4; continue 'dispatch;
	}
	// 831E7DC8: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E7DCC: 813E00C8  lwz r9, 0xc8(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(200 as u32) ) } as u64;
	// 831E7DD0: 1D4B0058  mulli r10, r11, 0x58
	ctx.r[10].s64 = ctx.r[11].s64 * 88;
	// 831E7DD4: C01E0070  lfs f0, 0x70(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(112 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E7DD8: 7D4A4A14  add r10, r10, r9
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[9].u64;
	// 831E7DDC: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E7DE0: 556B063E  clrlwi r11, r11, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 831E7DE4: D00A0028  stfs f0, 0x28(r10)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(40 as u32), tmp.u32 ) };
	// 831E7DE8: 893E0038  lbz r9, 0x38(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E7DEC: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E7DF0: 4198FFDC  blt cr6, 0x831e7dcc
	if ctx.cr[6].lt {
	pc = 0x831E7DCC; continue 'dispatch;
	}
	// 831E7DF4: 813F0004  lwz r9, 4(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E7DF8: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E7DFC: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831E7E00: 419A0040  beq cr6, 0x831e7e40
	if ctx.cr[6].eq {
	pc = 0x831E7E40; continue 'dispatch;
	}
	// 831E7E04: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E7E08: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831E7E0C: 409A0034  bne cr6, 0x831e7e40
	if !ctx.cr[6].eq {
	pc = 0x831E7E40; continue 'dispatch;
	}
	// 831E7E10: 3569FFFF  addic. r11, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E7E14: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E7E18: 40820028  bne 0x831e7e40
	if !ctx.cr[0].eq {
	pc = 0x831E7E40; continue 'dispatch;
	}
	// 831E7E1C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E7E20: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E7E24: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E7E28: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E7E2C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E7E30: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E7E34: 4805AC39  bl 0x83242a6c
	ctx.lr = 0x831E7E38;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E7E38: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E7E3C: 4805B331  bl 0x8324316c
	ctx.lr = 0x831E7E40;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E7E40: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E7E44: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E7E48: CBE1FFD0  lfd f31, -0x30(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 831E7E4C: 4BFC036C  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E7E50(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831E7E50 size=344
    let mut pc: u32 = 0x831E7E50;
    'dispatch: loop {
        match pc {
            0x831E7E50 => {
    //   block [0x831E7E50..0x831E7FA8)
	// 831E7E50: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E7E54: 4BFC0315  bl 0x831a8168
	ctx.lr = 0x831E7E58;
	sub_831A8130(ctx, base);
	// 831E7E58: DBE1FFD0  stfd f31, -0x30(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.f[31].u64 ) };
	// 831E7E5C: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E7E60: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E7E64: FFE00890  fmr f31, f1
	ctx.f[31].f64 = ctx.f[1].f64;
	// 831E7E68: 4805B2F5  bl 0x8324315c
	ctx.lr = 0x831E7E6C;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E7E6C: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E7E70: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E7E74: 3BCBD530  addi r30, r11, -0x2ad0
	ctx.r[30].s64 = ctx.r[11].s64 + -10960;
	// 831E7E78: 7DBD6B78  mr r29, r13
	ctx.r[29].u64 = ctx.r[13].u64;
	// 831E7E7C: 817E0004  lwz r11, 4(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E7E80: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E7E84: 419A0010  beq cr6, 0x831e7e94
	if ctx.cr[6].eq {
	pc = 0x831E7E94; continue 'dispatch;
	}
	// 831E7E88: 815E0008  lwz r10, 8(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E7E8C: 7F1D5040  cmplw cr6, r29, r10
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E7E90: 419A0018  beq cr6, 0x831e7ea8
	if ctx.cr[6].eq {
	pc = 0x831E7EA8; continue 'dispatch;
	}
	// 831E7E94: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E7E98: 4805ABE5  bl 0x83242a7c
	ctx.lr = 0x831E7E9C;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E7E9C: 817E0004  lwz r11, 4(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E7EA0: 93BE0008  stw r29, 8(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 831E7EA4: 9B9E000C  stb r28, 0xc(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 831E7EA8: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E7EAC: FC40F890  fmr f2, f31
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[2].f64 = ctx.f[31].f64;
	// 831E7EB0: 3D408205  lis r10, -0x7dfb
	ctx.r[10].s64 = -2113601536;
	// 831E7EB4: 917E0004  stw r11, 4(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E7EB8: C82AAA10  lfd f1, -0x55f0(r10)
	ctx.f[1].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[10].u32.wrapping_add(-22000 as u32) ) };
	// 831E7EBC: 4BFC35ED  bl 0x831ab4a8
	ctx.lr = 0x831E7EC0;
	sub_831AB4A8(ctx, base);
	// 831E7EC0: 893F0038  lbz r9, 0x38(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E7EC4: FC000818  frsp f0, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].f64 = (ctx.f[1].f64 as f32) as f64;
	// 831E7EC8: D01F0074  stfs f0, 0x74(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(116 as u32), tmp.u32 ) };
	// 831E7ECC: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831E7ED0: 419A007C  beq cr6, 0x831e7f4c
	if ctx.cr[6].eq {
	pc = 0x831E7F4C; continue 'dispatch;
	}
	// 831E7ED4: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E7ED8: 38E00010  li r7, 0x10
	ctx.r[7].s64 = 16;
	// 831E7EDC: 39000001  li r8, 1
	ctx.r[8].s64 = 1;
	// 831E7EE0: 554B1838  slwi r11, r10, 3
	ctx.r[11].u32 = ctx.r[10].u32.wrapping_shl(3);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831E7EE4: 813F00C8  lwz r9, 0xc8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(200 as u32) ) } as u64;
	// 831E7EE8: 38CA0008  addi r6, r10, 8
	ctx.r[6].s64 = ctx.r[10].s64 + 8;
	// 831E7EEC: C01F0074  lfs f0, 0x74(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(116 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E7EF0: 7CABFA14  add r5, r11, r31
	ctx.r[5].u64 = ctx.r[11].u64 + ctx.r[31].u64;
	// 831E7EF4: 1D6A0058  mulli r11, r10, 0x58
	ctx.r[11].s64 = ctx.r[10].s64 * 88;
	// 831E7EF8: 8065003C  lwz r3, 0x3c(r5)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(60 as u32) ) } as u64;
	// 831E7EFC: 7D6B4A14  add r11, r11, r9
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 831E7F00: F8610050  std r3, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[3].u64 ) };
	// 831E7F04: C9A10050  lfd f13, 0x50(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 831E7F08: FD806E9C  fcfid f12, f13
	ctx.f[12].f64 = (ctx.f[13].s64 as f64);
	// 831E7F0C: 54C91838  slwi r9, r6, 3
	ctx.r[9].u32 = ctx.r[6].u32.wrapping_shl(3);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831E7F10: FD606018  frsp f11, f12
	ctx.f[11].f64 = (ctx.f[12].f64 as f32) as f64;
	// 831E7F14: 7CA9F8AE  lbzx r5, r9, r31
	ctx.r[5].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[31].u32)) } as u64;
	// 831E7F18: 808B0050  lwz r4, 0x50(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(80 as u32) ) } as u64;
	// 831E7F1C: 38CA0001  addi r6, r10, 1
	ctx.r[6].s64 = ctx.r[10].s64 + 1;
	// 831E7F20: 990B000C  stb r8, 0xc(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[8].u8 ) };
	// 831E7F24: 60830001  ori r3, r4, 1
	ctx.r[3].u64 = ctx.r[4].u64 | 1;
	// 831E7F28: 54CA063E  clrlwi r10, r6, 0x18
	ctx.r[10].u64 = ctx.r[6].u32 as u64 & 0x000000FFu64;
	// 831E7F2C: 98AB000D  stb r5, 0xd(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(13 as u32), ctx.r[5].u8 ) };
	// 831E7F30: 906B0050  stw r3, 0x50(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(80 as u32), ctx.r[3].u32 ) };
	// 831E7F34: ED4B0032  fmuls f10, f11, f0
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E7F38: FD20565E  fctidz f9, f10
	ctx.f[9].s64 = if ctx.f[10].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[10].f64.trunc() as i64 };
	// 831E7F3C: 7D2B3FAE  stfiwx f9, r11, r7
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[7].u32), tmp.u32) };
	// 831E7F40: 897F0038  lbz r11, 0x38(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E7F44: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831E7F48: 4198FF98  blt cr6, 0x831e7ee0
	if ctx.cr[6].lt {
	pc = 0x831E7EE0; continue 'dispatch;
	}
	// 831E7F4C: 813E0004  lwz r9, 4(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E7F50: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E7F54: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831E7F58: 419A0040  beq cr6, 0x831e7f98
	if ctx.cr[6].eq {
	pc = 0x831E7F98; continue 'dispatch;
	}
	// 831E7F5C: 817E0008  lwz r11, 8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E7F60: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831E7F64: 409A0034  bne cr6, 0x831e7f98
	if !ctx.cr[6].eq {
	pc = 0x831E7F98; continue 'dispatch;
	}
	// 831E7F68: 3569FFFF  addic. r11, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E7F6C: 917E0004  stw r11, 4(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E7F70: 40820028  bne 0x831e7f98
	if !ctx.cr[0].eq {
	pc = 0x831E7F98; continue 'dispatch;
	}
	// 831E7F74: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E7F78: 8BFE000C  lbz r31, 0xc(r30)
	ctx.r[31].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E7F7C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E7F80: 915E0008  stw r10, 8(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E7F84: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E7F88: 997E000C  stb r11, 0xc(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E7F8C: 4805AAE1  bl 0x83242a6c
	ctx.lr = 0x831E7F90;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E7F90: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E7F94: 4805B1D9  bl 0x8324316c
	ctx.lr = 0x831E7F98;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E7F98: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E7F9C: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831E7FA0: CBE1FFD0  lfd f31, -0x30(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 831E7FA4: 4BFC0214  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E7FA8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831E7FA8 size=324
    let mut pc: u32 = 0x831E7FA8;
    'dispatch: loop {
        match pc {
            0x831E7FA8 => {
    //   block [0x831E7FA8..0x831E80EC)
	// 831E7FA8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E7FAC: 4BFC01BD  bl 0x831a8168
	ctx.lr = 0x831E7FB0;
	sub_831A8130(ctx, base);
	// 831E7FB0: DBE1FFD0  stfd f31, -0x30(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.f[31].u64 ) };
	// 831E7FB4: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E7FB8: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E7FBC: FFE00890  fmr f31, f1
	ctx.f[31].f64 = ctx.f[1].f64;
	// 831E7FC0: 4805B19D  bl 0x8324315c
	ctx.lr = 0x831E7FC4;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E7FC4: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E7FC8: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E7FCC: 3BCBD530  addi r30, r11, -0x2ad0
	ctx.r[30].s64 = ctx.r[11].s64 + -10960;
	// 831E7FD0: 7DBD6B78  mr r29, r13
	ctx.r[29].u64 = ctx.r[13].u64;
	// 831E7FD4: 817E0004  lwz r11, 4(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E7FD8: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E7FDC: 419A0010  beq cr6, 0x831e7fec
	if ctx.cr[6].eq {
	pc = 0x831E7FEC; continue 'dispatch;
	}
	// 831E7FE0: 815E0008  lwz r10, 8(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E7FE4: 7F1D5040  cmplw cr6, r29, r10
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E7FE8: 419A0018  beq cr6, 0x831e8000
	if ctx.cr[6].eq {
	pc = 0x831E8000; continue 'dispatch;
	}
	// 831E7FEC: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E7FF0: 4805AA8D  bl 0x83242a7c
	ctx.lr = 0x831E7FF4;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E7FF4: 817E0004  lwz r11, 4(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E7FF8: 93BE0008  stw r29, 8(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 831E7FFC: 9B9E000C  stb r28, 0xc(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 831E8000: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E8004: 917E0004  stw r11, 4(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E8008: D3FF0074  stfs f31, 0x74(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(116 as u32), tmp.u32 ) };
	// 831E800C: 897F0038  lbz r11, 0x38(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E8010: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E8014: 419A007C  beq cr6, 0x831e8090
	if ctx.cr[6].eq {
	pc = 0x831E8090; continue 'dispatch;
	}
	// 831E8018: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E801C: 38E00010  li r7, 0x10
	ctx.r[7].s64 = 16;
	// 831E8020: 39000001  li r8, 1
	ctx.r[8].s64 = 1;
	// 831E8024: 554B1838  slwi r11, r10, 3
	ctx.r[11].u32 = ctx.r[10].u32.wrapping_shl(3);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831E8028: 813F00C8  lwz r9, 0xc8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(200 as u32) ) } as u64;
	// 831E802C: 38CA0008  addi r6, r10, 8
	ctx.r[6].s64 = ctx.r[10].s64 + 8;
	// 831E8030: C01F0074  lfs f0, 0x74(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(116 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E8034: 7CABFA14  add r5, r11, r31
	ctx.r[5].u64 = ctx.r[11].u64 + ctx.r[31].u64;
	// 831E8038: 1D6A0058  mulli r11, r10, 0x58
	ctx.r[11].s64 = ctx.r[10].s64 * 88;
	// 831E803C: 8065003C  lwz r3, 0x3c(r5)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(60 as u32) ) } as u64;
	// 831E8040: 7D6B4A14  add r11, r11, r9
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 831E8044: F8610050  std r3, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[3].u64 ) };
	// 831E8048: C9A10050  lfd f13, 0x50(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 831E804C: FD806E9C  fcfid f12, f13
	ctx.f[12].f64 = (ctx.f[13].s64 as f64);
	// 831E8050: 54C91838  slwi r9, r6, 3
	ctx.r[9].u32 = ctx.r[6].u32.wrapping_shl(3);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831E8054: FD606018  frsp f11, f12
	ctx.f[11].f64 = (ctx.f[12].f64 as f32) as f64;
	// 831E8058: 7CA9F8AE  lbzx r5, r9, r31
	ctx.r[5].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[31].u32)) } as u64;
	// 831E805C: 808B0050  lwz r4, 0x50(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(80 as u32) ) } as u64;
	// 831E8060: 38CA0001  addi r6, r10, 1
	ctx.r[6].s64 = ctx.r[10].s64 + 1;
	// 831E8064: 990B000C  stb r8, 0xc(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[8].u8 ) };
	// 831E8068: 60830001  ori r3, r4, 1
	ctx.r[3].u64 = ctx.r[4].u64 | 1;
	// 831E806C: 54CA063E  clrlwi r10, r6, 0x18
	ctx.r[10].u64 = ctx.r[6].u32 as u64 & 0x000000FFu64;
	// 831E8070: 98AB000D  stb r5, 0xd(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(13 as u32), ctx.r[5].u8 ) };
	// 831E8074: 906B0050  stw r3, 0x50(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(80 as u32), ctx.r[3].u32 ) };
	// 831E8078: ED4B0032  fmuls f10, f11, f0
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E807C: FD20565E  fctidz f9, f10
	ctx.f[9].s64 = if ctx.f[10].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[10].f64.trunc() as i64 };
	// 831E8080: 7D2B3FAE  stfiwx f9, r11, r7
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[7].u32), tmp.u32) };
	// 831E8084: 897F0038  lbz r11, 0x38(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E8088: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831E808C: 4198FF98  blt cr6, 0x831e8024
	if ctx.cr[6].lt {
	pc = 0x831E8024; continue 'dispatch;
	}
	// 831E8090: 813E0004  lwz r9, 4(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E8094: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E8098: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831E809C: 419A0040  beq cr6, 0x831e80dc
	if ctx.cr[6].eq {
	pc = 0x831E80DC; continue 'dispatch;
	}
	// 831E80A0: 817E0008  lwz r11, 8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E80A4: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831E80A8: 409A0034  bne cr6, 0x831e80dc
	if !ctx.cr[6].eq {
	pc = 0x831E80DC; continue 'dispatch;
	}
	// 831E80AC: 3569FFFF  addic. r11, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E80B0: 917E0004  stw r11, 4(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E80B4: 40820028  bne 0x831e80dc
	if !ctx.cr[0].eq {
	pc = 0x831E80DC; continue 'dispatch;
	}
	// 831E80B8: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E80BC: 8BFE000C  lbz r31, 0xc(r30)
	ctx.r[31].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E80C0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E80C4: 915E0008  stw r10, 8(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E80C8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E80CC: 997E000C  stb r11, 0xc(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E80D0: 4805A99D  bl 0x83242a6c
	ctx.lr = 0x831E80D4;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E80D4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E80D8: 4805B095  bl 0x8324316c
	ctx.lr = 0x831E80DC;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E80DC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E80E0: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831E80E4: CBE1FFD0  lfd f31, -0x30(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 831E80E8: 4BFC00D0  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E80F0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831E80F0 size=480
    let mut pc: u32 = 0x831E80F0;
    'dispatch: loop {
        match pc {
            0x831E80F0 => {
    //   block [0x831E80F0..0x831E82D0)
	// 831E80F0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E80F4: 4BFC0065  bl 0x831a8158
	ctx.lr = 0x831E80F8;
	sub_831A8130(ctx, base);
	// 831E80F8: 3BE1FF60  addi r31, r1, -0xa0
	ctx.r[31].s64 = ctx.r[1].s64 + -160;
	// 831E80FC: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E8100: 7C691B78  mr r9, r3
	ctx.r[9].u64 = ctx.r[3].u64;
	// 831E8104: 88690038  lbz r3, 0x38(r9)
	ctx.r[3].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[9].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E8108: 546B083E  rotlwi r11, r3, 1
	ctx.r[11].u64 = ((ctx.r[3].u32).rotate_left(1)) as u64;
	// 831E810C: 7D635A14  add r11, r3, r11
	ctx.r[11].u64 = ctx.r[3].u64 + ctx.r[11].u64;
	// 831E8110: 556A103A  slwi r10, r11, 2
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831E8114: 7D0A00D0  neg r8, r10
	ctx.r[8].s64 = -ctx.r[10].s64;
	// 831E8118: 550C0036  rlwinm r12, r8, 0, 0, 0x1b
	ctx.r[12].u64 = ctx.r[8].u32 as u64 & 0xFFFFFFFFu64;
	// 831E811C: 4BFC3959  bl 0x831aba74
	ctx.lr = 0x831E8120;
	sub_831ABA74(ctx, base);
	// 831E8120: 80E10000  lwz r7, 0(r1)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E8124: 3B000001  li r24, 1
	ctx.r[24].s64 = 1;
	// 831E8128: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E812C: 7CE1616E  stwux r7, r1, r12
	ea = ctx.r[1].u32.wrapping_add(ctx.r[12].u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[7].u32) };
	ctx.r[1].u32 = ea;
	// 831E8130: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831E8134: 419A016C  beq cr6, 0x831e82a0
	if ctx.cr[6].eq {
	pc = 0x831E82A0; continue 'dispatch;
	}
	// 831E8138: 3D600000  lis r11, 0
	ctx.r[11].s64 = 0;
	// 831E813C: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 831E8140: 39490040  addi r10, r9, 0x40
	ctx.r[10].s64 = ctx.r[9].s64 + 64;
	// 831E8144: 39040004  addi r8, r4, 4
	ctx.r[8].s64 = ctx.r[4].s64 + 4;
	// 831E8148: 3B890114  addi r28, r9, 0x114
	ctx.r[28].s64 = ctx.r[9].s64 + 276;
	// 831E814C: 7C651B78  mr r5, r3
	ctx.r[5].u64 = ctx.r[3].u64;
	// 831E8150: 3B200010  li r25, 0x10
	ctx.r[25].s64 = 16;
	// 831E8154: 617EBB80  ori r30, r11, 0xbb80
	ctx.r[30].u64 = ctx.r[11].u64 | 48000;
	// 831E8158: 80CAFFFC  lwz r6, -4(r10)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-4 as u32) ) } as u64;
	// 831E815C: 3B400F80  li r26, 0xf80
	ctx.r[26].s64 = 3968;
	// 831E8160: 816900CC  lwz r11, 0xcc(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(204 as u32) ) } as u64;
	// 831E8164: 7D6B31D6  mullw r11, r11, r6
	ctx.r[11].s64 = (ctx.r[11].s32 as i64) * (ctx.r[6].s32 as i64);
	// 831E8168: 5566402E  slwi r6, r11, 8
	ctx.r[6].u32 = ctx.r[11].u32.wrapping_shl(8);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831E816C: 7D66F396  divwu r11, r6, r30
	ctx.r[11].u32 = ctx.r[6].u32 / ctx.r[30].u32;
	// 831E8170: 38CB0010  addi r6, r11, 0x10
	ctx.r[6].s64 = ctx.r[11].s64 + 16;
	// 831E8174: B0DC0000  sth r6, 0(r28)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[28].u32.wrapping_add(0 as u32), ctx.r[6].u16 ) };
	// 831E8178: 88CA0000  lbz r6, 0(r10)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E817C: 2B060001  cmplwi cr6, r6, 1
	ctx.cr[6].compare_u32(ctx.r[6].u32, 1 as u32, &mut ctx.xer);
	// 831E8180: 419A0008  beq cr6, 0x831e8188
	if ctx.cr[6].eq {
	pc = 0x831E8188; continue 'dispatch;
	}
	// 831E8184: 3B400780  li r26, 0x780
	ctx.r[26].s64 = 1920;
	// 831E8188: 8BAA0001  lbz r29, 1(r10)
	ctx.r[29].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(1 as u32) ) } as u64;
	// 831E818C: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 831E8190: 409A000C  bne cr6, 0x831e819c
	if !ctx.cr[6].eq {
	pc = 0x831E819C; continue 'dispatch;
	}
	// 831E8194: 39600008  li r11, 8
	ctx.r[11].s64 = 8;
	// 831E8198: 48000068  b 0x831e8200
	pc = 0x831E8200; continue 'dispatch;
	// 831E819C: 396B007F  addi r11, r11, 0x7f
	ctx.r[11].s64 = ctx.r[11].s64 + 127;
	// 831E81A0: 556BC9FE  srwi r11, r11, 7
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shr(7);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831E81A4: 38CBFFFF  addi r6, r11, -1
	ctx.r[6].s64 = ctx.r[11].s64 + -1;
	// 831E81A8: 557B3830  slwi r27, r11, 7
	ctx.r[27].u32 = ctx.r[11].u32.wrapping_shl(7);
	ctx.r[27].u64 = ctx.r[27].u32 as u64;
	// 831E81AC: 7CC65838  and r6, r6, r11
	ctx.r[6].u64 = ctx.r[6].u64 & ctx.r[11].u64;
	// 831E81B0: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 831E81B4: 419A0010  beq cr6, 0x831e81c4
	if ctx.cr[6].eq {
	pc = 0x831E81C4; continue 'dispatch;
	}
	// 831E81B8: 7D6B0034  cntlzw r11, r11
	ctx.r[11].u64 = if ctx.r[11].u32 == 0 { 32 } else { ctx.r[11].u32.leading_zeros() as u64 };
	// 831E81BC: 20CB0020  subfic r6, r11, 0x20
	ctx.xer.ca = ctx.r[11].u32 <= 32 as u32;
	ctx.r[6].s64 = (32 as i64) - ctx.r[11].s64;
	// 831E81C0: 7F0B3030  slw r11, r24, r6
	if (ctx.r[6].u8 & 0x20) != 0 {
		ctx.r[11].u64 = 0;
	} else {
		ctx.r[11].u64 = ((ctx.r[24].u32) << ((ctx.r[6].u8 & 0x1F) as u32)) as u64;
	}
	// 831E81C4: 2B0B0002  cmplwi cr6, r11, 2
	ctx.cr[6].compare_u32(ctx.r[11].u32, 2 as u32, &mut ctx.xer);
	// 831E81C8: 4098000C  bge cr6, 0x831e81d4
	if !ctx.cr[6].lt {
	pc = 0x831E81D4; continue 'dispatch;
	}
	// 831E81CC: 39600002  li r11, 2
	ctx.r[11].s64 = 2;
	// 831E81D0: 48000010  b 0x831e81e0
	pc = 0x831E81E0; continue 'dispatch;
	// 831E81D4: 2B0B0008  cmplwi cr6, r11, 8
	ctx.cr[6].compare_u32(ctx.r[11].u32, 8 as u32, &mut ctx.xer);
	// 831E81D8: 40990008  ble cr6, 0x831e81e0
	if !ctx.cr[6].gt {
	pc = 0x831E81E0; continue 'dispatch;
	}
	// 831E81DC: 39600008  li r11, 8
	ctx.r[11].s64 = 8;
	// 831E81E0: 55663830  slwi r6, r11, 7
	ctx.r[6].u32 = ctx.r[11].u32.wrapping_shl(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831E81E4: 2B1D00FF  cmplwi cr6, r29, 0xff
	ctx.cr[6].compare_u32(ctx.r[29].u32, 255 as u32, &mut ctx.xer);
	// 831E81E8: 7CC6DA14  add r6, r6, r27
	ctx.r[6].u64 = ctx.r[6].u64 + ctx.r[27].u64;
	// 831E81EC: 419A000C  beq cr6, 0x831e81f8
	if ctx.cr[6].eq {
	pc = 0x831E81F8; continue 'dispatch;
	}
	// 831E81F0: 57BD3830  slwi r29, r29, 7
	ctx.r[29].u32 = ctx.r[29].u32.wrapping_shl(7);
	ctx.r[29].u64 = ctx.r[29].u32 as u64;
	// 831E81F4: 7CDD3214  add r6, r29, r6
	ctx.r[6].u64 = ctx.r[29].u64 + ctx.r[6].u64;
	// 831E81F8: 7F06D040  cmplw cr6, r6, r26
	ctx.cr[6].compare_u32(ctx.r[6].u32, ctx.r[26].u32, &mut ctx.xer);
	// 831E81FC: 40990008  ble cr6, 0x831e8204
	if !ctx.cr[6].gt {
	pc = 0x831E8204; continue 'dispatch;
	}
	// 831E8200: 7F46D378  mr r6, r26
	ctx.r[6].u64 = ctx.r[26].u64;
	// 831E8204: 83AAFFFC  lwz r29, -4(r10)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-4 as u32) ) } as u64;
	// 831E8208: 34A5FFFF  addic. r5, r5, -1
	ctx.xer.ca = (ctx.r[5].u32 > (!(-1 as u32)));
	ctx.r[5].s64 = ctx.r[5].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[5].s32, 0, &mut ctx.xer);
	// 831E820C: 3B9C0002  addi r28, r28, 2
	ctx.r[28].s64 = ctx.r[28].s64 + 2;
	// 831E8210: 93A8FFFC  stw r29, -4(r8)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(-4 as u32), ctx.r[29].u32 ) };
	// 831E8214: 8BAA0000  lbz r29, 0(r10)
	ctx.r[29].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E8218: 90C80000  stw r6, 0(r8)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), ctx.r[6].u32 ) };
	// 831E821C: 99680005  stb r11, 5(r8)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[8].u32.wrapping_add(5 as u32), ctx.r[11].u8 ) };
	// 831E8220: 9BA80004  stb r29, 4(r8)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), ctx.r[29].u8 ) };
	// 831E8224: 3908000C  addi r8, r8, 0xc
	ctx.r[8].s64 = ctx.r[8].s64 + 12;
	// 831E8228: 816900C8  lwz r11, 0xc8(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(200 as u32) ) } as u64;
	// 831E822C: 7CC75A14  add r6, r7, r11
	ctx.r[6].u64 = ctx.r[7].u64 + ctx.r[11].u64;
	// 831E8230: 89690108  lbz r11, 0x108(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[9].u32.wrapping_add(264 as u32) ) } as u64;
	// 831E8234: 91660054  stw r11, 0x54(r6)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 831E8238: C0090074  lfs f0, 0x74(r9)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(116 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E823C: 83AAFFFC  lwz r29, -4(r10)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-4 as u32) ) } as u64;
	// 831E8240: FBBF0050  std r29, 0x50(r31)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[31].u32.wrapping_add(80 as u32), ctx.r[29].u64 ) };
	// 831E8244: C9BF0050  lfd f13, 0x50(r31)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) };
	// 831E8248: 816900C8  lwz r11, 0xc8(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(200 as u32) ) } as u64;
	// 831E824C: FD806E9C  fcfid f12, f13
	ctx.f[12].f64 = (ctx.f[13].s64 as f64);
	// 831E8250: 88CA0000  lbz r6, 0(r10)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E8254: 7D675A14  add r11, r7, r11
	ctx.r[11].u64 = ctx.r[7].u64 + ctx.r[11].u64;
	// 831E8258: 98CB000D  stb r6, 0xd(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(13 as u32), ctx.r[6].u8 ) };
	// 831E825C: FD606018  frsp f11, f12
	ctx.f[11].f64 = (ctx.f[12].f64 as f32) as f64;
	// 831E8260: 83AB0050  lwz r29, 0x50(r11)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(80 as u32) ) } as u64;
	// 831E8264: 63BD0001  ori r29, r29, 1
	ctx.r[29].u64 = ctx.r[29].u64 | 1;
	// 831E8268: 9B0B000C  stb r24, 0xc(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[24].u8 ) };
	// 831E826C: ED4B0032  fmuls f10, f11, f0
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E8270: 93AB0050  stw r29, 0x50(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(80 as u32), ctx.r[29].u32 ) };
	// 831E8274: 394A0008  addi r10, r10, 8
	ctx.r[10].s64 = ctx.r[10].s64 + 8;
	// 831E8278: FD20565E  fctidz f9, f10
	ctx.f[9].s64 = if ctx.f[10].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[10].f64.trunc() as i64 };
	// 831E827C: 7D2BCFAE  stfiwx f9, r11, r25
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[25].u32), tmp.u32) };
	// 831E8280: 816900C8  lwz r11, 0xc8(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(200 as u32) ) } as u64;
	// 831E8284: 7D675A14  add r11, r7, r11
	ctx.r[11].u64 = ctx.r[7].u64 + ctx.r[11].u64;
	// 831E8288: 80CB0050  lwz r6, 0x50(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(80 as u32) ) } as u64;
	// 831E828C: 60C60002  ori r6, r6, 2
	ctx.r[6].u64 = ctx.r[6].u64 | 2;
	// 831E8290: 38E70058  addi r7, r7, 0x58
	ctx.r[7].s64 = ctx.r[7].s64 + 88;
	// 831E8294: 93CB0020  stw r30, 0x20(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(32 as u32), ctx.r[30].u32 ) };
	// 831E8298: 90CB0050  stw r6, 0x50(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(80 as u32), ctx.r[6].u32 ) };
	// 831E829C: 4082FEBC  bne 0x831e8158
	if !ctx.cr[0].eq {
	pc = 0x831E8158; continue 'dispatch;
	}
	// 831E82A0: 89690108  lbz r11, 0x108(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[9].u32.wrapping_add(264 as u32) ) } as u64;
	// 831E82A4: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 831E82A8: 556A07BC  rlwinm r10, r11, 0, 0x1e, 0x1e
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831E82AC: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E82B0: 419A0008  beq cr6, 0x831e82b8
	if ctx.cr[6].eq {
	pc = 0x831E82B8; continue 'dispatch;
	}
	// 831E82B4: 7F05C378  mr r5, r24
	ctx.r[5].u64 = ctx.r[24].u64;
	// 831E82B8: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 831E82BC: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 831E82C0: 38C900B8  addi r6, r9, 0xb8
	ctx.r[6].s64 = ctx.r[9].s64 + 184;
	// 831E82C4: 4BFF1D35  bl 0x831d9ff8
	ctx.lr = 0x831E82C8;
	sub_831D9FF8(ctx, base);
	// 831E82C8: 383F00A0  addi r1, r31, 0xa0
	ctx.r[1].s64 = ctx.r[31].s64 + 160;
	// 831E82CC: 4BFBFEDC  b 0x831a81a8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E82D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E82D0 size=256
    let mut pc: u32 = 0x831E82D0;
    'dispatch: loop {
        match pc {
            0x831E82D0 => {
    //   block [0x831E82D0..0x831E83D0)
	// 831E82D0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E82D4: 4BFBFE95  bl 0x831a8168
	ctx.lr = 0x831E82D8;
	sub_831A8130(ctx, base);
	// 831E82D8: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E82DC: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831E82E0: 3BFD0128  addi r31, r29, 0x128
	ctx.r[31].s64 = ctx.r[29].s64 + 296;
	// 831E82E4: 4805AE79  bl 0x8324315c
	ctx.lr = 0x831E82E8;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E82E8: 817D012C  lwz r11, 0x12c(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(300 as u32) ) } as u64;
	// 831E82EC: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E82F0: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831E82F4: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E82F8: 419A0010  beq cr6, 0x831e8308
	if ctx.cr[6].eq {
	pc = 0x831E8308; continue 'dispatch;
	}
	// 831E82FC: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E8300: 7F1E5840  cmplw cr6, r30, r11
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831E8304: 419A0014  beq cr6, 0x831e8318
	if ctx.cr[6].eq {
	pc = 0x831E8318; continue 'dispatch;
	}
	// 831E8308: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E830C: 4805A771  bl 0x83242a7c
	ctx.lr = 0x831E8310;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E8310: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831E8314: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 831E8318: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E831C: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E8320: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E8324: 807D00B8  lwz r3, 0xb8(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E8328: 4BFF1FF9  bl 0x831da320
	ctx.lr = 0x831E832C;
	sub_831DA320(ctx, base);
	// 831E832C: 3B800000  li r28, 0
	ctx.r[28].s64 = 0;
	// 831E8330: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E8334: 419A0044  beq cr6, 0x831e8378
	if ctx.cr[6].eq {
	pc = 0x831E8378; continue 'dispatch;
	}
	// 831E8338: 807D00B8  lwz r3, 0xb8(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E833C: 4BFF2945  bl 0x831dac80
	ctx.lr = 0x831E8340;
	sub_831DAC80(ctx, base);
	// 831E8340: 807D00B8  lwz r3, 0xb8(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E8344: 4BFF29D5  bl 0x831dad18
	ctx.lr = 0x831E8348;
	sub_831DAD18(ctx, base);
	// 831E8348: 897D0038  lbz r11, 0x38(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E834C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E8350: 419A0028  beq cr6, 0x831e8378
	if ctx.cr[6].eq {
	pc = 0x831E8378; continue 'dispatch;
	}
	// 831E8354: 7F9EE378  mr r30, r28
	ctx.r[30].u64 = ctx.r[28].u64;
	// 831E8358: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 831E835C: 807D00B8  lwz r3, 0xb8(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E8360: 4BFF2569  bl 0x831da8c8
	ctx.lr = 0x831E8364;
	sub_831DA8C8(ctx, base);
	// 831E8364: 397E0001  addi r11, r30, 1
	ctx.r[11].s64 = ctx.r[30].s64 + 1;
	// 831E8368: 895D0038  lbz r10, 0x38(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E836C: 557E063E  clrlwi r30, r11, 0x18
	ctx.r[30].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 831E8370: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E8374: 4198FFE4  blt cr6, 0x831e8358
	if ctx.cr[6].lt {
	pc = 0x831E8358; continue 'dispatch;
	}
	// 831E8378: 9B9D0124  stb r28, 0x124(r29)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[29].u32.wrapping_add(292 as u32), ctx.r[28].u8 ) };
	// 831E837C: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E8380: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E8384: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E8388: 419A0038  beq cr6, 0x831e83c0
	if ctx.cr[6].eq {
	pc = 0x831E83C0; continue 'dispatch;
	}
	// 831E838C: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E8390: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E8394: 409A002C  bne cr6, 0x831e83c0
	if !ctx.cr[6].eq {
	pc = 0x831E83C0; continue 'dispatch;
	}
	// 831E8398: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E839C: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E83A0: 40820020  bne 0x831e83c0
	if !ctx.cr[0].eq {
	pc = 0x831E83C0; continue 'dispatch;
	}
	// 831E83A4: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E83A8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E83AC: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 831E83B0: 939F0008  stw r28, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[28].u32 ) };
	// 831E83B4: 4805A6B9  bl 0x83242a6c
	ctx.lr = 0x831E83B8;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E83B8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E83BC: 4805ADB1  bl 0x8324316c
	ctx.lr = 0x831E83C0;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E83C0: 387D0010  addi r3, r29, 0x10
	ctx.r[3].s64 = ctx.r[29].s64 + 16;
	// 831E83C4: 4BFFE785  bl 0x831e6b48
	ctx.lr = 0x831E83C8;
	sub_831E6B48(ctx, base);
	// 831E83C8: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E83CC: 4BFBFDEC  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E83D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E83D0 size=336
    let mut pc: u32 = 0x831E83D0;
    'dispatch: loop {
        match pc {
            0x831E83D0 => {
    //   block [0x831E83D0..0x831E8520)
	// 831E83D0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E83D4: 4BFBFD89  bl 0x831a815c
	ctx.lr = 0x831E83D8;
	sub_831A8130(ctx, base);
	// 831E83D8: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E83DC: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831E83E0: 3B200000  li r25, 0
	ctx.r[25].s64 = 0;
	// 831E83E4: 7C9B2378  mr r27, r4
	ctx.r[27].u64 = ctx.r[4].u64;
	// 831E83E8: 3BDD0128  addi r30, r29, 0x128
	ctx.r[30].s64 = ctx.r[29].s64 + 296;
	// 831E83EC: 7F3ACB78  mr r26, r25
	ctx.r[26].u64 = ctx.r[25].u64;
	// 831E83F0: 4805AD6D  bl 0x8324315c
	ctx.lr = 0x831E83F4;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E83F4: 817D012C  lwz r11, 0x12c(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(300 as u32) ) } as u64;
	// 831E83F8: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E83FC: 7DBF6B78  mr r31, r13
	ctx.r[31].u64 = ctx.r[13].u64;
	// 831E8400: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E8404: 419A0010  beq cr6, 0x831e8414
	if ctx.cr[6].eq {
	pc = 0x831E8414; continue 'dispatch;
	}
	// 831E8408: 817E0008  lwz r11, 8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E840C: 7F1F5840  cmplw cr6, r31, r11
	ctx.cr[6].compare_u32(ctx.r[31].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831E8410: 419A0014  beq cr6, 0x831e8424
	if ctx.cr[6].eq {
	pc = 0x831E8424; continue 'dispatch;
	}
	// 831E8414: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E8418: 4805A665  bl 0x83242a7c
	ctx.lr = 0x831E841C;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E841C: 9B9E000C  stb r28, 0xc(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 831E8420: 93FE0008  stw r31, 8(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(8 as u32), ctx.r[31].u32 ) };
	// 831E8424: 817E0004  lwz r11, 4(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E8428: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E842C: 917E0004  stw r11, 4(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E8430: 807D00B8  lwz r3, 0xb8(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E8434: 4BFF29AD  bl 0x831dade0
	ctx.lr = 0x831E8438;
	sub_831DADE0(ctx, base);
	// 831E8438: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E843C: 2F1C0000  cmpwi cr6, r28, 0
	ctx.cr[6].compare_i32(ctx.r[28].s32, 0, &mut ctx.xer);
	// 831E8440: 409A0020  bne cr6, 0x831e8460
	if !ctx.cr[6].eq {
	pc = 0x831E8460; continue 'dispatch;
	}
	// 831E8444: 807D00B8  lwz r3, 0xb8(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E8448: 4BFF2839  bl 0x831dac80
	ctx.lr = 0x831E844C;
	sub_831DAC80(ctx, base);
	// 831E844C: 7C7A1B78  mr r26, r3
	ctx.r[26].u64 = ctx.r[3].u64;
	// 831E8450: 2F1A0000  cmpwi cr6, r26, 0
	ctx.cr[6].compare_i32(ctx.r[26].s32, 0, &mut ctx.xer);
	// 831E8454: 4198007C  blt cr6, 0x831e84d0
	if ctx.cr[6].lt {
	pc = 0x831E84D0; continue 'dispatch;
	}
	// 831E8458: 807D00B8  lwz r3, 0xb8(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E845C: 4BFF28BD  bl 0x831dad18
	ctx.lr = 0x831E8460;
	sub_831DAD18(ctx, base);
	// 831E8460: 897D0038  lbz r11, 0x38(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E8464: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E8468: 419A0054  beq cr6, 0x831e84bc
	if ctx.cr[6].eq {
	pc = 0x831E84BC; continue 'dispatch;
	}
	// 831E846C: 7F3FCB78  mr r31, r25
	ctx.r[31].u64 = ctx.r[25].u64;
	// 831E8470: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 831E8474: 807D00B8  lwz r3, 0xb8(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E8478: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831E847C: 4BFF265D  bl 0x831daad8
	ctx.lr = 0x831E8480;
	sub_831DAAD8(ctx, base);
	// 831E8480: 7C7A1B78  mr r26, r3
	ctx.r[26].u64 = ctx.r[3].u64;
	// 831E8484: 2F1A0000  cmpwi cr6, r26, 0
	ctx.cr[6].compare_i32(ctx.r[26].s32, 0, &mut ctx.xer);
	// 831E8488: 41980034  blt cr6, 0x831e84bc
	if ctx.cr[6].lt {
	pc = 0x831E84BC; continue 'dispatch;
	}
	// 831E848C: 57EB1838  slwi r11, r31, 3
	ctx.r[11].u32 = ctx.r[31].u32.wrapping_shl(3);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831E8490: 81410058  lwz r10, 0x58(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) } as u64;
	// 831E8494: 81010054  lwz r8, 0x54(r1)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 831E8498: 393F0001  addi r9, r31, 1
	ctx.r[9].s64 = ctx.r[31].s64 + 1;
	// 831E849C: 7D6BDA14  add r11, r11, r27
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[27].u64;
	// 831E84A0: 55473C30  rlwinm r7, r10, 7, 0x10, 0x18
	ctx.r[7].u64 = ctx.r[10].u32 as u64 & 0x01FFFFFFu64;
	// 831E84A4: 553F063E  clrlwi r31, r9, 0x18
	ctx.r[31].u64 = ctx.r[9].u32 as u64 & 0x000000FFu64;
	// 831E84A8: 910B0000  stw r8, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 831E84AC: B0EB0004  sth r7, 4(r11)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[7].u16 ) };
	// 831E84B0: 88DD0038  lbz r6, 0x38(r29)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E84B4: 7F1F3040  cmplw cr6, r31, r6
	ctx.cr[6].compare_u32(ctx.r[31].u32, ctx.r[6].u32, &mut ctx.xer);
	// 831E84B8: 4198FFB8  blt cr6, 0x831e8470
	if ctx.cr[6].lt {
	pc = 0x831E8470; continue 'dispatch;
	}
	// 831E84BC: 2F1C0000  cmpwi cr6, r28, 0
	ctx.cr[6].compare_i32(ctx.r[28].s32, 0, &mut ctx.xer);
	// 831E84C0: 409A0010  bne cr6, 0x831e84d0
	if !ctx.cr[6].eq {
	pc = 0x831E84D0; continue 'dispatch;
	}
	// 831E84C4: 807D00B8  lwz r3, 0xb8(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E84C8: 4BFF2A69  bl 0x831daf30
	ctx.lr = 0x831E84CC;
	sub_831DAF30(ctx, base);
	// 831E84CC: 7C7A1B78  mr r26, r3
	ctx.r[26].u64 = ctx.r[3].u64;
	// 831E84D0: 817E0004  lwz r11, 4(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E84D4: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E84D8: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E84DC: 419A0038  beq cr6, 0x831e8514
	if ctx.cr[6].eq {
	pc = 0x831E8514; continue 'dispatch;
	}
	// 831E84E0: 813E0008  lwz r9, 8(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E84E4: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E84E8: 409A002C  bne cr6, 0x831e8514
	if !ctx.cr[6].eq {
	pc = 0x831E8514; continue 'dispatch;
	}
	// 831E84EC: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E84F0: 917E0004  stw r11, 4(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E84F4: 40820020  bne 0x831e8514
	if !ctx.cr[0].eq {
	pc = 0x831E8514; continue 'dispatch;
	}
	// 831E84F8: 8BFE000C  lbz r31, 0xc(r30)
	ctx.r[31].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E84FC: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E8500: 933E0008  stw r25, 8(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(8 as u32), ctx.r[25].u32 ) };
	// 831E8504: 9B3E000C  stb r25, 0xc(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(12 as u32), ctx.r[25].u8 ) };
	// 831E8508: 4805A565  bl 0x83242a6c
	ctx.lr = 0x831E850C;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E850C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E8510: 4805AC5D  bl 0x8324316c
	ctx.lr = 0x831E8514;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E8514: 7F43D378  mr r3, r26
	ctx.r[3].u64 = ctx.r[26].u64;
	// 831E8518: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 831E851C: 4BFBFC90  b 0x831a81ac
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E8520(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E8520 size=216
    let mut pc: u32 = 0x831E8520;
    'dispatch: loop {
        match pc {
            0x831E8520 => {
    //   block [0x831E8520..0x831E85F8)
	// 831E8520: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E8524: 4BFBFC41  bl 0x831a8164
	ctx.lr = 0x831E8528;
	sub_831A8130(ctx, base);
	// 831E8528: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E852C: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831E8530: 7C9B2378  mr r27, r4
	ctx.r[27].u64 = ctx.r[4].u64;
	// 831E8534: 897D0124  lbz r11, 0x124(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(292 as u32) ) } as u64;
	// 831E8538: 2B0B0002  cmplwi cr6, r11, 2
	ctx.cr[6].compare_u32(ctx.r[11].u32, 2 as u32, &mut ctx.xer);
	// 831E853C: 409A0014  bne cr6, 0x831e8550
	if !ctx.cr[6].eq {
	pc = 0x831E8550; continue 'dispatch;
	}
	// 831E8540: 3C608000  lis r3, -0x8000
	ctx.r[3].s64 = -2147483648;
	// 831E8544: 60634001  ori r3, r3, 0x4001
	ctx.r[3].u64 = ctx.r[3].u64 | 16385;
	// 831E8548: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E854C: 4BFBFC68  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
	// 831E8550: 3BFD0128  addi r31, r29, 0x128
	ctx.r[31].s64 = ctx.r[29].s64 + 296;
	// 831E8554: 4805AC09  bl 0x8324315c
	ctx.lr = 0x831E8558;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E8558: 817D012C  lwz r11, 0x12c(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(300 as u32) ) } as u64;
	// 831E855C: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E8560: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831E8564: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E8568: 419A0010  beq cr6, 0x831e8578
	if ctx.cr[6].eq {
	pc = 0x831E8578; continue 'dispatch;
	}
	// 831E856C: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E8570: 7F1E5840  cmplw cr6, r30, r11
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831E8574: 419A0014  beq cr6, 0x831e8588
	if ctx.cr[6].eq {
	pc = 0x831E8588; continue 'dispatch;
	}
	// 831E8578: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E857C: 4805A501  bl 0x83242a7c
	ctx.lr = 0x831E8580;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E8580: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 831E8584: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831E8588: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E858C: 387D0078  addi r3, r29, 0x78
	ctx.r[3].s64 = ctx.r[29].s64 + 120;
	// 831E8590: 38A00030  li r5, 0x30
	ctx.r[5].s64 = 48;
	// 831E8594: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E8598: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 831E859C: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E85A0: 4BFBFF71  bl 0x831a8510
	ctx.lr = 0x831E85A4;
	sub_831A8510(ctx, base);
	// 831E85A4: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E85A8: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E85AC: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E85B0: 419A003C  beq cr6, 0x831e85ec
	if ctx.cr[6].eq {
	pc = 0x831E85EC; continue 'dispatch;
	}
	// 831E85B4: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E85B8: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E85BC: 409A0030  bne cr6, 0x831e85ec
	if !ctx.cr[6].eq {
	pc = 0x831E85EC; continue 'dispatch;
	}
	// 831E85C0: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E85C4: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E85C8: 40820024  bne 0x831e85ec
	if !ctx.cr[0].eq {
	pc = 0x831E85EC; continue 'dispatch;
	}
	// 831E85CC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E85D0: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E85D4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E85D8: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E85DC: 917F0008  stw r11, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 831E85E0: 4805A48D  bl 0x83242a6c
	ctx.lr = 0x831E85E4;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E85E4: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E85E8: 4805AB85  bl 0x8324316c
	ctx.lr = 0x831E85EC;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E85EC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E85F0: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E85F4: 4BFBFBC0  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E85F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E85F8 size=8
    let mut pc: u32 = 0x831E85F8;
    'dispatch: loop {
        match pc {
            0x831E85F8 => {
    //   block [0x831E85F8..0x831E8600)
	// 831E85F8: 3863FFF0  addi r3, r3, -0x10
	ctx.r[3].s64 = ctx.r[3].s64 + -16;
	// 831E85FC: 4BFFF594  b 0x831e7b90
	sub_831E7B90(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E8600(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E8600 size=8
    let mut pc: u32 = 0x831E8600;
    'dispatch: loop {
        match pc {
            0x831E8600 => {
    //   block [0x831E8600..0x831E8608)
	// 831E8600: 3863FFF0  addi r3, r3, -0x10
	ctx.r[3].s64 = ctx.r[3].s64 + -16;
	// 831E8604: 4BFFF9A4  b 0x831e7fa8
	sub_831E7FA8(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E8608(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E8608 size=8
    let mut pc: u32 = 0x831E8608;
    'dispatch: loop {
        match pc {
            0x831E8608 => {
    //   block [0x831E8608..0x831E8610)
	// 831E8608: 3863FFF0  addi r3, r3, -0x10
	ctx.r[3].s64 = ctx.r[3].s64 + -16;
	// 831E860C: 4BFFF594  b 0x831e7ba0
	sub_831E7BA0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E8610(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E8610 size=8
    let mut pc: u32 = 0x831E8610;
    'dispatch: loop {
        match pc {
            0x831E8610 => {
    //   block [0x831E8610..0x831E8618)
	// 831E8610: 3863FFFC  addi r3, r3, -4
	ctx.r[3].s64 = ctx.r[3].s64 + -4;
	// 831E8614: 4BFF7C94  b 0x831e02a8
	sub_831E02A8(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E8618(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E8618 size=8
    let mut pc: u32 = 0x831E8618;
    'dispatch: loop {
        match pc {
            0x831E8618 => {
    //   block [0x831E8618..0x831E8620)
	// 831E8618: 3863FFF0  addi r3, r3, -0x10
	ctx.r[3].s64 = ctx.r[3].s64 + -16;
	// 831E861C: 4BFFF6F4  b 0x831e7d10
	sub_831E7D10(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E8620(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E8620 size=8
    let mut pc: u32 = 0x831E8620;
    'dispatch: loop {
        match pc {
            0x831E8620 => {
    //   block [0x831E8620..0x831E8628)
	// 831E8620: 3863FFF0  addi r3, r3, -0x10
	ctx.r[3].s64 = ctx.r[3].s64 + -16;
	// 831E8624: 48001E74  b 0x831ea498
	sub_831EA498(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E8628(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E8628 size=8
    let mut pc: u32 = 0x831E8628;
    'dispatch: loop {
        match pc {
            0x831E8628 => {
    //   block [0x831E8628..0x831E8630)
	// 831E8628: 3863FFFC  addi r3, r3, -4
	ctx.r[3].s64 = ctx.r[3].s64 + -4;
	// 831E862C: 4BFF933C  b 0x831e1968
	sub_831E1968(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E8630(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E8630 size=8
    let mut pc: u32 = 0x831E8630;
    'dispatch: loop {
        match pc {
            0x831E8630 => {
    //   block [0x831E8630..0x831E8638)
	// 831E8630: 3863FFF0  addi r3, r3, -0x10
	ctx.r[3].s64 = ctx.r[3].s64 + -16;
	// 831E8634: 48001DD4  b 0x831ea408
	sub_831EA408(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E8638(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E8638 size=8
    let mut pc: u32 = 0x831E8638;
    'dispatch: loop {
        match pc {
            0x831E8638 => {
    //   block [0x831E8638..0x831E8640)
	// 831E8638: 3863FFF0  addi r3, r3, -0x10
	ctx.r[3].s64 = ctx.r[3].s64 + -16;
	// 831E863C: 4BFFF71C  b 0x831e7d58
	sub_831E7D58(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E8640(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E8640 size=8
    let mut pc: u32 = 0x831E8640;
    'dispatch: loop {
        match pc {
            0x831E8640 => {
    //   block [0x831E8640..0x831E8648)
	// 831E8640: 3863FFFC  addi r3, r3, -4
	ctx.r[3].s64 = ctx.r[3].s64 + -4;
	// 831E8644: 4BFFF694  b 0x831e7cd8
	sub_831E7CD8(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E8648(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E8648 size=8
    let mut pc: u32 = 0x831E8648;
    'dispatch: loop {
        match pc {
            0x831E8648 => {
    //   block [0x831E8648..0x831E8650)
	// 831E8648: 3863FFF0  addi r3, r3, -0x10
	ctx.r[3].s64 = ctx.r[3].s64 + -16;
	// 831E864C: 4BFFFC84  b 0x831e82d0
	sub_831E82D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E8650(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E8650 size=8
    let mut pc: u32 = 0x831E8650;
    'dispatch: loop {
        match pc {
            0x831E8650 => {
    //   block [0x831E8650..0x831E8658)
	// 831E8650: 3863FFF0  addi r3, r3, -0x10
	ctx.r[3].s64 = ctx.r[3].s64 + -16;
	// 831E8654: 4BFFF61C  b 0x831e7c70
	sub_831E7C70(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E8658(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E8658 size=8
    let mut pc: u32 = 0x831E8658;
    'dispatch: loop {
        match pc {
            0x831E8658 => {
    //   block [0x831E8658..0x831E8660)
	// 831E8658: 3863FFF0  addi r3, r3, -0x10
	ctx.r[3].s64 = ctx.r[3].s64 + -16;
	// 831E865C: 4BFFF59C  b 0x831e7bf8
	sub_831E7BF8(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E8660(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E8660 size=8
    let mut pc: u32 = 0x831E8660;
    'dispatch: loop {
        match pc {
            0x831E8660 => {
    //   block [0x831E8660..0x831E8668)
	// 831E8660: 3863FFF0  addi r3, r3, -0x10
	ctx.r[3].s64 = ctx.r[3].s64 + -16;
	// 831E8664: 4BFFF7EC  b 0x831e7e50
	sub_831E7E50(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E8668(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E8668 size=4
    let mut pc: u32 = 0x831E8668;
    'dispatch: loop {
        match pc {
            0x831E8668 => {
    //   block [0x831E8668..0x831E866C)
	// 831E8668: 4BFFFC68  b 0x831e82d0
	sub_831E82D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E8670(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E8670 size=240
    let mut pc: u32 = 0x831E8670;
    'dispatch: loop {
        match pc {
            0x831E8670 => {
    //   block [0x831E8670..0x831E8760)
	// 831E8670: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E8674: 4BFBFAF5  bl 0x831a8168
	ctx.lr = 0x831E8678;
	sub_831A8130(ctx, base);
	// 831E8678: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E867C: 3BA30010  addi r29, r3, 0x10
	ctx.r[29].s64 = ctx.r[3].s64 + 16;
	// 831E8680: 4805AADD  bl 0x8324315c
	ctx.lr = 0x831E8684;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E8684: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E8688: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E868C: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831E8690: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831E8694: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E8698: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E869C: 419A0010  beq cr6, 0x831e86ac
	if ctx.cr[6].eq {
	pc = 0x831E86AC; continue 'dispatch;
	}
	// 831E86A0: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E86A4: 7F1E4040  cmplw cr6, r30, r8
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831E86A8: 419A001C  beq cr6, 0x831e86c4
	if ctx.cr[6].eq {
	pc = 0x831E86C4; continue 'dispatch;
	}
	// 831E86AC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E86B0: 4805A3CD  bl 0x83242a7c
	ctx.lr = 0x831E86B4;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E86B4: 7FC8F378  mr r8, r30
	ctx.r[8].u64 = ctx.r[30].u64;
	// 831E86B8: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E86BC: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 831E86C0: 911F0008  stw r8, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 831E86C4: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E86C8: 395D0004  addi r10, r29, 4
	ctx.r[10].s64 = ctx.r[29].s64 + 4;
	// 831E86CC: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E86D0: 813D0004  lwz r9, 4(r29)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E86D4: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E86D8: 419A0038  beq cr6, 0x831e8710
	if ctx.cr[6].eq {
	pc = 0x831E8710; continue 'dispatch;
	}
	// 831E86DC: 814A0008  lwz r10, 8(r10)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E86E0: 7D2A4850  subf r9, r10, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[10].s64;
	// 831E86E4: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831E86E8: 419A0028  beq cr6, 0x831e8710
	if ctx.cr[6].eq {
	pc = 0x831E8710; continue 'dispatch;
	}
	// 831E86EC: 817D0000  lwz r11, 0(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E86F0: 38A00008  li r5, 8
	ctx.r[5].s64 = 8;
	// 831E86F4: 38800008  li r4, 8
	ctx.r[4].s64 = 8;
	// 831E86F8: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831E86FC: 814B0054  lwz r10, 0x54(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(84 as u32) ) } as u64;
	// 831E8700: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E8704: 4E800421  bctrl
	ctx.lr = 0x831E8708;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E8708: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E870C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E8710: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E8714: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E8718: 419A003C  beq cr6, 0x831e8754
	if ctx.cr[6].eq {
	pc = 0x831E8754; continue 'dispatch;
	}
	// 831E871C: 7F0A4040  cmplw cr6, r10, r8
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831E8720: 409A0034  bne cr6, 0x831e8754
	if !ctx.cr[6].eq {
	pc = 0x831E8754; continue 'dispatch;
	}
	// 831E8724: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E8728: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E872C: 40820028  bne 0x831e8754
	if !ctx.cr[0].eq {
	pc = 0x831E8754; continue 'dispatch;
	}
	// 831E8730: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E8734: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E8738: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E873C: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E8740: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E8744: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E8748: 4805A325  bl 0x83242a6c
	ctx.lr = 0x831E874C;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E874C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E8750: 4805AA1D  bl 0x8324316c
	ctx.lr = 0x831E8754;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E8754: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E8758: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E875C: 4BFBFA5C  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E8760(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E8760 size=40
    let mut pc: u32 = 0x831E8760;
    'dispatch: loop {
        match pc {
            0x831E8760 => {
    //   block [0x831E8760..0x831E8788)
	// 831E8760: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 831E8764: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E8768: 894B0044  lbz r10, 0x44(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(68 as u32) ) } as u64;
	// 831E876C: 892B000C  lbz r9, 0xc(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E8770: 1D4A0078  mulli r10, r10, 0x78
	ctx.r[10].s64 = ctx.r[10].s64 * 120;
	// 831E8774: 1D690058  mulli r11, r9, 0x58
	ctx.r[11].s64 = ctx.r[9].s64 * 88;
	// 831E8778: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831E877C: 390B0138  addi r8, r11, 0x138
	ctx.r[8].s64 = ctx.r[11].s64 + 312;
	// 831E8780: 91040000  stw r8, 0(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 831E8784: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E8788(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E8788 size=2280
    let mut pc: u32 = 0x831E8788;
    'dispatch: loop {
        match pc {
            0x831E8788 => {
    //   block [0x831E8788..0x831E9070)
	// 831E8788: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E878C: 4BFBF9B5  bl 0x831a8140
	ctx.lr = 0x831E8790;
	sub_831A8130(ctx, base);
	// 831E8790: 9421FF20  stwu r1, -0xe0(r1)
	ea = ctx.r[1].u32.wrapping_add(-224 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E8794: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831E8798: 3A800000  li r20, 0
	ctx.r[20].s64 = 0;
	// 831E879C: 3B200001  li r25, 1
	ctx.r[25].s64 = 1;
	// 831E87A0: 7E98A378  mr r24, r20
	ctx.r[24].u64 = ctx.r[20].u64;
	// 831E87A4: 897D0038  lbz r11, 0x38(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E87A8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E87AC: 419A004C  beq cr6, 0x831e87f8
	if ctx.cr[6].eq {
	pc = 0x831E87F8; continue 'dispatch;
	}
	// 831E87B0: 7E9FA378  mr r31, r20
	ctx.r[31].u64 = ctx.r[20].u64;
	// 831E87B4: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831E87B8: 807D00B8  lwz r3, 0xb8(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E87BC: 4BFF1CCD  bl 0x831da488
	ctx.lr = 0x831E87C0;
	sub_831DA488(ctx, base);
	// 831E87C0: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E87C4: 419A0098  beq cr6, 0x831e885c
	if ctx.cr[6].eq {
	pc = 0x831E885C; continue 'dispatch;
	}
	// 831E87C8: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831E87CC: 807D00B8  lwz r3, 0xb8(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E87D0: 4BFF1D21  bl 0x831da4f0
	ctx.lr = 0x831E87D4;
	sub_831DA4F0(ctx, base);
	// 831E87D4: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E87D8: 409A0008  bne cr6, 0x831e87e0
	if !ctx.cr[6].eq {
	pc = 0x831E87E0; continue 'dispatch;
	}
	// 831E87DC: 7E99A378  mr r25, r20
	ctx.r[25].u64 = ctx.r[20].u64;
	// 831E87E0: 397F0001  addi r11, r31, 1
	ctx.r[11].s64 = ctx.r[31].s64 + 1;
	// 831E87E4: 895D0038  lbz r10, 0x38(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E87E8: 556B063E  clrlwi r11, r11, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 831E87EC: 7D7F5B78  mr r31, r11
	ctx.r[31].u64 = ctx.r[11].u64;
	// 831E87F0: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E87F4: 4198FFC0  blt cr6, 0x831e87b4
	if ctx.cr[6].lt {
	pc = 0x831E87B4; continue 'dispatch;
	}
	// 831E87F8: 4805A965  bl 0x8324315c
	ctx.lr = 0x831E87FC;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E87FC: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E8800: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831E8804: 3AABD530  addi r21, r11, -0x2ad0
	ctx.r[21].s64 = ctx.r[11].s64 + -10960;
	// 831E8808: 7DBF6B78  mr r31, r13
	ctx.r[31].u64 = ctx.r[13].u64;
	// 831E880C: 81750004  lwz r11, 4(r21)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E8810: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E8814: 419A0010  beq cr6, 0x831e8824
	if ctx.cr[6].eq {
	pc = 0x831E8824; continue 'dispatch;
	}
	// 831E8818: 81550008  lwz r10, 8(r21)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E881C: 7F1F5040  cmplw cr6, r31, r10
	ctx.cr[6].compare_u32(ctx.r[31].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E8820: 419A0018  beq cr6, 0x831e8838
	if ctx.cr[6].eq {
	pc = 0x831E8838; continue 'dispatch;
	}
	// 831E8824: 7EA3AB78  mr r3, r21
	ctx.r[3].u64 = ctx.r[21].u64;
	// 831E8828: 4805A255  bl 0x83242a7c
	ctx.lr = 0x831E882C;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E882C: 81750004  lwz r11, 4(r21)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E8830: 93F50008  stw r31, 8(r21)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(8 as u32), ctx.r[31].u32 ) };
	// 831E8834: 9BD5000C  stb r30, 0xc(r21)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[21].u32.wrapping_add(12 as u32), ctx.r[30].u8 ) };
	// 831E8838: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E883C: 3A7D0014  addi r19, r29, 0x14
	ctx.r[19].s64 = ctx.r[29].s64 + 20;
	// 831E8840: 91750004  stw r11, 4(r21)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E8844: 817D0014  lwz r11, 0x14(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E8848: 7F135840  cmplw cr6, r19, r11
	ctx.cr[6].compare_u32(ctx.r[19].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831E884C: 419A001C  beq cr6, 0x831e8868
	if ctx.cr[6].eq {
	pc = 0x831E8868; continue 'dispatch;
	}
	// 831E8850: 81530008  lwz r10, 8(r19)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E8854: 7FCA5850  subf r30, r10, r11
	ctx.r[30].s64 = ctx.r[11].s64 - ctx.r[10].s64;
	// 831E8858: 48000014  b 0x831e886c
	pc = 0x831E886C; continue 'dispatch;
	// 831E885C: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 831E8860: 382100E0  addi r1, r1, 0xe0
	ctx.r[1].s64 = ctx.r[1].s64 + 224;
	// 831E8864: 4BFBF92C  b 0x831a8190
	sub_831A8180(ctx, base);
	return;
	// 831E8868: 7E9EA378  mr r30, r20
	ctx.r[30].u64 = ctx.r[20].u64;
	// 831E886C: 7FDBF378  mr r27, r30
	ctx.r[27].u64 = ctx.r[30].u64;
	// 831E8870: 3A400004  li r18, 4
	ctx.r[18].s64 = 4;
	// 831E8874: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 831E8878: 419A036C  beq cr6, 0x831e8be4
	if ctx.cr[6].eq {
	pc = 0x831E8BE4; continue 'dispatch;
	}
	// 831E887C: 817D0110  lwz r11, 0x110(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(272 as u32) ) } as u64;
	// 831E8880: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E8884: 419A00F8  beq cr6, 0x831e897c
	if ctx.cr[6].eq {
	pc = 0x831E897C; continue 'dispatch;
	}
	// 831E8888: 815D00A8  lwz r10, 0xa8(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(168 as u32) ) } as u64;
	// 831E888C: 813D010C  lwz r9, 0x10c(r29)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(268 as u32) ) } as u64;
	// 831E8890: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E8894: 419800E8  blt cr6, 0x831e897c
	if ctx.cr[6].lt {
	pc = 0x831E897C; continue 'dispatch;
	}
	// 831E8898: 2F0BFFFF  cmpwi cr6, r11, -1
	ctx.cr[6].compare_i32(ctx.r[11].s32, -1, &mut ctx.xer);
	// 831E889C: 409A000C  bne cr6, 0x831e88a8
	if !ctx.cr[6].eq {
	pc = 0x831E88A8; continue 'dispatch;
	}
	// 831E88A0: 3960FFFF  li r11, -1
	ctx.r[11].s64 = -1;
	// 831E88A4: 4800000C  b 0x831e88b0
	pc = 0x831E88B0; continue 'dispatch;
	// 831E88A8: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 831E88AC: 917D0110  stw r11, 0x110(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(272 as u32), ctx.r[11].u32 ) };
	// 831E88B0: 917D0110  stw r11, 0x110(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(272 as u32), ctx.r[11].u32 ) };
	// 831E88B4: 3BFD0128  addi r31, r29, 0x128
	ctx.r[31].s64 = ctx.r[29].s64 + 296;
	// 831E88B8: 817E0018  lwz r11, 0x18(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(24 as u32) ) } as u64;
	// 831E88BC: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E88C0: 811E0014  lwz r8, 0x14(r30)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E88C4: 7D685850  subf r11, r8, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[8].s64;
	// 831E88C8: 7CEB4A14  add r7, r11, r9
	ctx.r[7].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 831E88CC: 90FD010C  stw r7, 0x10c(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(268 as u32), ctx.r[7].u32 ) };
	// 831E88D0: 817D012C  lwz r11, 0x12c(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(300 as u32) ) } as u64;
	// 831E88D4: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E88D8: 419A0038  beq cr6, 0x831e8910
	if ctx.cr[6].eq {
	pc = 0x831E8910; continue 'dispatch;
	}
	// 831E88DC: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E88E0: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E88E4: 409A002C  bne cr6, 0x831e8910
	if !ctx.cr[6].eq {
	pc = 0x831E8910; continue 'dispatch;
	}
	// 831E88E8: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E88EC: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E88F0: 40820020  bne 0x831e8910
	if !ctx.cr[0].eq {
	pc = 0x831E8910; continue 'dispatch;
	}
	// 831E88F4: 8B9F000C  lbz r28, 0xc(r31)
	ctx.r[28].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E88F8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E88FC: 9A9F000C  stb r20, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[20].u8 ) };
	// 831E8900: 929F0008  stw r20, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[20].u32 ) };
	// 831E8904: 4805A169  bl 0x83242a6c
	ctx.lr = 0x831E8908;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E8908: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 831E890C: 4805A861  bl 0x8324316c
	ctx.lr = 0x831E8910;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E8910: 817D00B4  lwz r11, 0xb4(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(180 as u32) ) } as u64;
	// 831E8914: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E8918: 419A0024  beq cr6, 0x831e893c
	if ctx.cr[6].eq {
	pc = 0x831E893C; continue 'dispatch;
	}
	// 831E891C: 815D000C  lwz r10, 0xc(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E8920: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 831E8924: 813E0024  lwz r9, 0x24(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(36 as u32) ) } as u64;
	// 831E8928: 92810060  stw r20, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[20].u32 ) };
	// 831E892C: 91410058  stw r10, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[10].u32 ) };
	// 831E8930: 9121005C  stw r9, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[9].u32 ) };
	// 831E8934: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 831E8938: 4E800421  bctrl
	ctx.lr = 0x831E893C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E893C: 4805A821  bl 0x8324315c
	ctx.lr = 0x831E8940;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E8940: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E8944: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E8948: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831E894C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E8950: 419A0010  beq cr6, 0x831e8960
	if ctx.cr[6].eq {
	pc = 0x831E8960; continue 'dispatch;
	}
	// 831E8954: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E8958: 7F1E5840  cmplw cr6, r30, r11
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831E895C: 419A0014  beq cr6, 0x831e8970
	if ctx.cr[6].eq {
	pc = 0x831E8970; continue 'dispatch;
	}
	// 831E8960: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E8964: 4805A119  bl 0x83242a7c
	ctx.lr = 0x831E8968;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E8968: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831E896C: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 831E8970: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E8974: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E8978: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E897C: 817D0120  lwz r11, 0x120(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(288 as u32) ) } as u64;
	// 831E8980: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E8984: 419A0048  beq cr6, 0x831e89cc
	if ctx.cr[6].eq {
	pc = 0x831E89CC; continue 'dispatch;
	}
	// 831E8988: 897D00C6  lbz r11, 0xc6(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(198 as u32) ) } as u64;
	// 831E898C: 895D0038  lbz r10, 0x38(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E8990: 929D0120  stw r20, 0x120(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(288 as u32), ctx.r[20].u32 ) };
	// 831E8994: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E8998: 917D0110  stw r11, 0x110(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(272 as u32), ctx.r[11].u32 ) };
	// 831E899C: 419A0030  beq cr6, 0x831e89cc
	if ctx.cr[6].eq {
	pc = 0x831E89CC; continue 'dispatch;
	}
	// 831E89A0: 3BDD00BC  addi r30, r29, 0xbc
	ctx.r[30].s64 = ctx.r[29].s64 + 188;
	// 831E89A4: 7E9FA378  mr r31, r20
	ctx.r[31].u64 = ctx.r[20].u64;
	// 831E89A8: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 831E89AC: 807D00B8  lwz r3, 0xb8(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E89B0: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831E89B4: 4BFF2045  bl 0x831da9f8
	ctx.lr = 0x831E89B8;
	sub_831DA9F8(ctx, base);
	// 831E89B8: 397F0001  addi r11, r31, 1
	ctx.r[11].s64 = ctx.r[31].s64 + 1;
	// 831E89BC: 895D0038  lbz r10, 0x38(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E89C0: 557F063E  clrlwi r31, r11, 0x18
	ctx.r[31].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 831E89C4: 7F1F5040  cmplw cr6, r31, r10
	ctx.cr[6].compare_u32(ctx.r[31].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E89C8: 4198FFE0  blt cr6, 0x831e89a8
	if ctx.cr[6].lt {
	pc = 0x831E89A8; continue 'dispatch;
	}
	// 831E89CC: 817B0000  lwz r11, 0(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E89D0: 7F0BD840  cmplw cr6, r11, r27
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[27].u32, &mut ctx.xer);
	// 831E89D4: 419A0210  beq cr6, 0x831e8be4
	if ctx.cr[6].eq {
	pc = 0x831E8BE4; continue 'dispatch;
	}
	// 831E89D8: 81730008  lwz r11, 8(r19)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E89DC: 7D4BD82E  lwzx r10, r11, r27
	ctx.r[10].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[27].u32)) } as u64;
	// 831E89E0: 7F135040  cmplw cr6, r19, r10
	ctx.cr[6].compare_u32(ctx.r[19].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E89E4: 7F4B5050  subf r26, r11, r10
	ctx.r[26].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 831E89E8: 409A0008  bne cr6, 0x831e89f0
	if !ctx.cr[6].eq {
	pc = 0x831E89F0; continue 'dispatch;
	}
	// 831E89EC: 7E9AA378  mr r26, r20
	ctx.r[26].u64 = ctx.r[20].u64;
	// 831E89F0: 897B0074  lbz r11, 0x74(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[27].u32.wrapping_add(116 as u32) ) } as u64;
	// 831E89F4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E89F8: 419A0078  beq cr6, 0x831e8a70
	if ctx.cr[6].eq {
	pc = 0x831E8A70; continue 'dispatch;
	}
	// 831E89FC: 897D0038  lbz r11, 0x38(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E8A00: 7E9EA378  mr r30, r20
	ctx.r[30].u64 = ctx.r[20].u64;
	// 831E8A04: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E8A08: 419A0054  beq cr6, 0x831e8a5c
	if ctx.cr[6].eq {
	pc = 0x831E8A5C; continue 'dispatch;
	}
	// 831E8A0C: 7E9FA378  mr r31, r20
	ctx.r[31].u64 = ctx.r[20].u64;
	// 831E8A10: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831E8A14: 80BB0008  lwz r5, 8(r27)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E8A18: 807D00B8  lwz r3, 0xb8(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E8A1C: 4BFF19ED  bl 0x831da408
	ctx.lr = 0x831E8A20;
	sub_831DA408(ctx, base);
	// 831E8A20: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E8A24: 419A001C  beq cr6, 0x831e8a40
	if ctx.cr[6].eq {
	pc = 0x831E8A40; continue 'dispatch;
	}
	// 831E8A28: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831E8A2C: 807D00B8  lwz r3, 0xb8(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E8A30: 4BFF1F49  bl 0x831da978
	ctx.lr = 0x831E8A34;
	sub_831DA978(ctx, base);
	// 831E8A34: 546B0738  rlwinm r11, r3, 0, 0x1c, 0x1c
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0xFFFFFFFFu64;
	// 831E8A38: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E8A3C: 419A001C  beq cr6, 0x831e8a58
	if ctx.cr[6].eq {
	pc = 0x831E8A58; continue 'dispatch;
	}
	// 831E8A40: 397F0001  addi r11, r31, 1
	ctx.r[11].s64 = ctx.r[31].s64 + 1;
	// 831E8A44: 895D0038  lbz r10, 0x38(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E8A48: 557F063E  clrlwi r31, r11, 0x18
	ctx.r[31].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 831E8A4C: 7F1F5040  cmplw cr6, r31, r10
	ctx.cr[6].compare_u32(ctx.r[31].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E8A50: 4198FFC0  blt cr6, 0x831e8a10
	if ctx.cr[6].lt {
	pc = 0x831E8A10; continue 'dispatch;
	}
	// 831E8A54: 48000008  b 0x831e8a5c
	pc = 0x831E8A5C; continue 'dispatch;
	// 831E8A58: 3BC00001  li r30, 1
	ctx.r[30].s64 = 1;
	// 831E8A5C: 57CB063E  clrlwi r11, r30, 0x18
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0x000000FFu64;
	// 831E8A60: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E8A64: 409A0010  bne cr6, 0x831e8a74
	if !ctx.cr[6].eq {
	pc = 0x831E8A74; continue 'dispatch;
	}
	// 831E8A68: 9A5B0074  stb r18, 0x74(r27)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[27].u32.wrapping_add(116 as u32), ctx.r[18].u8 ) };
	// 831E8A6C: 48000008  b 0x831e8a74
	pc = 0x831E8A74; continue 'dispatch;
	// 831E8A70: 3B000001  li r24, 1
	ctx.r[24].s64 = 1;
	// 831E8A74: 897B0074  lbz r11, 0x74(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[27].u32.wrapping_add(116 as u32) ) } as u64;
	// 831E8A78: 2B0B0004  cmplwi cr6, r11, 4
	ctx.cr[6].compare_u32(ctx.r[11].u32, 4 as u32, &mut ctx.xer);
	// 831E8A7C: 409A015C  bne cr6, 0x831e8bd8
	if !ctx.cr[6].eq {
	pc = 0x831E8BD8; continue 'dispatch;
	}
	// 831E8A80: 2B1A0000  cmplwi cr6, r26, 0
	ctx.cr[6].compare_u32(ctx.r[26].u32, 0 as u32, &mut ctx.xer);
	// 831E8A84: 409A0020  bne cr6, 0x831e8aa4
	if !ctx.cr[6].eq {
	pc = 0x831E8AA4; continue 'dispatch;
	}
	// 831E8A88: 897D00AC  lbz r11, 0xac(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(172 as u32) ) } as u64;
	// 831E8A8C: 556A07FE  clrlwi r10, r11, 0x1f
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0x00000001u64;
	// 831E8A90: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E8A94: 419A0010  beq cr6, 0x831e8aa4
	if ctx.cr[6].eq {
	pc = 0x831E8AA4; continue 'dispatch;
	}
	// 831E8A98: 556B06F6  rlwinm r11, r11, 0, 0x1b, 0x1b
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831E8A9C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E8AA0: 419A0138  beq cr6, 0x831e8bd8
	if ctx.cr[6].eq {
	pc = 0x831E8BD8; continue 'dispatch;
	}
	// 831E8AA4: 81550004  lwz r10, 4(r21)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E8AA8: 7DAB6B78  mr r11, r13
	ctx.r[11].u64 = ctx.r[13].u64;
	// 831E8AAC: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831E8AB0: 419A0044  beq cr6, 0x831e8af4
	if ctx.cr[6].eq {
	pc = 0x831E8AF4; continue 'dispatch;
	}
	// 831E8AB4: 81550008  lwz r10, 8(r21)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E8AB8: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E8ABC: 409A0038  bne cr6, 0x831e8af4
	if !ctx.cr[6].eq {
	pc = 0x831E8AF4; continue 'dispatch;
	}
	// 831E8AC0: 81750004  lwz r11, 4(r21)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E8AC4: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E8AC8: 91750004  stw r11, 4(r21)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E8ACC: 40820028  bne 0x831e8af4
	if !ctx.cr[0].eq {
	pc = 0x831E8AF4; continue 'dispatch;
	}
	// 831E8AD0: 7E8BA378  mr r11, r20
	ctx.r[11].u64 = ctx.r[20].u64;
	// 831E8AD4: 8BF5000C  lbz r31, 0xc(r21)
	ctx.r[31].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[21].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E8AD8: 7E8AA378  mr r10, r20
	ctx.r[10].u64 = ctx.r[20].u64;
	// 831E8ADC: 9975000C  stb r11, 0xc(r21)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[21].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E8AE0: 7EA3AB78  mr r3, r21
	ctx.r[3].u64 = ctx.r[21].u64;
	// 831E8AE4: 91550008  stw r10, 8(r21)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E8AE8: 48059F85  bl 0x83242a6c
	ctx.lr = 0x831E8AEC;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E8AEC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E8AF0: 4805A67D  bl 0x8324316c
	ctx.lr = 0x831E8AF4;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E8AF4: 817D012C  lwz r11, 0x12c(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(300 as u32) ) } as u64;
	// 831E8AF8: 3BFD0128  addi r31, r29, 0x128
	ctx.r[31].s64 = ctx.r[29].s64 + 296;
	// 831E8AFC: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E8B00: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E8B04: 419A0038  beq cr6, 0x831e8b3c
	if ctx.cr[6].eq {
	pc = 0x831E8B3C; continue 'dispatch;
	}
	// 831E8B08: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E8B0C: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E8B10: 409A002C  bne cr6, 0x831e8b3c
	if !ctx.cr[6].eq {
	pc = 0x831E8B3C; continue 'dispatch;
	}
	// 831E8B14: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E8B18: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E8B1C: 40820020  bne 0x831e8b3c
	if !ctx.cr[0].eq {
	pc = 0x831E8B3C; continue 'dispatch;
	}
	// 831E8B20: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E8B24: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E8B28: 9A9F000C  stb r20, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[20].u8 ) };
	// 831E8B2C: 929F0008  stw r20, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[20].u32 ) };
	// 831E8B30: 48059F3D  bl 0x83242a6c
	ctx.lr = 0x831E8B34;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E8B34: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E8B38: 4805A635  bl 0x8324316c
	ctx.lr = 0x831E8B3C;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E8B3C: 817D0010  lwz r11, 0x10(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E8B40: 387D0010  addi r3, r29, 0x10
	ctx.r[3].s64 = ctx.r[29].s64 + 16;
	// 831E8B44: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 831E8B48: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 831E8B4C: 814B005C  lwz r10, 0x5c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(92 as u32) ) } as u64;
	// 831E8B50: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E8B54: 4E800421  bctrl
	ctx.lr = 0x831E8B58;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E8B58: 4805A605  bl 0x8324315c
	ctx.lr = 0x831E8B5C;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E8B5C: 813F0004  lwz r9, 4(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E8B60: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E8B64: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831E8B68: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831E8B6C: 419A0010  beq cr6, 0x831e8b7c
	if ctx.cr[6].eq {
	pc = 0x831E8B7C; continue 'dispatch;
	}
	// 831E8B70: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E8B74: 7F1E5840  cmplw cr6, r30, r11
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831E8B78: 419A0014  beq cr6, 0x831e8b8c
	if ctx.cr[6].eq {
	pc = 0x831E8B8C; continue 'dispatch;
	}
	// 831E8B7C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E8B80: 48059EFD  bl 0x83242a7c
	ctx.lr = 0x831E8B84;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E8B84: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831E8B88: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 831E8B8C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E8B90: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E8B94: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E8B98: 4805A5C5  bl 0x8324315c
	ctx.lr = 0x831E8B9C;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E8B9C: 81750004  lwz r11, 4(r21)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E8BA0: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831E8BA4: 7DBF6B78  mr r31, r13
	ctx.r[31].u64 = ctx.r[13].u64;
	// 831E8BA8: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E8BAC: 419A0010  beq cr6, 0x831e8bbc
	if ctx.cr[6].eq {
	pc = 0x831E8BBC; continue 'dispatch;
	}
	// 831E8BB0: 81550008  lwz r10, 8(r21)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E8BB4: 7F1F5040  cmplw cr6, r31, r10
	ctx.cr[6].compare_u32(ctx.r[31].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E8BB8: 419A0018  beq cr6, 0x831e8bd0
	if ctx.cr[6].eq {
	pc = 0x831E8BD0; continue 'dispatch;
	}
	// 831E8BBC: 7EA3AB78  mr r3, r21
	ctx.r[3].u64 = ctx.r[21].u64;
	// 831E8BC0: 48059EBD  bl 0x83242a7c
	ctx.lr = 0x831E8BC4;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E8BC4: 81750004  lwz r11, 4(r21)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E8BC8: 93F50008  stw r31, 8(r21)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(8 as u32), ctx.r[31].u32 ) };
	// 831E8BCC: 9BD5000C  stb r30, 0xc(r21)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[21].u32.wrapping_add(12 as u32), ctx.r[30].u8 ) };
	// 831E8BD0: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E8BD4: 91750004  stw r11, 4(r21)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E8BD8: 7F5BD378  mr r27, r26
	ctx.r[27].u64 = ctx.r[26].u64;
	// 831E8BDC: 2B1A0000  cmplwi cr6, r26, 0
	ctx.cr[6].compare_u32(ctx.r[26].u32, 0 as u32, &mut ctx.xer);
	// 831E8BE0: 409AFDEC  bne cr6, 0x831e89cc
	if !ctx.cr[6].eq {
	pc = 0x831E89CC; continue 'dispatch;
	}
	// 831E8BE4: 897D0124  lbz r11, 0x124(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(292 as u32) ) } as u64;
	// 831E8BE8: 2B0B0002  cmplwi cr6, r11, 2
	ctx.cr[6].compare_u32(ctx.r[11].u32, 2 as u32, &mut ctx.xer);
	// 831E8BEC: 409A0014  bne cr6, 0x831e8c00
	if !ctx.cr[6].eq {
	pc = 0x831E8C00; continue 'dispatch;
	}
	// 831E8BF0: 572B063E  clrlwi r11, r25, 0x18
	ctx.r[11].u64 = ctx.r[25].u32 as u64 & 0x000000FFu64;
	// 831E8BF4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E8BF8: 409A0008  bne cr6, 0x831e8c00
	if !ctx.cr[6].eq {
	pc = 0x831E8C00; continue 'dispatch;
	}
	// 831E8BFC: 7E98A378  mr r24, r20
	ctx.r[24].u64 = ctx.r[20].u64;
	// 831E8C00: 81550004  lwz r10, 4(r21)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E8C04: 7DAB6B78  mr r11, r13
	ctx.r[11].u64 = ctx.r[13].u64;
	// 831E8C08: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831E8C0C: 419A0044  beq cr6, 0x831e8c50
	if ctx.cr[6].eq {
	pc = 0x831E8C50; continue 'dispatch;
	}
	// 831E8C10: 81550008  lwz r10, 8(r21)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E8C14: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E8C18: 409A0038  bne cr6, 0x831e8c50
	if !ctx.cr[6].eq {
	pc = 0x831E8C50; continue 'dispatch;
	}
	// 831E8C1C: 81750004  lwz r11, 4(r21)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E8C20: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E8C24: 91750004  stw r11, 4(r21)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E8C28: 40820028  bne 0x831e8c50
	if !ctx.cr[0].eq {
	pc = 0x831E8C50; continue 'dispatch;
	}
	// 831E8C2C: 7E8BA378  mr r11, r20
	ctx.r[11].u64 = ctx.r[20].u64;
	// 831E8C30: 8BF5000C  lbz r31, 0xc(r21)
	ctx.r[31].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[21].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E8C34: 7E8AA378  mr r10, r20
	ctx.r[10].u64 = ctx.r[20].u64;
	// 831E8C38: 9975000C  stb r11, 0xc(r21)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[21].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E8C3C: 7EA3AB78  mr r3, r21
	ctx.r[3].u64 = ctx.r[21].u64;
	// 831E8C40: 91550008  stw r10, 8(r21)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E8C44: 48059E29  bl 0x83242a6c
	ctx.lr = 0x831E8C48;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E8C48: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E8C4C: 4805A521  bl 0x8324316c
	ctx.lr = 0x831E8C50;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E8C50: 570B063E  clrlwi r11, r24, 0x18
	ctx.r[11].u64 = ctx.r[24].u32 as u64 & 0x000000FFu64;
	// 831E8C54: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E8C58: 419A0360  beq cr6, 0x831e8fb8
	if ctx.cr[6].eq {
	pc = 0x831E8FB8; continue 'dispatch;
	}
	// 831E8C5C: 4805A501  bl 0x8324315c
	ctx.lr = 0x831E8C60;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E8C60: 81750004  lwz r11, 4(r21)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E8C64: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831E8C68: 7DBF6B78  mr r31, r13
	ctx.r[31].u64 = ctx.r[13].u64;
	// 831E8C6C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E8C70: 419A0010  beq cr6, 0x831e8c80
	if ctx.cr[6].eq {
	pc = 0x831E8C80; continue 'dispatch;
	}
	// 831E8C74: 81350008  lwz r9, 8(r21)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E8C78: 7F1F4840  cmplw cr6, r31, r9
	ctx.cr[6].compare_u32(ctx.r[31].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E8C7C: 419A001C  beq cr6, 0x831e8c98
	if ctx.cr[6].eq {
	pc = 0x831E8C98; continue 'dispatch;
	}
	// 831E8C80: 7EA3AB78  mr r3, r21
	ctx.r[3].u64 = ctx.r[21].u64;
	// 831E8C84: 48059DF9  bl 0x83242a7c
	ctx.lr = 0x831E8C88;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E8C88: 7FE9FB78  mr r9, r31
	ctx.r[9].u64 = ctx.r[31].u64;
	// 831E8C8C: 81750004  lwz r11, 4(r21)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E8C90: 9BD5000C  stb r30, 0xc(r21)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[21].u32.wrapping_add(12 as u32), ctx.r[30].u8 ) };
	// 831E8C94: 91350008  stw r9, 8(r21)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 831E8C98: 394B0001  addi r10, r11, 1
	ctx.r[10].s64 = ctx.r[11].s64 + 1;
	// 831E8C9C: 91550004  stw r10, 4(r21)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831E8CA0: 81730000  lwz r11, 0(r19)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E8CA4: 7F135840  cmplw cr6, r19, r11
	ctx.cr[6].compare_u32(ctx.r[19].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831E8CA8: 419A0010  beq cr6, 0x831e8cb8
	if ctx.cr[6].eq {
	pc = 0x831E8CB8; continue 'dispatch;
	}
	// 831E8CAC: 81130008  lwz r8, 8(r19)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E8CB0: 7FE85850  subf r31, r8, r11
	ctx.r[31].s64 = ctx.r[11].s64 - ctx.r[8].s64;
	// 831E8CB4: 48000008  b 0x831e8cbc
	pc = 0x831E8CBC; continue 'dispatch;
	// 831E8CB8: 7E9FA378  mr r31, r20
	ctx.r[31].u64 = ctx.r[20].u64;
	// 831E8CBC: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 831E8CC0: 419A02B4  beq cr6, 0x831e8f74
	if ctx.cr[6].eq {
	pc = 0x831E8F74; continue 'dispatch;
	}
	// 831E8CC4: 3AC00003  li r22, 3
	ctx.r[22].s64 = 3;
	// 831E8CC8: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E8CCC: 7F0BF840  cmplw cr6, r11, r31
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[31].u32, &mut ctx.xer);
	// 831E8CD0: 419A029C  beq cr6, 0x831e8f6c
	if ctx.cr[6].eq {
	pc = 0x831E8F6C; continue 'dispatch;
	}
	// 831E8CD4: 81730008  lwz r11, 8(r19)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E8CD8: 7D4BF82E  lwzx r10, r11, r31
	ctx.r[10].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[31].u32)) } as u64;
	// 831E8CDC: 7F135040  cmplw cr6, r19, r10
	ctx.cr[6].compare_u32(ctx.r[19].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E8CE0: 7EEB5050  subf r23, r11, r10
	ctx.r[23].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 831E8CE4: 409A0008  bne cr6, 0x831e8cec
	if !ctx.cr[6].eq {
	pc = 0x831E8CEC; continue 'dispatch;
	}
	// 831E8CE8: 7E97A378  mr r23, r20
	ctx.r[23].u64 = ctx.r[20].u64;
	// 831E8CEC: 897F0074  lbz r11, 0x74(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(116 as u32) ) } as u64;
	// 831E8CF0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E8CF4: 409A026C  bne cr6, 0x831e8f60
	if !ctx.cr[6].eq {
	pc = 0x831E8F60; continue 'dispatch;
	}
	// 831E8CF8: 897D0038  lbz r11, 0x38(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E8CFC: 3B000001  li r24, 1
	ctx.r[24].s64 = 1;
	// 831E8D00: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E8D04: 419A024C  beq cr6, 0x831e8f50
	if ctx.cr[6].eq {
	pc = 0x831E8F50; continue 'dispatch;
	}
	// 831E8D08: 7E9EA378  mr r30, r20
	ctx.r[30].u64 = ctx.r[20].u64;
	// 831E8D0C: 897D0124  lbz r11, 0x124(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(292 as u32) ) } as u64;
	// 831E8D10: 7E9CA378  mr r28, r20
	ctx.r[28].u64 = ctx.r[20].u64;
	// 831E8D14: 2B0B0002  cmplwi cr6, r11, 2
	ctx.cr[6].compare_u32(ctx.r[11].u32, 2 as u32, &mut ctx.xer);
	// 831E8D18: 409A000C  bne cr6, 0x831e8d24
	if !ctx.cr[6].eq {
	pc = 0x831E8D24; continue 'dispatch;
	}
	// 831E8D1C: 3B800001  li r28, 1
	ctx.r[28].s64 = 1;
	// 831E8D20: 4800001C  b 0x831e8d3c
	pc = 0x831E8D3C; continue 'dispatch;
	// 831E8D24: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 831E8D28: 419A0014  beq cr6, 0x831e8d3c
	if ctx.cr[6].eq {
	pc = 0x831E8D3C; continue 'dispatch;
	}
	// 831E8D2C: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 831E8D30: 807D00B8  lwz r3, 0xb8(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E8D34: 4BFF17BD  bl 0x831da4f0
	ctx.lr = 0x831E8D38;
	sub_831DA4F0(ctx, base);
	// 831E8D38: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E8D3C: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 831E8D40: 80DF000C  lwz r6, 0xc(r31)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E8D44: 80BF0008  lwz r5, 8(r31)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E8D48: 807D00B8  lwz r3, 0xb8(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E8D4C: 4BFF15E5  bl 0x831da330
	ctx.lr = 0x831E8D50;
	sub_831DA330(ctx, base);
	// 831E8D50: 2F1C0000  cmpwi cr6, r28, 0
	ctx.cr[6].compare_i32(ctx.r[28].s32, 0, &mut ctx.xer);
	// 831E8D54: 419A0050  beq cr6, 0x831e8da4
	if ctx.cr[6].eq {
	pc = 0x831E8DA4; continue 'dispatch;
	}
	// 831E8D58: 897D0124  lbz r11, 0x124(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(292 as u32) ) } as u64;
	// 831E8D5C: 2B0B0002  cmplwi cr6, r11, 2
	ctx.cr[6].compare_u32(ctx.r[11].u32, 2 as u32, &mut ctx.xer);
	// 831E8D60: 409A002C  bne cr6, 0x831e8d8c
	if !ctx.cr[6].eq {
	pc = 0x831E8D8C; continue 'dispatch;
	}
	// 831E8D64: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 831E8D68: 80DF001C  lwz r6, 0x1c(r31)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(28 as u32) ) } as u64;
	// 831E8D6C: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 831E8D70: 809F000C  lwz r4, 0xc(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E8D74: 807F0008  lwz r3, 8(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E8D78: 4BFFE9E9  bl 0x831e7760
	ctx.lr = 0x831E8D7C;
	sub_831E7760(ctx, base);
	// 831E8D7C: 817F001C  lwz r11, 0x1c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(28 as u32) ) } as u64;
	// 831E8D80: 7C651B78  mr r5, r3
	ctx.r[5].u64 = ctx.r[3].u64;
	// 831E8D84: 5566CFBE  rlwinm r6, r11, 0x19, 0x1e, 0x1f
	ctx.r[6].u64 = ctx.r[11].u32 as u64 & 0x0000007Fu64;
	// 831E8D88: 48000010  b 0x831e8d98
	pc = 0x831E8D98; continue 'dispatch;
	// 831E8D8C: 57CB7022  slwi r11, r30, 0xe
	ctx.r[11].u32 = ctx.r[30].u32.wrapping_shl(14);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831E8D90: 7E86A378  mr r6, r20
	ctx.r[6].u64 = ctx.r[20].u64;
	// 831E8D94: 38AB0020  addi r5, r11, 0x20
	ctx.r[5].s64 = ctx.r[11].s64 + 32;
	// 831E8D98: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 831E8D9C: 807D00B8  lwz r3, 0xb8(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E8DA0: 4BFF1DC1  bl 0x831dab60
	ctx.lr = 0x831E8DA4;
	sub_831DAB60(ctx, base);
	// 831E8DA4: 817F0010  lwz r11, 0x10(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E8DA8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E8DAC: 419A0144  beq cr6, 0x831e8ef0
	if ctx.cr[6].eq {
	pc = 0x831E8EF0; continue 'dispatch;
	}
	// 831E8DB0: 929D00BC  stw r20, 0xbc(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(188 as u32), ctx.r[20].u32 ) };
	// 831E8DB4: 3B7D00BC  addi r27, r29, 0xbc
	ctx.r[27].s64 = ctx.r[29].s64 + 188;
	// 831E8DB8: 929D00C0  stw r20, 0xc0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(192 as u32), ctx.r[20].u32 ) };
	// 831E8DBC: 929D00C4  stw r20, 0xc4(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(196 as u32), ctx.r[20].u32 ) };
	// 831E8DC0: 815F0010  lwz r10, 0x10(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E8DC4: 897D0124  lbz r11, 0x124(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(292 as u32) ) } as u64;
	// 831E8DC8: 2B0B0002  cmplwi cr6, r11, 2
	ctx.cr[6].compare_u32(ctx.r[11].u32, 2 as u32, &mut ctx.xer);
	// 831E8DCC: 995D00C6  stb r10, 0xc6(r29)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[29].u32.wrapping_add(198 as u32), ctx.r[10].u8 ) };
	// 831E8DD0: 409A00D8  bne cr6, 0x831e8ea8
	if !ctx.cr[6].eq {
	pc = 0x831E8EA8; continue 'dispatch;
	}
	// 831E8DD4: 817F0018  lwz r11, 0x18(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) } as u64;
	// 831E8DD8: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 831E8DDC: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 831E8DE0: 809F000C  lwz r4, 0xc(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E8DE4: 3B4BFF80  addi r26, r11, -0x80
	ctx.r[26].s64 = ctx.r[11].s64 + -128;
	// 831E8DE8: 807F0008  lwz r3, 8(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E8DEC: 7F46D378  mr r6, r26
	ctx.r[6].u64 = ctx.r[26].u64;
	// 831E8DF0: 4BFFE971  bl 0x831e7760
	ctx.lr = 0x831E8DF4;
	sub_831E7760(ctx, base);
	// 831E8DF4: 38E10050  addi r7, r1, 0x50
	ctx.r[7].s64 = ctx.r[1].s64 + 80;
	// 831E8DF8: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 831E8DFC: 80DF0014  lwz r6, 0x14(r31)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E8E00: 7C791B78  mr r25, r3
	ctx.r[25].u64 = ctx.r[3].u64;
	// 831E8E04: 809F000C  lwz r4, 0xc(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E8E08: 807F0008  lwz r3, 8(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E8E0C: 92810050  stw r20, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[20].u32 ) };
	// 831E8E10: 4BFFE951  bl 0x831e7760
	ctx.lr = 0x831E8E14;
	sub_831E7760(ctx, base);
	// 831E8E14: 80DF0014  lwz r6, 0x14(r31)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E8E18: 54DCCFBE  rlwinm r28, r6, 0x19, 0x1e, 0x1f
	ctx.r[28].u64 = ctx.r[6].u32 as u64 & 0x0000007Fu64;
	// 831E8E1C: 2B1C0000  cmplwi cr6, r28, 0
	ctx.cr[6].compare_u32(ctx.r[28].u32, 0 as u32, &mut ctx.xer);
	// 831E8E20: 409A0058  bne cr6, 0x831e8e78
	if !ctx.cr[6].eq {
	pc = 0x831E8E78; continue 'dispatch;
	}
	// 831E8E24: 2B060200  cmplwi cr6, r6, 0x200
	ctx.cr[6].compare_u32(ctx.r[6].u32, 512 as u32, &mut ctx.xer);
	// 831E8E28: 41980030  blt cr6, 0x831e8e58
	if ctx.cr[6].lt {
	pc = 0x831E8E58; continue 'dispatch;
	}
	// 831E8E2C: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831E8E30: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E8E34: 409A0058  bne cr6, 0x831e8e8c
	if !ctx.cr[6].eq {
	pc = 0x831E8E8C; continue 'dispatch;
	}
	// 831E8E38: 38C6FE00  addi r6, r6, -0x200
	ctx.r[6].s64 = ctx.r[6].s64 + -512;
	// 831E8E3C: 809F000C  lwz r4, 0xc(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E8E40: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 831E8E44: 807F0008  lwz r3, 8(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E8E48: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 831E8E4C: 4BFFE915  bl 0x831e7760
	ctx.lr = 0x831E8E50;
	sub_831E7760(ctx, base);
	// 831E8E50: 7E5C9378  mr r28, r18
	ctx.r[28].u64 = ctx.r[18].u64;
	// 831E8E54: 48000038  b 0x831e8e8c
	pc = 0x831E8E8C; continue 'dispatch;
	// 831E8E58: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 831E8E5C: 809F000C  lwz r4, 0xc(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E8E60: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 831E8E64: 807F0008  lwz r3, 8(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E8E68: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 831E8E6C: 4BFFE8F5  bl 0x831e7760
	ctx.lr = 0x831E8E70;
	sub_831E7760(ctx, base);
	// 831E8E70: 7E9CA378  mr r28, r20
	ctx.r[28].u64 = ctx.r[20].u64;
	// 831E8E74: 48000018  b 0x831e8e8c
	pc = 0x831E8E8C; continue 'dispatch;
	// 831E8E78: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 831E8E7C: 809F000C  lwz r4, 0xc(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E8E80: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 831E8E84: 807F0008  lwz r3, 8(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E8E88: 4BFFE8D9  bl 0x831e7760
	ctx.lr = 0x831E8E8C;
	sub_831E7760(ctx, base);
	// 831E8E8C: 574BCFBE  rlwinm r11, r26, 0x19, 0x1e, 0x1f
	ctx.r[11].u64 = ctx.r[26].u32 as u64 & 0x0000007Fu64;
	// 831E8E90: 907B0000  stw r3, 0(r27)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(0 as u32), ctx.r[3].u32 ) };
	// 831E8E94: 933D00C0  stw r25, 0xc0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(192 as u32), ctx.r[25].u32 ) };
	// 831E8E98: 7F65DB78  mr r5, r27
	ctx.r[5].u64 = ctx.r[27].u64;
	// 831E8E9C: 997D00C4  stb r11, 0xc4(r29)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[29].u32.wrapping_add(196 as u32), ctx.r[11].u8 ) };
	// 831E8EA0: 9B9D00C5  stb r28, 0xc5(r29)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[29].u32.wrapping_add(197 as u32), ctx.r[28].u8 ) };
	// 831E8EA4: 48000068  b 0x831e8f0c
	pc = 0x831E8F0C; continue 'dispatch;
	// 831E8EA8: 57CA083C  slwi r10, r30, 1
	ctx.r[10].u32 = ctx.r[30].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831E8EAC: 397E0004  addi r11, r30, 4
	ctx.r[11].s64 = ctx.r[30].s64 + 4;
	// 831E8EB0: 7D3E5214  add r9, r30, r10
	ctx.r[9].u64 = ctx.r[30].u64 + ctx.r[10].u64;
	// 831E8EB4: 556A083C  slwi r10, r11, 1
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831E8EB8: 5529103A  slwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831E8EBC: 7D0B5214  add r8, r11, r10
	ctx.r[8].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831E8EC0: 7D69FA14  add r11, r9, r31
	ctx.r[11].u64 = ctx.r[9].u64 + ctx.r[31].u64;
	// 831E8EC4: 5507103A  slwi r7, r8, 2
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831E8EC8: 80CB0028  lwz r6, 0x28(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(40 as u32) ) } as u64;
	// 831E8ECC: 90DB0000  stw r6, 0(r27)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(0 as u32), ctx.r[6].u32 ) };
	// 831E8ED0: 80AB002C  lwz r5, 0x2c(r11)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(44 as u32) ) } as u64;
	// 831E8ED4: 90BD00C0  stw r5, 0xc0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(192 as u32), ctx.r[5].u32 ) };
	// 831E8ED8: 7F65DB78  mr r5, r27
	ctx.r[5].u64 = ctx.r[27].u64;
	// 831E8EDC: 7C87F8AE  lbzx r4, r7, r31
	ctx.r[4].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[7].u32.wrapping_add(ctx.r[31].u32)) } as u64;
	// 831E8EE0: 989D00C4  stb r4, 0xc4(r29)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[29].u32.wrapping_add(196 as u32), ctx.r[4].u8 ) };
	// 831E8EE4: 886B0031  lbz r3, 0x31(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(49 as u32) ) } as u64;
	// 831E8EE8: 987D00C5  stb r3, 0xc5(r29)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[29].u32.wrapping_add(197 as u32), ctx.r[3].u8 ) };
	// 831E8EEC: 48000020  b 0x831e8f0c
	pc = 0x831E8F0C; continue 'dispatch;
	// 831E8EF0: 897D0124  lbz r11, 0x124(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(292 as u32) ) } as u64;
	// 831E8EF4: 2B0B0002  cmplwi cr6, r11, 2
	ctx.cr[6].compare_u32(ctx.r[11].u32, 2 as u32, &mut ctx.xer);
	// 831E8EF8: 409A0020  bne cr6, 0x831e8f18
	if !ctx.cr[6].eq {
	pc = 0x831E8F18; continue 'dispatch;
	}
	// 831E8EFC: 929D00BC  stw r20, 0xbc(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(188 as u32), ctx.r[20].u32 ) };
	// 831E8F00: 38BD00BC  addi r5, r29, 0xbc
	ctx.r[5].s64 = ctx.r[29].s64 + 188;
	// 831E8F04: 929D00C0  stw r20, 0xc0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(192 as u32), ctx.r[20].u32 ) };
	// 831E8F08: 929D00C4  stw r20, 0xc4(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(196 as u32), ctx.r[20].u32 ) };
	// 831E8F0C: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 831E8F10: 807D00B8  lwz r3, 0xb8(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E8F14: 4BFF1AE5  bl 0x831da9f8
	ctx.lr = 0x831E8F18;
	sub_831DA9F8(ctx, base);
	// 831E8F18: 897D0124  lbz r11, 0x124(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(292 as u32) ) } as u64;
	// 831E8F1C: 2B0B0002  cmplwi cr6, r11, 2
	ctx.cr[6].compare_u32(ctx.r[11].u32, 2 as u32, &mut ctx.xer);
	// 831E8F20: 419A0018  beq cr6, 0x831e8f38
	if ctx.cr[6].eq {
	pc = 0x831E8F38; continue 'dispatch;
	}
	// 831E8F24: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 831E8F28: 807D00B8  lwz r3, 0xb8(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E8F2C: 4BFF155D  bl 0x831da488
	ctx.lr = 0x831E8F30;
	sub_831DA488(ctx, base);
	// 831E8F30: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E8F34: 409A0008  bne cr6, 0x831e8f3c
	if !ctx.cr[6].eq {
	pc = 0x831E8F3C; continue 'dispatch;
	}
	// 831E8F38: 7E98A378  mr r24, r20
	ctx.r[24].u64 = ctx.r[20].u64;
	// 831E8F3C: 397E0001  addi r11, r30, 1
	ctx.r[11].s64 = ctx.r[30].s64 + 1;
	// 831E8F40: 895D0038  lbz r10, 0x38(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E8F44: 557E063E  clrlwi r30, r11, 0x18
	ctx.r[30].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 831E8F48: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E8F4C: 4198FDC0  blt cr6, 0x831e8d0c
	if ctx.cr[6].lt {
	pc = 0x831E8D0C; continue 'dispatch;
	}
	// 831E8F50: 570B063E  clrlwi r11, r24, 0x18
	ctx.r[11].u64 = ctx.r[24].u32 as u64 & 0x000000FFu64;
	// 831E8F54: 9ADF0074  stb r22, 0x74(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(116 as u32), ctx.r[22].u8 ) };
	// 831E8F58: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E8F5C: 419A0010  beq cr6, 0x831e8f6c
	if ctx.cr[6].eq {
	pc = 0x831E8F6C; continue 'dispatch;
	}
	// 831E8F60: 7EFFBB78  mr r31, r23
	ctx.r[31].u64 = ctx.r[23].u64;
	// 831E8F64: 2B170000  cmplwi cr6, r23, 0
	ctx.cr[6].compare_u32(ctx.r[23].u32, 0 as u32, &mut ctx.xer);
	// 831E8F68: 409AFD60  bne cr6, 0x831e8cc8
	if !ctx.cr[6].eq {
	pc = 0x831E8CC8; continue 'dispatch;
	}
	// 831E8F6C: 81350008  lwz r9, 8(r21)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E8F70: 81550004  lwz r10, 4(r21)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E8F74: 7DAB6B78  mr r11, r13
	ctx.r[11].u64 = ctx.r[13].u64;
	// 831E8F78: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831E8F7C: 419A003C  beq cr6, 0x831e8fb8
	if ctx.cr[6].eq {
	pc = 0x831E8FB8; continue 'dispatch;
	}
	// 831E8F80: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E8F84: 409A0034  bne cr6, 0x831e8fb8
	if !ctx.cr[6].eq {
	pc = 0x831E8FB8; continue 'dispatch;
	}
	// 831E8F88: 356AFFFF  addic. r11, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E8F8C: 91750004  stw r11, 4(r21)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E8F90: 40820028  bne 0x831e8fb8
	if !ctx.cr[0].eq {
	pc = 0x831E8FB8; continue 'dispatch;
	}
	// 831E8F94: 7E8BA378  mr r11, r20
	ctx.r[11].u64 = ctx.r[20].u64;
	// 831E8F98: 8BF5000C  lbz r31, 0xc(r21)
	ctx.r[31].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[21].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E8F9C: 7E8AA378  mr r10, r20
	ctx.r[10].u64 = ctx.r[20].u64;
	// 831E8FA0: 9975000C  stb r11, 0xc(r21)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[21].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E8FA4: 7EA3AB78  mr r3, r21
	ctx.r[3].u64 = ctx.r[21].u64;
	// 831E8FA8: 91550008  stw r10, 8(r21)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E8FAC: 48059AC1  bl 0x83242a6c
	ctx.lr = 0x831E8FB0;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E8FB0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E8FB4: 4805A1B9  bl 0x8324316c
	ctx.lr = 0x831E8FB8;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E8FB8: 817D0078  lwz r11, 0x78(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(120 as u32) ) } as u64;
	// 831E8FBC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E8FC0: 419A0054  beq cr6, 0x831e9014
	if ctx.cr[6].eq {
	pc = 0x831E9014; continue 'dispatch;
	}
	// 831E8FC4: 897D0038  lbz r11, 0x38(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E8FC8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E8FCC: 419A0044  beq cr6, 0x831e9010
	if ctx.cr[6].eq {
	pc = 0x831E9010; continue 'dispatch;
	}
	// 831E8FD0: 7E9FA378  mr r31, r20
	ctx.r[31].u64 = ctx.r[20].u64;
	// 831E8FD4: 57EB1838  slwi r11, r31, 3
	ctx.r[11].u32 = ctx.r[31].u32.wrapping_shl(3);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831E8FD8: 807D00B8  lwz r3, 0xb8(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E8FDC: 395F000F  addi r10, r31, 0xf
	ctx.r[10].s64 = ctx.r[31].s64 + 15;
	// 831E8FE0: 7D2BEA14  add r9, r11, r29
	ctx.r[9].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 831E8FE4: 55481838  slwi r8, r10, 3
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shl(3);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831E8FE8: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831E8FEC: A0E9007C  lhz r7, 0x7c(r9)
	ctx.r[7].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(124 as u32) ) } as u64;
	// 831E8FF0: 7CA8E82E  lwzx r5, r8, r29
	ctx.r[5].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[8].u32.wrapping_add(ctx.r[29].u32)) } as u64;
	// 831E8FF4: 54E6C9FE  srwi r6, r7, 7
	ctx.r[6].u32 = ctx.r[7].u32.wrapping_shr(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831E8FF8: 4BFF1B69  bl 0x831dab60
	ctx.lr = 0x831E8FFC;
	sub_831DAB60(ctx, base);
	// 831E8FFC: 38DF0001  addi r6, r31, 1
	ctx.r[6].s64 = ctx.r[31].s64 + 1;
	// 831E9000: 88BD0038  lbz r5, 0x38(r29)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E9004: 54DF063E  clrlwi r31, r6, 0x18
	ctx.r[31].u64 = ctx.r[6].u32 as u64 & 0x000000FFu64;
	// 831E9008: 7F1F2840  cmplw cr6, r31, r5
	ctx.cr[6].compare_u32(ctx.r[31].u32, ctx.r[5].u32, &mut ctx.xer);
	// 831E900C: 4198FFC8  blt cr6, 0x831e8fd4
	if ctx.cr[6].lt {
	pc = 0x831E8FD4; continue 'dispatch;
	}
	// 831E9010: 929D0078  stw r20, 0x78(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(120 as u32), ctx.r[20].u32 ) };
	// 831E9014: 897D0038  lbz r11, 0x38(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E9018: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E901C: 419A0048  beq cr6, 0x831e9064
	if ctx.cr[6].eq {
	pc = 0x831E9064; continue 'dispatch;
	}
	// 831E9020: 7E9FA378  mr r31, r20
	ctx.r[31].u64 = ctx.r[20].u64;
	// 831E9024: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831E9028: 807D00B8  lwz r3, 0xb8(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E902C: 4BFF14C5  bl 0x831da4f0
	ctx.lr = 0x831E9030;
	sub_831DA4F0(ctx, base);
	// 831E9030: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E9034: 409A001C  bne cr6, 0x831e9050
	if !ctx.cr[6].eq {
	pc = 0x831E9050; continue 'dispatch;
	}
	// 831E9038: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831E903C: 807D00B8  lwz r3, 0xb8(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E9040: 4BFF1939  bl 0x831da978
	ctx.lr = 0x831E9044;
	sub_831DA978(ctx, base);
	// 831E9044: 546B0738  rlwinm r11, r3, 0, 0x1c, 0x1c
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0xFFFFFFFFu64;
	// 831E9048: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E904C: 419AF810  beq cr6, 0x831e885c
	if ctx.cr[6].eq {
	pc = 0x831E885C; continue 'dispatch;
	}
	// 831E9050: 397F0001  addi r11, r31, 1
	ctx.r[11].s64 = ctx.r[31].s64 + 1;
	// 831E9054: 895D0038  lbz r10, 0x38(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E9058: 557F063E  clrlwi r31, r11, 0x18
	ctx.r[31].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 831E905C: 7F1F5040  cmplw cr6, r31, r10
	ctx.cr[6].compare_u32(ctx.r[31].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E9060: 4198FFC4  blt cr6, 0x831e9024
	if ctx.cr[6].lt {
	pc = 0x831E9024; continue 'dispatch;
	}
	// 831E9064: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E9068: 382100E0  addi r1, r1, 0xe0
	ctx.r[1].s64 = ctx.r[1].s64 + 224;
	// 831E906C: 4BFBF124  b 0x831a8190
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E9070(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E9070 size=652
    let mut pc: u32 = 0x831E9070;
    'dispatch: loop {
        match pc {
            0x831E9070 => {
    //   block [0x831E9070..0x831E92FC)
	// 831E9070: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E9074: 4BFBF0E5  bl 0x831a8158
	ctx.lr = 0x831E9078;
	sub_831A8130(ctx, base);
	// 831E9078: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E907C: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E9080: 3B000001  li r24, 1
	ctx.r[24].s64 = 1;
	// 831E9084: 3B200000  li r25, 0
	ctx.r[25].s64 = 0;
	// 831E9088: 7F1DC378  mr r29, r24
	ctx.r[29].u64 = ctx.r[24].u64;
	// 831E908C: 897C0038  lbz r11, 0x38(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E9090: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E9094: 419A003C  beq cr6, 0x831e90d0
	if ctx.cr[6].eq {
	pc = 0x831E90D0; continue 'dispatch;
	}
	// 831E9098: 7F3FCB78  mr r31, r25
	ctx.r[31].u64 = ctx.r[25].u64;
	// 831E909C: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831E90A0: 807C00B8  lwz r3, 0xb8(r28)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E90A4: 4BFF144D  bl 0x831da4f0
	ctx.lr = 0x831E90A8;
	sub_831DA4F0(ctx, base);
	// 831E90A8: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E90AC: 419A0020  beq cr6, 0x831e90cc
	if ctx.cr[6].eq {
	pc = 0x831E90CC; continue 'dispatch;
	}
	// 831E90B0: 397F0001  addi r11, r31, 1
	ctx.r[11].s64 = ctx.r[31].s64 + 1;
	// 831E90B4: 895C0038  lbz r10, 0x38(r28)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E90B8: 556B063E  clrlwi r11, r11, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 831E90BC: 7D7F5B78  mr r31, r11
	ctx.r[31].u64 = ctx.r[11].u64;
	// 831E90C0: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E90C4: 4198FFD8  blt cr6, 0x831e909c
	if ctx.cr[6].lt {
	pc = 0x831E909C; continue 'dispatch;
	}
	// 831E90C8: 48000008  b 0x831e90d0
	pc = 0x831E90D0; continue 'dispatch;
	// 831E90CC: 7F3DCB78  mr r29, r25
	ctx.r[29].u64 = ctx.r[25].u64;
	// 831E90D0: 4805A08D  bl 0x8324315c
	ctx.lr = 0x831E90D4;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E90D4: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E90D8: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831E90DC: 3B6BD530  addi r27, r11, -0x2ad0
	ctx.r[27].s64 = ctx.r[11].s64 + -10960;
	// 831E90E0: 7DBF6B78  mr r31, r13
	ctx.r[31].u64 = ctx.r[13].u64;
	// 831E90E4: 815B0004  lwz r10, 4(r27)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E90E8: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831E90EC: 419A0010  beq cr6, 0x831e90fc
	if ctx.cr[6].eq {
	pc = 0x831E90FC; continue 'dispatch;
	}
	// 831E90F0: 817B0008  lwz r11, 8(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E90F4: 7F1F5840  cmplw cr6, r31, r11
	ctx.cr[6].compare_u32(ctx.r[31].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831E90F8: 419A0018  beq cr6, 0x831e9110
	if ctx.cr[6].eq {
	pc = 0x831E9110; continue 'dispatch;
	}
	// 831E90FC: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 831E9100: 4805997D  bl 0x83242a7c
	ctx.lr = 0x831E9104;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E9104: 815B0004  lwz r10, 4(r27)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E9108: 93FB0008  stw r31, 8(r27)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(8 as u32), ctx.r[31].u32 ) };
	// 831E910C: 9BDB000C  stb r30, 0xc(r27)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[27].u32.wrapping_add(12 as u32), ctx.r[30].u8 ) };
	// 831E9110: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 831E9114: 397C0014  addi r11, r28, 0x14
	ctx.r[11].s64 = ctx.r[28].s64 + 20;
	// 831E9118: 915B0004  stw r10, 4(r27)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831E911C: 813C0014  lwz r9, 0x14(r28)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E9120: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E9124: 419A0188  beq cr6, 0x831e92ac
	if ctx.cr[6].eq {
	pc = 0x831E92AC; continue 'dispatch;
	}
	// 831E9128: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E912C: 7FCB4850  subf r30, r11, r9
	ctx.r[30].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 831E9130: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 831E9134: 419A0178  beq cr6, 0x831e92ac
	if ctx.cr[6].eq {
	pc = 0x831E92AC; continue 'dispatch;
	}
	// 831E9138: 897E0074  lbz r11, 0x74(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(116 as u32) ) } as u64;
	// 831E913C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E9140: 419A016C  beq cr6, 0x831e92ac
	if ctx.cr[6].eq {
	pc = 0x831E92AC; continue 'dispatch;
	}
	// 831E9144: 817E0020  lwz r11, 0x20(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) } as u64;
	// 831E9148: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E914C: 419A0160  beq cr6, 0x831e92ac
	if ctx.cr[6].eq {
	pc = 0x831E92AC; continue 'dispatch;
	}
	// 831E9150: 897E0076  lbz r11, 0x76(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(118 as u32) ) } as u64;
	// 831E9154: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E9158: 419A0058  beq cr6, 0x831e91b0
	if ctx.cr[6].eq {
	pc = 0x831E91B0; continue 'dispatch;
	}
	// 831E915C: 57AB063E  clrlwi r11, r29, 0x18
	ctx.r[11].u64 = ctx.r[29].u32 as u64 & 0x000000FFu64;
	// 831E9160: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E9164: 419A0148  beq cr6, 0x831e92ac
	if ctx.cr[6].eq {
	pc = 0x831E92AC; continue 'dispatch;
	}
	// 831E9168: 897E0077  lbz r11, 0x77(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(119 as u32) ) } as u64;
	// 831E916C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E9170: 409A013C  bne cr6, 0x831e92ac
	if !ctx.cr[6].eq {
	pc = 0x831E92AC; continue 'dispatch;
	}
	// 831E9174: 897C0038  lbz r11, 0x38(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E9178: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E917C: 419A002C  beq cr6, 0x831e91a8
	if ctx.cr[6].eq {
	pc = 0x831E91A8; continue 'dispatch;
	}
	// 831E9180: 7F3FCB78  mr r31, r25
	ctx.r[31].u64 = ctx.r[25].u64;
	// 831E9184: 38A00080  li r5, 0x80
	ctx.r[5].s64 = 128;
	// 831E9188: 807C00B8  lwz r3, 0xb8(r28)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E918C: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831E9190: 4BFF16B1  bl 0x831da840
	ctx.lr = 0x831E9194;
	sub_831DA840(ctx, base);
	// 831E9194: 397F0001  addi r11, r31, 1
	ctx.r[11].s64 = ctx.r[31].s64 + 1;
	// 831E9198: 895C0038  lbz r10, 0x38(r28)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E919C: 557F063E  clrlwi r31, r11, 0x18
	ctx.r[31].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 831E91A0: 7F1F5040  cmplw cr6, r31, r10
	ctx.cr[6].compare_u32(ctx.r[31].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E91A4: 4198FFE0  blt cr6, 0x831e9184
	if ctx.cr[6].lt {
	pc = 0x831E9184; continue 'dispatch;
	}
	// 831E91A8: 9B1E0077  stb r24, 0x77(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(119 as u32), ctx.r[24].u8 ) };
	// 831E91AC: 480000FC  b 0x831e92a8
	pc = 0x831E92A8; continue 'dispatch;
	// 831E91B0: 817E0010  lwz r11, 0x10(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E91B4: 7F1DC378  mr r29, r24
	ctx.r[29].u64 = ctx.r[24].u64;
	// 831E91B8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E91BC: 419A004C  beq cr6, 0x831e9208
	if ctx.cr[6].eq {
	pc = 0x831E9208; continue 'dispatch;
	}
	// 831E91C0: 897C0038  lbz r11, 0x38(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E91C4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E91C8: 419A0040  beq cr6, 0x831e9208
	if ctx.cr[6].eq {
	pc = 0x831E9208; continue 'dispatch;
	}
	// 831E91CC: 7F3FCB78  mr r31, r25
	ctx.r[31].u64 = ctx.r[25].u64;
	// 831E91D0: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831E91D4: 807C00B8  lwz r3, 0xb8(r28)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E91D8: 4BFF1899  bl 0x831daa70
	ctx.lr = 0x831E91DC;
	sub_831DAA70(ctx, base);
	// 831E91DC: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E91E0: 409A0020  bne cr6, 0x831e9200
	if !ctx.cr[6].eq {
	pc = 0x831E9200; continue 'dispatch;
	}
	// 831E91E4: 397F0001  addi r11, r31, 1
	ctx.r[11].s64 = ctx.r[31].s64 + 1;
	// 831E91E8: 895C0038  lbz r10, 0x38(r28)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E91EC: 556B063E  clrlwi r11, r11, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 831E91F0: 7D7F5B78  mr r31, r11
	ctx.r[31].u64 = ctx.r[11].u64;
	// 831E91F4: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E91F8: 4198FFD8  blt cr6, 0x831e91d0
	if ctx.cr[6].lt {
	pc = 0x831E91D0; continue 'dispatch;
	}
	// 831E91FC: 48000008  b 0x831e9204
	pc = 0x831E9204; continue 'dispatch;
	// 831E9200: 7F3DCB78  mr r29, r25
	ctx.r[29].u64 = ctx.r[25].u64;
	// 831E9204: 815B0004  lwz r10, 4(r27)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E9208: 57AB063E  clrlwi r11, r29, 0x18
	ctx.r[11].u64 = ctx.r[29].u32 as u64 & 0x000000FFu64;
	// 831E920C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E9210: 419A009C  beq cr6, 0x831e92ac
	if ctx.cr[6].eq {
	pc = 0x831E92AC; continue 'dispatch;
	}
	// 831E9214: 897C0038  lbz r11, 0x38(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E9218: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E921C: 419A0088  beq cr6, 0x831e92a4
	if ctx.cr[6].eq {
	pc = 0x831E92A4; continue 'dispatch;
	}
	// 831E9220: 7F3FCB78  mr r31, r25
	ctx.r[31].u64 = ctx.r[25].u64;
	// 831E9224: 3B400003  li r26, 3
	ctx.r[26].s64 = 3;
	// 831E9228: 39410054  addi r10, r1, 0x54
	ctx.r[10].s64 = ctx.r[1].s64 + 84;
	// 831E922C: 93210050  stw r25, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[25].u32 ) };
	// 831E9230: 817E0020  lwz r11, 0x20(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) } as u64;
	// 831E9234: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 831E9238: 7FE5FB78  mr r5, r31
	ctx.r[5].u64 = ctx.r[31].u64;
	// 831E923C: 809E000C  lwz r4, 0xc(r30)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E9240: 3BABFF80  addi r29, r11, -0x80
	ctx.r[29].s64 = ctx.r[11].s64 + -128;
	// 831E9244: 807E0008  lwz r3, 8(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E9248: 932A0000  stw r25, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[25].u32 ) };
	// 831E924C: 7FA6EB78  mr r6, r29
	ctx.r[6].u64 = ctx.r[29].u64;
	// 831E9250: 932A0004  stw r25, 4(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), ctx.r[25].u32 ) };
	// 831E9254: 9B01005A  stb r24, 0x5a(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(90 as u32), ctx.r[24].u8 ) };
	// 831E9258: 4BFFE509  bl 0x831e7760
	ctx.lr = 0x831E925C;
	sub_831E7760(ctx, base);
	// 831E925C: 57A9CFBE  rlwinm r9, r29, 0x19, 0x1e, 0x1f
	ctx.r[9].u64 = ctx.r[29].u32 as u64 & 0x0000007Fu64;
	// 831E9260: 90610054  stw r3, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[3].u32 ) };
	// 831E9264: 7FE5FB78  mr r5, r31
	ctx.r[5].u64 = ctx.r[31].u64;
	// 831E9268: 99210058  stb r9, 0x58(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[9].u8 ) };
	// 831E926C: 809E000C  lwz r4, 0xc(r30)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E9270: 807E0008  lwz r3, 8(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E9274: 4BFFE5B5  bl 0x831e7828
	ctx.lr = 0x831E9278;
	sub_831E7828(ctx, base);
	// 831E9278: 90610050  stw r3, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[3].u32 ) };
	// 831E927C: 9B410059  stb r26, 0x59(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(89 as u32), ctx.r[26].u8 ) };
	// 831E9280: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 831E9284: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831E9288: 807C00B8  lwz r3, 0xb8(r28)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E928C: 4BFF176D  bl 0x831da9f8
	ctx.lr = 0x831E9290;
	sub_831DA9F8(ctx, base);
	// 831E9290: 391F0001  addi r8, r31, 1
	ctx.r[8].s64 = ctx.r[31].s64 + 1;
	// 831E9294: 88FC0038  lbz r7, 0x38(r28)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E9298: 551F063E  clrlwi r31, r8, 0x18
	ctx.r[31].u64 = ctx.r[8].u32 as u64 & 0x000000FFu64;
	// 831E929C: 7F1F3840  cmplw cr6, r31, r7
	ctx.cr[6].compare_u32(ctx.r[31].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831E92A0: 4198FF88  blt cr6, 0x831e9228
	if ctx.cr[6].lt {
	pc = 0x831E9228; continue 'dispatch;
	}
	// 831E92A4: 9B1E0076  stb r24, 0x76(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(118 as u32), ctx.r[24].u8 ) };
	// 831E92A8: 815B0004  lwz r10, 4(r27)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E92AC: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831E92B0: 7DAB6B78  mr r11, r13
	ctx.r[11].u64 = ctx.r[13].u64;
	// 831E92B4: 419A0040  beq cr6, 0x831e92f4
	if ctx.cr[6].eq {
	pc = 0x831E92F4; continue 'dispatch;
	}
	// 831E92B8: 813B0008  lwz r9, 8(r27)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E92BC: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E92C0: 409A0034  bne cr6, 0x831e92f4
	if !ctx.cr[6].eq {
	pc = 0x831E92F4; continue 'dispatch;
	}
	// 831E92C4: 356AFFFF  addic. r11, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E92C8: 917B0004  stw r11, 4(r27)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E92CC: 40820028  bne 0x831e92f4
	if !ctx.cr[0].eq {
	pc = 0x831E92F4; continue 'dispatch;
	}
	// 831E92D0: 7F2BCB78  mr r11, r25
	ctx.r[11].u64 = ctx.r[25].u64;
	// 831E92D4: 8BFB000C  lbz r31, 0xc(r27)
	ctx.r[31].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[27].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E92D8: 7F2ACB78  mr r10, r25
	ctx.r[10].u64 = ctx.r[25].u64;
	// 831E92DC: 997B000C  stb r11, 0xc(r27)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[27].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E92E0: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 831E92E4: 915B0008  stw r10, 8(r27)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E92E8: 48059785  bl 0x83242a6c
	ctx.lr = 0x831E92EC;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E92EC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E92F0: 48059E7D  bl 0x8324316c
	ctx.lr = 0x831E92F4;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E92F4: 382100B0  addi r1, r1, 0xb0
	ctx.r[1].s64 = ctx.r[1].s64 + 176;
	// 831E92F8: 4BFBEEB0  b 0x831a81a8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E9300(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E9300 size=436
    let mut pc: u32 = 0x831E9300;
    'dispatch: loop {
        match pc {
            0x831E9300 => {
    //   block [0x831E9300..0x831E94B4)
	// 831E9300: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E9304: 4BFBEE61  bl 0x831a8164
	ctx.lr = 0x831E9308;
	sub_831A8130(ctx, base);
	// 831E9308: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E930C: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831E9310: 3B600000  li r27, 0
	ctx.r[27].s64 = 0;
	// 831E9314: 897D0108  lbz r11, 0x108(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(264 as u32) ) } as u64;
	// 831E9318: 556A07BC  rlwinm r10, r11, 0, 0x1e, 0x1e
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831E931C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E9320: 419A00A0  beq cr6, 0x831e93c0
	if ctx.cr[6].eq {
	pc = 0x831E93C0; continue 'dispatch;
	}
	// 831E9324: 3BFD0128  addi r31, r29, 0x128
	ctx.r[31].s64 = ctx.r[29].s64 + 296;
	// 831E9328: 48059E35  bl 0x8324315c
	ctx.lr = 0x831E932C;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E932C: 817D012C  lwz r11, 0x12c(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(300 as u32) ) } as u64;
	// 831E9330: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E9334: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831E9338: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E933C: 419A0010  beq cr6, 0x831e934c
	if ctx.cr[6].eq {
	pc = 0x831E934C; continue 'dispatch;
	}
	// 831E9340: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E9344: 7F1E5840  cmplw cr6, r30, r11
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831E9348: 419A0014  beq cr6, 0x831e935c
	if ctx.cr[6].eq {
	pc = 0x831E935C; continue 'dispatch;
	}
	// 831E934C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E9350: 4805972D  bl 0x83242a7c
	ctx.lr = 0x831E9354;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E9354: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 831E9358: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831E935C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E9360: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E9364: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E9368: 807D00B8  lwz r3, 0xb8(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E936C: 4BFF184D  bl 0x831dabb8
	ctx.lr = 0x831E9370;
	sub_831DABB8(ctx, base);
	// 831E9370: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E9374: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831E9378: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E937C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E9380: 419A0038  beq cr6, 0x831e93b8
	if ctx.cr[6].eq {
	pc = 0x831E93B8; continue 'dispatch;
	}
	// 831E9384: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E9388: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E938C: 409A002C  bne cr6, 0x831e93b8
	if !ctx.cr[6].eq {
	pc = 0x831E93B8; continue 'dispatch;
	}
	// 831E9390: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E9394: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E9398: 40820020  bne 0x831e93b8
	if !ctx.cr[0].eq {
	pc = 0x831E93B8; continue 'dispatch;
	}
	// 831E939C: 8B9F000C  lbz r28, 0xc(r31)
	ctx.r[28].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E93A0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E93A4: 9B7F000C  stb r27, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[27].u8 ) };
	// 831E93A8: 937F0008  stw r27, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[27].u32 ) };
	// 831E93AC: 480596C1  bl 0x83242a6c
	ctx.lr = 0x831E93B0;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E93B0: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 831E93B4: 48059DB9  bl 0x8324316c
	ctx.lr = 0x831E93B8;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E93B8: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 831E93BC: 419800EC  blt cr6, 0x831e94a8
	if ctx.cr[6].lt {
	pc = 0x831E94A8; continue 'dispatch;
	}
	// 831E93C0: 3BDD0010  addi r30, r29, 0x10
	ctx.r[30].s64 = ctx.r[29].s64 + 16;
	// 831E93C4: 48059D99  bl 0x8324315c
	ctx.lr = 0x831E93C8;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E93C8: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E93CC: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E93D0: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831E93D4: 7DBD6B78  mr r29, r13
	ctx.r[29].u64 = ctx.r[13].u64;
	// 831E93D8: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E93DC: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E93E0: 419A0010  beq cr6, 0x831e93f0
	if ctx.cr[6].eq {
	pc = 0x831E93F0; continue 'dispatch;
	}
	// 831E93E4: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E93E8: 7F1D5040  cmplw cr6, r29, r10
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E93EC: 419A0018  beq cr6, 0x831e9404
	if ctx.cr[6].eq {
	pc = 0x831E9404; continue 'dispatch;
	}
	// 831E93F0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E93F4: 48059689  bl 0x83242a7c
	ctx.lr = 0x831E93F8;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E93F8: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E93FC: 93BF0008  stw r29, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 831E9400: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 831E9404: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E9408: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E940C: 895E009C  lbz r10, 0x9c(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(156 as u32) ) } as u64;
	// 831E9410: 554907FE  clrlwi r9, r10, 0x1f
	ctx.r[9].u64 = ctx.r[10].u32 as u64 & 0x00000001u64;
	// 831E9414: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831E9418: 409A0010  bne cr6, 0x831e9428
	if !ctx.cr[6].eq {
	pc = 0x831E9428; continue 'dispatch;
	}
	// 831E941C: 38A00003  li r5, 3
	ctx.r[5].s64 = 3;
	// 831E9420: 38800003  li r4, 3
	ctx.r[4].s64 = 3;
	// 831E9424: 48000018  b 0x831e943c
	pc = 0x831E943C; continue 'dispatch;
	// 831E9428: 554A077A  rlwinm r10, r10, 0, 0x1d, 0x1d
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0xFFFFFFFFu64;
	// 831E942C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E9430: 419A0024  beq cr6, 0x831e9454
	if ctx.cr[6].eq {
	pc = 0x831E9454; continue 'dispatch;
	}
	// 831E9434: 38A00002  li r5, 2
	ctx.r[5].s64 = 2;
	// 831E9438: 38800006  li r4, 6
	ctx.r[4].s64 = 6;
	// 831E943C: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E9440: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E9444: 814B0054  lwz r10, 0x54(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(84 as u32) ) } as u64;
	// 831E9448: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E944C: 4E800421  bctrl
	ctx.lr = 0x831E9450;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E9450: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E9454: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E9458: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E945C: 419A0040  beq cr6, 0x831e949c
	if ctx.cr[6].eq {
	pc = 0x831E949C; continue 'dispatch;
	}
	// 831E9460: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E9464: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E9468: 409A0034  bne cr6, 0x831e949c
	if !ctx.cr[6].eq {
	pc = 0x831E949C; continue 'dispatch;
	}
	// 831E946C: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E9470: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E9474: 40820028  bne 0x831e949c
	if !ctx.cr[0].eq {
	pc = 0x831E949C; continue 'dispatch;
	}
	// 831E9478: 7F6BDB78  mr r11, r27
	ctx.r[11].u64 = ctx.r[27].u64;
	// 831E947C: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E9480: 7F6ADB78  mr r10, r27
	ctx.r[10].u64 = ctx.r[27].u64;
	// 831E9484: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E9488: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E948C: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E9490: 480595DD  bl 0x83242a6c
	ctx.lr = 0x831E9494;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E9494: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E9498: 48059CD5  bl 0x8324316c
	ctx.lr = 0x831E949C;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E949C: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 831E94A0: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E94A4: 4BFBED10  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
	// 831E94A8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E94AC: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E94B0: 4BFBED04  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E94B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E94B8 size=480
    let mut pc: u32 = 0x831E94B8;
    'dispatch: loop {
        match pc {
            0x831E94B8 => {
    //   block [0x831E94B8..0x831E9698)
	// 831E94B8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E94BC: 4BFBECA5  bl 0x831a8160
	ctx.lr = 0x831E94C0;
	sub_831A8130(ctx, base);
	// 831E94C0: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E94C4: 549B07FE  clrlwi r27, r4, 0x1f
	ctx.r[27].u64 = ctx.r[4].u32 as u64 & 0x00000001u64;
	// 831E94C8: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831E94CC: 3B400000  li r26, 0
	ctx.r[26].s64 = 0;
	// 831E94D0: 2B1B0000  cmplwi cr6, r27, 0
	ctx.cr[6].compare_u32(ctx.r[27].u32, 0 as u32, &mut ctx.xer);
	// 831E94D4: 419A00A4  beq cr6, 0x831e9578
	if ctx.cr[6].eq {
	pc = 0x831E9578; continue 'dispatch;
	}
	// 831E94D8: 897D0108  lbz r11, 0x108(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(264 as u32) ) } as u64;
	// 831E94DC: 556A07BC  rlwinm r10, r11, 0, 0x1e, 0x1e
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831E94E0: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E94E4: 419A0094  beq cr6, 0x831e9578
	if ctx.cr[6].eq {
	pc = 0x831E9578; continue 'dispatch;
	}
	// 831E94E8: 3BFD0128  addi r31, r29, 0x128
	ctx.r[31].s64 = ctx.r[29].s64 + 296;
	// 831E94EC: 48059C71  bl 0x8324315c
	ctx.lr = 0x831E94F0;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E94F0: 817D012C  lwz r11, 0x12c(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(300 as u32) ) } as u64;
	// 831E94F4: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E94F8: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831E94FC: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E9500: 419A0010  beq cr6, 0x831e9510
	if ctx.cr[6].eq {
	pc = 0x831E9510; continue 'dispatch;
	}
	// 831E9504: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E9508: 7F1E5840  cmplw cr6, r30, r11
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831E950C: 419A0014  beq cr6, 0x831e9520
	if ctx.cr[6].eq {
	pc = 0x831E9520; continue 'dispatch;
	}
	// 831E9510: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E9514: 48059569  bl 0x83242a7c
	ctx.lr = 0x831E9518;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E9518: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 831E951C: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831E9520: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E9524: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E9528: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E952C: 807D00B8  lwz r3, 0xb8(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E9530: 4BFF0D79  bl 0x831da2a8
	ctx.lr = 0x831E9534;
	sub_831DA2A8(ctx, base);
	// 831E9534: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E9538: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E953C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E9540: 419A0038  beq cr6, 0x831e9578
	if ctx.cr[6].eq {
	pc = 0x831E9578; continue 'dispatch;
	}
	// 831E9544: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E9548: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E954C: 409A002C  bne cr6, 0x831e9578
	if !ctx.cr[6].eq {
	pc = 0x831E9578; continue 'dispatch;
	}
	// 831E9550: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E9554: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E9558: 40820020  bne 0x831e9578
	if !ctx.cr[0].eq {
	pc = 0x831E9578; continue 'dispatch;
	}
	// 831E955C: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E9560: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E9564: 9B5F000C  stb r26, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[26].u8 ) };
	// 831E9568: 935F0008  stw r26, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[26].u32 ) };
	// 831E956C: 48059501  bl 0x83242a6c
	ctx.lr = 0x831E9570;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E9570: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E9574: 48059BF9  bl 0x8324316c
	ctx.lr = 0x831E9578;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E9578: 3BDD0010  addi r30, r29, 0x10
	ctx.r[30].s64 = ctx.r[29].s64 + 16;
	// 831E957C: 48059BE1  bl 0x8324315c
	ctx.lr = 0x831E9580;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E9580: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E9584: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E9588: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831E958C: 7DBD6B78  mr r29, r13
	ctx.r[29].u64 = ctx.r[13].u64;
	// 831E9590: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E9594: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E9598: 419A0010  beq cr6, 0x831e95a8
	if ctx.cr[6].eq {
	pc = 0x831E95A8; continue 'dispatch;
	}
	// 831E959C: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E95A0: 7F1D5040  cmplw cr6, r29, r10
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E95A4: 419A0018  beq cr6, 0x831e95bc
	if ctx.cr[6].eq {
	pc = 0x831E95BC; continue 'dispatch;
	}
	// 831E95A8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E95AC: 480594D1  bl 0x83242a7c
	ctx.lr = 0x831E95B0;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E95B0: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E95B4: 93BF0008  stw r29, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 831E95B8: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 831E95BC: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E95C0: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E95C4: 895E009C  lbz r10, 0x9c(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(156 as u32) ) } as u64;
	// 831E95C8: 554907FE  clrlwi r9, r10, 0x1f
	ctx.r[9].u64 = ctx.r[10].u32 as u64 & 0x00000001u64;
	// 831E95CC: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831E95D0: 419A0074  beq cr6, 0x831e9644
	if ctx.cr[6].eq {
	pc = 0x831E9644; continue 'dispatch;
	}
	// 831E95D4: 2B1B0000  cmplwi cr6, r27, 0
	ctx.cr[6].compare_u32(ctx.r[27].u32, 0 as u32, &mut ctx.xer);
	// 831E95D8: 409A004C  bne cr6, 0x831e9624
	if !ctx.cr[6].eq {
	pc = 0x831E9624; continue 'dispatch;
	}
	// 831E95DC: 554906FC  rlwinm r9, r10, 0, 0x1b, 0x1e
	ctx.r[9].u64 = ctx.r[10].u32 as u64 & 0xFFFFFFFFu64;
	// 831E95E0: 552907B6  rlwinm r9, r9, 0, 0x1e, 0x1b
	ctx.r[9].u64 = ctx.r[9].u32 as u64 & 0xFFFFFFFFu64;
	// 831E95E4: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831E95E8: 409A003C  bne cr6, 0x831e9624
	if !ctx.cr[6].eq {
	pc = 0x831E9624; continue 'dispatch;
	}
	// 831E95EC: 554A077A  rlwinm r10, r10, 0, 0x1d, 0x1d
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0xFFFFFFFFu64;
	// 831E95F0: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E95F4: 409A0050  bne cr6, 0x831e9644
	if !ctx.cr[6].eq {
	pc = 0x831E9644; continue 'dispatch;
	}
	// 831E95F8: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E95FC: 38A00004  li r5, 4
	ctx.r[5].s64 = 4;
	// 831E9600: 38800004  li r4, 4
	ctx.r[4].s64 = 4;
	// 831E9604: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E9608: 814B0054  lwz r10, 0x54(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(84 as u32) ) } as u64;
	// 831E960C: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E9610: 4E800421  bctrl
	ctx.lr = 0x831E9614;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E9614: 3D20821A  lis r9, -0x7de6
	ctx.r[9].s64 = -2112225280;
	// 831E9618: A1691090  lhz r11, 0x1090(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(4240 as u32) ) } as u64;
	// 831E961C: B17E009E  sth r11, 0x9e(r30)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[30].u32.wrapping_add(158 as u32), ctx.r[11].u16 ) };
	// 831E9620: 48000020  b 0x831e9640
	pc = 0x831E9640; continue 'dispatch;
	// 831E9624: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E9628: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 831E962C: 38800057  li r4, 0x57
	ctx.r[4].s64 = 87;
	// 831E9630: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E9634: 814B0054  lwz r10, 0x54(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(84 as u32) ) } as u64;
	// 831E9638: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E963C: 4E800421  bctrl
	ctx.lr = 0x831E9640;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E9640: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E9644: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E9648: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E964C: 419A0040  beq cr6, 0x831e968c
	if ctx.cr[6].eq {
	pc = 0x831E968C; continue 'dispatch;
	}
	// 831E9650: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E9654: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E9658: 409A0034  bne cr6, 0x831e968c
	if !ctx.cr[6].eq {
	pc = 0x831E968C; continue 'dispatch;
	}
	// 831E965C: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E9660: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E9664: 40820028  bne 0x831e968c
	if !ctx.cr[0].eq {
	pc = 0x831E968C; continue 'dispatch;
	}
	// 831E9668: 7F4BD378  mr r11, r26
	ctx.r[11].u64 = ctx.r[26].u64;
	// 831E966C: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E9670: 7F4AD378  mr r10, r26
	ctx.r[10].u64 = ctx.r[26].u64;
	// 831E9674: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E9678: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E967C: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E9680: 480593ED  bl 0x83242a6c
	ctx.lr = 0x831E9684;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E9684: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E9688: 48059AE5  bl 0x8324316c
	ctx.lr = 0x831E968C;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E968C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E9690: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831E9694: 4BFBEB1C  b 0x831a81b0
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E9698(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E9698 size=8
    let mut pc: u32 = 0x831E9698;
    'dispatch: loop {
        match pc {
            0x831E9698 => {
    //   block [0x831E9698..0x831E96A0)
	// 831E9698: 3863FFF0  addi r3, r3, -0x10
	ctx.r[3].s64 = ctx.r[3].s64 + -16;
	// 831E969C: 4BFFFC64  b 0x831e9300
	sub_831E9300(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E96A0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E96A0 size=8
    let mut pc: u32 = 0x831E96A0;
    'dispatch: loop {
        match pc {
            0x831E96A0 => {
    //   block [0x831E96A0..0x831E96A8)
	// 831E96A0: 3863FFF0  addi r3, r3, -0x10
	ctx.r[3].s64 = ctx.r[3].s64 + -16;
	// 831E96A4: 4BFFEFC4  b 0x831e8668
	sub_831E8668(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E96A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E96A8 size=8
    let mut pc: u32 = 0x831E96A8;
    'dispatch: loop {
        match pc {
            0x831E96A8 => {
    //   block [0x831E96A8..0x831E96B0)
	// 831E96A8: 3863FFF0  addi r3, r3, -0x10
	ctx.r[3].s64 = ctx.r[3].s64 + -16;
	// 831E96AC: 4BFFEFC4  b 0x831e8670
	sub_831E8670(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E96B0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E96B0 size=8
    let mut pc: u32 = 0x831E96B0;
    'dispatch: loop {
        match pc {
            0x831E96B0 => {
    //   block [0x831E96B0..0x831E96B8)
	// 831E96B0: 3863FFF0  addi r3, r3, -0x10
	ctx.r[3].s64 = ctx.r[3].s64 + -16;
	// 831E96B4: 4BFFFE04  b 0x831e94b8
	sub_831E94B8(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E96B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E96B8 size=360
    let mut pc: u32 = 0x831E96B8;
    'dispatch: loop {
        match pc {
            0x831E96B8 => {
    //   block [0x831E96B8..0x831E9820)
	// 831E96B8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E96BC: 4BFBEAA5  bl 0x831a8160
	ctx.lr = 0x831E96C0;
	sub_831A8130(ctx, base);
	// 831E96C0: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E96C4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E96C8: 7C9B2378  mr r27, r4
	ctx.r[27].u64 = ctx.r[4].u64;
	// 831E96CC: 3B9F0004  addi r28, r31, 4
	ctx.r[28].s64 = ctx.r[31].s64 + 4;
	// 831E96D0: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 831E96D4: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 831E96D8: 4BFF7FE9  bl 0x831e16c0
	ctx.lr = 0x831E96DC;
	sub_831E16C0(ctx, base);
	// 831E96DC: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E96E0: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831E96E4: 3D20821A  lis r9, -0x7de6
	ctx.r[9].s64 = -2112225280;
	// 831E96E8: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 831E96EC: 390B1180  addi r8, r11, 0x1180
	ctx.r[8].s64 = ctx.r[11].s64 + 4480;
	// 831E96F0: 38EA1158  addi r7, r10, 0x1158
	ctx.r[7].s64 = ctx.r[10].s64 + 4440;
	// 831E96F4: 93DF00B8  stw r30, 0xb8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(184 as u32), ctx.r[30].u32 ) };
	// 831E96F8: 38C910F8  addi r6, r9, 0x10f8
	ctx.r[6].s64 = ctx.r[9].s64 + 4344;
	// 831E96FC: 911F0000  stw r8, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 831E9700: 90FF0004  stw r7, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[7].u32 ) };
	// 831E9704: 7FA5EB78  mr r5, r29
	ctx.r[5].u64 = ctx.r[29].u64;
	// 831E9708: 90DF0010  stw r6, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[6].u32 ) };
	// 831E970C: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 831E9710: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 831E9714: 897B0045  lbz r11, 0x45(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[27].u32.wrapping_add(69 as u32) ) } as u64;
	// 831E9718: 997F0108  stb r11, 0x108(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(264 as u32), ctx.r[11].u8 ) };
	// 831E971C: 93DF010C  stw r30, 0x10c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(268 as u32), ctx.r[30].u32 ) };
	// 831E9720: 93DF0110  stw r30, 0x110(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(272 as u32), ctx.r[30].u32 ) };
	// 831E9724: 93DF0120  stw r30, 0x120(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(288 as u32), ctx.r[30].u32 ) };
	// 831E9728: 9BDF0124  stb r30, 0x124(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(292 as u32), ctx.r[30].u8 ) };
	// 831E972C: 93DF012C  stw r30, 0x12c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(300 as u32), ctx.r[30].u32 ) };
	// 831E9730: 93DF0130  stw r30, 0x130(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(304 as u32), ctx.r[30].u32 ) };
	// 831E9734: 9BDF0134  stb r30, 0x134(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(308 as u32), ctx.r[30].u8 ) };
	// 831E9738: 93DF0128  stw r30, 0x128(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(296 as u32), ctx.r[30].u32 ) };
	// 831E973C: 4BFF7D15  bl 0x831e1450
	ctx.lr = 0x831E9740;
	sub_831E1450(ctx, base);
	// 831E9740: 3D4002E8  lis r10, 0x2e8
	ctx.r[10].s64 = 48758784;
	// 831E9744: 6149BA2E  ori r9, r10, 0xba2e
	ctx.r[9].u64 = ctx.r[10].u64 | 47662;
	// 831E9748: 8B9F0038  lbz r28, 0x38(r31)
	ctx.r[28].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E974C: 7F1C4840  cmplw cr6, r28, r9
	ctx.cr[6].compare_u32(ctx.r[28].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E9750: 1C9C0058  mulli r4, r28, 0x58
	ctx.r[4].s64 = ctx.r[28].s64 * 88;
	// 831E9754: 40990008  ble cr6, 0x831e975c
	if !ctx.cr[6].gt {
	pc = 0x831E975C; continue 'dispatch;
	}
	// 831E9758: 3880FFFF  li r4, -1
	ctx.r[4].s64 = -1;
	// 831E975C: 817D0000  lwz r11, 0(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E9760: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831E9764: 814B0014  lwz r10, 0x14(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E9768: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E976C: 4E800421  bctrl
	ctx.lr = 0x831E9770;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E9770: 7C7A1B78  mr r26, r3
	ctx.r[26].u64 = ctx.r[3].u64;
	// 831E9774: 2B1A0000  cmplwi cr6, r26, 0
	ctx.cr[6].compare_u32(ctx.r[26].u32, 0 as u32, &mut ctx.xer);
	// 831E9778: 419A0038  beq cr6, 0x831e97b0
	if ctx.cr[6].eq {
	pc = 0x831E97B0; continue 'dispatch;
	}
	// 831E977C: 379CFFFF  addic. r28, r28, -1
	ctx.xer.ca = (ctx.r[28].u32 > (!(-1 as u32)));
	ctx.r[28].s64 = ctx.r[28].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[28].s32, 0, &mut ctx.xer);
	// 831E9780: 7F5DD378  mr r29, r26
	ctx.r[29].u64 = ctx.r[26].u64;
	// 831E9784: 41800024  blt 0x831e97a8
	if ctx.cr[0].lt {
	pc = 0x831E97A8; continue 'dispatch;
	}
	// 831E9788: 38A0004C  li r5, 0x4c
	ctx.r[5].s64 = 76;
	// 831E978C: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831E9790: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831E9794: 4BFBEA4D  bl 0x831a81e0
	ctx.lr = 0x831E9798;
	sub_831A81E0(ctx, base);
	// 831E9798: 93DD004C  stw r30, 0x4c(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(76 as u32), ctx.r[30].u32 ) };
	// 831E979C: 379CFFFF  addic. r28, r28, -1
	ctx.xer.ca = (ctx.r[28].u32 > (!(-1 as u32)));
	ctx.r[28].s64 = ctx.r[28].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[28].s32, 0, &mut ctx.xer);
	// 831E97A0: 3BBD0058  addi r29, r29, 0x58
	ctx.r[29].s64 = ctx.r[29].s64 + 88;
	// 831E97A4: 4080FFE4  bge 0x831e9788
	if !ctx.cr[0].lt {
	pc = 0x831E9788; continue 'dispatch;
	}
	// 831E97A8: 7F4BD378  mr r11, r26
	ctx.r[11].u64 = ctx.r[26].u64;
	// 831E97AC: 48000008  b 0x831e97b4
	pc = 0x831E97B4; continue 'dispatch;
	// 831E97B0: 7FCBF378  mr r11, r30
	ctx.r[11].u64 = ctx.r[30].u64;
	// 831E97B4: 39400040  li r10, 0x40
	ctx.r[10].s64 = 64;
	// 831E97B8: 917F00C8  stw r11, 0xc8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(200 as u32), ctx.r[11].u32 ) };
	// 831E97BC: 100F038C  vspltisw v0, 0xf
	for i in 0..4 {
		ctx.v[0].u32[i] = 15;
	}
	// 831E97C0: 392000CC  li r9, 0xcc
	ctx.r[9].s64 = 204;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E9820(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831E9820 size=2756
    let mut pc: u32 = 0x831E9820;
    'dispatch: loop {
        match pc {
            0x831E9820 => {
    //   block [0x831E9820..0x831EA2E4)
	// 831E9820: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E9824: 4BFBE92D  bl 0x831a8150
	ctx.lr = 0x831E9828;
	sub_831A8130(ctx, base);
	// 831E9828: DBE1FFA0  stfd f31, -0x60(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-96 as u32), ctx.f[31].u64 ) };
	// 831E982C: 9421FF30  stwu r1, -0xd0(r1)
	ea = ctx.r[1].u32.wrapping_add(-208 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E9830: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E9834: 3AE00000  li r23, 0
	ctx.r[23].s64 = 0;
	// 831E9838: 7CBC2B78  mr r28, r5
	ctx.r[28].u64 = ctx.r[5].u64;
	// 831E983C: 3B1F0128  addi r24, r31, 0x128
	ctx.r[24].s64 = ctx.r[31].s64 + 296;
	// 831E9840: 7EFABB78  mr r26, r23
	ctx.r[26].u64 = ctx.r[23].u64;
	// 831E9844: 7EF6BB78  mr r22, r23
	ctx.r[22].u64 = ctx.r[23].u64;
	// 831E9848: 48059915  bl 0x8324315c
	ctx.lr = 0x831E984C;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E984C: 817F012C  lwz r11, 0x12c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(300 as u32) ) } as u64;
	// 831E9850: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831E9854: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831E9858: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E985C: 419A0010  beq cr6, 0x831e986c
	if ctx.cr[6].eq {
	pc = 0x831E986C; continue 'dispatch;
	}
	// 831E9860: 81780008  lwz r11, 8(r24)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E9864: 7F1E5840  cmplw cr6, r30, r11
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831E9868: 419A0014  beq cr6, 0x831e987c
	if ctx.cr[6].eq {
	pc = 0x831E987C; continue 'dispatch;
	}
	// 831E986C: 7F03C378  mr r3, r24
	ctx.r[3].u64 = ctx.r[24].u64;
	// 831E9870: 4805920D  bl 0x83242a7c
	ctx.lr = 0x831E9874;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E9874: 9BB8000C  stb r29, 0xc(r24)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[24].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831E9878: 93D80008  stw r30, 8(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831E987C: 81780004  lwz r11, 4(r24)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E9880: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E9884: 91780004  stw r11, 4(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E9888: 807F00B8  lwz r3, 0xb8(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E988C: 4BFF0A95  bl 0x831da320
	ctx.lr = 0x831E9890;
	sub_831DA320(ctx, base);
	// 831E9890: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E9894: 419A09FC  beq cr6, 0x831ea290
	if ctx.cr[6].eq {
	pc = 0x831EA290; continue 'dispatch;
	}
	// 831E9898: 807F00B8  lwz r3, 0xb8(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E989C: 4BFF13E5  bl 0x831dac80
	ctx.lr = 0x831E98A0;
	sub_831DAC80(ctx, base);
	// 831E98A0: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831E98A4: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 831E98A8: 40980058  bge cr6, 0x831e9900
	if !ctx.cr[6].lt {
	pc = 0x831E9900; continue 'dispatch;
	}
	// 831E98AC: 81780004  lwz r11, 4(r24)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E98B0: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E98B4: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E98B8: 419A0038  beq cr6, 0x831e98f0
	if ctx.cr[6].eq {
	pc = 0x831E98F0; continue 'dispatch;
	}
	// 831E98BC: 81380008  lwz r9, 8(r24)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E98C0: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E98C4: 409A002C  bne cr6, 0x831e98f0
	if !ctx.cr[6].eq {
	pc = 0x831E98F0; continue 'dispatch;
	}
	// 831E98C8: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E98CC: 91780004  stw r11, 4(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E98D0: 40820020  bne 0x831e98f0
	if !ctx.cr[0].eq {
	pc = 0x831E98F0; continue 'dispatch;
	}
	// 831E98D4: 8BF8000C  lbz r31, 0xc(r24)
	ctx.r[31].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[24].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E98D8: 7F03C378  mr r3, r24
	ctx.r[3].u64 = ctx.r[24].u64;
	// 831E98DC: 92F80008  stw r23, 8(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(8 as u32), ctx.r[23].u32 ) };
	// 831E98E0: 9AF8000C  stb r23, 0xc(r24)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[24].u32.wrapping_add(12 as u32), ctx.r[23].u8 ) };
	// 831E98E4: 48059189  bl 0x83242a6c
	ctx.lr = 0x831E98E8;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E98E8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E98EC: 48059881  bl 0x8324316c
	ctx.lr = 0x831E98F0;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E98F0: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E98F4: 382100D0  addi r1, r1, 0xd0
	ctx.r[1].s64 = ctx.r[1].s64 + 208;
	// 831E98F8: CBE1FFA0  lfd f31, -0x60(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-96 as u32) ) };
	// 831E98FC: 4BFBE8A4  b 0x831a81a0
	sub_831A8180(ctx, base);
	return;
	// 831E9900: 4805985D  bl 0x8324315c
	ctx.lr = 0x831E9904;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E9904: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E9908: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831E990C: 3B2BD530  addi r25, r11, -0x2ad0
	ctx.r[25].s64 = ctx.r[11].s64 + -10960;
	// 831E9910: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831E9914: 81790004  lwz r11, 4(r25)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E9918: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E991C: 419A0010  beq cr6, 0x831e992c
	if ctx.cr[6].eq {
	pc = 0x831E992C; continue 'dispatch;
	}
	// 831E9920: 81590008  lwz r10, 8(r25)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E9924: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E9928: 419A0018  beq cr6, 0x831e9940
	if ctx.cr[6].eq {
	pc = 0x831E9940; continue 'dispatch;
	}
	// 831E992C: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 831E9930: 4805914D  bl 0x83242a7c
	ctx.lr = 0x831E9934;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E9934: 81790004  lwz r11, 4(r25)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E9938: 93D90008  stw r30, 8(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831E993C: 9BB9000C  stb r29, 0xc(r25)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[25].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831E9940: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E9944: 38810058  addi r4, r1, 0x58
	ctx.r[4].s64 = ctx.r[1].s64 + 88;
	// 831E9948: 91790004  stw r11, 4(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E994C: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 831E9950: 4BFF8739  bl 0x831e2088
	ctx.lr = 0x831E9954;
	sub_831E2088(ctx, base);
	// 831E9954: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831E9958: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 831E995C: 4198005C  blt cr6, 0x831e99b8
	if ctx.cr[6].lt {
	pc = 0x831E99B8; continue 'dispatch;
	}
	// 831E9960: 897F0038  lbz r11, 0x38(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E9964: 7EEABB78  mr r10, r23
	ctx.r[10].u64 = ctx.r[23].u64;
	// 831E9968: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E996C: 419A002C  beq cr6, 0x831e9998
	if ctx.cr[6].eq {
	pc = 0x831E9998; continue 'dispatch;
	}
	// 831E9970: 5568063E  clrlwi r8, r11, 0x18
	ctx.r[8].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 831E9974: 7EEBBB78  mr r11, r23
	ctx.r[11].u64 = ctx.r[23].u64;
	// 831E9978: 392B0008  addi r9, r11, 8
	ctx.r[9].s64 = ctx.r[11].s64 + 8;
	// 831E997C: 38EB0001  addi r7, r11, 1
	ctx.r[7].s64 = ctx.r[11].s64 + 1;
	// 831E9980: 55261838  slwi r6, r9, 3
	ctx.r[6].u32 = ctx.r[9].u32.wrapping_shl(3);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831E9984: 54EB063E  clrlwi r11, r7, 0x18
	ctx.r[11].u64 = ctx.r[7].u32 as u64 & 0x000000FFu64;
	// 831E9988: 7F0B4040  cmplw cr6, r11, r8
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831E998C: 7D26F8AE  lbzx r9, r6, r31
	ctx.r[9].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[31].u32)) } as u64;
	// 831E9990: 7D495214  add r10, r9, r10
	ctx.r[10].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 831E9994: 4198FFE4  blt cr6, 0x831e9978
	if ctx.cr[6].lt {
	pc = 0x831E9978; continue 'dispatch;
	}
	// 831E9998: 99410059  stb r10, 0x59(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(89 as u32), ctx.r[10].u8 ) };
	// 831E999C: 38A00001  li r5, 1
	ctx.r[5].s64 = 1;
	// 831E99A0: 38810058  addi r4, r1, 0x58
	ctx.r[4].s64 = ctx.r[1].s64 + 88;
	// 831E99A4: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 831E99A8: 4BFF8941  bl 0x831e22e8
	ctx.lr = 0x831E99AC;
	sub_831E22E8(ctx, base);
	// 831E99AC: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831E99B0: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 831E99B4: 409802B8  bge cr6, 0x831e9c6c
	if !ctx.cr[6].lt {
	pc = 0x831E9C6C; continue 'dispatch;
	}
	// 831E99B8: 81390004  lwz r9, 4(r25)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E99BC: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E99C0: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831E99C4: 419A0040  beq cr6, 0x831e9a04
	if ctx.cr[6].eq {
	pc = 0x831E9A04; continue 'dispatch;
	}
	// 831E99C8: 81790008  lwz r11, 8(r25)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E99CC: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831E99D0: 409A0034  bne cr6, 0x831e9a04
	if !ctx.cr[6].eq {
	pc = 0x831E9A04; continue 'dispatch;
	}
	// 831E99D4: 3569FFFF  addic. r11, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E99D8: 91790004  stw r11, 4(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E99DC: 40820028  bne 0x831e9a04
	if !ctx.cr[0].eq {
	pc = 0x831E9A04; continue 'dispatch;
	}
	// 831E99E0: 7EEABB78  mr r10, r23
	ctx.r[10].u64 = ctx.r[23].u64;
	// 831E99E4: 8BB9000C  lbz r29, 0xc(r25)
	ctx.r[29].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[25].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E99E8: 7EEBBB78  mr r11, r23
	ctx.r[11].u64 = ctx.r[23].u64;
	// 831E99EC: 91590008  stw r10, 8(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E99F0: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 831E99F4: 9979000C  stb r11, 0xc(r25)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[25].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E99F8: 48059075  bl 0x83242a6c
	ctx.lr = 0x831E99FC;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E99FC: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831E9A00: 4805976D  bl 0x8324316c
	ctx.lr = 0x831E9A04;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E9A04: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 831E9A08: 409AFEA4  bne cr6, 0x831e98ac
	if !ctx.cr[6].eq {
	pc = 0x831E98AC; continue 'dispatch;
	}
	// 831E9A0C: 807F00B8  lwz r3, 0xb8(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E9A10: 4BFF1309  bl 0x831dad18
	ctx.lr = 0x831E9A14;
	sub_831DAD18(ctx, base);
	// 831E9A14: 897F0124  lbz r11, 0x124(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(292 as u32) ) } as u64;
	// 831E9A18: 2B0B0002  cmplwi cr6, r11, 2
	ctx.cr[6].compare_u32(ctx.r[11].u32, 2 as u32, &mut ctx.xer);
	// 831E9A1C: 409A000C  bne cr6, 0x831e9a28
	if !ctx.cr[6].eq {
	pc = 0x831E9A28; continue 'dispatch;
	}
	// 831E9A20: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E9A24: 4BFFF64D  bl 0x831e9070
	ctx.lr = 0x831E9A28;
	sub_831E9070(ctx, base);
	// 831E9A28: 897F0038  lbz r11, 0x38(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E9A2C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E9A30: 419A0178  beq cr6, 0x831e9ba8
	if ctx.cr[6].eq {
	pc = 0x831E9BA8; continue 'dispatch;
	}
	// 831E9A34: 7EFBBB78  mr r27, r23
	ctx.r[27].u64 = ctx.r[23].u64;
	// 831E9A38: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 831E9A3C: 807F00B8  lwz r3, 0xb8(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E9A40: 4BFF0B11  bl 0x831da550
	ctx.lr = 0x831E9A44;
	sub_831DA550(ctx, base);
	// 831E9A44: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E9A48: 7EFDBB78  mr r29, r23
	ctx.r[29].u64 = ctx.r[23].u64;
	// 831E9A4C: 2B1C0000  cmplwi cr6, r28, 0
	ctx.cr[6].compare_u32(ctx.r[28].u32, 0 as u32, &mut ctx.xer);
	// 831E9A50: 419A0098  beq cr6, 0x831e9ae8
	if ctx.cr[6].eq {
	pc = 0x831E9AE8; continue 'dispatch;
	}
	// 831E9A54: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 831E9A58: 807F00B8  lwz r3, 0xb8(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E9A5C: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 831E9A60: 4BFF0D39  bl 0x831da798
	ctx.lr = 0x831E9A64;
	sub_831DA798(ctx, base);
	// 831E9A64: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E9A68: 419A0080  beq cr6, 0x831e9ae8
	if ctx.cr[6].eq {
	pc = 0x831E9AE8; continue 'dispatch;
	}
	// 831E9A6C: 1FDB0058  mulli r30, r27, 0x58
	ctx.r[30].s64 = ctx.r[27].s64 * 88;
	// 831E9A70: 817F00C8  lwz r11, 0xc8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(200 as u32) ) } as u64;
	// 831E9A74: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E9A78: 81410050  lwz r10, 0x50(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831E9A7C: 7D7E5A14  add r11, r30, r11
	ctx.r[11].u64 = ctx.r[30].u64 + ctx.r[11].u64;
	// 831E9A80: 914B0000  stw r10, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E9A84: 906B0004  stw r3, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[3].u32 ) };
	// 831E9A88: 419A0008  beq cr6, 0x831e9a90
	if ctx.cr[6].eq {
	pc = 0x831E9A90; continue 'dispatch;
	}
	// 831E9A8C: 7EE3BB78  mr r3, r23
	ctx.r[3].u64 = ctx.r[23].u64;
	// 831E9A90: 906B0008  stw r3, 8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[3].u32 ) };
	// 831E9A94: 817F00C8  lwz r11, 0xc8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(200 as u32) ) } as u64;
	// 831E9A98: 7C7E5A14  add r3, r30, r11
	ctx.r[3].u64 = ctx.r[30].u64 + ctx.r[11].u64;
	// 831E9A9C: 4800291D  bl 0x831ec3b8
	ctx.lr = 0x831E9AA0;
	sub_831EC3B8(ctx, base);
	// 831E9AA0: 7C651B78  mr r5, r3
	ctx.r[5].u64 = ctx.r[3].u64;
	// 831E9AA4: 38C10050  addi r6, r1, 0x50
	ctx.r[6].s64 = ctx.r[1].s64 + 80;
	// 831E9AA8: 807F00B8  lwz r3, 0xb8(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E9AAC: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 831E9AB0: 7FA5EA14  add r29, r5, r29
	ctx.r[29].u64 = ctx.r[5].u64 + ctx.r[29].u64;
	// 831E9AB4: 4BFF0B2D  bl 0x831da5e0
	ctx.lr = 0x831E9AB8;
	sub_831DA5E0(ctx, base);
	// 831E9AB8: 817F00C8  lwz r11, 0xc8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(200 as u32) ) } as u64;
	// 831E9ABC: 7D7E5A14  add r11, r30, r11
	ctx.r[11].u64 = ctx.r[30].u64 + ctx.r[11].u64;
	// 831E9AC0: 814B0018  lwz r10, 0x18(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) } as u64;
	// 831E9AC4: 812B001C  lwz r9, 0x1c(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) } as u64;
	// 831E9AC8: 7D095051  subf. r8, r9, r10
	ctx.r[8].s64 = ctx.r[10].s64 - ctx.r[9].s64;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 831E9ACC: 4182001C  beq 0x831e9ae8
	if ctx.cr[0].eq {
	pc = 0x831E9AE8; continue 'dispatch;
	}
	// 831E9AD0: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 831E9AD4: 807F00B8  lwz r3, 0xb8(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E9AD8: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 831E9ADC: 4BFF0CBD  bl 0x831da798
	ctx.lr = 0x831E9AE0;
	sub_831DA798(ctx, base);
	// 831E9AE0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E9AE4: 409AFF8C  bne cr6, 0x831e9a70
	if !ctx.cr[6].eq {
	pc = 0x831E9A70; continue 'dispatch;
	}
	// 831E9AE8: 397B008A  addi r11, r27, 0x8a
	ctx.r[11].s64 = ctx.r[27].s64 + 138;
	// 831E9AEC: 7D5DE050  subf r10, r29, r28
	ctx.r[10].s64 = ctx.r[28].s64 - ctx.r[29].s64;
	// 831E9AF0: 5569083C  slwi r9, r11, 1
	ctx.r[9].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831E9AF4: 7D09FA2E  lhzx r8, r9, r31
	ctx.r[8].u64 = unsafe { crate::rt::load_u16(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[31].u32)) } as u64;
	// 831E9AF8: 7F0A4040  cmplw cr6, r10, r8
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831E9AFC: 41990008  bgt cr6, 0x831e9b04
	if ctx.cr[6].gt {
	pc = 0x831E9B04; continue 'dispatch;
	}
	// 831E9B00: 3AC00001  li r22, 1
	ctx.r[22].s64 = 1;
	// 831E9B04: 7F84E378  mr r4, r28
	ctx.r[4].u64 = ctx.r[28].u64;
	// 831E9B08: 38600004  li r3, 4
	ctx.r[3].s64 = 4;
	// 831E9B0C: 4BFF2BDD  bl 0x831dc6e8
	ctx.lr = 0x831E9B10;
	sub_831DC6E8(ctx, base);
	// 831E9B10: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 831E9B14: 38600005  li r3, 5
	ctx.r[3].s64 = 5;
	// 831E9B18: 4BFF2BD1  bl 0x831dc6e8
	ctx.lr = 0x831E9B1C;
	sub_831DC6E8(ctx, base);
	// 831E9B1C: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831E9B20: 807F00B8  lwz r3, 0xb8(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(184 as u32) ) } as u64;
	// 831E9B24: 4BFF0F95  bl 0x831daab8
	ctx.lr = 0x831E9B28;
	sub_831DAAB8(ctx, base);
	// 831E9B28: 815F00C8  lwz r10, 0xc8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(200 as u32) ) } as u64;
	// 831E9B2C: 1D7B0058  mulli r11, r27, 0x58
	ctx.r[11].s64 = ctx.r[27].s64 * 88;
	// 831E9B30: 907F00A8  stw r3, 0xa8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(168 as u32), ctx.r[3].u32 ) };
	// 831E9B34: 7FCB5214  add r30, r11, r10
	ctx.r[30].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831E9B38: 817E001C  lwz r11, 0x1c(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(28 as u32) ) } as u64;
	// 831E9B3C: 815E0018  lwz r10, 0x18(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(24 as u32) ) } as u64;
	// 831E9B40: 7D4B5051  subf. r10, r11, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831E9B44: 8BBE000D  lbz r29, 0xd(r30)
	ctx.r[29].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(13 as u32) ) } as u64;
	// 831E9B48: 41820038  beq 0x831e9b80
	if ctx.cr[0].eq {
	pc = 0x831E9B80; continue 'dispatch;
	}
	// 831E9B4C: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 831E9B50: 419A002C  beq cr6, 0x831e9b7c
	if ctx.cr[6].eq {
	pc = 0x831E9B7C; continue 'dispatch;
	}
	// 831E9B54: 555A103A  slwi r26, r10, 2
	ctx.r[26].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[26].u64 = ctx.r[26].u32 as u64;
	// 831E9B58: 557C103A  slwi r28, r11, 2
	ctx.r[28].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[28].u64 = ctx.r[28].u32 as u64;
	// 831E9B5C: 817E0014  lwz r11, 0x14(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E9B60: 7F45D378  mr r5, r26
	ctx.r[5].u64 = ctx.r[26].u64;
	// 831E9B64: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831E9B68: 7C7C5A14  add r3, r28, r11
	ctx.r[3].u64 = ctx.r[28].u64 + ctx.r[11].u64;
	// 831E9B6C: 4BFBE675  bl 0x831a81e0
	ctx.lr = 0x831E9B70;
	sub_831A81E0(ctx, base);
	// 831E9B70: 37BDFFFF  addic. r29, r29, -1
	ctx.xer.ca = (ctx.r[29].u32 > (!(-1 as u32)));
	ctx.r[29].s64 = ctx.r[29].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[29].s32, 0, &mut ctx.xer);
	// 831E9B74: 3B9C0400  addi r28, r28, 0x400
	ctx.r[28].s64 = ctx.r[28].s64 + 1024;
	// 831E9B78: 4082FFE4  bne 0x831e9b5c
	if !ctx.cr[0].eq {
	pc = 0x831E9B5C; continue 'dispatch;
	}
	// 831E9B7C: 3B400001  li r26, 1
	ctx.r[26].s64 = 1;
	// 831E9B80: 2B1B0000  cmplwi cr6, r27, 0
	ctx.cr[6].compare_u32(ctx.r[27].u32, 0 as u32, &mut ctx.xer);
	// 831E9B84: 409A0010  bne cr6, 0x831e9b94
	if !ctx.cr[6].eq {
	pc = 0x831E9B94; continue 'dispatch;
	}
	// 831E9B88: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 831E9B8C: 38600003  li r3, 3
	ctx.r[3].s64 = 3;
	// 831E9B90: 4BFF2B59  bl 0x831dc6e8
	ctx.lr = 0x831E9B94;
	sub_831DC6E8(ctx, base);
	// 831E9B94: 397B0001  addi r11, r27, 1
	ctx.r[11].s64 = ctx.r[27].s64 + 1;
	// 831E9B98: 895F0038  lbz r10, 0x38(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E9B9C: 557B063E  clrlwi r27, r11, 0x18
	ctx.r[27].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 831E9BA0: 7F1B5040  cmplw cr6, r27, r10
	ctx.cr[6].compare_u32(ctx.r[27].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E9BA4: 4198FE94  blt cr6, 0x831e9a38
	if ctx.cr[6].lt {
	pc = 0x831E9A38; continue 'dispatch;
	}
	// 831E9BA8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E9BAC: 4BFFEBDD  bl 0x831e8788
	ctx.lr = 0x831E9BB0;
	sub_831E8788(ctx, base);
	// 831E9BB0: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E9BB4: 480595A9  bl 0x8324315c
	ctx.lr = 0x831E9BB8;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E9BB8: 81790004  lwz r11, 4(r25)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E9BBC: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831E9BC0: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831E9BC4: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E9BC8: 419A0010  beq cr6, 0x831e9bd8
	if ctx.cr[6].eq {
	pc = 0x831E9BD8; continue 'dispatch;
	}
	// 831E9BCC: 81590008  lwz r10, 8(r25)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E9BD0: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E9BD4: 419A0018  beq cr6, 0x831e9bec
	if ctx.cr[6].eq {
	pc = 0x831E9BEC; continue 'dispatch;
	}
	// 831E9BD8: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 831E9BDC: 48058EA1  bl 0x83242a7c
	ctx.lr = 0x831E9BE0;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E9BE0: 81790004  lwz r11, 4(r25)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E9BE4: 93D90008  stw r30, 8(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831E9BE8: 9BB9000C  stb r29, 0xc(r25)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[25].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831E9BEC: 38EB0001  addi r7, r11, 1
	ctx.r[7].s64 = ctx.r[11].s64 + 1;
	// 831E9BF0: 90F90004  stw r7, 4(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(4 as u32), ctx.r[7].u32 ) };
	// 831E9BF4: 897F0038  lbz r11, 0x38(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E9BF8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E9BFC: 419A0034  beq cr6, 0x831e9c30
	if ctx.cr[6].eq {
	pc = 0x831E9C30; continue 'dispatch;
	}
	// 831E9C00: 7EEBBB78  mr r11, r23
	ctx.r[11].u64 = ctx.r[23].u64;
	// 831E9C04: 813F00C8  lwz r9, 0xc8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(200 as u32) ) } as u64;
	// 831E9C08: 1D4B0058  mulli r10, r11, 0x58
	ctx.r[10].s64 = ctx.r[11].s64 * 88;
	// 831E9C0C: 7D4A4A14  add r10, r10, r9
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[9].u64;
	// 831E9C10: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E9C14: 556B063E  clrlwi r11, r11, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 831E9C18: C00A0028  lfs f0, 0x28(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(40 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E9C1C: D00A0024  stfs f0, 0x24(r10)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831E9C20: 895F0038  lbz r10, 0x38(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E9C24: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E9C28: 4198FFDC  blt cr6, 0x831e9c04
	if ctx.cr[6].lt {
	pc = 0x831E9C04; continue 'dispatch;
	}
	// 831E9C2C: 80F90004  lwz r7, 4(r25)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E9C30: 574B063E  clrlwi r11, r26, 0x18
	ctx.r[11].u64 = ctx.r[26].u32 as u64 & 0x000000FFu64;
	// 831E9C34: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E9C38: 419A038C  beq cr6, 0x831e9fc4
	if ctx.cr[6].eq {
	pc = 0x831E9FC4; continue 'dispatch;
	}
	// 831E9C3C: 897F00AC  lbz r11, 0xac(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(172 as u32) ) } as u64;
	// 831E9C40: 556A0738  rlwinm r10, r11, 0, 0x1c, 0x1c
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831E9C44: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E9C48: 409A034C  bne cr6, 0x831e9f94
	if !ctx.cr[6].eq {
	pc = 0x831E9F94; continue 'dispatch;
	}
	// 831E9C4C: 7EEABB78  mr r10, r23
	ctx.r[10].u64 = ctx.r[23].u64;
	// 831E9C50: 7EE8BB78  mr r8, r23
	ctx.r[8].u64 = ctx.r[23].u64;
	// 831E9C54: 393F0014  addi r9, r31, 0x14
	ctx.r[9].s64 = ctx.r[31].s64 + 20;
	// 831E9C58: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E9C5C: 419A02C4  beq cr6, 0x831e9f20
	if ctx.cr[6].eq {
	pc = 0x831E9F20; continue 'dispatch;
	}
	// 831E9C60: 81690008  lwz r11, 8(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E9C64: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831E9C68: 480002BC  b 0x831e9f24
	pc = 0x831E9F24; continue 'dispatch;
	// 831E9C6C: 897F0038  lbz r11, 0x38(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E9C70: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E9C74: 419A0058  beq cr6, 0x831e9ccc
	if ctx.cr[6].eq {
	pc = 0x831E9CCC; continue 'dispatch;
	}
	// 831E9C78: 81210060  lwz r9, 0x60(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) } as u64;
	// 831E9C7C: 7EEABB78  mr r10, r23
	ctx.r[10].u64 = ctx.r[23].u64;
	// 831E9C80: 38E00100  li r7, 0x100
	ctx.r[7].s64 = 256;
	// 831E9C84: 817F00C8  lwz r11, 0xc8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(200 as u32) ) } as u64;
	// 831E9C88: 1D0A0058  mulli r8, r10, 0x58
	ctx.r[8].s64 = ctx.r[10].s64 * 88;
	// 831E9C8C: 7D685A14  add r11, r8, r11
	ctx.r[11].u64 = ctx.r[8].u64 + ctx.r[11].u64;
	// 831E9C90: 390A0008  addi r8, r10, 8
	ctx.r[8].s64 = ctx.r[10].s64 + 8;
	// 831E9C94: 38CA0001  addi r6, r10, 1
	ctx.r[6].s64 = ctx.r[10].s64 + 1;
	// 831E9C98: 55051838  slwi r5, r8, 3
	ctx.r[5].u32 = ctx.r[8].u32.wrapping_shl(3);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831E9C9C: 54CA063E  clrlwi r10, r6, 0x18
	ctx.r[10].u64 = ctx.r[6].u32 as u64 & 0x000000FFu64;
	// 831E9CA0: 912B0014  stw r9, 0x14(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), ctx.r[9].u32 ) };
	// 831E9CA4: 90EB0018  stw r7, 0x18(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), ctx.r[7].u32 ) };
	// 831E9CA8: 92EB001C  stw r23, 0x1c(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(28 as u32), ctx.r[23].u32 ) };
	// 831E9CAC: 80810060  lwz r4, 0x60(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) } as u64;
	// 831E9CB0: 7D65F8AE  lbzx r11, r5, r31
	ctx.r[11].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[5].u32.wrapping_add(ctx.r[31].u32)) } as u64;
	// 831E9CB4: 556B503E  rotlwi r11, r11, 0xa
	ctx.r[11].u64 = ((ctx.r[11].u32).rotate_left(10)) as u64;
	// 831E9CB8: 7D2B2214  add r9, r11, r4
	ctx.r[9].u64 = ctx.r[11].u64 + ctx.r[4].u64;
	// 831E9CBC: 887F0038  lbz r3, 0x38(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E9CC0: 7F0A1840  cmplw cr6, r10, r3
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[3].u32, &mut ctx.xer);
	// 831E9CC4: 91210060  stw r9, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[9].u32 ) };
	// 831E9CC8: 4198FFBC  blt cr6, 0x831e9c84
	if ctx.cr[6].lt {
	pc = 0x831E9C84; continue 'dispatch;
	}
	// 831E9CCC: 897F00AC  lbz r11, 0xac(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(172 as u32) ) } as u64;
	// 831E9CD0: 556A07FE  clrlwi r10, r11, 0x1f
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0x00000001u64;
	// 831E9CD4: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E9CD8: 419A0180  beq cr6, 0x831e9e58
	if ctx.cr[6].eq {
	pc = 0x831E9E58; continue 'dispatch;
	}
	// 831E9CDC: 556A06F6  rlwinm r10, r11, 0, 0x1b, 0x1b
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831E9CE0: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E9CE4: 409A0174  bne cr6, 0x831e9e58
	if !ctx.cr[6].eq {
	pc = 0x831E9E58; continue 'dispatch;
	}
	// 831E9CE8: 3D408200  lis r10, -0x7e00
	ctx.r[10].s64 = -2113929216;
	// 831E9CEC: 556907BC  rlwinm r9, r11, 0, 0x1e, 0x1e
	ctx.r[9].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831E9CF0: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831E9CF4: C3EA08A4  lfs f31, 0x8a4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(2212 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 831E9CF8: 419A0090  beq cr6, 0x831e9d88
	if ctx.cr[6].eq {
	pc = 0x831E9D88; continue 'dispatch;
	}
	// 831E9CFC: 897F0038  lbz r11, 0x38(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E9D00: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E9D04: 419A0068  beq cr6, 0x831e9d6c
	if ctx.cr[6].eq {
	pc = 0x831E9D6C; continue 'dispatch;
	}
	// 831E9D08: 7EE8BB78  mr r8, r23
	ctx.r[8].u64 = ctx.r[23].u64;
	// 831E9D0C: 815F00C8  lwz r10, 0xc8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(200 as u32) ) } as u64;
	// 831E9D10: 1D680058  mulli r11, r8, 0x58
	ctx.r[11].s64 = ctx.r[8].s64 * 88;
	// 831E9D14: C01F0070  lfs f0, 0x70(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(112 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E9D18: 7D4B5214  add r10, r11, r10
	ctx.r[10].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831E9D1C: 7EE7BB78  mr r7, r23
	ctx.r[7].u64 = ctx.r[23].u64;
	// 831E9D20: 39200006  li r9, 6
	ctx.r[9].s64 = 6;
	// 831E9D24: D00A0028  stfs f0, 0x28(r10)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(40 as u32), tmp.u32 ) };
	// 831E9D28: 815F00C8  lwz r10, 0xc8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(200 as u32) ) } as u64;
	// 831E9D2C: 7D4B5214  add r10, r11, r10
	ctx.r[10].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831E9D30: C1AA0028  lfs f13, 0x28(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E9D34: D1AA0024  stfs f13, 0x24(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831E9D38: 815F00C8  lwz r10, 0xc8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(200 as u32) ) } as u64;
	// 831E9D3C: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831E9D40: 394B0034  addi r10, r11, 0x34
	ctx.r[10].s64 = ctx.r[11].s64 + 52;
	// 831E9D44: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 831E9D48: 90EA0000  stw r7, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[7].u32 ) };
	// 831E9D4C: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 831E9D50: 4200FFF8  bdnz 0x831e9d48
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x831E9D48; continue 'dispatch;
	}
	// 831E9D54: 39480001  addi r10, r8, 1
	ctx.r[10].s64 = ctx.r[8].s64 + 1;
	// 831E9D58: D3EB0030  stfs f31, 0x30(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(48 as u32), tmp.u32 ) };
	// 831E9D5C: 893F0038  lbz r9, 0x38(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E9D60: 5548063E  clrlwi r8, r10, 0x18
	ctx.r[8].u64 = ctx.r[10].u32 as u64 & 0x000000FFu64;
	// 831E9D64: 7F084840  cmplw cr6, r8, r9
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E9D68: 4198FFA4  blt cr6, 0x831e9d0c
	if ctx.cr[6].lt {
	pc = 0x831E9D0C; continue 'dispatch;
	}
	// 831E9D6C: 817F0010  lwz r11, 0x10(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E9D70: 387F0010  addi r3, r31, 0x10
	ctx.r[3].s64 = ctx.r[31].s64 + 16;
	// 831E9D74: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 831E9D78: 38800002  li r4, 2
	ctx.r[4].s64 = 2;
	// 831E9D7C: 814B0054  lwz r10, 0x54(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(84 as u32) ) } as u64;
	// 831E9D80: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E9D84: 4E800421  bctrl
	ctx.lr = 0x831E9D88;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E9D88: 897F00AC  lbz r11, 0xac(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(172 as u32) ) } as u64;
	// 831E9D8C: 556A077A  rlwinm r10, r11, 0, 0x1d, 0x1d
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831E9D90: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E9D94: 419A0074  beq cr6, 0x831e9e08
	if ctx.cr[6].eq {
	pc = 0x831E9E08; continue 'dispatch;
	}
	// 831E9D98: A15F00AE  lhz r10, 0xae(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(174 as u32) ) } as u64;
	// 831E9D9C: 397F0010  addi r11, r31, 0x10
	ctx.r[11].s64 = ctx.r[31].s64 + 16;
	// 831E9DA0: 813F00C8  lwz r9, 0xc8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(200 as u32) ) } as u64;
	// 831E9DA4: 3D0A0001  addis r8, r10, 1
	ctx.r[8].s64 = ctx.r[10].s64 + 65536;
	// 831E9DA8: 3908FFFF  addi r8, r8, -1
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	// 831E9DAC: 5507043E  clrlwi r7, r8, 0x10
	ctx.r[7].u64 = ctx.r[8].u32 as u64 & 0x0000FFFFu64;
	// 831E9DB0: C1A90028  lfs f13, 0x28(r9)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E9DB4: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 831E9DB8: B0FF00AE  sth r7, 0xae(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(174 as u32), ctx.r[7].u16 ) };
	// 831E9DBC: 419A0014  beq cr6, 0x831e9dd0
	if ctx.cr[6].eq {
	pc = 0x831E9DD0; continue 'dispatch;
	}
	// 831E9DC0: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E9DC4: C00B1094  lfs f0, 0x1094(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4244 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E9DC8: EC0D0032  fmuls f0, f13, f0
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E9DCC: 48000008  b 0x831e9dd4
	pc = 0x831E9DD4; continue 'dispatch;
	// 831E9DD0: FC00F890  fmr f0, f31
	ctx.f[0].f64 = ctx.f[31].f64;
	// 831E9DD4: 897F0038  lbz r11, 0x38(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E9DD8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E9DDC: 419A002C  beq cr6, 0x831e9e08
	if ctx.cr[6].eq {
	pc = 0x831E9E08; continue 'dispatch;
	}
	// 831E9DE0: 7EEBBB78  mr r11, r23
	ctx.r[11].u64 = ctx.r[23].u64;
	// 831E9DE4: 815F00C8  lwz r10, 0xc8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(200 as u32) ) } as u64;
	// 831E9DE8: 1D2B0058  mulli r9, r11, 0x58
	ctx.r[9].s64 = ctx.r[11].s64 * 88;
	// 831E9DEC: 7D495214  add r10, r9, r10
	ctx.r[10].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 831E9DF0: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E9DF4: 556B063E  clrlwi r11, r11, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 831E9DF8: D00A0028  stfs f0, 0x28(r10)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(40 as u32), tmp.u32 ) };
	// 831E9DFC: 893F0038  lbz r9, 0x38(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E9E00: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E9E04: 4198FFE0  blt cr6, 0x831e9de4
	if ctx.cr[6].lt {
	pc = 0x831E9DE4; continue 'dispatch;
	}
	// 831E9E08: 81390004  lwz r9, 4(r25)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E9E0C: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E9E10: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831E9E14: 419AFBF8  beq cr6, 0x831e9a0c
	if ctx.cr[6].eq {
	pc = 0x831E9A0C; continue 'dispatch;
	}
	// 831E9E18: 81790008  lwz r11, 8(r25)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E9E1C: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831E9E20: 409AFBEC  bne cr6, 0x831e9a0c
	if !ctx.cr[6].eq {
	pc = 0x831E9A0C; continue 'dispatch;
	}
	// 831E9E24: 3569FFFF  addic. r11, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E9E28: 91790004  stw r11, 4(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E9E2C: 4082FBE0  bne 0x831e9a0c
	if !ctx.cr[0].eq {
	pc = 0x831E9A0C; continue 'dispatch;
	}
	// 831E9E30: 7EEABB78  mr r10, r23
	ctx.r[10].u64 = ctx.r[23].u64;
	// 831E9E34: 8BD9000C  lbz r30, 0xc(r25)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[25].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E9E38: 7EEBBB78  mr r11, r23
	ctx.r[11].u64 = ctx.r[23].u64;
	// 831E9E3C: 91590008  stw r10, 8(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E9E40: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 831E9E44: 9979000C  stb r11, 0xc(r25)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[25].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E9E48: 48058C25  bl 0x83242a6c
	ctx.lr = 0x831E9E4C;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E9E4C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E9E50: 4805931D  bl 0x8324316c
	ctx.lr = 0x831E9E54;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E9E54: 4BFFFBB8  b 0x831e9a0c
	pc = 0x831E9A0C; continue 'dispatch;
	// 831E9E58: 897F0038  lbz r11, 0x38(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E9E5C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E9E60: 419A006C  beq cr6, 0x831e9ecc
	if ctx.cr[6].eq {
	pc = 0x831E9ECC; continue 'dispatch;
	}
	// 831E9E64: 7EFABB78  mr r26, r23
	ctx.r[26].u64 = ctx.r[23].u64;
	// 831E9E68: 817F00C8  lwz r11, 0xc8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(200 as u32) ) } as u64;
	// 831E9E6C: 1D5A0058  mulli r10, r26, 0x58
	ctx.r[10].s64 = ctx.r[26].s64 * 88;
	// 831E9E70: 7F8A5A14  add r28, r10, r11
	ctx.r[28].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831E9E74: 817C0018  lwz r11, 0x18(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(24 as u32) ) } as u64;
	// 831E9E78: 8BDC000D  lbz r30, 0xd(r28)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(13 as u32) ) } as u64;
	// 831E9E7C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E9E80: 419A0034  beq cr6, 0x831e9eb4
	if ctx.cr[6].eq {
	pc = 0x831E9EB4; continue 'dispatch;
	}
	// 831E9E84: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 831E9E88: 419A002C  beq cr6, 0x831e9eb4
	if ctx.cr[6].eq {
	pc = 0x831E9EB4; continue 'dispatch;
	}
	// 831E9E8C: 557B103A  slwi r27, r11, 2
	ctx.r[27].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[27].u64 = ctx.r[27].u32 as u64;
	// 831E9E90: 7EFDBB78  mr r29, r23
	ctx.r[29].u64 = ctx.r[23].u64;
	// 831E9E94: 817C0014  lwz r11, 0x14(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E9E98: 7F65DB78  mr r5, r27
	ctx.r[5].u64 = ctx.r[27].u64;
	// 831E9E9C: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831E9EA0: 7C6BEA14  add r3, r11, r29
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 831E9EA4: 4BFBE33D  bl 0x831a81e0
	ctx.lr = 0x831E9EA8;
	sub_831A81E0(ctx, base);
	// 831E9EA8: 37DEFFFF  addic. r30, r30, -1
	ctx.xer.ca = (ctx.r[30].u32 > (!(-1 as u32)));
	ctx.r[30].s64 = ctx.r[30].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 831E9EAC: 3BBD0400  addi r29, r29, 0x400
	ctx.r[29].s64 = ctx.r[29].s64 + 1024;
	// 831E9EB0: 4082FFE4  bne 0x831e9e94
	if !ctx.cr[0].eq {
	pc = 0x831E9E94; continue 'dispatch;
	}
	// 831E9EB4: 397A0001  addi r11, r26, 1
	ctx.r[11].s64 = ctx.r[26].s64 + 1;
	// 831E9EB8: 895F0038  lbz r10, 0x38(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E9EBC: 556B063E  clrlwi r11, r11, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 831E9EC0: 7D7A5B78  mr r26, r11
	ctx.r[26].u64 = ctx.r[11].u64;
	// 831E9EC4: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E9EC8: 4198FFA0  blt cr6, 0x831e9e68
	if ctx.cr[6].lt {
	pc = 0x831E9E68; continue 'dispatch;
	}
	// 831E9ECC: 81390004  lwz r9, 4(r25)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E9ED0: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E9ED4: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831E9ED8: 419A0040  beq cr6, 0x831e9f18
	if ctx.cr[6].eq {
	pc = 0x831E9F18; continue 'dispatch;
	}
	// 831E9EDC: 81790008  lwz r11, 8(r25)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E9EE0: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831E9EE4: 409A0034  bne cr6, 0x831e9f18
	if !ctx.cr[6].eq {
	pc = 0x831E9F18; continue 'dispatch;
	}
	// 831E9EE8: 3569FFFF  addic. r11, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E9EEC: 91790004  stw r11, 4(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E9EF0: 40820028  bne 0x831e9f18
	if !ctx.cr[0].eq {
	pc = 0x831E9F18; continue 'dispatch;
	}
	// 831E9EF4: 7EEABB78  mr r10, r23
	ctx.r[10].u64 = ctx.r[23].u64;
	// 831E9EF8: 8BF9000C  lbz r31, 0xc(r25)
	ctx.r[31].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[25].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E9EFC: 7EEBBB78  mr r11, r23
	ctx.r[11].u64 = ctx.r[23].u64;
	// 831E9F00: 91590008  stw r10, 8(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E9F04: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 831E9F08: 9979000C  stb r11, 0xc(r25)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[25].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E9F0C: 48058B61  bl 0x83242a6c
	ctx.lr = 0x831E9F10;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E9F10: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E9F14: 48059259  bl 0x8324316c
	ctx.lr = 0x831E9F18;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E9F18: 3BC00001  li r30, 1
	ctx.r[30].s64 = 1;
	// 831E9F1C: 4BFFF990  b 0x831e98ac
	pc = 0x831E98AC; continue 'dispatch;
	// 831E9F20: 7D2B4B78  mr r11, r9
	ctx.r[11].u64 = ctx.r[9].u64;
	// 831E9F24: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E9F28: 7F095840  cmplw cr6, r9, r11
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831E9F2C: 419A0010  beq cr6, 0x831e9f3c
	if ctx.cr[6].eq {
	pc = 0x831E9F3C; continue 'dispatch;
	}
	// 831E9F30: 81490008  lwz r10, 8(r9)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E9F34: 7D6A5850  subf r11, r10, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[10].s64;
	// 831E9F38: 48000008  b 0x831e9f40
	pc = 0x831E9F40; continue 'dispatch;
	// 831E9F3C: 7EEBBB78  mr r11, r23
	ctx.r[11].u64 = ctx.r[23].u64;
	// 831E9F40: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 831E9F44: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E9F48: 419A0020  beq cr6, 0x831e9f68
	if ctx.cr[6].eq {
	pc = 0x831E9F68; continue 'dispatch;
	}
	// 831E9F4C: 896B0074  lbz r11, 0x74(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(116 as u32) ) } as u64;
	// 831E9F50: 396BFFFC  addi r11, r11, -4
	ctx.r[11].s64 = ctx.r[11].s64 + -4;
	// 831E9F54: 7D660034  cntlzw r6, r11
	ctx.r[6].u64 = if ctx.r[11].u32 == 0 { 32 } else { ctx.r[11].u32.leading_zeros() as u64 };
	// 831E9F58: 54C5DFFE  rlwinm r5, r6, 0x1b, 0x1f, 0x1f
	ctx.r[5].u64 = ctx.r[6].u32 as u64 & 0x0000001Fu64;
	// 831E9F5C: 68A40001  xori r4, r5, 1
	ctx.r[4].u64 = ctx.r[5].u64 ^ 1;
	// 831E9F60: 7C884378  or r8, r4, r8
	ctx.r[8].u64 = ctx.r[4].u64 | ctx.r[8].u64;
	// 831E9F64: 4BFFFCF4  b 0x831e9c58
	pc = 0x831E9C58; continue 'dispatch;
	// 831E9F68: 550B063E  clrlwi r11, r8, 0x18
	ctx.r[11].u64 = ctx.r[8].u32 as u64 & 0x000000FFu64;
	// 831E9F6C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E9F70: 409A0054  bne cr6, 0x831e9fc4
	if !ctx.cr[6].eq {
	pc = 0x831E9FC4; continue 'dispatch;
	}
	// 831E9F74: 817F0010  lwz r11, 0x10(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E9F78: 387F0010  addi r3, r31, 0x10
	ctx.r[3].s64 = ctx.r[31].s64 + 16;
	// 831E9F7C: 38A00010  li r5, 0x10
	ctx.r[5].s64 = 16;
	// 831E9F80: 38800010  li r4, 0x10
	ctx.r[4].s64 = 16;
	// 831E9F84: 814B0054  lwz r10, 0x54(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(84 as u32) ) } as u64;
	// 831E9F88: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E9F8C: 4E800421  bctrl
	ctx.lr = 0x831E9F90;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E9F90: 48000030  b 0x831e9fc0
	pc = 0x831E9FC0; continue 'dispatch;
	// 831E9F94: 2F1C0000  cmpwi cr6, r28, 0
	ctx.cr[6].compare_i32(ctx.r[28].s32, 0, &mut ctx.xer);
	// 831E9F98: 409A002C  bne cr6, 0x831e9fc4
	if !ctx.cr[6].eq {
	pc = 0x831E9FC4; continue 'dispatch;
	}
	// 831E9F9C: 556B06F6  rlwinm r11, r11, 0, 0x1b, 0x1b
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831E9FA0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E9FA4: 409A0020  bne cr6, 0x831e9fc4
	if !ctx.cr[6].eq {
	pc = 0x831E9FC4; continue 'dispatch;
	}
	// 831E9FA8: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E9FAC: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 831E9FB0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E9FB4: 814B0034  lwz r10, 0x34(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(52 as u32) ) } as u64;
	// 831E9FB8: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E9FBC: 4E800421  bctrl
	ctx.lr = 0x831E9FC0;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E9FC0: 80F90004  lwz r7, 4(r25)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E9FC4: 897F00AC  lbz r11, 0xac(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(172 as u32) ) } as u64;
	// 831E9FC8: 556A077A  rlwinm r10, r11, 0, 0x1d, 0x1d
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831E9FCC: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E9FD0: 419A0038  beq cr6, 0x831ea008
	if ctx.cr[6].eq {
	pc = 0x831EA008; continue 'dispatch;
	}
	// 831E9FD4: A15F00AE  lhz r10, 0xae(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(174 as u32) ) } as u64;
	// 831E9FD8: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E9FDC: 419A0010  beq cr6, 0x831e9fec
	if ctx.cr[6].eq {
	pc = 0x831E9FEC; continue 'dispatch;
	}
	// 831E9FE0: 556B06F6  rlwinm r11, r11, 0, 0x1b, 0x1b
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831E9FE4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E9FE8: 419A0020  beq cr6, 0x831ea008
	if ctx.cr[6].eq {
	pc = 0x831EA008; continue 'dispatch;
	}
	// 831E9FEC: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E9FF0: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 831E9FF4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E9FF8: 814B0034  lwz r10, 0x34(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(52 as u32) ) } as u64;
	// 831E9FFC: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831EA000: 4E800421  bctrl
	ctx.lr = 0x831EA004;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831EA004: 80F90004  lwz r7, 4(r25)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EA008: 897F00AC  lbz r11, 0xac(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(172 as u32) ) } as u64;
	// 831EA00C: 556A07FE  clrlwi r10, r11, 0x1f
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0x00000001u64;
	// 831EA010: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831EA014: 419A0010  beq cr6, 0x831ea024
	if ctx.cr[6].eq {
	pc = 0x831EA024; continue 'dispatch;
	}
	// 831EA018: 556B06F6  rlwinm r11, r11, 0, 0x1b, 0x1b
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831EA01C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831EA020: 419A01A4  beq cr6, 0x831ea1c4
	if ctx.cr[6].eq {
	pc = 0x831EA1C4; continue 'dispatch;
	}
	// 831EA024: 817F0014  lwz r11, 0x14(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 831EA028: 3B7F0014  addi r27, r31, 0x14
	ctx.r[27].s64 = ctx.r[31].s64 + 20;
	// 831EA02C: 7F1B5840  cmplw cr6, r27, r11
	ctx.cr[6].compare_u32(ctx.r[27].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831EA030: 419A0010  beq cr6, 0x831ea040
	if ctx.cr[6].eq {
	pc = 0x831EA040; continue 'dispatch;
	}
	// 831EA034: 815B0008  lwz r10, 8(r27)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EA038: 7D6A5850  subf r11, r10, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[10].s64;
	// 831EA03C: 48000008  b 0x831ea044
	pc = 0x831EA044; continue 'dispatch;
	// 831EA040: 7EEBBB78  mr r11, r23
	ctx.r[11].u64 = ctx.r[23].u64;
	// 831EA044: 7D7C5B78  mr r28, r11
	ctx.r[28].u64 = ctx.r[11].u64;
	// 831EA048: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831EA04C: 419A0178  beq cr6, 0x831ea1c4
	if ctx.cr[6].eq {
	pc = 0x831EA1C4; continue 'dispatch;
	}
	// 831EA050: 7F9EE378  mr r30, r28
	ctx.r[30].u64 = ctx.r[28].u64;
	// 831EA054: 2B1C0000  cmplwi cr6, r28, 0
	ctx.cr[6].compare_u32(ctx.r[28].u32, 0 as u32, &mut ctx.xer);
	// 831EA058: 419A0010  beq cr6, 0x831ea068
	if ctx.cr[6].eq {
	pc = 0x831EA068; continue 'dispatch;
	}
	// 831EA05C: 817B0008  lwz r11, 8(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EA060: 7D6BE214  add r11, r11, r28
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[28].u64;
	// 831EA064: 48000008  b 0x831ea06c
	pc = 0x831EA06C; continue 'dispatch;
	// 831EA068: 7F6BDB78  mr r11, r27
	ctx.r[11].u64 = ctx.r[27].u64;
	// 831EA06C: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831EA070: 7F1B5840  cmplw cr6, r27, r11
	ctx.cr[6].compare_u32(ctx.r[27].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831EA074: 419A0010  beq cr6, 0x831ea084
	if ctx.cr[6].eq {
	pc = 0x831EA084; continue 'dispatch;
	}
	// 831EA078: 815B0008  lwz r10, 8(r27)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EA07C: 7F8A5850  subf r28, r10, r11
	ctx.r[28].s64 = ctx.r[11].s64 - ctx.r[10].s64;
	// 831EA080: 48000008  b 0x831ea088
	pc = 0x831EA088; continue 'dispatch;
	// 831EA084: 7EFCBB78  mr r28, r23
	ctx.r[28].u64 = ctx.r[23].u64;
	// 831EA088: 897E0074  lbz r11, 0x74(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(116 as u32) ) } as u64;
	// 831EA08C: 2B0B0004  cmplwi cr6, r11, 4
	ctx.cr[6].compare_u32(ctx.r[11].u32, 4 as u32, &mut ctx.xer);
	// 831EA090: 409A012C  bne cr6, 0x831ea1bc
	if !ctx.cr[6].eq {
	pc = 0x831EA1BC; continue 'dispatch;
	}
	// 831EA094: 7DAB6B78  mr r11, r13
	ctx.r[11].u64 = ctx.r[13].u64;
	// 831EA098: 2F070000  cmpwi cr6, r7, 0
	ctx.cr[6].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 831EA09C: 419A0040  beq cr6, 0x831ea0dc
	if ctx.cr[6].eq {
	pc = 0x831EA0DC; continue 'dispatch;
	}
	// 831EA0A0: 81590008  lwz r10, 8(r25)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EA0A4: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831EA0A8: 409A0034  bne cr6, 0x831ea0dc
	if !ctx.cr[6].eq {
	pc = 0x831EA0DC; continue 'dispatch;
	}
	// 831EA0AC: 3567FFFF  addic. r11, r7, -1
	ctx.xer.ca = (ctx.r[7].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[7].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EA0B0: 91790004  stw r11, 4(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831EA0B4: 40820028  bne 0x831ea0dc
	if !ctx.cr[0].eq {
	pc = 0x831EA0DC; continue 'dispatch;
	}
	// 831EA0B8: 7EEBBB78  mr r11, r23
	ctx.r[11].u64 = ctx.r[23].u64;
	// 831EA0BC: 8BB9000C  lbz r29, 0xc(r25)
	ctx.r[29].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[25].u32.wrapping_add(12 as u32) ) } as u64;
	// 831EA0C0: 7EEABB78  mr r10, r23
	ctx.r[10].u64 = ctx.r[23].u64;
	// 831EA0C4: 9979000C  stb r11, 0xc(r25)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[25].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831EA0C8: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 831EA0CC: 91590008  stw r10, 8(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831EA0D0: 4805899D  bl 0x83242a6c
	ctx.lr = 0x831EA0D4;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831EA0D4: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831EA0D8: 48059095  bl 0x8324316c
	ctx.lr = 0x831EA0DC;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831EA0DC: 81780004  lwz r11, 4(r24)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EA0E0: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831EA0E4: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EA0E8: 419A0038  beq cr6, 0x831ea120
	if ctx.cr[6].eq {
	pc = 0x831EA120; continue 'dispatch;
	}
	// 831EA0EC: 81380008  lwz r9, 8(r24)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EA0F0: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831EA0F4: 409A002C  bne cr6, 0x831ea120
	if !ctx.cr[6].eq {
	pc = 0x831EA120; continue 'dispatch;
	}
	// 831EA0F8: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EA0FC: 91780004  stw r11, 4(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831EA100: 40820020  bne 0x831ea120
	if !ctx.cr[0].eq {
	pc = 0x831EA120; continue 'dispatch;
	}
	// 831EA104: 8BB8000C  lbz r29, 0xc(r24)
	ctx.r[29].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[24].u32.wrapping_add(12 as u32) ) } as u64;
	// 831EA108: 7F03C378  mr r3, r24
	ctx.r[3].u64 = ctx.r[24].u64;
	// 831EA10C: 9AF8000C  stb r23, 0xc(r24)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[24].u32.wrapping_add(12 as u32), ctx.r[23].u8 ) };
	// 831EA110: 92F80008  stw r23, 8(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(8 as u32), ctx.r[23].u32 ) };
	// 831EA114: 48058959  bl 0x83242a6c
	ctx.lr = 0x831EA118;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831EA118: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831EA11C: 48059051  bl 0x8324316c
	ctx.lr = 0x831EA120;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831EA120: 817F0010  lwz r11, 0x10(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 831EA124: 387F0010  addi r3, r31, 0x10
	ctx.r[3].s64 = ctx.r[31].s64 + 16;
	// 831EA128: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 831EA12C: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 831EA130: 814B005C  lwz r10, 0x5c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(92 as u32) ) } as u64;
	// 831EA134: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831EA138: 4E800421  bctrl
	ctx.lr = 0x831EA13C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831EA13C: 48059021  bl 0x8324315c
	ctx.lr = 0x831EA140;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831EA140: 81380004  lwz r9, 4(r24)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EA144: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831EA148: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831EA14C: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831EA150: 419A0010  beq cr6, 0x831ea160
	if ctx.cr[6].eq {
	pc = 0x831EA160; continue 'dispatch;
	}
	// 831EA154: 81780008  lwz r11, 8(r24)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EA158: 7F1E5840  cmplw cr6, r30, r11
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831EA15C: 419A0014  beq cr6, 0x831ea170
	if ctx.cr[6].eq {
	pc = 0x831EA170; continue 'dispatch;
	}
	// 831EA160: 7F03C378  mr r3, r24
	ctx.r[3].u64 = ctx.r[24].u64;
	// 831EA164: 48058919  bl 0x83242a7c
	ctx.lr = 0x831EA168;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831EA168: 93D80008  stw r30, 8(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831EA16C: 9BB8000C  stb r29, 0xc(r24)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[24].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831EA170: 81780004  lwz r11, 4(r24)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EA174: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831EA178: 91780004  stw r11, 4(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831EA17C: 48058FE1  bl 0x8324315c
	ctx.lr = 0x831EA180;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831EA180: 81790004  lwz r11, 4(r25)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EA184: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831EA188: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831EA18C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EA190: 419A0010  beq cr6, 0x831ea1a0
	if ctx.cr[6].eq {
	pc = 0x831EA1A0; continue 'dispatch;
	}
	// 831EA194: 81590008  lwz r10, 8(r25)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EA198: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831EA19C: 419A0018  beq cr6, 0x831ea1b4
	if ctx.cr[6].eq {
	pc = 0x831EA1B4; continue 'dispatch;
	}
	// 831EA1A0: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 831EA1A4: 480588D9  bl 0x83242a7c
	ctx.lr = 0x831EA1A8;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831EA1A8: 81790004  lwz r11, 4(r25)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EA1AC: 93D90008  stw r30, 8(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831EA1B0: 9BB9000C  stb r29, 0xc(r25)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[25].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831EA1B4: 38EB0001  addi r7, r11, 1
	ctx.r[7].s64 = ctx.r[11].s64 + 1;
	// 831EA1B8: 90F90004  stw r7, 4(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(4 as u32), ctx.r[7].u32 ) };
	// 831EA1BC: 2B1C0000  cmplwi cr6, r28, 0
	ctx.cr[6].compare_u32(ctx.r[28].u32, 0 as u32, &mut ctx.xer);
	// 831EA1C0: 409AFE90  bne cr6, 0x831ea050
	if !ctx.cr[6].eq {
	pc = 0x831EA050; continue 'dispatch;
	}
	// 831EA1C4: 7DAB6B78  mr r11, r13
	ctx.r[11].u64 = ctx.r[13].u64;
	// 831EA1C8: 2F070000  cmpwi cr6, r7, 0
	ctx.cr[6].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 831EA1CC: 419A0040  beq cr6, 0x831ea20c
	if ctx.cr[6].eq {
	pc = 0x831EA20C; continue 'dispatch;
	}
	// 831EA1D0: 81590008  lwz r10, 8(r25)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EA1D4: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831EA1D8: 409A0034  bne cr6, 0x831ea20c
	if !ctx.cr[6].eq {
	pc = 0x831EA20C; continue 'dispatch;
	}
	// 831EA1DC: 3567FFFF  addic. r11, r7, -1
	ctx.xer.ca = (ctx.r[7].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[7].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EA1E0: 91790004  stw r11, 4(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831EA1E4: 40820028  bne 0x831ea20c
	if !ctx.cr[0].eq {
	pc = 0x831EA20C; continue 'dispatch;
	}
	// 831EA1E8: 7EEBBB78  mr r11, r23
	ctx.r[11].u64 = ctx.r[23].u64;
	// 831EA1EC: 8BD9000C  lbz r30, 0xc(r25)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[25].u32.wrapping_add(12 as u32) ) } as u64;
	// 831EA1F0: 7EEABB78  mr r10, r23
	ctx.r[10].u64 = ctx.r[23].u64;
	// 831EA1F4: 9979000C  stb r11, 0xc(r25)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[25].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831EA1F8: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 831EA1FC: 91590008  stw r10, 8(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831EA200: 4805886D  bl 0x83242a6c
	ctx.lr = 0x831EA204;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831EA204: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831EA208: 48058F65  bl 0x8324316c
	ctx.lr = 0x831EA20C;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831EA20C: 56CB063E  clrlwi r11, r22, 0x18
	ctx.r[11].u64 = ctx.r[22].u32 as u64 & 0x000000FFu64;
	// 831EA210: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831EA214: 419A007C  beq cr6, 0x831ea290
	if ctx.cr[6].eq {
	pc = 0x831EA290; continue 'dispatch;
	}
	// 831EA218: 807F00B8  lwz r3, 0xb8(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(184 as u32) ) } as u64;
	// 831EA21C: 4BFF0105  bl 0x831da320
	ctx.lr = 0x831EA220;
	sub_831DA320(ctx, base);
	// 831EA220: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831EA224: 419A006C  beq cr6, 0x831ea290
	if ctx.cr[6].eq {
	pc = 0x831EA290; continue 'dispatch;
	}
	// 831EA228: 807F00B8  lwz r3, 0xb8(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(184 as u32) ) } as u64;
	// 831EA22C: 4BFF0D05  bl 0x831daf30
	ctx.lr = 0x831EA230;
	sub_831DAF30(ctx, base);
	// 831EA230: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831EA234: 2F1F0000  cmpwi cr6, r31, 0
	ctx.cr[6].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 831EA238: 40980058  bge cr6, 0x831ea290
	if !ctx.cr[6].lt {
	pc = 0x831EA290; continue 'dispatch;
	}
	// 831EA23C: 81780004  lwz r11, 4(r24)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EA240: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831EA244: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EA248: 419A0038  beq cr6, 0x831ea280
	if ctx.cr[6].eq {
	pc = 0x831EA280; continue 'dispatch;
	}
	// 831EA24C: 81380008  lwz r9, 8(r24)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EA250: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831EA254: 409A002C  bne cr6, 0x831ea280
	if !ctx.cr[6].eq {
	pc = 0x831EA280; continue 'dispatch;
	}
	// 831EA258: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EA25C: 91780004  stw r11, 4(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831EA260: 40820020  bne 0x831ea280
	if !ctx.cr[0].eq {
	pc = 0x831EA280; continue 'dispatch;
	}
	// 831EA264: 8BD8000C  lbz r30, 0xc(r24)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[24].u32.wrapping_add(12 as u32) ) } as u64;
	// 831EA268: 7F03C378  mr r3, r24
	ctx.r[3].u64 = ctx.r[24].u64;
	// 831EA26C: 92F80008  stw r23, 8(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(8 as u32), ctx.r[23].u32 ) };
	// 831EA270: 9AF8000C  stb r23, 0xc(r24)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[24].u32.wrapping_add(12 as u32), ctx.r[23].u8 ) };
	// 831EA274: 480587F9  bl 0x83242a6c
	ctx.lr = 0x831EA278;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831EA278: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831EA27C: 48058EF1  bl 0x8324316c
	ctx.lr = 0x831EA280;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831EA280: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831EA284: 382100D0  addi r1, r1, 0xd0
	ctx.r[1].s64 = ctx.r[1].s64 + 208;
	// 831EA288: CBE1FFA0  lfd f31, -0x60(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-96 as u32) ) };
	// 831EA28C: 4BFBDF14  b 0x831a81a0
	sub_831A8180(ctx, base);
	return;
	// 831EA290: 81780004  lwz r11, 4(r24)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EA294: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831EA298: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EA29C: 419A0038  beq cr6, 0x831ea2d4
	if ctx.cr[6].eq {
	pc = 0x831EA2D4; continue 'dispatch;
	}
	// 831EA2A0: 81380008  lwz r9, 8(r24)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EA2A4: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831EA2A8: 409A002C  bne cr6, 0x831ea2d4
	if !ctx.cr[6].eq {
	pc = 0x831EA2D4; continue 'dispatch;
	}
	// 831EA2AC: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EA2B0: 91780004  stw r11, 4(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831EA2B4: 40820020  bne 0x831ea2d4
	if !ctx.cr[0].eq {
	pc = 0x831EA2D4; continue 'dispatch;
	}
	// 831EA2B8: 8BF8000C  lbz r31, 0xc(r24)
	ctx.r[31].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[24].u32.wrapping_add(12 as u32) ) } as u64;
	// 831EA2BC: 7F03C378  mr r3, r24
	ctx.r[3].u64 = ctx.r[24].u64;
	// 831EA2C0: 92F80008  stw r23, 8(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(8 as u32), ctx.r[23].u32 ) };
	// 831EA2C4: 9AF8000C  stb r23, 0xc(r24)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[24].u32.wrapping_add(12 as u32), ctx.r[23].u8 ) };
	// 831EA2C8: 480587A5  bl 0x83242a6c
	ctx.lr = 0x831EA2CC;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831EA2CC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831EA2D0: 48058E9D  bl 0x8324316c
	ctx.lr = 0x831EA2D4;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831EA2D4: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831EA2D8: 382100D0  addi r1, r1, 0xd0
	ctx.r[1].s64 = ctx.r[1].s64 + 208;
	// 831EA2DC: CBE1FFA0  lfd f31, -0x60(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-96 as u32) ) };
	// 831EA2E0: 4BFBDEC0  b 0x831a81a0
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EA2E8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831EA2E8 size=172
    let mut pc: u32 = 0x831EA2E8;
    'dispatch: loop {
        match pc {
            0x831EA2E8 => {
    //   block [0x831EA2E8..0x831EA394)
	// 831EA2E8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EA2EC: 4BFBDE81  bl 0x831a816c
	ctx.lr = 0x831EA2F0;
	sub_831A8130(ctx, base);
	// 831EA2F0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831EA2F4: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 831EA2F8: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831EA2FC: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 831EA300: 38800138  li r4, 0x138
	ctx.r[4].s64 = 312;
	// 831EA304: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831EA308: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831EA30C: 814B0014  lwz r10, 0x14(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 831EA310: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831EA314: 4E800421  bctrl
	ctx.lr = 0x831EA318;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831EA318: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831EA31C: 419A001C  beq cr6, 0x831ea338
	if ctx.cr[6].eq {
	pc = 0x831EA338; continue 'dispatch;
	}
	// 831EA320: 7FE5FB78  mr r5, r31
	ctx.r[5].u64 = ctx.r[31].u64;
	// 831EA324: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 831EA328: 4BFFF391  bl 0x831e96b8
	ctx.lr = 0x831EA32C;
	sub_831E96B8(ctx, base);
	// 831EA32C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831EA330: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 831EA334: 409A0014  bne cr6, 0x831ea348
	if !ctx.cr[6].eq {
	pc = 0x831EA348; continue 'dispatch;
	}
	// 831EA338: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 831EA33C: 6063000E  ori r3, r3, 0xe
	ctx.r[3].u64 = ctx.r[3].u64 | 14;
	// 831EA340: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831EA344: 4BFBDE78  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 831EA348: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831EA34C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831EA350: 814B0078  lwz r10, 0x78(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(120 as u32) ) } as u64;
	// 831EA354: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831EA358: 4E800421  bctrl
	ctx.lr = 0x831EA35C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831EA35C: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831EA360: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 831EA364: 41980010  blt cr6, 0x831ea374
	if ctx.cr[6].lt {
	pc = 0x831EA374; continue 'dispatch;
	}
	// 831EA368: 93FD0000  stw r31, 0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[31].u32 ) };
	// 831EA36C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831EA370: 4BFBDE4C  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 831EA374: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EA378: 387F0004  addi r3, r31, 4
	ctx.r[3].s64 = ctx.r[31].s64 + 4;
	// 831EA37C: 814B000C  lwz r10, 0xc(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 831EA380: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831EA384: 4E800421  bctrl
	ctx.lr = 0x831EA388;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831EA388: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831EA38C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831EA390: 4BFBDE2C  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EA398(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831EA398 size=8
    let mut pc: u32 = 0x831EA398;
    'dispatch: loop {
        match pc {
            0x831EA398 => {
    //   block [0x831EA398..0x831EA3A0)
	// 831EA398: 3863FFFC  addi r3, r3, -4
	ctx.r[3].s64 = ctx.r[3].s64 + -4;
	// 831EA39C: 4800015C  b 0x831ea4f8
	sub_831EA4F8(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EA3A0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831EA3A0 size=8
    let mut pc: u32 = 0x831EA3A0;
    'dispatch: loop {
        match pc {
            0x831EA3A0 => {
    //   block [0x831EA3A0..0x831EA3A8)
	// 831EA3A0: 3863FFF0  addi r3, r3, -0x10
	ctx.r[3].s64 = ctx.r[3].s64 + -16;
	// 831EA3A4: 48000154  b 0x831ea4f8
	sub_831EA4F8(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EA3A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831EA3A8 size=8
    let mut pc: u32 = 0x831EA3A8;
    'dispatch: loop {
        match pc {
            0x831EA3A8 => {
    //   block [0x831EA3A8..0x831EA3B0)
	// 831EA3A8: 38630010  addi r3, r3, 0x10
	ctx.r[3].s64 = ctx.r[3].s64 + 16;
	// 831EA3AC: 4BFFCCCC  b 0x831e7078
	sub_831E7078(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EA3B0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831EA3B0 size=8
    let mut pc: u32 = 0x831EA3B0;
    'dispatch: loop {
        match pc {
            0x831EA3B0 => {
    //   block [0x831EA3B0..0x831EA3B8)
	// 831EA3B0: 38630010  addi r3, r3, 0x10
	ctx.r[3].s64 = ctx.r[3].s64 + 16;
	// 831EA3B4: 4BFFCF7C  b 0x831e7330
	sub_831E7330(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EA3B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831EA3B8 size=8
    let mut pc: u32 = 0x831EA3B8;
    'dispatch: loop {
        match pc {
            0x831EA3B8 => {
    //   block [0x831EA3B8..0x831EA3C0)
	// 831EA3B8: 38630010  addi r3, r3, 0x10
	ctx.r[3].s64 = ctx.r[3].s64 + 16;
	// 831EA3BC: 4BFFC78C  b 0x831e6b48
	sub_831E6B48(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EA3C0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831EA3C0 size=72
    let mut pc: u32 = 0x831EA3C0;
    'dispatch: loop {
        match pc {
            0x831EA3C0 => {
    //   block [0x831EA3C0..0x831EA408)
	// 831EA3C0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EA3C4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831EA3C8: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831EA3CC: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831EA3D0: C0230074  lfs f1, 0x74(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(116 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831EA3D4: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 831EA3D8: 4BFC3EF9  bl 0x831ae2d0
	ctx.lr = 0x831EA3DC;
	sub_831AE2D0(ctx, base);
	// 831EA3DC: FDA00818  frsp f13, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[13].f64 = (ctx.f[1].f64 as f32) as f64;
	// 831EA3E0: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831EA3E4: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831EA3E8: C00B01D0  lfs f0, 0x1d0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(464 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831EA3EC: ED8D0032  fmuls f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 831EA3F0: D19F0000  stfs f12, 0(r31)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831EA3F4: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831EA3F8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831EA3FC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831EA400: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831EA404: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EA408(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831EA408 size=16
    let mut pc: u32 = 0x831EA408;
    'dispatch: loop {
        match pc {
            0x831EA408 => {
    //   block [0x831EA408..0x831EA418)
	// 831EA408: C0030074  lfs f0, 0x74(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(116 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831EA40C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831EA410: D0040000  stfs f0, 0(r4)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831EA414: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EA418(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831EA418 size=28
    let mut pc: u32 = 0x831EA418;
    'dispatch: loop {
        match pc {
            0x831EA418 => {
    //   block [0x831EA418..0x831EA434)
	// 831EA418: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 831EA41C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831EA420: A14B006C  lhz r10, 0x6c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(108 as u32) ) } as u64;
	// 831EA424: 812B0078  lwz r9, 0x78(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(120 as u32) ) } as u64;
	// 831EA428: 7D0A49D6  mullw r8, r10, r9
	ctx.r[8].s64 = (ctx.r[10].s32 as i64) * (ctx.r[9].s32 as i64);
	// 831EA42C: 91040000  stw r8, 0(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 831EA430: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EA438(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831EA438 size=16
    let mut pc: u32 = 0x831EA438;
    'dispatch: loop {
        match pc {
            0x831EA438 => {
    //   block [0x831EA438..0x831EA448)
	// 831EA438: 816300A8  lwz r11, 0xa8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(168 as u32) ) } as u64;
	// 831EA43C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831EA440: 91640000  stw r11, 0(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831EA444: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EA448(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831EA448 size=80
    let mut pc: u32 = 0x831EA448;
    'dispatch: loop {
        match pc {
            0x831EA448 => {
    //   block [0x831EA448..0x831EA498)
	// 831EA448: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EA44C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831EA450: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831EA454: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831EA458: 81630010  lwz r11, 0x10(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 831EA45C: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 831EA460: 38630010  addi r3, r3, 0x10
	ctx.r[3].s64 = ctx.r[3].s64 + 16;
	// 831EA464: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831EA468: 814B0058  lwz r10, 0x58(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(88 as u32) ) } as u64;
	// 831EA46C: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831EA470: 4E800421  bctrl
	ctx.lr = 0x831EA474;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831EA474: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831EA478: 4198000C  blt cr6, 0x831ea484
	if ctx.cr[6].lt {
	pc = 0x831EA484; continue 'dispatch;
	}
	// 831EA47C: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831EA480: 93EB0010  stw r31, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[31].u32 ) };
	// 831EA484: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831EA488: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831EA48C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831EA490: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831EA494: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EA498(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831EA498 size=84
    let mut pc: u32 = 0x831EA498;
    'dispatch: loop {
        match pc {
            0x831EA498 => {
    //   block [0x831EA498..0x831EA4EC)
	// 831EA498: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EA49C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831EA4A0: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831EA4A4: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831EA4A8: 81630010  lwz r11, 0x10(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 831EA4AC: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 831EA4B0: 38630010  addi r3, r3, 0x10
	ctx.r[3].s64 = ctx.r[3].s64 + 16;
	// 831EA4B4: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831EA4B8: 814B0058  lwz r10, 0x58(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(88 as u32) ) } as u64;
	// 831EA4BC: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831EA4C0: 4E800421  bctrl
	ctx.lr = 0x831EA4C4;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831EA4C4: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831EA4C8: 41980010  blt cr6, 0x831ea4d8
	if ctx.cr[6].lt {
	pc = 0x831EA4D8; continue 'dispatch;
	}
	// 831EA4CC: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831EA4D0: 814B0024  lwz r10, 0x24(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) } as u64;
	// 831EA4D4: 915F0000  stw r10, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831EA4D8: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831EA4DC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831EA4E0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831EA4E4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831EA4E8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EA4F0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831EA4F0 size=8
    let mut pc: u32 = 0x831EA4F0;
    'dispatch: loop {
        match pc {
            0x831EA4F0 => {
    //   block [0x831EA4F0..0x831EA4F8)
	// 831EA4F0: 38630004  addi r3, r3, 4
	ctx.r[3].s64 = ctx.r[3].s64 + 4;
	// 831EA4F4: 4BFF6F8C  b 0x831e1480
	sub_831E1480(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EA4F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831EA4F8 size=88
    let mut pc: u32 = 0x831EA4F8;
    'dispatch: loop {
        match pc {
            0x831EA4F8 => {
    //   block [0x831EA4F8..0x831EA550)
	// 831EA4F8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EA4FC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831EA500: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831EA504: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831EA508: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831EA50C: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831EA510: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831EA514: 3D20821A  lis r9, -0x7de6
	ctx.r[9].s64 = -2112225280;
	// 831EA518: 390B1288  addi r8, r11, 0x1288
	ctx.r[8].s64 = ctx.r[11].s64 + 4744;
	// 831EA51C: 38EA1260  addi r7, r10, 0x1260
	ctx.r[7].s64 = ctx.r[10].s64 + 4704;
	// 831EA520: 38C91200  addi r6, r9, 0x1200
	ctx.r[6].s64 = ctx.r[9].s64 + 4608;
	// 831EA524: 911F0000  stw r8, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 831EA528: 90FF0004  stw r7, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[7].u32 ) };
	// 831EA52C: 387F0004  addi r3, r31, 4
	ctx.r[3].s64 = ctx.r[31].s64 + 4;
	// 831EA530: 90DF0010  stw r6, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[6].u32 ) };
	// 831EA534: 4BFF749D  bl 0x831e19d0
	ctx.lr = 0x831EA538;
	sub_831E19D0(ctx, base);
	// 831EA538: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831EA53C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831EA540: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831EA544: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831EA548: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831EA54C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EA550(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831EA550 size=96
    let mut pc: u32 = 0x831EA550;
    'dispatch: loop {
        match pc {
            0x831EA550 => {
    //   block [0x831EA550..0x831EA5B0)
	// 831EA550: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EA554: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831EA558: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831EA55C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831EA560: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831EA564: 387F0010  addi r3, r31, 0x10
	ctx.r[3].s64 = ctx.r[31].s64 + 16;
	// 831EA568: 4BFFCA71  bl 0x831e6fd8
	ctx.lr = 0x831EA56C;
	sub_831E6FD8(ctx, base);
	// 831EA56C: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831EA570: 4198002C  blt cr6, 0x831ea59c
	if ctx.cr[6].lt {
	pc = 0x831EA59C; continue 'dispatch;
	}
	// 831EA574: 897F00C4  lbz r11, 0xc4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(196 as u32) ) } as u64;
	// 831EA578: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831EA57C: 893F00C5  lbz r9, 0xc5(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(197 as u32) ) } as u64;
	// 831EA580: 39000001  li r8, 1
	ctx.r[8].s64 = 1;
	// 831EA584: 38EA1300  addi r7, r10, 0x1300
	ctx.r[7].s64 = ctx.r[10].s64 + 4864;
	// 831EA588: 5566103E  rotlwi r6, r11, 2
	ctx.r[6].u64 = ((ctx.r[11].u32).rotate_left(2)) as u64;
	// 831EA58C: 7CA6382E  lwzx r5, r6, r7
	ctx.r[5].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[7].u32)) } as u64;
	// 831EA590: B11F006E  sth r8, 0x6e(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(110 as u32), ctx.r[8].u16 ) };
	// 831EA594: 7C8549D6  mullw r4, r5, r9
	ctx.r[4].s64 = (ctx.r[5].s32 as i64) * (ctx.r[9].s32 as i64);
	// 831EA598: B09F006C  sth r4, 0x6c(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(108 as u32), ctx.r[4].u16 ) };
	// 831EA59C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831EA5A0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831EA5A4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831EA5A8: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831EA5AC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EA5B0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831EA5B0 size=196
    let mut pc: u32 = 0x831EA5B0;
    'dispatch: loop {
        match pc {
            0x831EA5B0 => {
    //   block [0x831EA5B0..0x831EA674)
	// 831EA5B0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EA5B4: 4BFBDBB5  bl 0x831a8168
	ctx.lr = 0x831EA5B8;
	sub_831A8130(ctx, base);
	// 831EA5B8: DBE1FFD0  stfd f31, -0x30(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.f[31].u64 ) };
	// 831EA5BC: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831EA5C0: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831EA5C4: FFE00890  fmr f31, f1
	ctx.f[31].f64 = ctx.f[1].f64;
	// 831EA5C8: 48058B95  bl 0x8324315c
	ctx.lr = 0x831EA5CC;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831EA5CC: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831EA5D0: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831EA5D4: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831EA5D8: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831EA5DC: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EA5E0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EA5E4: 419A0010  beq cr6, 0x831ea5f4
	if ctx.cr[6].eq {
	pc = 0x831EA5F4; continue 'dispatch;
	}
	// 831EA5E8: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EA5EC: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831EA5F0: 419A0018  beq cr6, 0x831ea608
	if ctx.cr[6].eq {
	pc = 0x831EA608; continue 'dispatch;
	}
	// 831EA5F4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831EA5F8: 48058485  bl 0x83242a7c
	ctx.lr = 0x831EA5FC;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831EA5FC: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EA600: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831EA604: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 831EA608: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831EA60C: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831EA610: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831EA614: D3FD0070  stfs f31, 0x70(r29)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(112 as u32), tmp.u32 ) };
	// 831EA618: D3FD00E0  stfs f31, 0xe0(r29)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(224 as u32), tmp.u32 ) };
	// 831EA61C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EA620: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EA624: 419A0040  beq cr6, 0x831ea664
	if ctx.cr[6].eq {
	pc = 0x831EA664; continue 'dispatch;
	}
	// 831EA628: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EA62C: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831EA630: 409A0034  bne cr6, 0x831ea664
	if !ctx.cr[6].eq {
	pc = 0x831EA664; continue 'dispatch;
	}
	// 831EA634: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EA638: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831EA63C: 40820028  bne 0x831ea664
	if !ctx.cr[0].eq {
	pc = 0x831EA664; continue 'dispatch;
	}
	// 831EA640: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831EA644: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831EA648: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831EA64C: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831EA650: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831EA654: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831EA658: 48058415  bl 0x83242a6c
	ctx.lr = 0x831EA65C;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831EA65C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831EA660: 48058B0D  bl 0x8324316c
	ctx.lr = 0x831EA664;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831EA664: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831EA668: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831EA66C: CBE1FFD0  lfd f31, -0x30(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 831EA670: 4BFBDB48  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EA678(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831EA678 size=280
    let mut pc: u32 = 0x831EA678;
    'dispatch: loop {
        match pc {
            0x831EA678 => {
    //   block [0x831EA678..0x831EA790)
	// 831EA678: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EA67C: 4BFBDAED  bl 0x831a8168
	ctx.lr = 0x831EA680;
	sub_831A8130(ctx, base);
	// 831EA680: DBE1FFD0  stfd f31, -0x30(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.f[31].u64 ) };
	// 831EA684: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831EA688: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831EA68C: FFE00890  fmr f31, f1
	ctx.f[31].f64 = ctx.f[1].f64;
	// 831EA690: 48058ACD  bl 0x8324315c
	ctx.lr = 0x831EA694;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831EA694: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831EA698: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831EA69C: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831EA6A0: 7DBD6B78  mr r29, r13
	ctx.r[29].u64 = ctx.r[13].u64;
	// 831EA6A4: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EA6A8: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EA6AC: 419A0010  beq cr6, 0x831ea6bc
	if ctx.cr[6].eq {
	pc = 0x831EA6BC; continue 'dispatch;
	}
	// 831EA6B0: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EA6B4: 7F1D5040  cmplw cr6, r29, r10
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831EA6B8: 419A0018  beq cr6, 0x831ea6d0
	if ctx.cr[6].eq {
	pc = 0x831EA6D0; continue 'dispatch;
	}
	// 831EA6BC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831EA6C0: 480583BD  bl 0x83242a7c
	ctx.lr = 0x831EA6C4;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831EA6C4: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EA6C8: 93BF0008  stw r29, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 831EA6CC: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 831EA6D0: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831EA6D4: FC40F890  fmr f2, f31
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[2].f64 = ctx.f[31].f64;
	// 831EA6D8: 3D408205  lis r10, -0x7dfb
	ctx.r[10].s64 = -2113601536;
	// 831EA6DC: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831EA6E0: C82AAA10  lfd f1, -0x55f0(r10)
	ctx.f[1].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[10].u32.wrapping_add(-22000 as u32) ) };
	// 831EA6E4: 4BFC0DC5  bl 0x831ab4a8
	ctx.lr = 0x831EA6E8;
	sub_831AB4A8(ctx, base);
	// 831EA6E8: 80FE003C  lwz r7, 0x3c(r30)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(60 as u32) ) } as u64;
	// 831EA6EC: FC000818  frsp f0, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].f64 = (ctx.f[1].f64 as f32) as f64;
	// 831EA6F0: 891E0038  lbz r8, 0x38(r30)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(56 as u32) ) } as u64;
	// 831EA6F4: 88DE0034  lbz r6, 0x34(r30)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(52 as u32) ) } as u64;
	// 831EA6F8: D01E0074  stfs f0, 0x74(r30)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(116 as u32), tmp.u32 ) };
	// 831EA6FC: 991E00C5  stb r8, 0xc5(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(197 as u32), ctx.r[8].u8 ) };
	// 831EA700: 397E00B8  addi r11, r30, 0xb8
	ctx.r[11].s64 = ctx.r[30].s64 + 184;
	// 831EA704: 98DE00C4  stb r6, 0xc4(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(196 as u32), ctx.r[6].u8 ) };
	// 831EA708: 38A00010  li r5, 0x10
	ctx.r[5].s64 = 16;
	// 831EA70C: F8E10050  std r7, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[7].u64 ) };
	// 831EA710: C9A10050  lfd f13, 0x50(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 831EA714: 809E0108  lwz r4, 0x108(r30)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(264 as u32) ) } as u64;
	// 831EA718: 60830001  ori r3, r4, 1
	ctx.r[3].u64 = ctx.r[4].u64 | 1;
	// 831EA71C: FD806E9C  fcfid f12, f13
	ctx.f[12].f64 = (ctx.f[13].s64 as f64);
	// 831EA720: 907E0108  stw r3, 0x108(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(264 as u32), ctx.r[3].u32 ) };
	// 831EA724: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831EA728: FD606018  frsp f11, f12
	ctx.f[11].f64 = (ctx.f[12].f64 as f32) as f64;
	// 831EA72C: ED4B0032  fmuls f10, f11, f0
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 831EA730: FD20565E  fctidz f9, f10
	ctx.f[9].s64 = if ctx.f[10].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[10].f64.trunc() as i64 };
	// 831EA734: 7D2B2FAE  stfiwx f9, r11, r5
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[5].u32), tmp.u32) };
	// 831EA738: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EA73C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EA740: 419A0040  beq cr6, 0x831ea780
	if ctx.cr[6].eq {
	pc = 0x831EA780; continue 'dispatch;
	}
	// 831EA744: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EA748: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831EA74C: 409A0034  bne cr6, 0x831ea780
	if !ctx.cr[6].eq {
	pc = 0x831EA780; continue 'dispatch;
	}
	// 831EA750: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EA754: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831EA758: 40820028  bne 0x831ea780
	if !ctx.cr[0].eq {
	pc = 0x831EA780; continue 'dispatch;
	}
	// 831EA75C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831EA760: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831EA764: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831EA768: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831EA76C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831EA770: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831EA774: 480582F9  bl 0x83242a6c
	ctx.lr = 0x831EA778;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831EA778: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831EA77C: 480589F1  bl 0x8324316c
	ctx.lr = 0x831EA780;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831EA780: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831EA784: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831EA788: CBE1FFD0  lfd f31, -0x30(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 831EA78C: 4BFBDA2C  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EA790(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831EA790 size=260
    let mut pc: u32 = 0x831EA790;
    'dispatch: loop {
        match pc {
            0x831EA790 => {
    //   block [0x831EA790..0x831EA894)
	// 831EA790: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EA794: 4BFBD9D5  bl 0x831a8168
	ctx.lr = 0x831EA798;
	sub_831A8130(ctx, base);
	// 831EA798: DBE1FFD0  stfd f31, -0x30(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.f[31].u64 ) };
	// 831EA79C: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831EA7A0: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831EA7A4: FFE00890  fmr f31, f1
	ctx.f[31].f64 = ctx.f[1].f64;
	// 831EA7A8: 480589B5  bl 0x8324315c
	ctx.lr = 0x831EA7AC;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831EA7AC: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831EA7B0: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831EA7B4: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831EA7B8: 7DBD6B78  mr r29, r13
	ctx.r[29].u64 = ctx.r[13].u64;
	// 831EA7BC: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EA7C0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EA7C4: 419A0010  beq cr6, 0x831ea7d4
	if ctx.cr[6].eq {
	pc = 0x831EA7D4; continue 'dispatch;
	}
	// 831EA7C8: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EA7CC: 7F1D5040  cmplw cr6, r29, r10
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831EA7D0: 419A0018  beq cr6, 0x831ea7e8
	if ctx.cr[6].eq {
	pc = 0x831EA7E8; continue 'dispatch;
	}
	// 831EA7D4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831EA7D8: 480582A5  bl 0x83242a7c
	ctx.lr = 0x831EA7DC;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831EA7DC: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EA7E0: 93BF0008  stw r29, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 831EA7E4: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 831EA7E8: 394B0001  addi r10, r11, 1
	ctx.r[10].s64 = ctx.r[11].s64 + 1;
	// 831EA7EC: 397E00B8  addi r11, r30, 0xb8
	ctx.r[11].s64 = ctx.r[30].s64 + 184;
	// 831EA7F0: 915F0004  stw r10, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831EA7F4: D3FE0074  stfs f31, 0x74(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(116 as u32), tmp.u32 ) };
	// 831EA7F8: 813E003C  lwz r9, 0x3c(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(60 as u32) ) } as u64;
	// 831EA7FC: 38C00010  li r6, 0x10
	ctx.r[6].s64 = 16;
	// 831EA800: F9210050  std r9, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[9].u64 ) };
	// 831EA804: C8010050  lfd f0, 0x50(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 831EA808: FDA0069C  fcfid f13, f0
	ctx.f[13].f64 = (ctx.f[0].s64 as f64);
	// 831EA80C: 891E0038  lbz r8, 0x38(r30)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(56 as u32) ) } as u64;
	// 831EA810: 88FE0034  lbz r7, 0x34(r30)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(52 as u32) ) } as u64;
	// 831EA814: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831EA818: 98FE00C4  stb r7, 0xc4(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(196 as u32), ctx.r[7].u8 ) };
	// 831EA81C: FD806818  frsp f12, f13
	ctx.f[12].f64 = (ctx.f[13].f64 as f32) as f64;
	// 831EA820: 991E00C5  stb r8, 0xc5(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(197 as u32), ctx.r[8].u8 ) };
	// 831EA824: 80BE0108  lwz r5, 0x108(r30)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(264 as u32) ) } as u64;
	// 831EA828: 60A40001  ori r4, r5, 1
	ctx.r[4].u64 = ctx.r[5].u64 | 1;
	// 831EA82C: ED6C07F2  fmuls f11, f12, f31
	ctx.f[11].f64 = (((ctx.f[12].f64 * ctx.f[31].f64) as f32) as f64);
	// 831EA830: 909E0108  stw r4, 0x108(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(264 as u32), ctx.r[4].u32 ) };
	// 831EA834: FD405E5E  fctidz f10, f11
	ctx.f[10].s64 = if ctx.f[11].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[11].f64.trunc() as i64 };
	// 831EA838: 7D4B37AE  stfiwx f10, r11, r6
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[6].u32), tmp.u32) };
	// 831EA83C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EA840: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EA844: 419A0040  beq cr6, 0x831ea884
	if ctx.cr[6].eq {
	pc = 0x831EA884; continue 'dispatch;
	}
	// 831EA848: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EA84C: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831EA850: 409A0034  bne cr6, 0x831ea884
	if !ctx.cr[6].eq {
	pc = 0x831EA884; continue 'dispatch;
	}
	// 831EA854: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EA858: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831EA85C: 40820028  bne 0x831ea884
	if !ctx.cr[0].eq {
	pc = 0x831EA884; continue 'dispatch;
	}
	// 831EA860: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831EA864: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831EA868: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831EA86C: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831EA870: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831EA874: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831EA878: 480581F5  bl 0x83242a6c
	ctx.lr = 0x831EA87C;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831EA87C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831EA880: 480588ED  bl 0x8324316c
	ctx.lr = 0x831EA884;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831EA884: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831EA888: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831EA88C: CBE1FFD0  lfd f31, -0x30(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 831EA890: 4BFBD928  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EA898(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831EA898 size=8
    let mut pc: u32 = 0x831EA898;
    'dispatch: loop {
        match pc {
            0x831EA898 => {
    //   block [0x831EA898..0x831EA8A0)
	// 831EA898: 3863FFF0  addi r3, r3, -0x10
	ctx.r[3].s64 = ctx.r[3].s64 + -16;
	// 831EA89C: 4BFFD2E4  b 0x831e7b80
	sub_831E7B80(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EA8A0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831EA8A0 size=8
    let mut pc: u32 = 0x831EA8A0;
    'dispatch: loop {
        match pc {
            0x831EA8A0 => {
    //   block [0x831EA8A0..0x831EA8A8)
	// 831EA8A0: 3863FFF0  addi r3, r3, -0x10
	ctx.r[3].s64 = ctx.r[3].s64 + -16;
	// 831EA8A4: 4BFFFD0C  b 0x831ea5b0
	sub_831EA5B0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EA8A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831EA8A8 size=8
    let mut pc: u32 = 0x831EA8A8;
    'dispatch: loop {
        match pc {
            0x831EA8A8 => {
    //   block [0x831EA8A8..0x831EA8B0)
	// 831EA8A8: 3863FFF0  addi r3, r3, -0x10
	ctx.r[3].s64 = ctx.r[3].s64 + -16;
	// 831EA8AC: 4BFFFB9C  b 0x831ea448
	sub_831EA448(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EA8B0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831EA8B0 size=8
    let mut pc: u32 = 0x831EA8B0;
    'dispatch: loop {
        match pc {
            0x831EA8B0 => {
    //   block [0x831EA8B0..0x831EA8B8)
	// 831EA8B0: 3863FFF0  addi r3, r3, -0x10
	ctx.r[3].s64 = ctx.r[3].s64 + -16;
	// 831EA8B4: 4BFFFDC4  b 0x831ea678
	sub_831EA678(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EA8B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831EA8B8 size=8
    let mut pc: u32 = 0x831EA8B8;
    'dispatch: loop {
        match pc {
            0x831EA8B8 => {
    //   block [0x831EA8B8..0x831EA8C0)
	// 831EA8B8: 3863FFFC  addi r3, r3, -4
	ctx.r[3].s64 = ctx.r[3].s64 + -4;
	// 831EA8BC: 4BFFFC34  b 0x831ea4f0
	sub_831EA4F0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EA8C0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831EA8C0 size=8
    let mut pc: u32 = 0x831EA8C0;
    'dispatch: loop {
        match pc {
            0x831EA8C0 => {
    //   block [0x831EA8C0..0x831EA8C8)
	// 831EA8C0: 3863FFF0  addi r3, r3, -0x10
	ctx.r[3].s64 = ctx.r[3].s64 + -16;
	// 831EA8C4: 4BFFFAEC  b 0x831ea3b0
	sub_831EA3B0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EA8C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831EA8C8 size=8
    let mut pc: u32 = 0x831EA8C8;
    'dispatch: loop {
        match pc {
            0x831EA8C8 => {
    //   block [0x831EA8C8..0x831EA8D0)
	// 831EA8C8: 3863FFF0  addi r3, r3, -0x10
	ctx.r[3].s64 = ctx.r[3].s64 + -16;
	// 831EA8CC: 4BFFFEC4  b 0x831ea790
	sub_831EA790(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EA8D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831EA8D0 size=8
    let mut pc: u32 = 0x831EA8D0;
    'dispatch: loop {
        match pc {
            0x831EA8D0 => {
    //   block [0x831EA8D0..0x831EA8D8)
	// 831EA8D0: 3863FFF0  addi r3, r3, -0x10
	ctx.r[3].s64 = ctx.r[3].s64 + -16;
	// 831EA8D4: 4BFFFAEC  b 0x831ea3c0
	sub_831EA3C0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EA8D8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831EA8D8 size=8
    let mut pc: u32 = 0x831EA8D8;
    'dispatch: loop {
        match pc {
            0x831EA8D8 => {
    //   block [0x831EA8D8..0x831EA8E0)
	// 831EA8D8: 3863FFF0  addi r3, r3, -0x10
	ctx.r[3].s64 = ctx.r[3].s64 + -16;
	// 831EA8DC: 4BFFFADC  b 0x831ea3b8
	sub_831EA3B8(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EA8E0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831EA8E0 size=8
    let mut pc: u32 = 0x831EA8E0;
    'dispatch: loop {
        match pc {
            0x831EA8E0 => {
    //   block [0x831EA8E0..0x831EA8E8)
	// 831EA8E0: 3863FFF0  addi r3, r3, -0x10
	ctx.r[3].s64 = ctx.r[3].s64 + -16;
	// 831EA8E4: 4BFFFC6C  b 0x831ea550
	sub_831EA550(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EA8E8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831EA8E8 size=8
    let mut pc: u32 = 0x831EA8E8;
    'dispatch: loop {
        match pc {
            0x831EA8E8 => {
    //   block [0x831EA8E8..0x831EA8F0)
	// 831EA8E8: 3863FFF0  addi r3, r3, -0x10
	ctx.r[3].s64 = ctx.r[3].s64 + -16;
	// 831EA8EC: 4BFFFABC  b 0x831ea3a8
	sub_831EA3A8(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EA8F0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831EA8F0 size=208
    let mut pc: u32 = 0x831EA8F0;
    'dispatch: loop {
        match pc {
            0x831EA8F0 => {
    //   block [0x831EA8F0..0x831EA9C0)
	// 831EA8F0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EA8F4: 4BFBD871  bl 0x831a8164
	ctx.lr = 0x831EA8F8;
	sub_831A8130(ctx, base);
	// 831EA8F8: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831EA8FC: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831EA900: 7C9B2378  mr r27, r4
	ctx.r[27].u64 = ctx.r[4].u64;
	// 831EA904: 48058859  bl 0x8324315c
	ctx.lr = 0x831EA908;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831EA908: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831EA90C: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831EA910: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831EA914: 7DBD6B78  mr r29, r13
	ctx.r[29].u64 = ctx.r[13].u64;
	// 831EA918: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EA91C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EA920: 419A0010  beq cr6, 0x831ea930
	if ctx.cr[6].eq {
	pc = 0x831EA930; continue 'dispatch;
	}
	// 831EA924: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EA928: 7F1D5040  cmplw cr6, r29, r10
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831EA92C: 419A0018  beq cr6, 0x831ea944
	if ctx.cr[6].eq {
	pc = 0x831EA944; continue 'dispatch;
	}
	// 831EA930: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831EA934: 48058149  bl 0x83242a7c
	ctx.lr = 0x831EA938;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831EA938: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EA93C: 93BF0008  stw r29, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 831EA940: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 831EA944: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831EA948: 39200001  li r9, 1
	ctx.r[9].s64 = 1;
	// 831EA94C: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831EA950: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831EA954: 811B0000  lwz r8, 0(r27)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) } as u64;
	// 831EA958: A0FE006C  lhz r7, 0x6c(r30)
	ctx.r[7].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(108 as u32) ) } as u64;
	// 831EA95C: 7CC83B96  divwu r6, r8, r7
	ctx.r[6].u32 = ctx.r[8].u32 / ctx.r[7].u32;
	// 831EA960: 913E0110  stw r9, 0x110(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(272 as u32), ctx.r[9].u32 ) };
	// 831EA964: 0CC70000  twi 6, r7, 0
	// 831EA968: 90DE0078  stw r6, 0x78(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(120 as u32), ctx.r[6].u32 ) };
	// 831EA96C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EA970: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EA974: 419A0040  beq cr6, 0x831ea9b4
	if ctx.cr[6].eq {
	pc = 0x831EA9B4; continue 'dispatch;
	}
	// 831EA978: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EA97C: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831EA980: 409A0034  bne cr6, 0x831ea9b4
	if !ctx.cr[6].eq {
	pc = 0x831EA9B4; continue 'dispatch;
	}
	// 831EA984: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EA988: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831EA98C: 40820028  bne 0x831ea9b4
	if !ctx.cr[0].eq {
	pc = 0x831EA9B4; continue 'dispatch;
	}
	// 831EA990: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831EA994: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831EA998: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831EA99C: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831EA9A0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831EA9A4: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831EA9A8: 480580C5  bl 0x83242a6c
	ctx.lr = 0x831EA9AC;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831EA9AC: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831EA9B0: 480587BD  bl 0x8324316c
	ctx.lr = 0x831EA9B4;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831EA9B4: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831EA9B8: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831EA9BC: 4BFBD7F8  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EA9C0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831EA9C0 size=244
    let mut pc: u32 = 0x831EA9C0;
    'dispatch: loop {
        match pc {
            0x831EA9C0 => {
    //   block [0x831EA9C0..0x831EAAB4)
	// 831EA9C0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EA9C4: 4BFBD7A5  bl 0x831a8168
	ctx.lr = 0x831EA9C8;
	sub_831A8130(ctx, base);
	// 831EA9C8: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831EA9CC: 3BC30010  addi r30, r3, 0x10
	ctx.r[30].s64 = ctx.r[3].s64 + 16;
	// 831EA9D0: 4805878D  bl 0x8324315c
	ctx.lr = 0x831EA9D4;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831EA9D4: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831EA9D8: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831EA9DC: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831EA9E0: 7DBD6B78  mr r29, r13
	ctx.r[29].u64 = ctx.r[13].u64;
	// 831EA9E4: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EA9E8: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EA9EC: 419A0010  beq cr6, 0x831ea9fc
	if ctx.cr[6].eq {
	pc = 0x831EA9FC; continue 'dispatch;
	}
	// 831EA9F0: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EA9F4: 7F1D5040  cmplw cr6, r29, r10
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831EA9F8: 419A0018  beq cr6, 0x831eaa10
	if ctx.cr[6].eq {
	pc = 0x831EAA10; continue 'dispatch;
	}
	// 831EA9FC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831EAA00: 4805807D  bl 0x83242a7c
	ctx.lr = 0x831EAA04;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831EAA04: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EAA08: 93BF0008  stw r29, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 831EAA0C: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 831EAA10: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831EAA14: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831EAA18: 895E009C  lbz r10, 0x9c(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(156 as u32) ) } as u64;
	// 831EAA1C: 554907FE  clrlwi r9, r10, 0x1f
	ctx.r[9].u64 = ctx.r[10].u32 as u64 & 0x00000001u64;
	// 831EAA20: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831EAA24: 409A0010  bne cr6, 0x831eaa34
	if !ctx.cr[6].eq {
	pc = 0x831EAA34; continue 'dispatch;
	}
	// 831EAA28: 38A00003  li r5, 3
	ctx.r[5].s64 = 3;
	// 831EAA2C: 38800003  li r4, 3
	ctx.r[4].s64 = 3;
	// 831EAA30: 48000018  b 0x831eaa48
	pc = 0x831EAA48; continue 'dispatch;
	// 831EAA34: 554A077A  rlwinm r10, r10, 0, 0x1d, 0x1d
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0xFFFFFFFFu64;
	// 831EAA38: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831EAA3C: 419A0024  beq cr6, 0x831eaa60
	if ctx.cr[6].eq {
	pc = 0x831EAA60; continue 'dispatch;
	}
	// 831EAA40: 38A00002  li r5, 2
	ctx.r[5].s64 = 2;
	// 831EAA44: 38800006  li r4, 6
	ctx.r[4].s64 = 6;
	// 831EAA48: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831EAA4C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831EAA50: 814B0054  lwz r10, 0x54(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(84 as u32) ) } as u64;
	// 831EAA54: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831EAA58: 4E800421  bctrl
	ctx.lr = 0x831EAA5C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831EAA5C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EAA60: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831EAA64: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EAA68: 419A0040  beq cr6, 0x831eaaa8
	if ctx.cr[6].eq {
	pc = 0x831EAAA8; continue 'dispatch;
	}
	// 831EAA6C: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EAA70: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831EAA74: 409A0034  bne cr6, 0x831eaaa8
	if !ctx.cr[6].eq {
	pc = 0x831EAAA8; continue 'dispatch;
	}
	// 831EAA78: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EAA7C: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831EAA80: 40820028  bne 0x831eaaa8
	if !ctx.cr[0].eq {
	pc = 0x831EAAA8; continue 'dispatch;
	}
	// 831EAA84: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831EAA88: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831EAA8C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831EAA90: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831EAA94: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831EAA98: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831EAA9C: 48057FD1  bl 0x83242a6c
	ctx.lr = 0x831EAAA0;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831EAAA0: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831EAAA4: 480586C9  bl 0x8324316c
	ctx.lr = 0x831EAAA8;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831EAAA8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831EAAAC: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831EAAB0: 4BFBD708  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EAAB8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831EAAB8 size=308
    let mut pc: u32 = 0x831EAAB8;
    'dispatch: loop {
        match pc {
            0x831EAAB8 => {
    //   block [0x831EAAB8..0x831EABEC)
	// 831EAAB8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EAABC: 4BFBD6A9  bl 0x831a8164
	ctx.lr = 0x831EAAC0;
	sub_831A8130(ctx, base);
	// 831EAAC0: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831EAAC4: 7C9B2378  mr r27, r4
	ctx.r[27].u64 = ctx.r[4].u64;
	// 831EAAC8: 3BC30010  addi r30, r3, 0x10
	ctx.r[30].s64 = ctx.r[3].s64 + 16;
	// 831EAACC: 48058691  bl 0x8324315c
	ctx.lr = 0x831EAAD0;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831EAAD0: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831EAAD4: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831EAAD8: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831EAADC: 7DBD6B78  mr r29, r13
	ctx.r[29].u64 = ctx.r[13].u64;
	// 831EAAE0: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EAAE4: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EAAE8: 419A0010  beq cr6, 0x831eaaf8
	if ctx.cr[6].eq {
	pc = 0x831EAAF8; continue 'dispatch;
	}
	// 831EAAEC: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EAAF0: 7F1D5040  cmplw cr6, r29, r10
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831EAAF4: 419A0018  beq cr6, 0x831eab0c
	if ctx.cr[6].eq {
	pc = 0x831EAB0C; continue 'dispatch;
	}
	// 831EAAF8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831EAAFC: 48057F81  bl 0x83242a7c
	ctx.lr = 0x831EAB00;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831EAB00: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EAB04: 93BF0008  stw r29, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 831EAB08: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 831EAB0C: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831EAB10: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831EAB14: 895E009C  lbz r10, 0x9c(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(156 as u32) ) } as u64;
	// 831EAB18: 554907FE  clrlwi r9, r10, 0x1f
	ctx.r[9].u64 = ctx.r[10].u32 as u64 & 0x00000001u64;
	// 831EAB1C: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831EAB20: 419A0078  beq cr6, 0x831eab98
	if ctx.cr[6].eq {
	pc = 0x831EAB98; continue 'dispatch;
	}
	// 831EAB24: 576907FE  clrlwi r9, r27, 0x1f
	ctx.r[9].u64 = ctx.r[27].u32 as u64 & 0x00000001u64;
	// 831EAB28: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831EAB2C: 409A004C  bne cr6, 0x831eab78
	if !ctx.cr[6].eq {
	pc = 0x831EAB78; continue 'dispatch;
	}
	// 831EAB30: 554906FC  rlwinm r9, r10, 0, 0x1b, 0x1e
	ctx.r[9].u64 = ctx.r[10].u32 as u64 & 0xFFFFFFFFu64;
	// 831EAB34: 552907B6  rlwinm r9, r9, 0, 0x1e, 0x1b
	ctx.r[9].u64 = ctx.r[9].u32 as u64 & 0xFFFFFFFFu64;
	// 831EAB38: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831EAB3C: 409A003C  bne cr6, 0x831eab78
	if !ctx.cr[6].eq {
	pc = 0x831EAB78; continue 'dispatch;
	}
	// 831EAB40: 554A077A  rlwinm r10, r10, 0, 0x1d, 0x1d
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0xFFFFFFFFu64;
	// 831EAB44: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831EAB48: 409A0050  bne cr6, 0x831eab98
	if !ctx.cr[6].eq {
	pc = 0x831EAB98; continue 'dispatch;
	}
	// 831EAB4C: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831EAB50: 38A00004  li r5, 4
	ctx.r[5].s64 = 4;
	// 831EAB54: 38800004  li r4, 4
	ctx.r[4].s64 = 4;
	// 831EAB58: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831EAB5C: 814B0054  lwz r10, 0x54(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(84 as u32) ) } as u64;
	// 831EAB60: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831EAB64: 4E800421  bctrl
	ctx.lr = 0x831EAB68;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831EAB68: 3D20821A  lis r9, -0x7de6
	ctx.r[9].s64 = -2112225280;
	// 831EAB6C: A1691090  lhz r11, 0x1090(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(4240 as u32) ) } as u64;
	// 831EAB70: B17E009E  sth r11, 0x9e(r30)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[30].u32.wrapping_add(158 as u32), ctx.r[11].u16 ) };
	// 831EAB74: 48000020  b 0x831eab94
	pc = 0x831EAB94; continue 'dispatch;
	// 831EAB78: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831EAB7C: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 831EAB80: 38800057  li r4, 0x57
	ctx.r[4].s64 = 87;
	// 831EAB84: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831EAB88: 814B0054  lwz r10, 0x54(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(84 as u32) ) } as u64;
	// 831EAB8C: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831EAB90: 4E800421  bctrl
	ctx.lr = 0x831EAB94;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831EAB94: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EAB98: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831EAB9C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EABA0: 419A0040  beq cr6, 0x831eabe0
	if ctx.cr[6].eq {
	pc = 0x831EABE0; continue 'dispatch;
	}
	// 831EABA4: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EABA8: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831EABAC: 409A0034  bne cr6, 0x831eabe0
	if !ctx.cr[6].eq {
	pc = 0x831EABE0; continue 'dispatch;
	}
	// 831EABB0: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EABB4: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831EABB8: 40820028  bne 0x831eabe0
	if !ctx.cr[0].eq {
	pc = 0x831EABE0; continue 'dispatch;
	}
	// 831EABBC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831EABC0: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831EABC4: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831EABC8: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831EABCC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831EABD0: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831EABD4: 48057E99  bl 0x83242a6c
	ctx.lr = 0x831EABD8;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831EABD8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831EABDC: 48058591  bl 0x8324316c
	ctx.lr = 0x831EABE0;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831EABE0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831EABE4: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831EABE8: 4BFBD5CC  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EABF0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831EABF0 size=24
    let mut pc: u32 = 0x831EABF0;
    'dispatch: loop {
        match pc {
            0x831EABF0 => {
    //   block [0x831EABF0..0x831EAC08)
	// 831EABF0: 89630044  lbz r11, 0x44(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(68 as u32) ) } as u64;
	// 831EABF4: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831EABF8: 1D6B0078  mulli r11, r11, 0x78
	ctx.r[11].s64 = ctx.r[11].s64 * 120;
	// 831EABFC: 394B0114  addi r10, r11, 0x114
	ctx.r[10].s64 = ctx.r[11].s64 + 276;
	// 831EAC00: 91440000  stw r10, 0(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831EAC04: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EAC08(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831EAC08 size=8
    let mut pc: u32 = 0x831EAC08;
    'dispatch: loop {
        match pc {
            0x831EAC08 => {
    //   block [0x831EAC08..0x831EAC10)
	// 831EAC08: 3863FFF0  addi r3, r3, -0x10
	ctx.r[3].s64 = ctx.r[3].s64 + -16;
	// 831EAC0C: 4BFFFEAC  b 0x831eaab8
	sub_831EAAB8(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EAC10(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831EAC10 size=8
    let mut pc: u32 = 0x831EAC10;
    'dispatch: loop {
        match pc {
            0x831EAC10 => {
    //   block [0x831EAC10..0x831EAC18)
	// 831EAC10: 3863FFF0  addi r3, r3, -0x10
	ctx.r[3].s64 = ctx.r[3].s64 + -16;
	// 831EAC14: 4BFFFDAC  b 0x831ea9c0
	sub_831EA9C0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EAC18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831EAC18 size=272
    let mut pc: u32 = 0x831EAC18;
    'dispatch: loop {
        match pc {
            0x831EAC18 => {
    //   block [0x831EAC18..0x831EAD28)
	// 831EAC18: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EAC1C: 4BFBD549  bl 0x831a8164
	ctx.lr = 0x831EAC20;
	sub_831A8130(ctx, base);
	// 831EAC20: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831EAC24: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831EAC28: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 831EAC2C: 3BBF0004  addi r29, r31, 4
	ctx.r[29].s64 = ctx.r[31].s64 + 4;
	// 831EAC30: 7CBB2B78  mr r27, r5
	ctx.r[27].u64 = ctx.r[5].u64;
	// 831EAC34: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831EAC38: 4BFF6A89  bl 0x831e16c0
	ctx.lr = 0x831EAC3C;
	sub_831E16C0(ctx, base);
	// 831EAC3C: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831EAC40: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831EAC44: 3D20821A  lis r9, -0x7de6
	ctx.r[9].s64 = -2112225280;
	// 831EAC48: 3BDF00B8  addi r30, r31, 0xb8
	ctx.r[30].s64 = ctx.r[31].s64 + 184;
	// 831EAC4C: 390B1288  addi r8, r11, 0x1288
	ctx.r[8].s64 = ctx.r[11].s64 + 4744;
	// 831EAC50: 38EA1260  addi r7, r10, 0x1260
	ctx.r[7].s64 = ctx.r[10].s64 + 4704;
	// 831EAC54: 38C91200  addi r6, r9, 0x1200
	ctx.r[6].s64 = ctx.r[9].s64 + 4608;
	// 831EAC58: 911F0000  stw r8, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 831EAC5C: 38A0004C  li r5, 0x4c
	ctx.r[5].s64 = 76;
	// 831EAC60: 90FF0004  stw r7, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[7].u32 ) };
	// 831EAC64: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831EAC68: 90DF0010  stw r6, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[6].u32 ) };
	// 831EAC6C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831EAC70: 4BFBD571  bl 0x831a81e0
	ctx.lr = 0x831EAC74;
	sub_831A81E0(ctx, base);
	// 831EAC74: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831EAC78: 7F65DB78  mr r5, r27
	ctx.r[5].u64 = ctx.r[27].u64;
	// 831EAC7C: 917F0104  stw r11, 0x104(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(260 as u32), ctx.r[11].u32 ) };
	// 831EAC80: 7F84E378  mr r4, r28
	ctx.r[4].u64 = ctx.r[28].u64;
	// 831EAC84: 917F0110  stw r11, 0x110(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(272 as u32), ctx.r[11].u32 ) };
	// 831EAC88: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831EAC8C: 4BFF67C5  bl 0x831e1450
	ctx.lr = 0x831EAC90;
	sub_831E1450(ctx, base);
	// 831EAC90: 3C800000  lis r4, 0
	ctx.r[4].s64 = 0;
	// 831EAC94: C01F0074  lfs f0, 0x74(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(116 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831EAC98: 891C0045  lbz r8, 0x45(r28)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(69 as u32) ) } as u64;
	// 831EAC9C: 608BBB80  ori r11, r4, 0xbb80
	ctx.r[11].u64 = ctx.r[4].u64 | 48000;
	// 831EACA0: 88DF0038  lbz r6, 0x38(r31)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(56 as u32) ) } as u64;
	// 831EACA4: 3C60821A  lis r3, -0x7de6
	ctx.r[3].s64 = -2112225280;
	// 831EACA8: 38A00010  li r5, 0x10
	ctx.r[5].s64 = 16;
	// 831EACAC: 39431300  addi r10, r3, 0x1300
	ctx.r[10].s64 = ctx.r[3].s64 + 4864;
	// 831EACB0: 911F010C  stw r8, 0x10c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(268 as u32), ctx.r[8].u32 ) };
	// 831EACB4: 39200001  li r9, 1
	ctx.r[9].s64 = 1;
	// 831EACB8: 809F003C  lwz r4, 0x3c(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(60 as u32) ) } as u64;
	// 831EACBC: 811F0108  lwz r8, 0x108(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(264 as u32) ) } as u64;
	// 831EACC0: 61070001  ori r7, r8, 1
	ctx.r[7].u64 = ctx.r[8].u64 | 1;
	// 831EACC4: F8810050  std r4, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[4].u64 ) };
	// 831EACC8: C9A10050  lfd f13, 0x50(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 831EACCC: FD806E9C  fcfid f12, f13
	ctx.f[12].f64 = (ctx.f[13].s64 as f64);
	// 831EACD0: 887F0034  lbz r3, 0x34(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(52 as u32) ) } as u64;
	// 831EACD4: FD606018  frsp f11, f12
	ctx.f[11].f64 = (ctx.f[12].f64 as f32) as f64;
	// 831EACD8: 98DF00C5  stb r6, 0xc5(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(197 as u32), ctx.r[6].u8 ) };
	// 831EACDC: 54E6003E  slwi r6, r7, 0
	ctx.r[6].u32 = ctx.r[7].u32.wrapping_shl(0);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831EACE0: 987F00C4  stb r3, 0xc4(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(196 as u32), ctx.r[3].u8 ) };
	// 831EACE4: 90FF0108  stw r7, 0x108(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(264 as u32), ctx.r[7].u32 ) };
	// 831EACE8: ED4B0032  fmuls f10, f11, f0
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 831EACEC: FD20565E  fctidz f9, f10
	ctx.f[9].s64 = if ctx.f[10].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[10].f64.trunc() as i64 };
	// 831EACF0: 7D3E2FAE  stfiwx f9, r30, r5
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[5].u32), tmp.u32) };
	// 831EACF4: 60C50002  ori r5, r6, 2
	ctx.r[5].u64 = ctx.r[6].u64 | 2;
	// 831EACF8: 917F00D8  stw r11, 0xd8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(216 as u32), ctx.r[11].u32 ) };
	// 831EACFC: 90BF0108  stw r5, 0x108(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(264 as u32), ctx.r[5].u32 ) };
	// 831EAD00: 889F00C5  lbz r4, 0xc5(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(197 as u32) ) } as u64;
	// 831EAD04: 887F00C4  lbz r3, 0xc4(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(196 as u32) ) } as u64;
	// 831EAD08: 546B103E  rotlwi r11, r3, 2
	ctx.r[11].u64 = ((ctx.r[3].u32).rotate_left(2)) as u64;
	// 831EAD0C: 7D4B502E  lwzx r10, r11, r10
	ctx.r[10].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 831EAD10: 7D0A21D6  mullw r8, r10, r4
	ctx.r[8].s64 = (ctx.r[10].s32 as i64) * (ctx.r[4].s32 as i64);
	// 831EAD14: B13F006E  sth r9, 0x6e(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(110 as u32), ctx.r[9].u16 ) };
	// 831EAD18: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831EAD1C: B11F006C  sth r8, 0x6c(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(108 as u32), ctx.r[8].u16 ) };
	// 831EAD20: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831EAD24: 4BFBD490  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EAD28(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831EAD28 size=1808
    let mut pc: u32 = 0x831EAD28;
    'dispatch: loop {
        match pc {
            0x831EAD28 => {
    //   block [0x831EAD28..0x831EB438)
	// 831EAD28: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EAD2C: 4BFBD429  bl 0x831a8154
	ctx.lr = 0x831EAD30;
	sub_831A8130(ctx, base);
	// 831EAD30: DBE1FFA8  stfd f31, -0x58(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-88 as u32), ctx.f[31].u64 ) };
	// 831EAD34: 9421FF40  stwu r1, -0xc0(r1)
	ea = ctx.r[1].u32.wrapping_add(-192 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831EAD38: 3AE00000  li r23, 0
	ctx.r[23].s64 = 0;
	// 831EAD3C: 7C7A1B78  mr r26, r3
	ctx.r[26].u64 = ctx.r[3].u64;
	// 831EAD40: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 831EAD44: 7EF9BB78  mr r25, r23
	ctx.r[25].u64 = ctx.r[23].u64;
	// 831EAD48: 3B85FFF8  addi r28, r5, -8
	ctx.r[28].s64 = ctx.r[5].s64 + -8;
	// 831EAD4C: 409A0008  bne cr6, 0x831ead54
	if !ctx.cr[6].eq {
	pc = 0x831EAD54; continue 'dispatch;
	}
	// 831EAD50: 7EFCBB78  mr r28, r23
	ctx.r[28].u64 = ctx.r[23].u64;
	// 831EAD54: 48058409  bl 0x8324315c
	ctx.lr = 0x831EAD58;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831EAD58: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831EAD5C: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831EAD60: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831EAD64: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831EAD68: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EAD6C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EAD70: 419A0010  beq cr6, 0x831ead80
	if ctx.cr[6].eq {
	pc = 0x831EAD80; continue 'dispatch;
	}
	// 831EAD74: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EAD78: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831EAD7C: 419A0018  beq cr6, 0x831ead94
	if ctx.cr[6].eq {
	pc = 0x831EAD94; continue 'dispatch;
	}
	// 831EAD80: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831EAD84: 48057CF9  bl 0x83242a7c
	ctx.lr = 0x831EAD88;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831EAD88: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EAD8C: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831EAD90: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831EAD94: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831EAD98: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831EAD9C: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831EADA0: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 831EADA4: 4BFF72BD  bl 0x831e2060
	ctx.lr = 0x831EADA8;
	sub_831E2060(ctx, base);
	// 831EADA8: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831EADAC: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 831EADB0: 41980028  blt cr6, 0x831eadd8
	if ctx.cr[6].lt {
	pc = 0x831EADD8; continue 'dispatch;
	}
	// 831EADB4: 897A0038  lbz r11, 0x38(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[26].u32.wrapping_add(56 as u32) ) } as u64;
	// 831EADB8: 38A00001  li r5, 1
	ctx.r[5].s64 = 1;
	// 831EADBC: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831EADC0: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 831EADC4: 99610051  stb r11, 0x51(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(81 as u32), ctx.r[11].u8 ) };
	// 831EADC8: 4BFF73F9  bl 0x831e21c0
	ctx.lr = 0x831EADCC;
	sub_831E21C0(ctx, base);
	// 831EADCC: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831EADD0: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 831EADD4: 409800DC  bge cr6, 0x831eaeb0
	if !ctx.cr[6].lt {
	pc = 0x831EAEB0; continue 'dispatch;
	}
	// 831EADD8: 813F0004  lwz r9, 4(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EADDC: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831EADE0: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831EADE4: 419A0040  beq cr6, 0x831eae24
	if ctx.cr[6].eq {
	pc = 0x831EAE24; continue 'dispatch;
	}
	// 831EADE8: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EADEC: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831EADF0: 409A0034  bne cr6, 0x831eae24
	if !ctx.cr[6].eq {
	pc = 0x831EAE24; continue 'dispatch;
	}
	// 831EADF4: 3569FFFF  addic. r11, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EADF8: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831EADFC: 40820028  bne 0x831eae24
	if !ctx.cr[0].eq {
	pc = 0x831EAE24; continue 'dispatch;
	}
	// 831EAE00: 7EEABB78  mr r10, r23
	ctx.r[10].u64 = ctx.r[23].u64;
	// 831EAE04: 8BBF000C  lbz r29, 0xc(r31)
	ctx.r[29].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831EAE08: 7EEBBB78  mr r11, r23
	ctx.r[11].u64 = ctx.r[23].u64;
	// 831EAE0C: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831EAE10: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831EAE14: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831EAE18: 48057C55  bl 0x83242a6c
	ctx.lr = 0x831EAE1C;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831EAE1C: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831EAE20: 4805834D  bl 0x8324316c
	ctx.lr = 0x831EAE24;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831EAE24: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831EAE28: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 831EAE2C: 409A0600  bne cr6, 0x831eb42c
	if !ctx.cr[6].eq {
	pc = 0x831EB42C; continue 'dispatch;
	}
	// 831EAE30: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 831EAE34: 38600006  li r3, 6
	ctx.r[3].s64 = 6;
	// 831EAE38: 4BFF18B1  bl 0x831dc6e8
	ctx.lr = 0x831EAE3C;
	sub_831DC6E8(ctx, base);
	// 831EAE3C: 3B000001  li r24, 1
	ctx.r[24].s64 = 1;
	// 831EAE40: 7F3ECB78  mr r30, r25
	ctx.r[30].u64 = ctx.r[25].u64;
	// 831EAE44: 2B190000  cmplwi cr6, r25, 0
	ctx.cr[6].compare_u32(ctx.r[25].u32, 0 as u32, &mut ctx.xer);
	// 831EAE48: 419A0258  beq cr6, 0x831eb0a0
	if ctx.cr[6].eq {
	pc = 0x831EB0A0; continue 'dispatch;
	}
	// 831EAE4C: 817A00BC  lwz r11, 0xbc(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(188 as u32) ) } as u64;
	// 831EAE50: 815A00C0  lwz r10, 0xc0(r26)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(192 as u32) ) } as u64;
	// 831EAE54: 7D2A5851  subf. r9, r10, r11
	ctx.r[9].s64 = ctx.r[11].s64 - ctx.r[10].s64;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831EAE58: 40820248  bne 0x831eb0a0
	if !ctx.cr[0].eq {
	pc = 0x831EB0A0; continue 'dispatch;
	}
	// 831EAE5C: 81790010  lwz r11, 0x10(r25)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(16 as u32) ) } as u64;
	// 831EAE60: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831EAE64: 419A021C  beq cr6, 0x831eb080
	if ctx.cr[6].eq {
	pc = 0x831EB080; continue 'dispatch;
	}
	// 831EAE68: 2F0BFFFF  cmpwi cr6, r11, -1
	ctx.cr[6].compare_i32(ctx.r[11].s32, -1, &mut ctx.xer);
	// 831EAE6C: 419A000C  beq cr6, 0x831eae78
	if ctx.cr[6].eq {
	pc = 0x831EAE78; continue 'dispatch;
	}
	// 831EAE70: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 831EAE74: 91790010  stw r11, 0x10(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 831EAE78: 81790014  lwz r11, 0x14(r25)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(20 as u32) ) } as u64;
	// 831EAE7C: 917A0078  stw r11, 0x78(r26)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(120 as u32), ctx.r[11].u32 ) };
	// 831EAE80: 817A00B4  lwz r11, 0xb4(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(180 as u32) ) } as u64;
	// 831EAE84: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831EAE88: 419A0218  beq cr6, 0x831eb0a0
	if ctx.cr[6].eq {
	pc = 0x831EB0A0; continue 'dispatch;
	}
	// 831EAE8C: 815A000C  lwz r10, 0xc(r26)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(12 as u32) ) } as u64;
	// 831EAE90: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 831EAE94: 81390024  lwz r9, 0x24(r25)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(36 as u32) ) } as u64;
	// 831EAE98: 92E10058  stw r23, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[23].u32 ) };
	// 831EAE9C: 91410050  stw r10, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[10].u32 ) };
	// 831EAEA0: 91210054  stw r9, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[9].u32 ) };
	// 831EAEA4: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 831EAEA8: 4E800421  bctrl
	ctx.lr = 0x831EAEAC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831EAEAC: 480001F4  b 0x831eb0a0
	pc = 0x831EB0A0; continue 'dispatch;
	// 831EAEB0: 81610058  lwz r11, 0x58(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) } as u64;
	// 831EAEB4: 39400100  li r10, 0x100
	ctx.r[10].s64 = 256;
	// 831EAEB8: 92FA00D4  stw r23, 0xd4(r26)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(212 as u32), ctx.r[23].u32 ) };
	// 831EAEBC: 3BDA00B8  addi r30, r26, 0xb8
	ctx.r[30].s64 = ctx.r[26].s64 + 184;
	// 831EAEC0: 915A00D0  stw r10, 0xd0(r26)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(208 as u32), ctx.r[10].u32 ) };
	// 831EAEC4: 917A00CC  stw r11, 0xcc(r26)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(204 as u32), ctx.r[11].u32 ) };
	// 831EAEC8: 897A00AC  lbz r11, 0xac(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[26].u32.wrapping_add(172 as u32) ) } as u64;
	// 831EAECC: 556907FE  clrlwi r9, r11, 0x1f
	ctx.r[9].u64 = ctx.r[11].u32 as u64 & 0x00000001u64;
	// 831EAED0: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831EAED4: 419A010C  beq cr6, 0x831eafe0
	if ctx.cr[6].eq {
	pc = 0x831EAFE0; continue 'dispatch;
	}
	// 831EAED8: 556A06F6  rlwinm r10, r11, 0, 0x1b, 0x1b
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831EAEDC: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831EAEE0: 409A0100  bne cr6, 0x831eafe0
	if !ctx.cr[6].eq {
	pc = 0x831EAFE0; continue 'dispatch;
	}
	// 831EAEE4: 3D408200  lis r10, -0x7e00
	ctx.r[10].s64 = -2113929216;
	// 831EAEE8: 556907BC  rlwinm r9, r11, 0, 0x1e, 0x1e
	ctx.r[9].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831EAEEC: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831EAEF0: C3EA08A4  lfs f31, 0x8a4(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(2212 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 831EAEF4: 419A0050  beq cr6, 0x831eaf44
	if ctx.cr[6].eq {
	pc = 0x831EAF44; continue 'dispatch;
	}
	// 831EAEF8: C01A0070  lfs f0, 0x70(r26)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(112 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831EAEFC: 397E0034  addi r11, r30, 0x34
	ctx.r[11].s64 = ctx.r[30].s64 + 52;
	// 831EAF00: D01A00E0  stfs f0, 0xe0(r26)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(224 as u32), tmp.u32 ) };
	// 831EAF04: 7EE9BB78  mr r9, r23
	ctx.r[9].u64 = ctx.r[23].u64;
	// 831EAF08: C1BE0028  lfs f13, 0x28(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831EAF0C: 39400006  li r10, 6
	ctx.r[10].s64 = 6;
	// 831EAF10: D1BE0024  stfs f13, 0x24(r30)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831EAF14: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831EAF18: 912B0000  stw r9, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831EAF1C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 831EAF20: 4200FFF8  bdnz 0x831eaf18
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x831EAF18; continue 'dispatch;
	}
	// 831EAF24: D3FE0030  stfs f31, 0x30(r30)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(48 as u32), tmp.u32 ) };
	// 831EAF28: 817A0010  lwz r11, 0x10(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(16 as u32) ) } as u64;
	// 831EAF2C: 387A0010  addi r3, r26, 0x10
	ctx.r[3].s64 = ctx.r[26].s64 + 16;
	// 831EAF30: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 831EAF34: 38800002  li r4, 2
	ctx.r[4].s64 = 2;
	// 831EAF38: 814B0054  lwz r10, 0x54(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(84 as u32) ) } as u64;
	// 831EAF3C: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831EAF40: 4E800421  bctrl
	ctx.lr = 0x831EAF44;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831EAF44: 897A00AC  lbz r11, 0xac(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[26].u32.wrapping_add(172 as u32) ) } as u64;
	// 831EAF48: 556A077A  rlwinm r10, r11, 0, 0x1d, 0x1d
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831EAF4C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831EAF50: 419A0040  beq cr6, 0x831eaf90
	if ctx.cr[6].eq {
	pc = 0x831EAF90; continue 'dispatch;
	}
	// 831EAF54: A15A00AE  lhz r10, 0xae(r26)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[26].u32.wrapping_add(174 as u32) ) } as u64;
	// 831EAF58: C1BA00E0  lfs f13, 0xe0(r26)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(224 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831EAF5C: 397A0010  addi r11, r26, 0x10
	ctx.r[11].s64 = ctx.r[26].s64 + 16;
	// 831EAF60: 3D2A0001  addis r9, r10, 1
	ctx.r[9].s64 = ctx.r[10].s64 + 65536;
	// 831EAF64: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 831EAF68: 5528043E  clrlwi r8, r9, 0x10
	ctx.r[8].u64 = ctx.r[9].u32 as u64 & 0x0000FFFFu64;
	// 831EAF6C: B11A00AE  sth r8, 0xae(r26)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[26].u32.wrapping_add(174 as u32), ctx.r[8].u16 ) };
	// 831EAF70: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 831EAF74: 419A0014  beq cr6, 0x831eaf88
	if ctx.cr[6].eq {
	pc = 0x831EAF88; continue 'dispatch;
	}
	// 831EAF78: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831EAF7C: C00B1094  lfs f0, 0x1094(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4244 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831EAF80: EC0D0032  fmuls f0, f13, f0
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 831EAF84: 48000008  b 0x831eaf8c
	pc = 0x831EAF8C; continue 'dispatch;
	// 831EAF88: FC00F890  fmr f0, f31
	ctx.f[0].f64 = ctx.f[31].f64;
	// 831EAF8C: D01A00E0  stfs f0, 0xe0(r26)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(224 as u32), tmp.u32 ) };
	// 831EAF90: 813F0004  lwz r9, 4(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EAF94: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831EAF98: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831EAF9C: 419AFE94  beq cr6, 0x831eae30
	if ctx.cr[6].eq {
	pc = 0x831EAE30; continue 'dispatch;
	}
	// 831EAFA0: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EAFA4: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831EAFA8: 409AFE88  bne cr6, 0x831eae30
	if !ctx.cr[6].eq {
	pc = 0x831EAE30; continue 'dispatch;
	}
	// 831EAFAC: 3569FFFF  addic. r11, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EAFB0: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831EAFB4: 4082FE7C  bne 0x831eae30
	if !ctx.cr[0].eq {
	pc = 0x831EAE30; continue 'dispatch;
	}
	// 831EAFB8: 7EEABB78  mr r10, r23
	ctx.r[10].u64 = ctx.r[23].u64;
	// 831EAFBC: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831EAFC0: 7EEBBB78  mr r11, r23
	ctx.r[11].u64 = ctx.r[23].u64;
	// 831EAFC4: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831EAFC8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831EAFCC: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831EAFD0: 48057A9D  bl 0x83242a6c
	ctx.lr = 0x831EAFD4;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831EAFD4: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831EAFD8: 48058195  bl 0x8324316c
	ctx.lr = 0x831EAFDC;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831EAFDC: 4BFFFE54  b 0x831eae30
	pc = 0x831EAE30; continue 'dispatch;
	// 831EAFE0: 817E001C  lwz r11, 0x1c(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(28 as u32) ) } as u64;
	// 831EAFE4: 815E0018  lwz r10, 0x18(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(24 as u32) ) } as u64;
	// 831EAFE8: 8BBE000D  lbz r29, 0xd(r30)
	ctx.r[29].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(13 as u32) ) } as u64;
	// 831EAFEC: 7D4B5051  subf. r10, r11, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831EAFF0: 41820034  beq 0x831eb024
	if ctx.cr[0].eq {
	pc = 0x831EB024; continue 'dispatch;
	}
	// 831EAFF4: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 831EAFF8: 419A002C  beq cr6, 0x831eb024
	if ctx.cr[6].eq {
	pc = 0x831EB024; continue 'dispatch;
	}
	// 831EAFFC: 555B103A  slwi r27, r10, 2
	ctx.r[27].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[27].u64 = ctx.r[27].u32 as u64;
	// 831EB000: 557C103A  slwi r28, r11, 2
	ctx.r[28].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[28].u64 = ctx.r[28].u32 as u64;
	// 831EB004: 817E0014  lwz r11, 0x14(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(20 as u32) ) } as u64;
	// 831EB008: 7F65DB78  mr r5, r27
	ctx.r[5].u64 = ctx.r[27].u64;
	// 831EB00C: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831EB010: 7C7C5A14  add r3, r28, r11
	ctx.r[3].u64 = ctx.r[28].u64 + ctx.r[11].u64;
	// 831EB014: 4BFBD1CD  bl 0x831a81e0
	ctx.lr = 0x831EB018;
	sub_831A81E0(ctx, base);
	// 831EB018: 37BDFFFF  addic. r29, r29, -1
	ctx.xer.ca = (ctx.r[29].u32 > (!(-1 as u32)));
	ctx.r[29].s64 = ctx.r[29].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[29].s32, 0, &mut ctx.xer);
	// 831EB01C: 3B9C0400  addi r28, r28, 0x400
	ctx.r[28].s64 = ctx.r[28].s64 + 1024;
	// 831EB020: 4082FFE4  bne 0x831eb004
	if !ctx.cr[0].eq {
	pc = 0x831EB004; continue 'dispatch;
	}
	// 831EB024: 813F0004  lwz r9, 4(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EB028: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831EB02C: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831EB030: 419A0040  beq cr6, 0x831eb070
	if ctx.cr[6].eq {
	pc = 0x831EB070; continue 'dispatch;
	}
	// 831EB034: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EB038: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831EB03C: 409A0034  bne cr6, 0x831eb070
	if !ctx.cr[6].eq {
	pc = 0x831EB070; continue 'dispatch;
	}
	// 831EB040: 3569FFFF  addic. r11, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EB044: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831EB048: 40820028  bne 0x831eb070
	if !ctx.cr[0].eq {
	pc = 0x831EB070; continue 'dispatch;
	}
	// 831EB04C: 7EEABB78  mr r10, r23
	ctx.r[10].u64 = ctx.r[23].u64;
	// 831EB050: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831EB054: 7EEBBB78  mr r11, r23
	ctx.r[11].u64 = ctx.r[23].u64;
	// 831EB058: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831EB05C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831EB060: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831EB064: 48057A09  bl 0x83242a6c
	ctx.lr = 0x831EB068;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831EB068: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831EB06C: 48058101  bl 0x8324316c
	ctx.lr = 0x831EB070;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831EB070: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 831EB074: 382100C0  addi r1, r1, 0xc0
	ctx.r[1].s64 = ctx.r[1].s64 + 192;
	// 831EB078: CBE1FFA8  lfd f31, -0x58(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-88 as u32) ) };
	// 831EB07C: 4BFBD128  b 0x831a81a4
	sub_831A8180(ctx, base);
	return;
	// 831EB080: 817A0010  lwz r11, 0x10(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(16 as u32) ) } as u64;
	// 831EB084: 387A0010  addi r3, r26, 0x10
	ctx.r[3].s64 = ctx.r[26].s64 + 16;
	// 831EB088: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 831EB08C: 7F24CB78  mr r4, r25
	ctx.r[4].u64 = ctx.r[25].u64;
	// 831EB090: 814B005C  lwz r10, 0x5c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(92 as u32) ) } as u64;
	// 831EB094: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831EB098: 4E800421  bctrl
	ctx.lr = 0x831EB09C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831EB09C: 7EFEBB78  mr r30, r23
	ctx.r[30].u64 = ctx.r[23].u64;
	// 831EB0A0: 817A00D0  lwz r11, 0xd0(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(208 as u32) ) } as u64;
	// 831EB0A4: 3B9A00B8  addi r28, r26, 0xb8
	ctx.r[28].s64 = ctx.r[26].s64 + 184;
	// 831EB0A8: 815A00D4  lwz r10, 0xd4(r26)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(212 as u32) ) } as u64;
	// 831EB0AC: 7D2A5851  subf. r9, r10, r11
	ctx.r[9].s64 = ctx.r[11].s64 - ctx.r[10].s64;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831EB0B0: 418201F4  beq 0x831eb2a4
	if ctx.cr[0].eq {
	pc = 0x831EB2A4; continue 'dispatch;
	}
	// 831EB0B4: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 831EB0B8: 409A00EC  bne cr6, 0x831eb1a4
	if !ctx.cr[6].eq {
	pc = 0x831EB1A4; continue 'dispatch;
	}
	// 831EB0BC: 480580A1  bl 0x8324315c
	ctx.lr = 0x831EB0C0;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831EB0C0: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EB0C4: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831EB0C8: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831EB0CC: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EB0D0: 419A0010  beq cr6, 0x831eb0e0
	if ctx.cr[6].eq {
	pc = 0x831EB0E0; continue 'dispatch;
	}
	// 831EB0D4: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EB0D8: 7F1E4040  cmplw cr6, r30, r8
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831EB0DC: 419A001C  beq cr6, 0x831eb0f8
	if ctx.cr[6].eq {
	pc = 0x831EB0F8; continue 'dispatch;
	}
	// 831EB0E0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831EB0E4: 48057999  bl 0x83242a7c
	ctx.lr = 0x831EB0E8;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831EB0E8: 7FC8F378  mr r8, r30
	ctx.r[8].u64 = ctx.r[30].u64;
	// 831EB0EC: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EB0F0: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831EB0F4: 911F0008  stw r8, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 831EB0F8: 392B0001  addi r9, r11, 1
	ctx.r[9].s64 = ctx.r[11].s64 + 1;
	// 831EB0FC: 397A0014  addi r11, r26, 0x14
	ctx.r[11].s64 = ctx.r[26].s64 + 20;
	// 831EB100: 913F0004  stw r9, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 831EB104: 815A0014  lwz r10, 0x14(r26)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(20 as u32) ) } as u64;
	// 831EB108: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831EB10C: 419A0010  beq cr6, 0x831eb11c
	if ctx.cr[6].eq {
	pc = 0x831EB11C; continue 'dispatch;
	}
	// 831EB110: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EB114: 7D6B5050  subf r11, r11, r10
	ctx.r[11].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 831EB118: 48000008  b 0x831eb120
	pc = 0x831EB120; continue 'dispatch;
	// 831EB11C: 7EEBBB78  mr r11, r23
	ctx.r[11].u64 = ctx.r[23].u64;
	// 831EB120: 7D7E5B78  mr r30, r11
	ctx.r[30].u64 = ctx.r[11].u64;
	// 831EB124: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831EB128: 419A0038  beq cr6, 0x831eb160
	if ctx.cr[6].eq {
	pc = 0x831EB160; continue 'dispatch;
	}
	// 831EB12C: 894B0075  lbz r10, 0x75(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(117 as u32) ) } as u64;
	// 831EB130: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831EB134: 409A002C  bne cr6, 0x831eb160
	if !ctx.cr[6].eq {
	pc = 0x831EB160; continue 'dispatch;
	}
	// 831EB138: 815A0110  lwz r10, 0x110(r26)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(272 as u32) ) } as u64;
	// 831EB13C: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831EB140: 419A000C  beq cr6, 0x831eb14c
	if ctx.cr[6].eq {
	pc = 0x831EB14C; continue 'dispatch;
	}
	// 831EB144: 92FA0110  stw r23, 0x110(r26)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(272 as u32), ctx.r[23].u32 ) };
	// 831EB148: 4800000C  b 0x831eb154
	pc = 0x831EB154; continue 'dispatch;
	// 831EB14C: 814B001C  lwz r10, 0x1c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) } as u64;
	// 831EB150: 915A0078  stw r10, 0x78(r26)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(120 as u32), ctx.r[10].u32 ) };
	// 831EB154: 9B0B0075  stb r24, 0x75(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(117 as u32), ctx.r[24].u8 ) };
	// 831EB158: 813F0004  lwz r9, 4(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EB15C: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EB160: 7DAB6B78  mr r11, r13
	ctx.r[11].u64 = ctx.r[13].u64;
	// 831EB164: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831EB168: 419A003C  beq cr6, 0x831eb1a4
	if ctx.cr[6].eq {
	pc = 0x831EB1A4; continue 'dispatch;
	}
	// 831EB16C: 7F0B4040  cmplw cr6, r11, r8
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831EB170: 409A0034  bne cr6, 0x831eb1a4
	if !ctx.cr[6].eq {
	pc = 0x831EB1A4; continue 'dispatch;
	}
	// 831EB174: 3569FFFF  addic. r11, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EB178: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831EB17C: 40820028  bne 0x831eb1a4
	if !ctx.cr[0].eq {
	pc = 0x831EB1A4; continue 'dispatch;
	}
	// 831EB180: 7EEBBB78  mr r11, r23
	ctx.r[11].u64 = ctx.r[23].u64;
	// 831EB184: 8BBF000C  lbz r29, 0xc(r31)
	ctx.r[29].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831EB188: 7EEABB78  mr r10, r23
	ctx.r[10].u64 = ctx.r[23].u64;
	// 831EB18C: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831EB190: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831EB194: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831EB198: 480578D5  bl 0x83242a6c
	ctx.lr = 0x831EB19C;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831EB19C: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831EB1A0: 48057FCD  bl 0x8324316c
	ctx.lr = 0x831EB1A4;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831EB1A4: 7FD9F378  mr r25, r30
	ctx.r[25].u64 = ctx.r[30].u64;
	// 831EB1A8: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 831EB1AC: 419A00F8  beq cr6, 0x831eb2a4
	if ctx.cr[6].eq {
	pc = 0x831EB2A4; continue 'dispatch;
	}
	// 831EB1B0: 817E0010  lwz r11, 0x10(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) } as u64;
	// 831EB1B4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831EB1B8: 419A000C  beq cr6, 0x831eb1c4
	if ctx.cr[6].eq {
	pc = 0x831EB1C4; continue 'dispatch;
	}
	// 831EB1BC: 817E0018  lwz r11, 0x18(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(24 as u32) ) } as u64;
	// 831EB1C0: 48000008  b 0x831eb1c8
	pc = 0x831EB1C8; continue 'dispatch;
	// 831EB1C4: 817E0020  lwz r11, 0x20(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) } as u64;
	// 831EB1C8: 815E0008  lwz r10, 8(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EB1CC: 837A0078  lwz r27, 0x78(r26)
	ctx.r[27].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(120 as u32) ) } as u64;
	// 831EB1D0: 917C0004  stw r11, 4(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831EB1D4: 7F1B5840  cmplw cr6, r27, r11
	ctx.cr[6].compare_u32(ctx.r[27].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831EB1D8: 915C0000  stw r10, 0(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831EB1DC: 40980008  bge cr6, 0x831eb1e4
	if !ctx.cr[6].lt {
	pc = 0x831EB1E4; continue 'dispatch;
	}
	// 831EB1E0: 7F6BDB78  mr r11, r27
	ctx.r[11].u64 = ctx.r[27].u64;
	// 831EB1E4: 917C0008  stw r11, 8(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 831EB1E8: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 831EB1EC: 480011CD  bl 0x831ec3b8
	ctx.lr = 0x831EB1F0;
	sub_831EC3B8(ctx, base);
	// 831EB1F0: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831EB1F4: 48057F69  bl 0x8324315c
	ctx.lr = 0x831EB1F8;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831EB1F8: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EB1FC: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831EB200: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831EB204: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EB208: 419A0010  beq cr6, 0x831eb218
	if ctx.cr[6].eq {
	pc = 0x831EB218; continue 'dispatch;
	}
	// 831EB20C: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EB210: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831EB214: 419A0018  beq cr6, 0x831eb22c
	if ctx.cr[6].eq {
	pc = 0x831EB22C; continue 'dispatch;
	}
	// 831EB218: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831EB21C: 48057861  bl 0x83242a7c
	ctx.lr = 0x831EB220;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831EB220: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EB224: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831EB228: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831EB22C: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831EB230: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831EB234: 817A0078  lwz r11, 0x78(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(120 as u32) ) } as u64;
	// 831EB238: 7F1B5840  cmplw cr6, r27, r11
	ctx.cr[6].compare_u32(ctx.r[27].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831EB23C: 409A000C  bne cr6, 0x831eb248
	if !ctx.cr[6].eq {
	pc = 0x831EB248; continue 'dispatch;
	}
	// 831EB240: 7D7CDA14  add r11, r28, r27
	ctx.r[11].u64 = ctx.r[28].u64 + ctx.r[27].u64;
	// 831EB244: 917A0078  stw r11, 0x78(r26)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(120 as u32), ctx.r[11].u32 ) };
	// 831EB248: 817A00A8  lwz r11, 0xa8(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(168 as u32) ) } as u64;
	// 831EB24C: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831EB250: 7D6BE214  add r11, r11, r28
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[28].u64;
	// 831EB254: 917A00A8  stw r11, 0xa8(r26)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(168 as u32), ctx.r[11].u32 ) };
	// 831EB258: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EB25C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EB260: 419AFBE0  beq cr6, 0x831eae40
	if ctx.cr[6].eq {
	pc = 0x831EAE40; continue 'dispatch;
	}
	// 831EB264: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EB268: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831EB26C: 409AFBD4  bne cr6, 0x831eae40
	if !ctx.cr[6].eq {
	pc = 0x831EAE40; continue 'dispatch;
	}
	// 831EB270: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EB274: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831EB278: 4082FBC8  bne 0x831eae40
	if !ctx.cr[0].eq {
	pc = 0x831EAE40; continue 'dispatch;
	}
	// 831EB27C: 7EEABB78  mr r10, r23
	ctx.r[10].u64 = ctx.r[23].u64;
	// 831EB280: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831EB284: 7EEBBB78  mr r11, r23
	ctx.r[11].u64 = ctx.r[23].u64;
	// 831EB288: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831EB28C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831EB290: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831EB294: 480577D9  bl 0x83242a6c
	ctx.lr = 0x831EB298;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831EB298: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831EB29C: 48057ED1  bl 0x8324316c
	ctx.lr = 0x831EB2A0;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831EB2A0: 4BFFFBA0  b 0x831eae40
	pc = 0x831EAE40; continue 'dispatch;
	// 831EB2A4: 48057EB9  bl 0x8324315c
	ctx.lr = 0x831EB2A8;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831EB2A8: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EB2AC: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831EB2B0: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831EB2B4: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EB2B8: 419A0010  beq cr6, 0x831eb2c8
	if ctx.cr[6].eq {
	pc = 0x831EB2C8; continue 'dispatch;
	}
	// 831EB2BC: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EB2C0: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831EB2C4: 419A0018  beq cr6, 0x831eb2dc
	if ctx.cr[6].eq {
	pc = 0x831EB2DC; continue 'dispatch;
	}
	// 831EB2C8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831EB2CC: 480577B1  bl 0x83242a7c
	ctx.lr = 0x831EB2D0;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831EB2D0: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EB2D4: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831EB2D8: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831EB2DC: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831EB2E0: 3BDA00B8  addi r30, r26, 0xb8
	ctx.r[30].s64 = ctx.r[26].s64 + 184;
	// 831EB2E4: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831EB2E8: C01A00E0  lfs f0, 0xe0(r26)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(224 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831EB2EC: D01A00DC  stfs f0, 0xdc(r26)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(220 as u32), tmp.u32 ) };
	// 831EB2F0: 8BBA00C5  lbz r29, 0xc5(r26)
	ctx.r[29].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[26].u32.wrapping_add(197 as u32) ) } as u64;
	// 831EB2F4: 817A00D4  lwz r11, 0xd4(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(212 as u32) ) } as u64;
	// 831EB2F8: 815A00D0  lwz r10, 0xd0(r26)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(208 as u32) ) } as u64;
	// 831EB2FC: 7D4B5051  subf. r10, r11, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831EB300: 4182009C  beq 0x831eb39c
	if ctx.cr[0].eq {
	pc = 0x831EB39C; continue 'dispatch;
	}
	// 831EB304: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 831EB308: 419A002C  beq cr6, 0x831eb334
	if ctx.cr[6].eq {
	pc = 0x831EB334; continue 'dispatch;
	}
	// 831EB30C: 555B103A  slwi r27, r10, 2
	ctx.r[27].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[27].u64 = ctx.r[27].u32 as u64;
	// 831EB310: 557C103A  slwi r28, r11, 2
	ctx.r[28].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[28].u64 = ctx.r[28].u32 as u64;
	// 831EB314: 817E0014  lwz r11, 0x14(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(20 as u32) ) } as u64;
	// 831EB318: 7F65DB78  mr r5, r27
	ctx.r[5].u64 = ctx.r[27].u64;
	// 831EB31C: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831EB320: 7C7C5A14  add r3, r28, r11
	ctx.r[3].u64 = ctx.r[28].u64 + ctx.r[11].u64;
	// 831EB324: 4BFBCEBD  bl 0x831a81e0
	ctx.lr = 0x831EB328;
	sub_831A81E0(ctx, base);
	// 831EB328: 37BDFFFF  addic. r29, r29, -1
	ctx.xer.ca = (ctx.r[29].u32 > (!(-1 as u32)));
	ctx.r[29].s64 = ctx.r[29].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[29].s32, 0, &mut ctx.xer);
	// 831EB32C: 3B9C0400  addi r28, r28, 0x400
	ctx.r[28].s64 = ctx.r[28].s64 + 1024;
	// 831EB330: 4082FFE4  bne 0x831eb314
	if !ctx.cr[0].eq {
	pc = 0x831EB314; continue 'dispatch;
	}
	// 831EB334: 897A00AC  lbz r11, 0xac(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[26].u32.wrapping_add(172 as u32) ) } as u64;
	// 831EB338: 556A0738  rlwinm r10, r11, 0, 0x1c, 0x1c
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831EB33C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831EB340: 409A0044  bne cr6, 0x831eb384
	if !ctx.cr[6].eq {
	pc = 0x831EB384; continue 'dispatch;
	}
	// 831EB344: 815A0014  lwz r10, 0x14(r26)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(20 as u32) ) } as u64;
	// 831EB348: 397A0014  addi r11, r26, 0x14
	ctx.r[11].s64 = ctx.r[26].s64 + 20;
	// 831EB34C: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831EB350: 419A0014  beq cr6, 0x831eb364
	if ctx.cr[6].eq {
	pc = 0x831EB364; continue 'dispatch;
	}
	// 831EB354: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EB358: 7D4B5050  subf r10, r11, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 831EB35C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831EB360: 409A003C  bne cr6, 0x831eb39c
	if !ctx.cr[6].eq {
	pc = 0x831EB39C; continue 'dispatch;
	}
	// 831EB364: 817A0010  lwz r11, 0x10(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(16 as u32) ) } as u64;
	// 831EB368: 387A0010  addi r3, r26, 0x10
	ctx.r[3].s64 = ctx.r[26].s64 + 16;
	// 831EB36C: 38A00010  li r5, 0x10
	ctx.r[5].s64 = 16;
	// 831EB370: 38800010  li r4, 0x10
	ctx.r[4].s64 = 16;
	// 831EB374: 814B0054  lwz r10, 0x54(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(84 as u32) ) } as u64;
	// 831EB378: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831EB37C: 4E800421  bctrl
	ctx.lr = 0x831EB380;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831EB380: 4800001C  b 0x831eb39c
	pc = 0x831EB39C; continue 'dispatch;
	// 831EB384: 817A0000  lwz r11, 0(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(0 as u32) ) } as u64;
	// 831EB388: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 831EB38C: 7F43D378  mr r3, r26
	ctx.r[3].u64 = ctx.r[26].u64;
	// 831EB390: 814B0034  lwz r10, 0x34(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(52 as u32) ) } as u64;
	// 831EB394: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831EB398: 4E800421  bctrl
	ctx.lr = 0x831EB39C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831EB39C: 897A00AC  lbz r11, 0xac(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[26].u32.wrapping_add(172 as u32) ) } as u64;
	// 831EB3A0: 556A077A  rlwinm r10, r11, 0, 0x1d, 0x1d
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831EB3A4: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831EB3A8: 419A0034  beq cr6, 0x831eb3dc
	if ctx.cr[6].eq {
	pc = 0x831EB3DC; continue 'dispatch;
	}
	// 831EB3AC: A15A00AE  lhz r10, 0xae(r26)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[26].u32.wrapping_add(174 as u32) ) } as u64;
	// 831EB3B0: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831EB3B4: 419A0010  beq cr6, 0x831eb3c4
	if ctx.cr[6].eq {
	pc = 0x831EB3C4; continue 'dispatch;
	}
	// 831EB3B8: 556B06F6  rlwinm r11, r11, 0, 0x1b, 0x1b
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831EB3BC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831EB3C0: 419A001C  beq cr6, 0x831eb3dc
	if ctx.cr[6].eq {
	pc = 0x831EB3DC; continue 'dispatch;
	}
	// 831EB3C4: 817A0000  lwz r11, 0(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(0 as u32) ) } as u64;
	// 831EB3C8: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 831EB3CC: 7F43D378  mr r3, r26
	ctx.r[3].u64 = ctx.r[26].u64;
	// 831EB3D0: 814B0034  lwz r10, 0x34(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(52 as u32) ) } as u64;
	// 831EB3D4: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831EB3D8: 4E800421  bctrl
	ctx.lr = 0x831EB3DC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831EB3DC: 813F0004  lwz r9, 4(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EB3E0: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831EB3E4: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831EB3E8: 419A0040  beq cr6, 0x831eb428
	if ctx.cr[6].eq {
	pc = 0x831EB428; continue 'dispatch;
	}
	// 831EB3EC: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EB3F0: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831EB3F4: 409A0034  bne cr6, 0x831eb428
	if !ctx.cr[6].eq {
	pc = 0x831EB428; continue 'dispatch;
	}
	// 831EB3F8: 3569FFFF  addic. r11, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831EB3FC: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831EB400: 40820028  bne 0x831eb428
	if !ctx.cr[0].eq {
	pc = 0x831EB428; continue 'dispatch;
	}
	// 831EB404: 7EEABB78  mr r10, r23
	ctx.r[10].u64 = ctx.r[23].u64;
	// 831EB408: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831EB40C: 7EEBBB78  mr r11, r23
	ctx.r[11].u64 = ctx.r[23].u64;
	// 831EB410: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831EB414: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831EB418: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831EB41C: 48057651  bl 0x83242a6c
	ctx.lr = 0x831EB420;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831EB420: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831EB424: 48057D49  bl 0x8324316c
	ctx.lr = 0x831EB428;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831EB428: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831EB42C: 382100C0  addi r1, r1, 0xc0
	ctx.r[1].s64 = ctx.r[1].s64 + 192;
	// 831EB430: CBE1FFA8  lfd f31, -0x58(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-88 as u32) ) };
	// 831EB434: 4BFBCD70  b 0x831a81a4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EB438(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831EB438 size=112
    let mut pc: u32 = 0x831EB438;
    'dispatch: loop {
        match pc {
            0x831EB438 => {
    //   block [0x831EB438..0x831EB4A8)
	// 831EB438: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EB43C: 4BFBCD31  bl 0x831a816c
	ctx.lr = 0x831EB440;
	sub_831A8130(ctx, base);
	// 831EB440: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831EB444: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 831EB448: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831EB44C: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 831EB450: 38800114  li r4, 0x114
	ctx.r[4].s64 = 276;
	// 831EB454: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831EB458: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831EB45C: 814B0014  lwz r10, 0x14(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 831EB460: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831EB464: 4E800421  bctrl
	ctx.lr = 0x831EB468;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831EB468: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831EB46C: 419A002C  beq cr6, 0x831eb498
	if ctx.cr[6].eq {
	pc = 0x831EB498; continue 'dispatch;
	}
	// 831EB470: 7FE5FB78  mr r5, r31
	ctx.r[5].u64 = ctx.r[31].u64;
	// 831EB474: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 831EB478: 4BFFF7A1  bl 0x831eac18
	ctx.lr = 0x831EB47C;
	sub_831EAC18(ctx, base);
	// 831EB47C: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 831EB480: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831EB484: 419A0014  beq cr6, 0x831eb498
	if ctx.cr[6].eq {
	pc = 0x831EB498; continue 'dispatch;
	}
	// 831EB488: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831EB48C: 917D0000  stw r11, 0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831EB490: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831EB494: 4BFBCD28  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 831EB498: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 831EB49C: 6063000E  ori r3, r3, 0xe
	ctx.r[3].u64 = ctx.r[3].u64 | 14;
	// 831EB4A0: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831EB4A4: 4BFBCD18  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EB4A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831EB4A8 size=16
    let mut pc: u32 = 0x831EB4A8;
    'dispatch: loop {
        match pc {
            0x831EB4A8 => {
    //   block [0x831EB4A8..0x831EB4B8)
	// 831EB4A8: 2B030001  cmplwi cr6, r3, 1
	ctx.cr[6].compare_u32(ctx.r[3].u32, 1 as u32, &mut ctx.xer);
	// 831EB4AC: 4199000C  bgt cr6, 0x831eb4b8
	if ctx.cr[6].gt {
		sub_831EB4B8(ctx, base);
		return;
	}
	// 831EB4B0: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 831EB4B4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EB4B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831EB4B8 size=16
    let mut pc: u32 = 0x831EB4B8;
    'dispatch: loop {
        match pc {
            0x831EB4B8 => {
    //   block [0x831EB4B8..0x831EB4C8)
	// 831EB4B8: 2B0326F5  cmplwi cr6, r3, 0x26f5
	ctx.cr[6].compare_u32(ctx.r[3].u32, 9973 as u32, &mut ctx.xer);
	// 831EB4BC: 4198000C  blt cr6, 0x831eb4c8
	if ctx.cr[6].lt {
		sub_831EB4C8(ctx, base);
		return;
	}
	// 831EB4C0: 386026F5  li r3, 0x26f5
	ctx.r[3].s64 = 9973;
	// 831EB4C4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EB4C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831EB4C8 size=60
    let mut pc: u32 = 0x831EB4C8;
    'dispatch: loop {
        match pc {
            0x831EB4C8 => {
    //   block [0x831EB4C8..0x831EB504)
	// 831EB4C8: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831EB4CC: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 831EB4D0: 390004CD  li r8, 0x4cd
	ctx.r[8].s64 = 1229;
	// 831EB4D4: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 831EB4D8: 38CA1310  addi r6, r10, 0x1310
	ctx.r[6].s64 = ctx.r[10].s64 + 4880;
	// 831EB4DC: 7D484A14  add r10, r8, r9
	ctx.r[10].u64 = ctx.r[8].u64 + ctx.r[9].u64;
	// 831EB4E0: 7D675B78  mr r7, r11
	ctx.r[7].u64 = ctx.r[11].u64;
	// 831EB4E4: 554BF87E  srwi r11, r10, 1
	ctx.r[11].u32 = ctx.r[10].u32.wrapping_shr(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831EB4E8: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831EB4EC: 7D45302E  lwzx r10, r5, r6
	ctx.r[10].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[5].u32.wrapping_add(ctx.r[6].u32)) } as u64;
	// 831EB4F0: 7F0A1840  cmplw cr6, r10, r3
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[3].u32, &mut ctx.xer);
	// 831EB4F4: 419A001C  beq cr6, 0x831eb510
	if ctx.cr[6].eq {
		sub_831EB504(ctx, base);
		return;
	}
	// 831EB4F8: 4099000C  ble cr6, 0x831eb504
	if !ctx.cr[6].gt {
		sub_831EB504(ctx, base);
		return;
	}
	// 831EB4FC: 390BFFFF  addi r8, r11, -1
	ctx.r[8].s64 = ctx.r[11].s64 + -1;
	// 831EB500: 48000008  b 0x831eb508
	sub_831EB504(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EB504(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831EB504 size=24
    let mut pc: u32 = 0x831EB504;
    'dispatch: loop {
        match pc {
            0x831EB504 => {
    //   block [0x831EB504..0x831EB51C)
	// 831EB504: 392B0001  addi r9, r11, 1
	ctx.r[9].s64 = ctx.r[11].s64 + 1;
	// 831EB508: 7F0B3840  cmplw cr6, r11, r7
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831EB50C: 409AFFD0  bne cr6, 0x831eb4dc
	if !ctx.cr[6].eq {
		sub_831EB4C8(ctx, base);
		return;
	}
	// 831EB510: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831EB514: 7C6B302E  lwzx r3, r11, r6
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[6].u32)) } as u64;
	// 831EB518: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EB520(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831EB520 size=56
    let mut pc: u32 = 0x831EB520;
    'dispatch: loop {
        match pc {
            0x831EB520 => {
    //   block [0x831EB520..0x831EB558)
	// 831EB520: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EB524: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831EB528: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831EB52C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831EB530: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831EB534: 387F000C  addi r3, r31, 0xc
	ctx.r[3].s64 = ctx.r[31].s64 + 12;
	// 831EB538: 4BFEDD31  bl 0x831d9268
	ctx.lr = 0x831EB53C;
	sub_831D9268(ctx, base);
	// 831EB53C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831EB540: 4BFEDD29  bl 0x831d9268
	ctx.lr = 0x831EB544;
	sub_831D9268(ctx, base);
	// 831EB544: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831EB548: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831EB54C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831EB550: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831EB554: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EB558(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831EB558 size=188
    let mut pc: u32 = 0x831EB558;
    'dispatch: loop {
        match pc {
            0x831EB558 => {
    //   block [0x831EB558..0x831EB614)
	// 831EB558: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EB55C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831EB560: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831EB564: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831EB568: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831EB56C: 549E063E  clrlwi r30, r4, 0x18
	ctx.r[30].u64 = ctx.r[4].u32 as u64 & 0x000000FFu64;
	// 831EB570: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831EB574: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 831EB578: 419A0084  beq cr6, 0x831eb5fc
	if ctx.cr[6].eq {
	pc = 0x831EB5FC; continue 'dispatch;
	}
	// 831EB57C: 81650000  lwz r11, 0(r5)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 831EB580: 1C9E0078  mulli r4, r30, 0x78
	ctx.r[4].s64 = ctx.r[30].s64 * 120;
	// 831EB584: 814B0014  lwz r10, 0x14(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 831EB588: 7CA32B78  mr r3, r5
	ctx.r[3].u64 = ctx.r[5].u64;
	// 831EB58C: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831EB590: 4E800421  bctrl
	ctx.lr = 0x831EB594;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831EB594: 907F0018  stw r3, 0x18(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), ctx.r[3].u32 ) };
	// 831EB598: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 831EB59C: 419A0060  beq cr6, 0x831eb5fc
	if ctx.cr[6].eq {
	pc = 0x831EB5FC; continue 'dispatch;
	}
	// 831EB5A0: 393F000C  addi r9, r31, 0xc
	ctx.r[9].s64 = ctx.r[31].s64 + 12;
	// 831EB5A4: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831EB5A8: 7FC8F378  mr r8, r30
	ctx.r[8].u64 = ctx.r[30].u64;
	// 831EB5AC: 817F0018  lwz r11, 0x18(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) } as u64;
	// 831EB5B0: 3508FFFF  addic. r8, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 831EB5B4: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831EB5B8: 916B0000  stw r11, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831EB5BC: 817F0018  lwz r11, 0x18(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) } as u64;
	// 831EB5C0: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831EB5C4: 80EB0000  lwz r7, 0(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831EB5C8: 90EB0004  stw r7, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[7].u32 ) };
	// 831EB5CC: 80FF0018  lwz r7, 0x18(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) } as u64;
	// 831EB5D0: 81690008  lwz r11, 8(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EB5D4: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831EB5D8: 7D6B3A14  add r11, r11, r7
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[7].u64;
	// 831EB5DC: 394A0078  addi r10, r10, 0x78
	ctx.r[10].s64 = ctx.r[10].s64 + 120;
	// 831EB5E0: 912B0000  stw r9, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831EB5E4: 80C90004  lwz r6, 4(r9)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EB5E8: 90CB0004  stw r6, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[6].u32 ) };
	// 831EB5EC: 91690004  stw r11, 4(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831EB5F0: 80AB0004  lwz r5, 4(r11)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EB5F4: 91650000  stw r11, 0(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831EB5F8: 4082FFB4  bne 0x831eb5ac
	if !ctx.cr[0].eq {
	pc = 0x831EB5AC; continue 'dispatch;
	}
	// 831EB5FC: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831EB600: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831EB604: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831EB608: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831EB60C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831EB610: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EB618(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831EB618 size=36
    let mut pc: u32 = 0x831EB618;
    'dispatch: loop {
        match pc {
            0x831EB618 => {
    //   block [0x831EB618..0x831EB63C)
	// 831EB618: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831EB61C: 90630000  stw r3, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[3].u32 ) };
	// 831EB620: 3963000C  addi r11, r3, 0xc
	ctx.r[11].s64 = ctx.r[3].s64 + 12;
	// 831EB624: 90630004  stw r3, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[3].u32 ) };
	// 831EB628: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831EB62C: 9163000C  stw r11, 0xc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[11].u32 ) };
	// 831EB630: 91430014  stw r10, 0x14(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(20 as u32), ctx.r[10].u32 ) };
	// 831EB634: 91630010  stw r11, 0x10(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 831EB638: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EB640(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831EB640 size=616
    let mut pc: u32 = 0x831EB640;
    'dispatch: loop {
        match pc {
            0x831EB640 => {
    //   block [0x831EB640..0x831EB8A8)
	// 831EB640: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EB644: 4BFBCB25  bl 0x831a8168
	ctx.lr = 0x831EB648;
	sub_831A8130(ctx, base);
	// 831EB648: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831EB64C: 7CFF3B78  mr r31, r7
	ctx.r[31].u64 = ctx.r[7].u64;
	// 831EB650: C01F0024  lfs f0, 0x24(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831EB654: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 831EB658: 7C001A2C  dcbt 0, r3
	// 831EB65C: 3D608211  lis r11, -0x7def
	ctx.r[11].s64 = -2112815104;
	// 831EB660: C1BF0028  lfs f13, 0x28(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831EB664: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831EB668: C17F002C  lfs f11, 0x2c(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(44 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831EB66C: 3D00821A  lis r8, -0x7de6
	ctx.r[8].s64 = -2112225280;
	// 831EB670: D1BF0024  stfs f13, 0x24(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831EB674: 3D20821A  lis r9, -0x7de6
	ctx.r[9].s64 = -2112225280;
	// 831EB678: C15F0030  lfs f10, 0x30(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(48 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831EB67C: 38882990  addi r4, r8, 0x2990
	ctx.r[4].s64 = ctx.r[8].s64 + 10640;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EB8A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831EB8A8 size=716
    let mut pc: u32 = 0x831EB8A8;
    'dispatch: loop {
        match pc {
            0x831EB8A8 => {
    //   block [0x831EB8A8..0x831EBB74)
	// 831EB8A8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EB8AC: 4BFBC8B5  bl 0x831a8160
	ctx.lr = 0x831EB8B0;
	sub_831A8130(ctx, base);
	// 831EB8B0: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831EB8B4: 7CFE3B78  mr r30, r7
	ctx.r[30].u64 = ctx.r[7].u64;
	// 831EB8B8: C01E0024  lfs f0, 0x24(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831EB8BC: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 831EB8C0: 7C001A2C  dcbt 0, r3
	// 831EB8C4: 3D608211  lis r11, -0x7def
	ctx.r[11].s64 = -2112815104;
	// 831EB8C8: C1BE0028  lfs f13, 0x28(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831EB8CC: 3D20821A  lis r9, -0x7de6
	ctx.r[9].s64 = -2112225280;
	// 831EB8D0: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831EB8D4: C17E002C  lfs f11, 0x2c(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(44 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831EB8D8: 3D00821A  lis r8, -0x7de6
	ctx.r[8].s64 = -2112225280;
	// 831EB8DC: 38E929A0  addi r7, r9, 0x29a0
	ctx.r[7].s64 = ctx.r[9].s64 + 10656;
	// 831EB8E0: D1BE0024  stfs f13, 0x24(r30)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831EB8E4: 38882990  addi r4, r8, 0x2990
	ctx.r[4].s64 = ctx.r[8].s64 + 10640;
	// 831EB8E8: C15E0030  lfs f10, 0x30(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(48 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831EB8EC: C80BEA20  lfd f0, -0x15e0(r11)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(-5600 as u32) ) };
	// 831EB8F0: 39000004  li r8, 4
	ctx.r[8].s64 = 4;
	// 831EB8F4: FD2B0032  fmul f9, f11, f0
	ctx.f[9].f64 = ctx.f[11].f64 * ctx.f[0].f64;
	// 831EB8F8: 39610058  addi r11, r1, 0x58
	ctx.r[11].s64 = ctx.r[1].s64 + 88;
	// 831EB8FC: 7CCA07B4  extsw r10, r6
	ctx.r[10].s64 = ctx.r[6].s32 as i64;
	// 831EB900: F9410060  std r10, 0x60(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[10].u64 ) };
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EBB78(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831EBB78 size=928
    let mut pc: u32 = 0x831EBB78;
    'dispatch: loop {
        match pc {
            0x831EBB78 => {
    //   block [0x831EBB78..0x831EBF18)
	// 831EBB78: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EBB7C: 4BFBC5C5  bl 0x831a8140
	ctx.lr = 0x831EBB80;
	sub_831A8130(ctx, base);
	// 831EBB80: 9421FF10  stwu r1, -0xf0(r1)
	ea = ctx.r[1].u32.wrapping_add(-240 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831EBB84: 7CF83B78  mr r24, r7
	ctx.r[24].u64 = ctx.r[7].u64;
	// 831EBB88: C0180024  lfs f0, 0x24(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831EBB8C: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 831EBB90: 7C001A2C  dcbt 0, r3
	// 831EBB94: 3D608211  lis r11, -0x7def
	ctx.r[11].s64 = -2112815104;
	// 831EBB98: C1B80028  lfs f13, 0x28(r24)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831EBB9C: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831EBBA0: C178002C  lfs f11, 0x2c(r24)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(44 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831EBBA4: 7CC807B4  extsw r8, r6
	ctx.r[8].s64 = ctx.r[6].s32 as i64;
	// 831EBBA8: F9010068  std r8, 0x68(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[8].u64 ) };
	// 831EBBAC: 38E00004  li r7, 4
	ctx.r[7].s64 = 4;
	// 831EBBB0: C1580030  lfs f10, 0x30(r24)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(48 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831EBBB4: 39210058  addi r9, r1, 0x58
	ctx.r[9].s64 = ctx.r[1].s64 + 88;
	// 831EBBB8: D1B80024  stfs f13, 0x24(r24)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831EBBBC: C80BEA20  lfd f0, -0x15e0(r11)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(-5600 as u32) ) };
	// 831EBBC0: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831EBBC4: FD2B0032  fmul f9, f11, f0
	ctx.f[9].f64 = ctx.f[11].f64 * ctx.f[0].f64;
	// 831EBBC8: 3FA08201  lis r29, -0x7dff
	ctx.r[29].s64 = -2113863680;
	// 831EBBCC: FD0A0032  fmul f8, f10, f0
	ctx.f[8].f64 = ctx.f[10].f64 * ctx.f[0].f64;
	// 831EBBD0: 3BC10058  addi r30, r1, 0x58
	ctx.r[30].s64 = ctx.r[1].s64 + 88;
	// 831EBBD4: 390B29A0  addi r8, r11, 0x29a0
	ctx.r[8].s64 = ctx.r[11].s64 + 10656;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EBF18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831EBF18 size=1184
    let mut pc: u32 = 0x831EBF18;
    'dispatch: loop {
        match pc {
            0x831EBF18 => {
    //   block [0x831EBF18..0x831EC3B8)
	// 831EBF18: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EBF1C: 4BFBC215  bl 0x831a8130
	ctx.lr = 0x831EBF20;
	sub_831A8130(ctx, base);
	// 831EBF20: 9421FEF0  stwu r1, -0x110(r1)
	ea = ctx.r[1].u32.wrapping_add(-272 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831EBF24: C0070024  lfs f0, 0x24(r7)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831EBF28: 90C1013C  stw r6, 0x13c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(316 as u32), ctx.r[6].u32 ) };
	// 831EBF2C: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 831EBF30: 90E10144  stw r7, 0x144(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(324 as u32), ctx.r[7].u32 ) };
	// 831EBF34: 7C001A2C  dcbt 0, r3
	// 831EBF38: 3D608211  lis r11, -0x7def
	ctx.r[11].s64 = -2112815104;
	// 831EBF3C: C1A70028  lfs f13, 0x28(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831EBF40: 3AC00004  li r22, 4
	ctx.r[22].s64 = 4;
	// 831EBF44: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831EBF48: C167002C  lfs f11, 0x2c(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(44 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831EBF4C: 39010058  addi r8, r1, 0x58
	ctx.r[8].s64 = ctx.r[1].s64 + 88;
	// 831EBF50: C1470030  lfs f10, 0x30(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(48 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831EBF54: 7CCA07B4  extsw r10, r6
	ctx.r[10].s64 = ctx.r[6].s32 as i64;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EC3B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831EC3B8 size=444
    let mut pc: u32 = 0x831EC3B8;
    'dispatch: loop {
        match pc {
            0x831EC3B8 => {
    //   block [0x831EC3B8..0x831EC500)
	// 831EC3B8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EC3BC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831EC3C0: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831EC3C4: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831EC3C8: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831EC3CC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831EC3D0: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EC3D4: 83DF0008  lwz r30, 8(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EC3D8: 7F1E5840  cmplw cr6, r30, r11
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831EC3DC: 4198000C  blt cr6, 0x831ec3e8
	if ctx.cr[6].lt {
	pc = 0x831EC3E8; continue 'dispatch;
	}
	// 831EC3E0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831EC3E4: 48000178  b 0x831ec55c
	pc = 0x831EC55C; continue 'dispatch;
	// 831EC3E8: 817F001C  lwz r11, 0x1c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(28 as u32) ) } as u64;
	// 831EC3EC: 815F0018  lwz r10, 0x18(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) } as u64;
	// 831EC3F0: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831EC3F4: 4098FFEC  bge cr6, 0x831ec3e0
	if !ctx.cr[6].lt {
	pc = 0x831EC3E0; continue 'dispatch;
	}
	// 831EC3F8: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 831EC3FC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831EC400: 419A0144  beq cr6, 0x831ec544
	if ctx.cr[6].eq {
	pc = 0x831EC544; continue 'dispatch;
	}
	// 831EC404: 556B07BE  clrlwi r11, r11, 0x1e
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x00000003u64;
	// 831EC408: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831EC40C: 419A0130  beq cr6, 0x831ec53c
	if ctx.cr[6].eq {
	pc = 0x831EC53C; continue 'dispatch;
	}
	// 831EC410: 815F0020  lwz r10, 0x20(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) } as u64;
	// 831EC414: 80FF0010  lwz r7, 0x10(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 831EC418: 7D485378  mr r8, r10
	ctx.r[8].u64 = ctx.r[10].u64;
	// 831EC41C: 817F0054  lwz r11, 0x54(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(84 as u32) ) } as u64;
	// 831EC420: F9010050  std r8, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[8].u64 ) };
	// 831EC424: C8010050  lfd f0, 0x50(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 831EC428: FD60069C  fcfid f11, f0
	ctx.f[11].f64 = (ctx.f[0].s64 as f64);
	// 831EC42C: 556907FE  clrlwi r9, r11, 0x1f
	ctx.r[9].u64 = ctx.r[11].u32 as u64 & 0x00000001u64;
	// 831EC430: F8E10050  std r7, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[7].u64 ) };
	// 831EC434: C9A10050  lfd f13, 0x50(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 831EC438: FD806E9C  fcfid f12, f13
	ctx.f[12].f64 = (ctx.f[13].s64 as f64);
	// 831EC43C: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831EC440: FD406018  frsp f10, f12
	ctx.f[10].f64 = (ctx.f[12].f64 as f32) as f64;
	// 831EC444: FD205818  frsp f9, f11
	ctx.f[9].f64 = (ctx.f[11].f64 as f32) as f64;
	// 831EC448: ED0A4824  fdivs f8, f10, f9
	ctx.f[8].f64 = ((ctx.f[10].f64 / ctx.f[9].f64) as f32) as f64;
	// 831EC44C: D11F002C  stfs f8, 0x2c(r31)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(44 as u32), tmp.u32 ) };
	// 831EC450: 419A0058  beq cr6, 0x831ec4a8
	if ctx.cr[6].eq {
	pc = 0x831EC4A8; continue 'dispatch;
	}
	// 831EC454: 54E8003E  slwi r8, r7, 0
	ctx.r[8].u32 = ctx.r[7].u32.wrapping_shl(0);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831EC458: 7F085040  cmplw cr6, r8, r10
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831EC45C: 409A001C  bne cr6, 0x831ec478
	if !ctx.cr[6].eq {
	pc = 0x831EC478; continue 'dispatch;
	}
	// 831EC460: 556B0630  rlwinm r11, r11, 0, 0x18, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831EC464: 214B0000  subfic r10, r11, 0
	ctx.xer.ca = ctx.r[11].u32 <= 0 as u32;
	ctx.r[10].s64 = (0 as i64) - ctx.r[11].s64;
	// 831EC468: 7D2A5110  subfe r9, r10, r10
	let x = (!ctx.r[10].u32);
	let y = ctx.r[10].u32;
	let s = x.wrapping_add(y);
	let res = s.wrapping_add(ctx.xer.ca as u32);
	tmp.u8 = (s < x) as u8 | (res < s) as u8;
	ctx.r[9].u32 = res;
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	ctx.xer.ca = (tmp.u8 != 0);
	// 831EC46C: 552B07FA  rlwinm r11, r9, 0, 0x1f, 0x1d
	ctx.r[11].u64 = ctx.r[9].u32 as u64 & 0xFFFFFFFFu64;
	// 831EC470: 394B0004  addi r10, r11, 4
	ctx.r[10].s64 = ctx.r[11].s64 + 4;
	// 831EC474: 48000048  b 0x831ec4bc
	pc = 0x831EC4BC; continue 'dispatch;
	// 831EC478: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831EC47C: 419A002C  beq cr6, 0x831ec4a8
	if ctx.cr[6].eq {
	pc = 0x831EC4A8; continue 'dispatch;
	}
	// 831EC480: 813F0010  lwz r9, 0x10(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 831EC484: 5528083C  slwi r8, r9, 1
	ctx.r[8].u32 = ctx.r[9].u32.wrapping_shl(1);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831EC488: 7F085040  cmplw cr6, r8, r10
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831EC48C: 409A001C  bne cr6, 0x831ec4a8
	if !ctx.cr[6].eq {
	pc = 0x831EC4A8; continue 'dispatch;
	}
	// 831EC490: 556B0630  rlwinm r11, r11, 0, 0x18, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831EC494: 214B0000  subfic r10, r11, 0
	ctx.xer.ca = ctx.r[11].u32 <= 0 as u32;
	ctx.r[10].s64 = (0 as i64) - ctx.r[11].s64;
	// 831EC498: 7D2A5110  subfe r9, r10, r10
	let x = (!ctx.r[10].u32);
	let y = ctx.r[10].u32;
	let s = x.wrapping_add(y);
	let res = s.wrapping_add(ctx.xer.ca as u32);
	tmp.u8 = (s < x) as u8 | (res < s) as u8;
	ctx.r[9].u32 = res;
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	ctx.xer.ca = (tmp.u8 != 0);
	// 831EC49C: 552B07FA  rlwinm r11, r9, 0, 0x1f, 0x1d
	ctx.r[11].u64 = ctx.r[9].u32 as u64 & 0xFFFFFFFFu64;
	// 831EC4A0: 394B0005  addi r10, r11, 5
	ctx.r[10].s64 = ctx.r[11].s64 + 5;
	// 831EC4A4: 48000018  b 0x831ec4bc
	pc = 0x831EC4BC; continue 'dispatch;
	// 831EC4A8: 556B0630  rlwinm r11, r11, 0, 0x18, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831EC4AC: 214B0000  subfic r10, r11, 0
	ctx.xer.ca = ctx.r[11].u32 <= 0 as u32;
	ctx.r[10].s64 = (0 as i64) - ctx.r[11].s64;
	// 831EC4B0: 7D2A5110  subfe r9, r10, r10
	let x = (!ctx.r[10].u32);
	let y = ctx.r[10].u32;
	let s = x.wrapping_add(y);
	let res = s.wrapping_add(ctx.xer.ca as u32);
	tmp.u8 = (s < x) as u8 | (res < s) as u8;
	ctx.r[9].u32 = res;
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	ctx.xer.ca = (tmp.u8 != 0);
	// 831EC4B4: 552B07FA  rlwinm r11, r9, 0, 0x1f, 0x1d
	ctx.r[11].u64 = ctx.r[9].u32 as u64 & 0xFFFFFFFFu64;
	// 831EC4B8: 394B0003  addi r10, r11, 3
	ctx.r[10].s64 = ctx.r[11].s64 + 3;
	// 831EC4BC: 897F000D  lbz r11, 0xd(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(13 as u32) ) } as u64;
	// 831EC4C0: 891F000C  lbz r8, 0xc(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831EC4C4: 392BFFFF  addi r9, r11, -1
	ctx.r[9].s64 = ctx.r[11].s64 + -1;
	// 831EC4C8: 2B090005  cmplwi cr6, r9, 5
	ctx.cr[6].compare_u32(ctx.r[9].u32, 5 as u32, &mut ctx.xer);
	// 831EC4CC: 41990040  bgt cr6, 0x831ec50c
	if ctx.cr[6].gt {
	pc = 0x831EC50C; continue 'dispatch;
	}
	// 831EC4D0: 3D80831F  lis r12, -0x7ce1
	ctx.r[12].s64 = -2095120384;
	// 831EC4D4: 398CC4E8  addi r12, r12, -0x3b18
	ctx.r[12].s64 = ctx.r[12].s64 + -15128;
	// 831EC4D8: 5520103A  slwi r0, r9, 2
	ctx.r[0].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[0].u64 = ctx.r[0].u32 as u64;
	// 831EC4DC: 7C0C002E  lwzx r0, r12, r0
	ctx.r[0].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[12].u32.wrapping_add(ctx.r[0].u32)) } as u64;
	// 831EC4E0: 7C0903A6  mtctr r0
	ctx.ctr.u64 = ctx.r[0].u64;
	// 831EC4E4: 4E800420  bctr
	match ctx.r[9].u64 {
		0 => {
	pc = 0x831EC500; continue 'dispatch;
		},
		1 => {
	pc = 0x831EC500; continue 'dispatch;
		},
		2 => {
	pc = 0x831EC50C; continue 'dispatch;
		},
		3 => {
	pc = 0x831EC500; continue 'dispatch;
		},
		4 => {
	pc = 0x831EC50C; continue 'dispatch;
		},
		5 => {
	pc = 0x831EC500; continue 'dispatch;
		},
		_ => unsafe { core::hint::unreachable_unchecked() },
	}
	// 831EC4E8: 831EC500  lwz r24, -0x3b00(r30)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-15104 as u32) ) } as u64;
	// 831EC4EC: 831EC500  lwz r24, -0x3b00(r30)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-15104 as u32) ) } as u64;
	// 831EC4F0: 831EC50C  lwz r24, -0x3af4(r30)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-15092 as u32) ) } as u64;
	// 831EC4F4: 831EC500  lwz r24, -0x3b00(r30)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-15104 as u32) ) } as u64;
	// 831EC4F8: 831EC50C  lwz r24, -0x3af4(r30)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-15092 as u32) ) } as u64;
	// 831EC4FC: 831EC500  lwz r24, -0x3b00(r30)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-15104 as u32) ) } as u64;
            }
            0x831EC500 => {
    //   block [0x831EC500..0x831EC50C)
	// 831EC500: 556BF87E  srwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shr(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831EC504: 392B0001  addi r9, r11, 1
	ctx.r[9].s64 = ctx.r[11].s64 + 1;
	// 831EC508: 48000008  b 0x831ec510
	pc = 0x831EC510; continue 'dispatch;
            }
            0x831EC50C => {
    //   block [0x831EC50C..0x831EC574)
	// 831EC50C: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 831EC510: 554B103A  slwi r11, r10, 2
	ctx.r[11].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831EC514: 3CE0821A  lis r7, -0x7de6
	ctx.r[7].s64 = -2112225280;
	// 831EC518: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831EC51C: 38C72648  addi r6, r7, 0x2648
	ctx.r[6].s64 = ctx.r[7].s64 + 9800;
	// 831EC520: 7D6B4214  add r11, r11, r8
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 831EC524: 556A103A  slwi r10, r11, 2
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831EC528: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831EC52C: 7CAB4A14  add r5, r11, r9
	ctx.r[5].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 831EC530: 54A4103A  slwi r4, r5, 2
	ctx.r[4].u32 = ctx.r[5].u32.wrapping_shl(2);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 831EC534: 7C64302E  lwzx r3, r4, r6
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[4].u32.wrapping_add(ctx.r[6].u32)) } as u64;
	// 831EC538: 907F004C  stw r3, 0x4c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(76 as u32), ctx.r[3].u32 ) };
	// 831EC53C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831EC540: 917F0050  stw r11, 0x50(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 831EC544: 817F004C  lwz r11, 0x4c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(76 as u32) ) } as u64;
	// 831EC548: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831EC54C: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 831EC550: 4E800421  bctrl
	ctx.lr = 0x831EC554;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831EC554: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EC558: 7C7E5050  subf r3, r30, r10
	ctx.r[3].s64 = ctx.r[10].s64 - ctx.r[30].s64;
	// 831EC55C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831EC560: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831EC564: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831EC568: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831EC56C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831EC570: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EC578(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831EC578 size=508
    let mut pc: u32 = 0x831EC578;
    'dispatch: loop {
        match pc {
            0x831EC578 => {
    //   block [0x831EC578..0x831EC774)
	// 831EC578: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EC57C: 4BFBBBF1  bl 0x831a816c
	ctx.lr = 0x831EC580;
	sub_831A8130(ctx, base);
	// 831EC580: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831EC584: 7CFF3B78  mr r31, r7
	ctx.r[31].u64 = ctx.r[7].u64;
	// 831EC588: C01F0024  lfs f0, 0x24(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831EC58C: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 831EC590: 7C001A2C  dcbt 0, r3
	// 831EC594: 3D208211  lis r9, -0x7def
	ctx.r[9].s64 = -2112815104;
	// 831EC598: C1BF0028  lfs f13, 0x28(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831EC59C: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831EC5A0: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831EC5A4: C15F002C  lfs f10, 0x2c(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(44 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831EC5A8: 7CCB07B4  extsw r11, r6
	ctx.r[11].s64 = ctx.r[6].s32 as i64;
	// 831EC5AC: 38EA2990  addi r7, r10, 0x2990
	ctx.r[7].s64 = ctx.r[10].s64 + 10640;
	// 831EC5B0: D1BF0024  stfs f13, 0x24(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831EC5B4: F9610058  std r11, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[11].u64 ) };
	// 831EC5B8: C9610058  lfd f11, 0x58(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 831EC5BC: C809EA20  lfd f0, -0x15e0(r9)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[9].u32.wrapping_add(-5600 as u32) ) };
	// 831EC5C0: FC805E9C  fcfid f4, f11
	ctx.f[4].f64 = (ctx.f[11].s64 as f64);
	// 831EC5C4: FD0A0032  fmul f8, f10, f0
	ctx.f[8].f64 = ctx.f[10].f64 * ctx.f[0].f64;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EC778(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831EC778 size=560
    let mut pc: u32 = 0x831EC778;
    'dispatch: loop {
        match pc {
            0x831EC778 => {
    //   block [0x831EC778..0x831EC9A8)
	// 831EC778: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EC77C: 4BFBB9ED  bl 0x831a8168
	ctx.lr = 0x831EC780;
	sub_831A8130(ctx, base);
	// 831EC780: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831EC784: 7CFE3B78  mr r30, r7
	ctx.r[30].u64 = ctx.r[7].u64;
	// 831EC788: C01E0024  lfs f0, 0x24(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831EC78C: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 831EC790: 7C001A2C  dcbt 0, r3
	// 831EC794: 3D208211  lis r9, -0x7def
	ctx.r[9].s64 = -2112815104;
	// 831EC798: C1BE0028  lfs f13, 0x28(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831EC79C: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831EC7A0: C15E002C  lfs f10, 0x2c(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(44 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831EC7A4: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831EC7A8: D1BE0024  stfs f13, 0x24(r30)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831EC7AC: 7CCB07B4  extsw r11, r6
	ctx.r[11].s64 = ctx.r[6].s32 as i64;
	// 831EC7B0: C13E0030  lfs f9, 0x30(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(48 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831EC7B4: 38EA2990  addi r7, r10, 0x2990
	ctx.r[7].s64 = ctx.r[10].s64 + 10640;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EC9A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831EC9A8 size=664
    let mut pc: u32 = 0x831EC9A8;
    'dispatch: loop {
        match pc {
            0x831EC9A8 => {
    //   block [0x831EC9A8..0x831ECC40)
	// 831EC9A8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EC9AC: 4BFBB7A5  bl 0x831a8150
	ctx.lr = 0x831EC9B0;
	sub_831A8130(ctx, base);
	// 831EC9B0: 9421FF30  stwu r1, -0xd0(r1)
	ea = ctx.r[1].u32.wrapping_add(-208 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831EC9B4: 7CFA3B78  mr r26, r7
	ctx.r[26].u64 = ctx.r[7].u64;
	// 831EC9B8: C01A0024  lfs f0, 0x24(r26)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831EC9BC: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 831EC9C0: 7C001A2C  dcbt 0, r3
	// 831EC9C4: 3D608211  lis r11, -0x7def
	ctx.r[11].s64 = -2112815104;
	// 831EC9C8: C1BA0028  lfs f13, 0x28(r26)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831EC9CC: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831EC9D0: C17A002C  lfs f11, 0x2c(r26)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(44 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831EC9D4: 39000004  li r8, 4
	ctx.r[8].s64 = 4;
	// 831EC9D8: C15A0030  lfs f10, 0x30(r26)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(48 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831EC9DC: 38810058  addi r4, r1, 0x58
	ctx.r[4].s64 = ctx.r[1].s64 + 88;
	// 831EC9E0: D1BA0024  stfs f13, 0x24(r26)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831EC9E4: 7CCA07B4  extsw r10, r6
	ctx.r[10].s64 = ctx.r[6].s32 as i64;
	// 831EC9E8: F9410060  std r10, 0x60(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[10].u64 ) };
	// 831EC9EC: C80BEA20  lfd f0, -0x15e0(r11)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(-5600 as u32) ) };
	// 831EC9F0: 3D20821A  lis r9, -0x7de6
	ctx.r[9].s64 = -2112225280;
	// 831EC9F4: FD2B0032  fmul f9, f11, f0
	ctx.f[9].f64 = ctx.f[11].f64 * ctx.f[0].f64;
	// 831EC9F8: 39410050  addi r10, r1, 0x50
	ctx.r[10].s64 = ctx.r[1].s64 + 80;
	// 831EC9FC: 38E92990  addi r7, r9, 0x2990
	ctx.r[7].s64 = ctx.r[9].s64 + 10640;
	// 831ECA00: FD0A0032  fmul f8, f10, f0
	ctx.f[8].f64 = ctx.f[10].f64 * ctx.f[0].f64;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831ECC40(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831ECC40 size=784
    let mut pc: u32 = 0x831ECC40;
    'dispatch: loop {
        match pc {
            0x831ECC40 => {
    //   block [0x831ECC40..0x831ECF50)
	// 831ECC40: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831ECC44: 4BFBB4F1  bl 0x831a8134
	ctx.lr = 0x831ECC48;
	sub_831A8130(ctx, base);
	// 831ECC48: 9421FF00  stwu r1, -0x100(r1)
	ea = ctx.r[1].u32.wrapping_add(-256 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831ECC4C: 7CF43B78  mr r20, r7
	ctx.r[20].u64 = ctx.r[7].u64;
	// 831ECC50: C0140024  lfs f0, 0x24(r20)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831ECC54: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 831ECC58: 7C001A2C  dcbt 0, r3
	// 831ECC5C: 3D608211  lis r11, -0x7def
	ctx.r[11].s64 = -2112815104;
	// 831ECC60: C1B40028  lfs f13, 0x28(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831ECC64: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831ECC68: C174002C  lfs f11, 0x2c(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(44 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831ECC6C: 38E00004  li r7, 4
	ctx.r[7].s64 = 4;
	// 831ECC70: C1540030  lfs f10, 0x30(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(48 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831ECC74: 38810058  addi r4, r1, 0x58
	ctx.r[4].s64 = ctx.r[1].s64 + 88;
	// 831ECC78: D1B40024  stfs f13, 0x24(r20)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831ECC7C: 7CCA07B4  extsw r10, r6
	ctx.r[10].s64 = ctx.r[6].s32 as i64;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831ECF50(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831ECF50 size=788
    let mut pc: u32 = 0x831ECF50;
    'dispatch: loop {
        match pc {
            0x831ECF50 => {
    //   block [0x831ECF50..0x831ED264)
	// 831ECF50: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831ECF54: 4BFBB215  bl 0x831a8168
	ctx.lr = 0x831ECF58;
	sub_831A8130(ctx, base);
	// 831ECF58: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831ECF5C: 7CFF3B78  mr r31, r7
	ctx.r[31].u64 = ctx.r[7].u64;
	// 831ECF60: C01F0024  lfs f0, 0x24(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831ECF64: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 831ECF68: 7C001A2C  dcbt 0, r3
	// 831ECF6C: 3D608211  lis r11, -0x7def
	ctx.r[11].s64 = -2112815104;
	// 831ECF70: C1BF0028  lfs f13, 0x28(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831ECF74: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831ECF78: C15F0030  lfs f10, 0x30(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(48 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831ECF7C: 3D20821A  lis r9, -0x7de6
	ctx.r[9].s64 = -2112225280;
	// 831ECF80: D1BF0024  stfs f13, 0x24(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831ECF84: 7CCA07B4  extsw r10, r6
	ctx.r[10].s64 = ctx.r[6].s32 as i64;
	// 831ECF88: F9410060  std r10, 0x60(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[10].u64 ) };
	// 831ECF8C: 3D00821A  lis r8, -0x7de6
	ctx.r[8].s64 = -2112225280;
	// 831ECF90: C17F002C  lfs f11, 0x2c(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(44 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831ECF94: C80BEA20  lfd f0, -0x15e0(r11)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(-5600 as u32) ) };
	// 831ECF98: 396929C0  addi r11, r9, 0x29c0
	ctx.r[11].s64 = ctx.r[9].s64 + 10688;
	// 831ECF9C: FD0A0032  fmul f8, f10, f0
	ctx.f[8].f64 = ctx.f[10].f64 * ctx.f[0].f64;
	// 831ECFA0: 3CE0821A  lis r7, -0x7de6
	ctx.r[7].s64 = -2112225280;
	// 831ECFA4: 39400004  li r10, 4
	ctx.r[10].s64 = 4;
	// 831ECFA8: FD2B0032  fmul f9, f11, f0
	ctx.f[9].f64 = ctx.f[11].f64 * ctx.f[0].f64;
	// 831ECFAC: 3BC10068  addi r30, r1, 0x68
	ctx.r[30].s64 = ctx.r[1].s64 + 104;
	// 831ECFB0: 1007030C  vspltisb v0, 7
	for i in 0..16 {
		ctx.v[0].u8[i] = 7 as u8;
	}
	// 831ECFB4: 3C80821A  lis r4, -0x7de6
	ctx.r[4].s64 = -2112225280;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831ED268(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831ED268 size=1008
    let mut pc: u32 = 0x831ED268;
    'dispatch: loop {
        match pc {
            0x831ED268 => {
    //   block [0x831ED268..0x831ED658)
	// 831ED268: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831ED26C: 4BFBAEE5  bl 0x831a8150
	ctx.lr = 0x831ED270;
	sub_831A8130(ctx, base);
	// 831ED270: 9421FF30  stwu r1, -0xd0(r1)
	ea = ctx.r[1].u32.wrapping_add(-208 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831ED274: 7CFC3B78  mr r28, r7
	ctx.r[28].u64 = ctx.r[7].u64;
	// 831ED278: C01C0024  lfs f0, 0x24(r28)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831ED27C: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 831ED280: 7C001A2C  dcbt 0, r3
	// 831ED284: 3D608211  lis r11, -0x7def
	ctx.r[11].s64 = -2112815104;
	// 831ED288: C1BC0028  lfs f13, 0x28(r28)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831ED28C: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831ED290: C15C0030  lfs f10, 0x30(r28)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(48 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831ED294: 3D20821A  lis r9, -0x7de6
	ctx.r[9].s64 = -2112225280;
	// 831ED298: D1BC0024  stfs f13, 0x24(r28)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831ED29C: 7CCA07B4  extsw r10, r6
	ctx.r[10].s64 = ctx.r[6].s32 as i64;
	// 831ED2A0: F9410060  std r10, 0x60(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[10].u64 ) };
	// 831ED2A4: 394929C0  addi r10, r9, 0x29c0
	ctx.r[10].s64 = ctx.r[9].s64 + 10688;
	// 831ED2A8: C17C002C  lfs f11, 0x2c(r28)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(44 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831ED2AC: C80BEA20  lfd f0, -0x15e0(r11)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(-5600 as u32) ) };
	// 831ED2B0: 3D00821A  lis r8, -0x7de6
	ctx.r[8].s64 = -2112225280;
	// 831ED2B4: FD0A0032  fmul f8, f10, f0
	ctx.f[8].f64 = ctx.f[10].f64 * ctx.f[0].f64;
	// 831ED2B8: 3CE0821A  lis r7, -0x7de6
	ctx.r[7].s64 = -2112225280;
	// 831ED2BC: 3C80821A  lis r4, -0x7de6
	ctx.r[4].s64 = -2112225280;
	// 831ED2C0: FD2B0032  fmul f9, f11, f0
	ctx.f[9].f64 = ctx.f[11].f64 * ctx.f[0].f64;
	// 831ED2C4: 392829B0  addi r9, r8, 0x29b0
	ctx.r[9].s64 = ctx.r[8].s64 + 10672;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831ED658(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831ED658 size=1520
    let mut pc: u32 = 0x831ED658;
    'dispatch: loop {
        match pc {
            0x831ED658 => {
    //   block [0x831ED658..0x831EDC48)
	// 831ED658: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831ED65C: 4BFBAAD5  bl 0x831a8130
	ctx.lr = 0x831ED660;
	sub_831A8130(ctx, base);
	// 831ED660: 9421FEC0  stwu r1, -0x140(r1)
	ea = ctx.r[1].u32.wrapping_add(-320 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831ED664: C0070024  lfs f0, 0x24(r7)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831ED668: 90C1016C  stw r6, 0x16c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(364 as u32), ctx.r[6].u32 ) };
	// 831ED66C: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 831ED670: 90E10174  stw r7, 0x174(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(372 as u32), ctx.r[7].u32 ) };
	// 831ED674: 7C001A2C  dcbt 0, r3
	// 831ED678: 3D608211  lis r11, -0x7def
	ctx.r[11].s64 = -2112815104;
	// 831ED67C: C1A70028  lfs f13, 0x28(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831ED680: 7CCA07B4  extsw r10, r6
	ctx.r[10].s64 = ctx.r[6].s32 as i64;
	// 831ED684: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831ED688: C1470030  lfs f10, 0x30(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(48 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831ED68C: 3D20821A  lis r9, -0x7de6
	ctx.r[9].s64 = -2112225280;
	// 831ED690: D1A70024  stfs f13, 0x24(r7)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831ED694: 3CC0821A  lis r6, -0x7de6
	ctx.r[6].s64 = -2112225280;
	// 831ED698: C167002C  lfs f11, 0x2c(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(44 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831ED69C: C80BEA20  lfd f0, -0x15e0(r11)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(-5600 as u32) ) };
	// 831ED6A0: 388929C0  addi r4, r9, 0x29c0
	ctx.r[4].s64 = ctx.r[9].s64 + 10688;
	// 831ED6A4: FD0A0032  fmul f8, f10, f0
	ctx.f[8].f64 = ctx.f[10].f64 * ctx.f[0].f64;
	// 831ED6A8: 39262990  addi r9, r6, 0x2990
	ctx.r[9].s64 = ctx.r[6].s64 + 10640;
	// 831ED6AC: F9410060  std r10, 0x60(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[10].u64 ) };
	// 831ED6B0: 3CE0821A  lis r7, -0x7de6
	ctx.r[7].s64 = -2112225280;
	// 831ED6B4: FD2B0032  fmul f9, f11, f0
	ctx.f[9].f64 = ctx.f[11].f64 * ctx.f[0].f64;
	// 831ED6B8: 3B600004  li r27, 4
	ctx.r[27].s64 = 4;
	// 831ED6BC: 394729A0  addi r10, r7, 0x29a0
	ctx.r[10].s64 = ctx.r[7].s64 + 10656;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EDC48(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831EDC48 size=2124
    let mut pc: u32 = 0x831EDC48;
    'dispatch: loop {
        match pc {
            0x831EDC48 => {
    //   block [0x831EDC48..0x831EE494)
	// 831EDC48: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EDC4C: 4BFBA4E5  bl 0x831a8130
	ctx.lr = 0x831EDC50;
	sub_831A8130(ctx, base);
	// 831EDC50: 9421FE60  stwu r1, -0x1a0(r1)
	ea = ctx.r[1].u32.wrapping_add(-416 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831EDC54: C0070024  lfs f0, 0x24(r7)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831EDC58: 90C101CC  stw r6, 0x1cc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(460 as u32), ctx.r[6].u32 ) };
	// 831EDC5C: D0010070  stfs f0, 0x70(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), tmp.u32 ) };
	// 831EDC60: 90E101D4  stw r7, 0x1d4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(468 as u32), ctx.r[7].u32 ) };
	// 831EDC64: 7C001A2C  dcbt 0, r3
	// 831EDC68: 3D608211  lis r11, -0x7def
	ctx.r[11].s64 = -2112815104;
	// 831EDC6C: C1A70028  lfs f13, 0x28(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831EDC70: 3D20821A  lis r9, -0x7de6
	ctx.r[9].s64 = -2112225280;
	// 831EDC74: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831EDC78: C1470030  lfs f10, 0x30(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(48 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831EDC7C: 7CCA07B4  extsw r10, r6
	ctx.r[10].s64 = ctx.r[6].s32 as i64;
	// 831EDC80: C167002C  lfs f11, 0x2c(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(44 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831EDC84: 38C929C0  addi r6, r9, 0x29c0
	ctx.r[6].s64 = ctx.r[9].s64 + 10688;
	// 831EDC88: F9410060  std r10, 0x60(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[10].u64 ) };
	// 831EDC8C: C80BEA20  lfd f0, -0x15e0(r11)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(-5600 as u32) ) };
	// 831EDC90: 3D00821A  lis r8, -0x7de6
	ctx.r[8].s64 = -2112225280;
	// 831EDC94: FD0A0032  fmul f8, f10, f0
	ctx.f[8].f64 = ctx.f[10].f64 * ctx.f[0].f64;
	// 831EDC98: 3AC00004  li r22, 4
	ctx.r[22].s64 = 4;
	// 831EDC9C: FD2B0032  fmul f9, f11, f0
	ctx.f[9].f64 = ctx.f[11].f64 * ctx.f[0].f64;
	// 831EDCA0: 388829B0  addi r4, r8, 0x29b0
	ctx.r[4].s64 = ctx.r[8].s64 + 10672;
	// 831EDCA4: 39010058  addi r8, r1, 0x58
	ctx.r[8].s64 = ctx.r[1].s64 + 88;
	// 831EDCA8: D1A70024  stfs f13, 0x24(r7)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831EDCAC: 3CE0821A  lis r7, -0x7de6
	ctx.r[7].s64 = -2112225280;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EE498(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831EE498 size=644
    let mut pc: u32 = 0x831EE498;
    'dispatch: loop {
        match pc {
            0x831EE498 => {
    //   block [0x831EE498..0x831EE71C)
	// 831EE498: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EE49C: 4BFB9CCD  bl 0x831a8168
	ctx.lr = 0x831EE4A0;
	sub_831A8130(ctx, base);
	// 831EE4A0: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831EE4A4: 7CFF3B78  mr r31, r7
	ctx.r[31].u64 = ctx.r[7].u64;
	// 831EE4A8: C01F0024  lfs f0, 0x24(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831EE4AC: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 831EE4B0: 7C001A2C  dcbt 0, r3
	// 831EE4B4: 3D608211  lis r11, -0x7def
	ctx.r[11].s64 = -2112815104;
	// 831EE4B8: C1BF0028  lfs f13, 0x28(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831EE4BC: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831EE4C0: C17F002C  lfs f11, 0x2c(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(44 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831EE4C4: 3D00821A  lis r8, -0x7de6
	ctx.r[8].s64 = -2112225280;
	// 831EE4C8: D1BF0024  stfs f13, 0x24(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831EE4CC: 3D20821A  lis r9, -0x7de6
	ctx.r[9].s64 = -2112225280;
	// 831EE4D0: C15F0030  lfs f10, 0x30(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(48 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831EE4D4: 38882990  addi r4, r8, 0x2990
	ctx.r[4].s64 = ctx.r[8].s64 + 10640;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EE720(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831EE720 size=744
    let mut pc: u32 = 0x831EE720;
    'dispatch: loop {
        match pc {
            0x831EE720 => {
    //   block [0x831EE720..0x831EEA08)
	// 831EE720: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EE724: 4BFB9A3D  bl 0x831a8160
	ctx.lr = 0x831EE728;
	sub_831A8130(ctx, base);
	// 831EE728: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831EE72C: 7CFE3B78  mr r30, r7
	ctx.r[30].u64 = ctx.r[7].u64;
	// 831EE730: C01E0024  lfs f0, 0x24(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831EE734: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 831EE738: 7C001A2C  dcbt 0, r3
	// 831EE73C: 3D608211  lis r11, -0x7def
	ctx.r[11].s64 = -2112815104;
	// 831EE740: C1BE0028  lfs f13, 0x28(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831EE744: 3D20821A  lis r9, -0x7de6
	ctx.r[9].s64 = -2112225280;
	// 831EE748: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831EE74C: C17E002C  lfs f11, 0x2c(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(44 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831EE750: 3D00821A  lis r8, -0x7de6
	ctx.r[8].s64 = -2112225280;
	// 831EE754: 38E929A0  addi r7, r9, 0x29a0
	ctx.r[7].s64 = ctx.r[9].s64 + 10656;
	// 831EE758: D1BE0024  stfs f13, 0x24(r30)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831EE75C: 38882990  addi r4, r8, 0x2990
	ctx.r[4].s64 = ctx.r[8].s64 + 10640;
	// 831EE760: C15E0030  lfs f10, 0x30(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(48 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831EE764: C80BEA20  lfd f0, -0x15e0(r11)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(-5600 as u32) ) };
	// 831EE768: 39000004  li r8, 4
	ctx.r[8].s64 = 4;
	// 831EE76C: FD2B0032  fmul f9, f11, f0
	ctx.f[9].f64 = ctx.f[11].f64 * ctx.f[0].f64;
	// 831EE770: 39610058  addi r11, r1, 0x58
	ctx.r[11].s64 = ctx.r[1].s64 + 88;
	// 831EE774: 7CCA07B4  extsw r10, r6
	ctx.r[10].s64 = ctx.r[6].s32 as i64;
	// 831EE778: F9410060  std r10, 0x60(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[10].u64 ) };
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EEA08(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831EEA08 size=956
    let mut pc: u32 = 0x831EEA08;
    'dispatch: loop {
        match pc {
            0x831EEA08 => {
    //   block [0x831EEA08..0x831EEDC4)
	// 831EEA08: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EEA0C: 4BFB9735  bl 0x831a8140
	ctx.lr = 0x831EEA10;
	sub_831A8130(ctx, base);
	// 831EEA10: 9421FF10  stwu r1, -0xf0(r1)
	ea = ctx.r[1].u32.wrapping_add(-240 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831EEA14: 7CF83B78  mr r24, r7
	ctx.r[24].u64 = ctx.r[7].u64;
	// 831EEA18: C0180024  lfs f0, 0x24(r24)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831EEA1C: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 831EEA20: 7C001A2C  dcbt 0, r3
	// 831EEA24: 3D608211  lis r11, -0x7def
	ctx.r[11].s64 = -2112815104;
	// 831EEA28: C1B80028  lfs f13, 0x28(r24)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831EEA2C: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831EEA30: C178002C  lfs f11, 0x2c(r24)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(44 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831EEA34: 7CC407B4  extsw r4, r6
	ctx.r[4].s64 = ctx.r[6].s32 as i64;
	// 831EEA38: F8810068  std r4, 0x68(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[4].u64 ) };
	// 831EEA3C: 38E00004  li r7, 4
	ctx.r[7].s64 = 4;
	// 831EEA40: C1580030  lfs f10, 0x30(r24)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(48 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831EEA44: 39210058  addi r9, r1, 0x58
	ctx.r[9].s64 = ctx.r[1].s64 + 88;
	// 831EEA48: D1B80024  stfs f13, 0x24(r24)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831EEA4C: C80BEA20  lfd f0, -0x15e0(r11)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(-5600 as u32) ) };
	// 831EEA50: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831EEA54: FD2B0032  fmul f9, f11, f0
	ctx.f[9].f64 = ctx.f[11].f64 * ctx.f[0].f64;
	// 831EEA58: 3FA08201  lis r29, -0x7dff
	ctx.r[29].s64 = -2113863680;
	// 831EEA5C: FD0A0032  fmul f8, f10, f0
	ctx.f[8].f64 = ctx.f[10].f64 * ctx.f[0].f64;
	// 831EEA60: 388B29A0  addi r4, r11, 0x29a0
	ctx.r[4].s64 = ctx.r[11].s64 + 10656;
	// 831EEA64: 3BC10058  addi r30, r1, 0x58
	ctx.r[30].s64 = ctx.r[1].s64 + 88;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EEDC8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831EEDC8 size=1212
    let mut pc: u32 = 0x831EEDC8;
    'dispatch: loop {
        match pc {
            0x831EEDC8 => {
    //   block [0x831EEDC8..0x831EF284)
	// 831EEDC8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EEDCC: 4BFB9365  bl 0x831a8130
	ctx.lr = 0x831EEDD0;
	sub_831A8130(ctx, base);
	// 831EEDD0: 9421FEF0  stwu r1, -0x110(r1)
	ea = ctx.r[1].u32.wrapping_add(-272 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831EEDD4: C0070024  lfs f0, 0x24(r7)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831EEDD8: 90C1013C  stw r6, 0x13c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(316 as u32), ctx.r[6].u32 ) };
	// 831EEDDC: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 831EEDE0: 90E10144  stw r7, 0x144(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(324 as u32), ctx.r[7].u32 ) };
	// 831EEDE4: 7C001A2C  dcbt 0, r3
	// 831EEDE8: 3D608211  lis r11, -0x7def
	ctx.r[11].s64 = -2112815104;
	// 831EEDEC: C1A70028  lfs f13, 0x28(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831EEDF0: 3AC00004  li r22, 4
	ctx.r[22].s64 = 4;
	// 831EEDF4: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831EEDF8: C167002C  lfs f11, 0x2c(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(44 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831EEDFC: 39010058  addi r8, r1, 0x58
	ctx.r[8].s64 = ctx.r[1].s64 + 88;
	// 831EEE00: C1470030  lfs f10, 0x30(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(48 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831EEE04: 7CCA07B4  extsw r10, r6
	ctx.r[10].s64 = ctx.r[6].s32 as i64;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EF288(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831EF288 size=876
    let mut pc: u32 = 0x831EF288;
    'dispatch: loop {
        match pc {
            0x831EF288 => {
    //   block [0x831EF288..0x831EF5F4)
	// 831EF288: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EF28C: 4BFB8EB1  bl 0x831a813c
	ctx.lr = 0x831EF290;
	sub_831A8130(ctx, base);
	// 831EF290: 80A30008  lwz r5, 8(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EF294: 3B03000D  addi r24, r3, 0xd
	ctx.r[24].s64 = ctx.r[3].s64 + 13;
	// 831EF298: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831EF29C: 3A830008  addi r20, r3, 8
	ctx.r[20].s64 = ctx.r[3].s64 + 8;
	// 831EF2A0: 8083001C  lwz r4, 0x1c(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831EF2A4: 3A23001C  addi r17, r3, 0x1c
	ctx.r[17].s64 = ctx.r[3].s64 + 28;
	// 831EF2A8: 80C30018  lwz r6, 0x18(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831EF2AC: 7D2551D6  mullw r9, r5, r10
	ctx.r[9].s64 = (ctx.r[5].s32 as i64) * (ctx.r[10].s32 as i64);
	// 831EF2B0: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831EF2B4: 83C30004  lwz r30, 4(r3)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EF2B8: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831EF2BC: 7FE43050  subf r31, r4, r6
	ctx.r[31].s64 = ctx.r[6].s64 - ctx.r[4].s64;
	// 831EF2C0: 5529103A  slwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831EF2C4: 5487103A  slwi r7, r4, 2
	ctx.r[7].u32 = ctx.r[4].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831EF2C8: 93E1FF70  stw r31, -0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-144 as u32), ctx.r[31].u32 ) };
	// 831EF2CC: 3A430018  addi r18, r3, 0x18
	ctx.r[18].s64 = ctx.r[3].s64 + 24;
	// 831EF2D0: 3AE30004  addi r23, r3, 4
	ctx.r[23].s64 = ctx.r[3].s64 + 4;
	// 831EF2D4: 3A630014  addi r19, r3, 0x14
	ctx.r[19].s64 = ctx.r[3].s64 + 20;
	// 831EF2D8: 3B630034  addi r27, r3, 0x34
	ctx.r[27].s64 = ctx.r[3].s64 + 52;
	// 831EF2DC: 7CC95A14  add r6, r9, r11
	ctx.r[6].u64 = ctx.r[9].u64 + ctx.r[11].u64;
	// 831EF2E0: 7F25F050  subf r25, r5, r30
	ctx.r[25].s64 = ctx.r[30].s64 - ctx.r[5].s64;
	// 831EF2E4: 7C874214  add r4, r7, r8
	ctx.r[4].u64 = ctx.r[7].u64 + ctx.r[8].u64;
	// 831EF2E8: 7C00322C  dcbt 0, r6
	// 831EF2EC: 39000001  li r8, 1
	ctx.r[8].s64 = 1;
	// 831EF2F0: C0030030  lfs f0, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831EF2F4: 39200028  li r9, 0x28
	ctx.r[9].s64 = 40;
	// 831EF2F8: C1A3002C  lfs f13, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831EF2FC: 790507E6  rldicr r5, r8, 0x20, 0x3f
	ctx.r[5].u64 = (ctx.r[8].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 831EF300: 38E1FF70  addi r7, r1, -0x90
	ctx.r[7].s64 = ctx.r[1].s64 + -144;
	// 831EF304: F8A1FF78  std r5, -0x88(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-136 as u32), ctx.r[5].u64 ) };
	// 831EF308: C981FF78  lfd f12, -0x88(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-136 as u32) ) };
	// 831EF30C: FD60669C  fcfid f11, f12
	ctx.f[11].f64 = (ctx.f[12].s64 as f64);
	// 831EF310: 39600004  li r11, 4
	ctx.r[11].s64 = 4;
	// 831EF314: FD4002F2  fmul f10, f0, f11
	ctx.f[10].f64 = ctx.f[0].f64 * ctx.f[11].f64;
	// 831EF318: 13834C07  vcmpneb. (lvlx128) v28, v3, v9
	tmp.u32 = ctx.r[3].u32 + ctx.r[9].u32;
	// load shuffled into ctx.v[60] using VectorMaskL[(tmp.u32 & 0xF)]
	// 831EF31C: 3921FF70  addi r9, r1, -0x90
	ctx.r[9].s64 = ctx.r[1].s64 + -144;
	// 831EF320: 13E03C07  vcmpneb. (lvlx128) v31, v0, v7
	tmp.u32 = ctx.r[7].u32;
	// load shuffled into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EF5F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831EF5F8 size=736
    let mut pc: u32 = 0x831EF5F8;
    'dispatch: loop {
        match pc {
            0x831EF5F8 => {
    //   block [0x831EF5F8..0x831EF8D8)
	// 831EF5F8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EF5FC: 4BFB8B45  bl 0x831a8140
	ctx.lr = 0x831EF600;
	sub_831A8130(ctx, base);
	// 831EF600: 80A30008  lwz r5, 8(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EF604: 3AE30008  addi r23, r3, 8
	ctx.r[23].s64 = ctx.r[3].s64 + 8;
	// 831EF608: 8883000D  lbz r4, 0xd(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831EF60C: 3BA3000D  addi r29, r3, 0xd
	ctx.r[29].s64 = ctx.r[3].s64 + 13;
	// 831EF610: 8123001C  lwz r9, 0x1c(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831EF614: 3A83001C  addi r20, r3, 0x1c
	ctx.r[20].s64 = ctx.r[3].s64 + 28;
	// 831EF618: 7CC429D6  mullw r6, r4, r5
	ctx.r[6].s64 = (ctx.r[4].s32 as i64) * (ctx.r[5].s32 as i64);
	// 831EF61C: 80E30018  lwz r7, 0x18(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831EF620: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831EF624: 80830004  lwz r4, 4(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EF628: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831EF62C: 54CA103A  slwi r10, r6, 2
	ctx.r[10].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831EF630: 5526103A  slwi r6, r9, 2
	ctx.r[6].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831EF634: 7CE93850  subf r7, r9, r7
	ctx.r[7].s64 = ctx.r[7].s64 - ctx.r[9].s64;
	// 831EF638: 3AA30018  addi r21, r3, 0x18
	ctx.r[21].s64 = ctx.r[3].s64 + 24;
	// 831EF63C: 3B830004  addi r28, r3, 4
	ctx.r[28].s64 = ctx.r[3].s64 + 4;
	// 831EF640: 90E1FF70  stw r7, -0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-144 as u32), ctx.r[7].u32 ) };
	// 831EF644: 3AC30014  addi r22, r3, 0x14
	ctx.r[22].s64 = ctx.r[3].s64 + 20;
	// 831EF648: 3BE30034  addi r31, r3, 0x34
	ctx.r[31].s64 = ctx.r[3].s64 + 52;
	// 831EF64C: 7D2A5A14  add r9, r10, r11
	ctx.r[9].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831EF650: 7F252050  subf r25, r5, r4
	ctx.r[25].s64 = ctx.r[4].s64 - ctx.r[5].s64;
	// 831EF654: 7D064214  add r8, r6, r8
	ctx.r[8].u64 = ctx.r[6].u64 + ctx.r[8].u64;
	// 831EF658: 7C004A2C  dcbt 0, r9
	// 831EF65C: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 831EF660: C0030030  lfs f0, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831EF664: 3941FF70  addi r10, r1, -0x90
	ctx.r[10].s64 = ctx.r[1].s64 + -144;
	// 831EF668: C1A3002C  lfs f13, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831EF66C: 796607E6  rldicr r6, r11, 0x20, 0x3f
	ctx.r[6].u64 = (ctx.r[11].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 831EF670: 3D608205  lis r11, -0x7dfb
	ctx.r[11].s64 = -2113601536;
	// 831EF674: F8C1FF78  std r6, -0x88(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-136 as u32), ctx.r[6].u64 ) };
	// 831EF678: C981FF78  lfd f12, -0x88(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-136 as u32) ) };
	// 831EF67C: FD60669C  fcfid f11, f12
	ctx.f[11].f64 = (ctx.f[12].s64 as f64);
	// 831EF680: 3BC1FF70  addi r30, r1, -0x90
	ctx.r[30].s64 = ctx.r[1].s64 + -144;
	// 831EF684: FD4002F2  fmul f10, f0, f11
	ctx.f[10].f64 = ctx.f[0].f64 * ctx.f[11].f64;
	// 831EF688: 13E05407  vcmpneb. (lvlx128) v31, v0, v10
	tmp.u32 = ctx.r[10].u32;
	// load shuffled into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 831EF68C: 39400004  li r10, 4
	ctx.r[10].s64 = 4;
	// 831EF690: C80BE3A0  lfd f0, -0x1c60(r11)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(-7264 as u32) ) };
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EF8D8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831EF8D8 size=808
    let mut pc: u32 = 0x831EF8D8;
    'dispatch: loop {
        match pc {
            0x831EF8D8 => {
    //   block [0x831EF8D8..0x831EFC00)
	// 831EF8D8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EF8DC: 4BFB8865  bl 0x831a8140
	ctx.lr = 0x831EF8E0;
	sub_831A8130(ctx, base);
	// 831EF8E0: 80A30008  lwz r5, 8(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831EF8E4: 3AA30008  addi r21, r3, 8
	ctx.r[21].s64 = ctx.r[3].s64 + 8;
	// 831EF8E8: 8883000D  lbz r4, 0xd(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831EF8EC: 3B63000D  addi r27, r3, 0xd
	ctx.r[27].s64 = ctx.r[3].s64 + 13;
	// 831EF8F0: 8103001C  lwz r8, 0x1c(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831EF8F4: 3A43001C  addi r18, r3, 0x1c
	ctx.r[18].s64 = ctx.r[3].s64 + 28;
	// 831EF8F8: 80C30018  lwz r6, 0x18(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831EF8FC: 7C8429D6  mullw r4, r4, r5
	ctx.r[4].s64 = (ctx.r[4].s32 as i64) * (ctx.r[5].s32 as i64);
	// 831EF900: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831EF904: 83E30004  lwz r31, 4(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EF908: 81230014  lwz r9, 0x14(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831EF90C: 5507103A  slwi r7, r8, 2
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831EF910: 7CC83050  subf r6, r8, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[8].s64;
	// 831EF914: 548A103A  slwi r10, r4, 2
	ctx.r[10].u32 = ctx.r[4].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831EF918: 3A630018  addi r19, r3, 0x18
	ctx.r[19].s64 = ctx.r[3].s64 + 24;
	// 831EF91C: 90C1FF70  stw r6, -0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-144 as u32), ctx.r[6].u32 ) };
	// 831EF920: 3B430004  addi r26, r3, 4
	ctx.r[26].s64 = ctx.r[3].s64 + 4;
	// 831EF924: 3A830014  addi r20, r3, 0x14
	ctx.r[20].s64 = ctx.r[3].s64 + 20;
	// 831EF928: 3BA30034  addi r29, r3, 0x34
	ctx.r[29].s64 = ctx.r[3].s64 + 52;
	// 831EF92C: 7D0A5A14  add r8, r10, r11
	ctx.r[8].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831EF930: 7EC5F850  subf r22, r5, r31
	ctx.r[22].s64 = ctx.r[31].s64 - ctx.r[5].s64;
	// 831EF934: 7D274A14  add r9, r7, r9
	ctx.r[9].u64 = ctx.r[7].u64 + ctx.r[9].u64;
	// 831EF938: 7C00422C  dcbt 0, r8
	// 831EF93C: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 831EF940: C0030030  lfs f0, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831EF944: 38A00028  li r5, 0x28
	ctx.r[5].s64 = 40;
	// 831EF948: C1A3002C  lfs f13, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831EF94C: 796707E6  rldicr r7, r11, 0x20, 0x3f
	ctx.r[7].u64 = (ctx.r[11].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 831EF950: 3941FF70  addi r10, r1, -0x90
	ctx.r[10].s64 = ctx.r[1].s64 + -144;
	// 831EF954: F8E1FF78  std r7, -0x88(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-136 as u32), ctx.r[7].u64 ) };
	// 831EF958: C981FF78  lfd f12, -0x88(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-136 as u32) ) };
	// 831EF95C: FD60669C  fcfid f11, f12
	ctx.f[11].f64 = (ctx.f[12].s64 as f64);
	// 831EF960: 38E00004  li r7, 4
	ctx.r[7].s64 = 4;
	// 831EF964: FD4002F2  fmul f10, f0, f11
	ctx.f[10].f64 = ctx.f[0].f64 * ctx.f[11].f64;
	// 831EF968: 13832C07  vcmpneb. (lvlx128) v28, v3, v5
	tmp.u32 = ctx.r[3].u32 + ctx.r[5].u32;
	// load shuffled into ctx.v[60] using VectorMaskL[(tmp.u32 & 0xF)]
	// 831EF96C: 38A1FF70  addi r5, r1, -0x90
	ctx.r[5].s64 = ctx.r[1].s64 + -144;
	// 831EF970: 13E05407  vcmpneb. (lvlx128) v31, v0, v10
	tmp.u32 = ctx.r[10].u32;
	// load shuffled into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EFC00(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831EFC00 size=1012
    let mut pc: u32 = 0x831EFC00;
    'dispatch: loop {
        match pc {
            0x831EFC00 => {
    //   block [0x831EFC00..0x831EFFF4)
	// 831EFC00: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EFC04: 4BFB8535  bl 0x831a8138
	ctx.lr = 0x831EFC08;
	sub_831A8130(ctx, base);
	// 831EFC08: 39430008  addi r10, r3, 8
	ctx.r[10].s64 = ctx.r[3].s64 + 8;
	// 831EFC0C: 88C3000D  lbz r6, 0xd(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831EFC10: 3923001C  addi r9, r3, 0x1c
	ctx.r[9].s64 = ctx.r[3].s64 + 28;
	// 831EFC14: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831EFC18: 9141FF64  stw r10, -0x9c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-156 as u32), ctx.r[10].u32 ) };
	// 831EFC1C: 39030018  addi r8, r3, 0x18
	ctx.r[8].s64 = ctx.r[3].s64 + 24;
	// 831EFC20: 9121FF50  stw r9, -0xb0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-176 as u32), ctx.r[9].u32 ) };
	// 831EFC24: 3AE3000D  addi r23, r3, 0xd
	ctx.r[23].s64 = ctx.r[3].s64 + 13;
	// 831EFC28: 9101FF68  stw r8, -0x98(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-152 as u32), ctx.r[8].u32 ) };
	// 831EFC2C: 3AC30004  addi r22, r3, 4
	ctx.r[22].s64 = ctx.r[3].s64 + 4;
	// 831EFC30: 80EA0000  lwz r7, 0(r10)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831EFC34: 39430014  addi r10, r3, 0x14
	ctx.r[10].s64 = ctx.r[3].s64 + 20;
	// 831EFC38: 80890000  lwz r4, 0(r9)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 831EFC3C: 3BE30034  addi r31, r3, 0x34
	ctx.r[31].s64 = ctx.r[3].s64 + 52;
	// 831EFC40: 7CA639D6  mullw r5, r6, r7
	ctx.r[5].s64 = (ctx.r[6].s32 as i64) * (ctx.r[7].s32 as i64);
	// 831EFC44: 80C80000  lwz r6, 0(r8)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 831EFC48: 9141FF60  stw r10, -0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-160 as u32), ctx.r[10].u32 ) };
	// 831EFC4C: 83C30004  lwz r30, 4(r3)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831EFC50: 812A0000  lwz r9, 0(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831EFC54: 54AA103A  slwi r10, r5, 2
	ctx.r[10].u32 = ctx.r[5].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831EFC58: 5488103A  slwi r8, r4, 2
	ctx.r[8].u32 = ctx.r[4].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831EFC5C: 7CA43050  subf r5, r4, r6
	ctx.r[5].s64 = ctx.r[6].s64 - ctx.r[4].s64;
	// 831EFC60: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831EFC64: 90A1FF58  stw r5, -0xa8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-168 as u32), ctx.r[5].u32 ) };
	// 831EFC68: 7E67F050  subf r19, r7, r30
	ctx.r[19].s64 = ctx.r[30].s64 - ctx.r[7].s64;
	// 831EFC6C: 7D484A14  add r10, r8, r9
	ctx.r[10].u64 = ctx.r[8].u64 + ctx.r[9].u64;
	// 831EFC70: 7C005A2C  dcbt 0, r11
	// 831EFC74: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 831EFC78: C0030030  lfs f0, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831EFC7C: 38E00028  li r7, 0x28
	ctx.r[7].s64 = 40;
	// 831EFC80: C1A3002C  lfs f13, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831EFC84: 788807E6  rldicr r8, r4, 0x20, 0x3f
	ctx.r[8].u64 = (ctx.r[4].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 831EFC88: 3921FF58  addi r9, r1, -0xa8
	ctx.r[9].s64 = ctx.r[1].s64 + -168;
	// 831EFC8C: F901FF70  std r8, -0x90(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-144 as u32), ctx.r[8].u64 ) };
	// 831EFC90: C981FF70  lfd f12, -0x90(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-144 as u32) ) };
	// 831EFC94: FD60669C  fcfid f11, f12
	ctx.f[11].f64 = (ctx.f[12].s64 as f64);
	// 831EFC98: 38C00004  li r6, 4
	ctx.r[6].s64 = 4;
	// 831EFC9C: FD4002F2  fmul f10, f0, f11
	ctx.f[10].f64 = ctx.f[0].f64 * ctx.f[11].f64;
	// 831EFCA0: 13833C07  vcmpneb. (lvlx128) v28, v3, v7
	tmp.u32 = ctx.r[3].u32 + ctx.r[7].u32;
	// load shuffled into ctx.v[60] using VectorMaskL[(tmp.u32 & 0xF)]
	// 831EFCA4: 38E1FF58  addi r7, r1, -0xa8
	ctx.r[7].s64 = ctx.r[1].s64 + -168;
	// 831EFCA8: 13E04C07  vcmpneb. (lvlx128) v31, v0, v9
	tmp.u32 = ctx.r[9].u32;
	// load shuffled into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831EFFF8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831EFFF8 size=1280
    let mut pc: u32 = 0x831EFFF8;
    'dispatch: loop {
        match pc {
            0x831EFFF8 => {
    //   block [0x831EFFF8..0x831F04F8)
	// 831EFFF8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831EFFFC: 4BFB8145  bl 0x831a8140
	ctx.lr = 0x831F0000;
	sub_831A8130(ctx, base);
	// 831F0000: 39230008  addi r9, r3, 8
	ctx.r[9].s64 = ctx.r[3].s64 + 8;
	// 831F0004: 8963000D  lbz r11, 0xd(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F0008: 3903001C  addi r8, r3, 0x1c
	ctx.r[8].s64 = ctx.r[3].s64 + 28;
	// 831F000C: 81430000  lwz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F0010: 38E30004  addi r7, r3, 4
	ctx.r[7].s64 = ctx.r[3].s64 + 4;
	// 831F0014: 9121FF6C  stw r9, -0x94(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-148 as u32), ctx.r[9].u32 ) };
	// 831F0018: 38C30018  addi r6, r3, 0x18
	ctx.r[6].s64 = ctx.r[3].s64 + 24;
	// 831F001C: 9101FF5C  stw r8, -0xa4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-164 as u32), ctx.r[8].u32 ) };
	// 831F0020: 90E1FF60  stw r7, -0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-160 as u32), ctx.r[7].u32 ) };
	// 831F0024: 80890000  lwz r4, 0(r9)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F0028: 39230014  addi r9, r3, 0x14
	ctx.r[9].s64 = ctx.r[3].s64 + 20;
	// 831F002C: 90C1FF70  stw r6, -0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-144 as u32), ctx.r[6].u32 ) };
	// 831F0030: 7CAB21D6  mullw r5, r11, r4
	ctx.r[5].s64 = (ctx.r[11].s32 as i64) * (ctx.r[4].s32 as i64);
	// 831F0034: 83E80000  lwz r31, 0(r8)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F0038: 80C60000  lwz r6, 0(r6)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F003C: 83C70000  lwz r30, 0(r7)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F0040: 9121FF68  stw r9, -0x98(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-152 as u32), ctx.r[9].u32 ) };
	// 831F0044: 81290000  lwz r9, 0(r9)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F0048: 3963000D  addi r11, r3, 0xd
	ctx.r[11].s64 = ctx.r[3].s64 + 13;
	// 831F004C: 54AB103A  slwi r11, r5, 2
	ctx.r[11].u32 = ctx.r[5].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831F0050: 7CE4F050  subf r7, r4, r30
	ctx.r[7].s64 = ctx.r[30].s64 - ctx.r[4].s64;
	// 831F0054: 57E8103A  slwi r8, r31, 2
	ctx.r[8].u32 = ctx.r[31].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831F0058: 7CBF3050  subf r5, r31, r6
	ctx.r[5].s64 = ctx.r[6].s64 - ctx.r[31].s64;
	// 831F005C: 90E1FF58  stw r7, -0xa8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-168 as u32), ctx.r[7].u32 ) };
	// 831F0060: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831F0064: 90A1FF50  stw r5, -0xb0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-176 as u32), ctx.r[5].u32 ) };
	// 831F0068: 38830034  addi r4, r3, 0x34
	ctx.r[4].s64 = ctx.r[3].s64 + 52;
	// 831F006C: 7D484A14  add r10, r8, r9
	ctx.r[10].u64 = ctx.r[8].u64 + ctx.r[9].u64;
	// 831F0070: 7C005A2C  dcbt 0, r11
	// 831F0074: 38C00001  li r6, 1
	ctx.r[6].s64 = 1;
	// 831F0078: C003002C  lfs f0, 0x2c(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F007C: 39230030  addi r9, r3, 0x30
	ctx.r[9].s64 = ctx.r[3].s64 + 48;
	// 831F0080: 78C807E6  rldicr r8, r6, 0x20, 0x3f
	ctx.r[8].u64 = (ctx.r[6].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 831F0084: 38C00028  li r6, 0x28
	ctx.r[6].s64 = 40;
	// 831F0088: 9121FF64  stw r9, -0x9c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-156 as u32), ctx.r[9].u32 ) };
	// 831F008C: F901FF78  std r8, -0x88(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-136 as u32), ctx.r[8].u64 ) };
	// 831F0090: C9A1FF78  lfd f13, -0x88(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-136 as u32) ) };
	// 831F0094: FD806E9C  fcfid f12, f13
	ctx.f[12].f64 = (ctx.f[13].s64 as f64);
	// 831F0098: 38E1FF50  addi r7, r1, -0xb0
	ctx.r[7].s64 = ctx.r[1].s64 + -176;
	// 831F009C: C1690000  lfs f11, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831F00A0: FD400332  fmul f10, f0, f12
	ctx.f[10].f64 = ctx.f[0].f64 * ctx.f[12].f64;
	// 831F00A4: FD2B0332  fmul f9, f11, f12
	ctx.f[9].f64 = ctx.f[11].f64 * ctx.f[12].f64;
	// 831F00A8: 13A33407  vcmpneb. (lvlx128) v29, v3, v6
	tmp.u32 = ctx.r[3].u32 + ctx.r[6].u32;
	// load shuffled into ctx.v[61] using VectorMaskL[(tmp.u32 & 0xF)]
	// 831F00AC: 38C00004  li r6, 4
	ctx.r[6].s64 = 4;
	// 831F00B0: 13E03C07  vcmpneb. (lvlx128) v31, v0, v7
	tmp.u32 = ctx.r[7].u32;
	// load shuffled into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 831F00B4: 3BE1FF78  addi r31, r1, -0x88
	ctx.r[31].s64 = ctx.r[1].s64 + -136;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F04F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F04F8 size=936
    let mut pc: u32 = 0x831F04F8;
    'dispatch: loop {
        match pc {
            0x831F04F8 => {
    //   block [0x831F04F8..0x831F08A0)
	// 831F04F8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831F04FC: 4BFB7C41  bl 0x831a813c
	ctx.lr = 0x831F0500;
	sub_831A8130(ctx, base);
	// 831F0500: 80A30008  lwz r5, 8(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F0504: 3B03000D  addi r24, r3, 0xd
	ctx.r[24].s64 = ctx.r[3].s64 + 13;
	// 831F0508: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F050C: 3A830008  addi r20, r3, 8
	ctx.r[20].s64 = ctx.r[3].s64 + 8;
	// 831F0510: 8083001C  lwz r4, 0x1c(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F0514: 3A23001C  addi r17, r3, 0x1c
	ctx.r[17].s64 = ctx.r[3].s64 + 28;
	// 831F0518: 80C30018  lwz r6, 0x18(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F051C: 7D2A29D6  mullw r9, r10, r5
	ctx.r[9].s64 = (ctx.r[10].s32 as i64) * (ctx.r[5].s32 as i64);
	// 831F0520: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F0524: 83C30004  lwz r30, 4(r3)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F0528: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F052C: 7FE43050  subf r31, r4, r6
	ctx.r[31].s64 = ctx.r[6].s64 - ctx.r[4].s64;
	// 831F0530: 5529083C  slwi r9, r9, 1
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(1);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831F0534: 5487103A  slwi r7, r4, 2
	ctx.r[7].u32 = ctx.r[4].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F0538: 93E1FF70  stw r31, -0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-144 as u32), ctx.r[31].u32 ) };
	// 831F053C: 3A430018  addi r18, r3, 0x18
	ctx.r[18].s64 = ctx.r[3].s64 + 24;
	// 831F0540: 3AE30004  addi r23, r3, 4
	ctx.r[23].s64 = ctx.r[3].s64 + 4;
	// 831F0544: 3A630014  addi r19, r3, 0x14
	ctx.r[19].s64 = ctx.r[3].s64 + 20;
	// 831F0548: 3B430034  addi r26, r3, 0x34
	ctx.r[26].s64 = ctx.r[3].s64 + 52;
	// 831F054C: 7CC95A14  add r6, r9, r11
	ctx.r[6].u64 = ctx.r[9].u64 + ctx.r[11].u64;
	// 831F0550: 7F25F050  subf r25, r5, r30
	ctx.r[25].s64 = ctx.r[30].s64 - ctx.r[5].s64;
	// 831F0554: 7C874214  add r4, r7, r8
	ctx.r[4].u64 = ctx.r[7].u64 + ctx.r[8].u64;
	// 831F0558: 7C00322C  dcbt 0, r6
	// 831F055C: 39000001  li r8, 1
	ctx.r[8].s64 = 1;
	// 831F0560: C0030030  lfs f0, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F0564: 39200028  li r9, 0x28
	ctx.r[9].s64 = 40;
	// 831F0568: C1A3002C  lfs f13, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F056C: 790507E6  rldicr r5, r8, 0x20, 0x3f
	ctx.r[5].u64 = (ctx.r[8].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 831F0570: 38E1FF70  addi r7, r1, -0x90
	ctx.r[7].s64 = ctx.r[1].s64 + -144;
	// 831F0574: F8A1FF78  std r5, -0x88(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-136 as u32), ctx.r[5].u64 ) };
	// 831F0578: C981FF78  lfd f12, -0x88(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-136 as u32) ) };
	// 831F057C: FD60669C  fcfid f11, f12
	ctx.f[11].f64 = (ctx.f[12].s64 as f64);
	// 831F0580: 39600004  li r11, 4
	ctx.r[11].s64 = 4;
	// 831F0584: FD4002F2  fmul f10, f0, f11
	ctx.f[10].f64 = ctx.f[0].f64 * ctx.f[11].f64;
	// 831F0588: 13834C07  vcmpneb. (lvlx128) v28, v3, v9
	tmp.u32 = ctx.r[3].u32 + ctx.r[9].u32;
	// load shuffled into ctx.v[60] using VectorMaskL[(tmp.u32 & 0xF)]
	// 831F058C: 3921FF70  addi r9, r1, -0x90
	ctx.r[9].s64 = ctx.r[1].s64 + -144;
	// 831F0590: 13E03C07  vcmpneb. (lvlx128) v31, v0, v7
	tmp.u32 = ctx.r[7].u32;
	// load shuffled into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F08A0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F08A0 size=792
    let mut pc: u32 = 0x831F08A0;
    'dispatch: loop {
        match pc {
            0x831F08A0 => {
    //   block [0x831F08A0..0x831F0BB8)
	// 831F08A0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831F08A4: 4BFB789D  bl 0x831a8140
	ctx.lr = 0x831F08A8;
	sub_831A8130(ctx, base);
	// 831F08A8: 80A30008  lwz r5, 8(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F08AC: 3AE30008  addi r23, r3, 8
	ctx.r[23].s64 = ctx.r[3].s64 + 8;
	// 831F08B0: 8883000D  lbz r4, 0xd(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F08B4: 3BA3000D  addi r29, r3, 0xd
	ctx.r[29].s64 = ctx.r[3].s64 + 13;
	// 831F08B8: 8123001C  lwz r9, 0x1c(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F08BC: 3A83001C  addi r20, r3, 0x1c
	ctx.r[20].s64 = ctx.r[3].s64 + 28;
	// 831F08C0: 7CC429D6  mullw r6, r4, r5
	ctx.r[6].s64 = (ctx.r[4].s32 as i64) * (ctx.r[5].s32 as i64);
	// 831F08C4: 80E30018  lwz r7, 0x18(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F08C8: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F08CC: 80830004  lwz r4, 4(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F08D0: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F08D4: 54CA083C  slwi r10, r6, 1
	ctx.r[10].u32 = ctx.r[6].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F08D8: 5526103A  slwi r6, r9, 2
	ctx.r[6].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831F08DC: 7CE93850  subf r7, r9, r7
	ctx.r[7].s64 = ctx.r[7].s64 - ctx.r[9].s64;
	// 831F08E0: 3AA30018  addi r21, r3, 0x18
	ctx.r[21].s64 = ctx.r[3].s64 + 24;
	// 831F08E4: 3B830004  addi r28, r3, 4
	ctx.r[28].s64 = ctx.r[3].s64 + 4;
	// 831F08E8: 90E1FF70  stw r7, -0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-144 as u32), ctx.r[7].u32 ) };
	// 831F08EC: 3AC30014  addi r22, r3, 0x14
	ctx.r[22].s64 = ctx.r[3].s64 + 20;
	// 831F08F0: 3BE30034  addi r31, r3, 0x34
	ctx.r[31].s64 = ctx.r[3].s64 + 52;
	// 831F08F4: 7D2A5A14  add r9, r10, r11
	ctx.r[9].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831F08F8: 7F252050  subf r25, r5, r4
	ctx.r[25].s64 = ctx.r[4].s64 - ctx.r[5].s64;
	// 831F08FC: 7D064214  add r8, r6, r8
	ctx.r[8].u64 = ctx.r[6].u64 + ctx.r[8].u64;
	// 831F0900: 7C004A2C  dcbt 0, r9
	// 831F0904: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 831F0908: C0030030  lfs f0, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F090C: 3941FF70  addi r10, r1, -0x90
	ctx.r[10].s64 = ctx.r[1].s64 + -144;
	// 831F0910: C1A3002C  lfs f13, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F0914: 796607E6  rldicr r6, r11, 0x20, 0x3f
	ctx.r[6].u64 = (ctx.r[11].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 831F0918: 3D608205  lis r11, -0x7dfb
	ctx.r[11].s64 = -2113601536;
	// 831F091C: F8C1FF78  std r6, -0x88(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-136 as u32), ctx.r[6].u64 ) };
	// 831F0920: C981FF78  lfd f12, -0x88(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-136 as u32) ) };
	// 831F0924: FD60669C  fcfid f11, f12
	ctx.f[11].f64 = (ctx.f[12].s64 as f64);
	// 831F0928: 3BC1FF70  addi r30, r1, -0x90
	ctx.r[30].s64 = ctx.r[1].s64 + -144;
	// 831F092C: FD4002F2  fmul f10, f0, f11
	ctx.f[10].f64 = ctx.f[0].f64 * ctx.f[11].f64;
	// 831F0930: 13E05407  vcmpneb. (lvlx128) v31, v0, v10
	tmp.u32 = ctx.r[10].u32;
	// load shuffled into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 831F0934: 39400004  li r10, 4
	ctx.r[10].s64 = 4;
	// 831F0938: C80BE3A0  lfd f0, -0x1c60(r11)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(-7264 as u32) ) };
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F0BB8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F0BB8 size=916
    let mut pc: u32 = 0x831F0BB8;
    'dispatch: loop {
        match pc {
            0x831F0BB8 => {
    //   block [0x831F0BB8..0x831F0F4C)
	// 831F0BB8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831F0BBC: 4BFB7585  bl 0x831a8140
	ctx.lr = 0x831F0BC0;
	sub_831A8130(ctx, base);
	// 831F0BC0: 80A30008  lwz r5, 8(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F0BC4: 3AA30008  addi r21, r3, 8
	ctx.r[21].s64 = ctx.r[3].s64 + 8;
	// 831F0BC8: 8883000D  lbz r4, 0xd(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F0BCC: 3B63000D  addi r27, r3, 0xd
	ctx.r[27].s64 = ctx.r[3].s64 + 13;
	// 831F0BD0: 8103001C  lwz r8, 0x1c(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F0BD4: 3A43001C  addi r18, r3, 0x1c
	ctx.r[18].s64 = ctx.r[3].s64 + 28;
	// 831F0BD8: 7CC429D6  mullw r6, r4, r5
	ctx.r[6].s64 = (ctx.r[4].s32 as i64) * (ctx.r[5].s32 as i64);
	// 831F0BDC: 80E30018  lwz r7, 0x18(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F0BE0: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F0BE4: 80830004  lwz r4, 4(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F0BE8: 81230014  lwz r9, 0x14(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F0BEC: 54CA083C  slwi r10, r6, 1
	ctx.r[10].u32 = ctx.r[6].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F0BF0: 5506103A  slwi r6, r8, 2
	ctx.r[6].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831F0BF4: 7CE83850  subf r7, r8, r7
	ctx.r[7].s64 = ctx.r[7].s64 - ctx.r[8].s64;
	// 831F0BF8: 3A630018  addi r19, r3, 0x18
	ctx.r[19].s64 = ctx.r[3].s64 + 24;
	// 831F0BFC: 3B430004  addi r26, r3, 4
	ctx.r[26].s64 = ctx.r[3].s64 + 4;
	// 831F0C00: 90E1FF70  stw r7, -0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-144 as u32), ctx.r[7].u32 ) };
	// 831F0C04: 3A830014  addi r20, r3, 0x14
	ctx.r[20].s64 = ctx.r[3].s64 + 20;
	// 831F0C08: 3BA30034  addi r29, r3, 0x34
	ctx.r[29].s64 = ctx.r[3].s64 + 52;
	// 831F0C0C: 7D0A5A14  add r8, r10, r11
	ctx.r[8].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831F0C10: 7EC52050  subf r22, r5, r4
	ctx.r[22].s64 = ctx.r[4].s64 - ctx.r[5].s64;
	// 831F0C14: 7D264A14  add r9, r6, r9
	ctx.r[9].u64 = ctx.r[6].u64 + ctx.r[9].u64;
	// 831F0C18: 7C00422C  dcbt 0, r8
	// 831F0C1C: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 831F0C20: C0030030  lfs f0, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F0C24: 3941FF70  addi r10, r1, -0x90
	ctx.r[10].s64 = ctx.r[1].s64 + -144;
	// 831F0C28: C1A3002C  lfs f13, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F0C2C: 796607E6  rldicr r6, r11, 0x20, 0x3f
	ctx.r[6].u64 = (ctx.r[11].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 831F0C30: 3B81FF70  addi r28, r1, -0x90
	ctx.r[28].s64 = ctx.r[1].s64 + -144;
	// 831F0C34: F8C1FF78  std r6, -0x88(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-136 as u32), ctx.r[6].u64 ) };
	// 831F0C38: C981FF78  lfd f12, -0x88(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-136 as u32) ) };
	// 831F0C3C: FD60669C  fcfid f11, f12
	ctx.f[11].f64 = (ctx.f[12].s64 as f64);
	// 831F0C40: 38A00028  li r5, 0x28
	ctx.r[5].s64 = 40;
	// 831F0C44: FD4002F2  fmul f10, f0, f11
	ctx.f[10].f64 = ctx.f[0].f64 * ctx.f[11].f64;
	// 831F0C48: 13E05407  vcmpneb. (lvlx128) v31, v0, v10
	tmp.u32 = ctx.r[10].u32;
	// load shuffled into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 831F0C4C: 39400004  li r10, 4
	ctx.r[10].s64 = 4;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F0F50(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F0F50 size=1220
    let mut pc: u32 = 0x831F0F50;
    'dispatch: loop {
        match pc {
            0x831F0F50 => {
    //   block [0x831F0F50..0x831F1414)
	// 831F0F50: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831F0F54: 4BFB71E9  bl 0x831a813c
	ctx.lr = 0x831F0F58;
	sub_831A8130(ctx, base);
	// 831F0F58: 39430008  addi r10, r3, 8
	ctx.r[10].s64 = ctx.r[3].s64 + 8;
	// 831F0F5C: 88C3000D  lbz r6, 0xd(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F0F60: 3923001C  addi r9, r3, 0x1c
	ctx.r[9].s64 = ctx.r[3].s64 + 28;
	// 831F0F64: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F0F68: 9141FF64  stw r10, -0x9c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-156 as u32), ctx.r[10].u32 ) };
	// 831F0F6C: 39030018  addi r8, r3, 0x18
	ctx.r[8].s64 = ctx.r[3].s64 + 24;
	// 831F0F70: 9121FF50  stw r9, -0xb0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-176 as u32), ctx.r[9].u32 ) };
	// 831F0F74: 3B03000D  addi r24, r3, 0xd
	ctx.r[24].s64 = ctx.r[3].s64 + 13;
	// 831F0F78: 9101FF68  stw r8, -0x98(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-152 as u32), ctx.r[8].u32 ) };
	// 831F0F7C: 3AE30004  addi r23, r3, 4
	ctx.r[23].s64 = ctx.r[3].s64 + 4;
	// 831F0F80: 80EA0000  lwz r7, 0(r10)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F0F84: 39430014  addi r10, r3, 0x14
	ctx.r[10].s64 = ctx.r[3].s64 + 20;
	// 831F0F88: 80890000  lwz r4, 0(r9)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F0F8C: 7CA639D6  mullw r5, r6, r7
	ctx.r[5].s64 = (ctx.r[6].s32 as i64) * (ctx.r[7].s32 as i64);
	// 831F0F90: 80C80000  lwz r6, 0(r8)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F0F94: 9141FF60  stw r10, -0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-160 as u32), ctx.r[10].u32 ) };
	// 831F0F98: 83E30004  lwz r31, 4(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F0F9C: 812A0000  lwz r9, 0(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F0FA0: 54AA083C  slwi r10, r5, 1
	ctx.r[10].u32 = ctx.r[5].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F0FA4: 5488103A  slwi r8, r4, 2
	ctx.r[8].u32 = ctx.r[4].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831F0FA8: 7CC43050  subf r6, r4, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[4].s64;
	// 831F0FAC: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831F0FB0: 90C1FF58  stw r6, -0xa8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-168 as u32), ctx.r[6].u32 ) };
	// 831F0FB4: 38A30034  addi r5, r3, 0x34
	ctx.r[5].s64 = ctx.r[3].s64 + 52;
	// 831F0FB8: 7E87F850  subf r20, r7, r31
	ctx.r[20].s64 = ctx.r[31].s64 - ctx.r[7].s64;
	// 831F0FBC: 7D484A14  add r10, r8, r9
	ctx.r[10].u64 = ctx.r[8].u64 + ctx.r[9].u64;
	// 831F0FC0: 7C005A2C  dcbt 0, r11
	// 831F0FC4: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 831F0FC8: C0030030  lfs f0, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F0FCC: 3921FF58  addi r9, r1, -0xa8
	ctx.r[9].s64 = ctx.r[1].s64 + -168;
	// 831F0FD0: C1A3002C  lfs f13, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F0FD4: 788807E6  rldicr r8, r4, 0x20, 0x3f
	ctx.r[8].u64 = (ctx.r[4].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 831F0FD8: 3B61FF58  addi r27, r1, -0xa8
	ctx.r[27].s64 = ctx.r[1].s64 + -168;
	// 831F0FDC: F901FF70  std r8, -0x90(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-144 as u32), ctx.r[8].u64 ) };
	// 831F0FE0: C981FF70  lfd f12, -0x90(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-144 as u32) ) };
	// 831F0FE4: FD60669C  fcfid f11, f12
	ctx.f[11].f64 = (ctx.f[12].s64 as f64);
	// 831F0FE8: 39000004  li r8, 4
	ctx.r[8].s64 = 4;
	// 831F0FEC: FD4002F2  fmul f10, f0, f11
	ctx.f[10].f64 = ctx.f[0].f64 * ctx.f[11].f64;
	// 831F0FF0: 13E04C07  vcmpneb. (lvlx128) v31, v0, v9
	tmp.u32 = ctx.r[9].u32;
	// load shuffled into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F1418(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F1418 size=1572
    let mut pc: u32 = 0x831F1418;
    'dispatch: loop {
        match pc {
            0x831F1418 => {
    //   block [0x831F1418..0x831F1A3C)
	// 831F1418: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831F141C: 4BFB6D1D  bl 0x831a8138
	ctx.lr = 0x831F1420;
	sub_831A8130(ctx, base);
	// 831F1420: 39230008  addi r9, r3, 8
	ctx.r[9].s64 = ctx.r[3].s64 + 8;
	// 831F1424: 8883000D  lbz r4, 0xd(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F1428: 3903001C  addi r8, r3, 0x1c
	ctx.r[8].s64 = ctx.r[3].s64 + 28;
	// 831F142C: 81430000  lwz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F1430: 38A30018  addi r5, r3, 0x18
	ctx.r[5].s64 = ctx.r[3].s64 + 24;
	// 831F1434: 9121FF5C  stw r9, -0xa4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-164 as u32), ctx.r[9].u32 ) };
	// 831F1438: 38E30004  addi r7, r3, 4
	ctx.r[7].s64 = ctx.r[3].s64 + 4;
	// 831F143C: 9101FF4C  stw r8, -0xb4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-180 as u32), ctx.r[8].u32 ) };
	// 831F1440: 90A1FF60  stw r5, -0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-160 as u32), ctx.r[5].u32 ) };
	// 831F1444: 3963000D  addi r11, r3, 0xd
	ctx.r[11].s64 = ctx.r[3].s64 + 13;
	// 831F1448: 80C90000  lwz r6, 0(r9)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F144C: 39230014  addi r9, r3, 0x14
	ctx.r[9].s64 = ctx.r[3].s64 + 20;
	// 831F1450: 83E80000  lwz r31, 0(r8)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F1454: 7C8431D6  mullw r4, r4, r6
	ctx.r[4].s64 = (ctx.r[4].s32 as i64) * (ctx.r[6].s32 as i64);
	// 831F1458: 80A50000  lwz r5, 0(r5)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F145C: 83C70000  lwz r30, 0(r7)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F1460: 9121FF58  stw r9, -0xa8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-168 as u32), ctx.r[9].u32 ) };
	// 831F1464: 81290000  lwz r9, 0(r9)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F1468: 90E1FF50  stw r7, -0xb0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-176 as u32), ctx.r[7].u32 ) };
	// 831F146C: 548B083C  slwi r11, r4, 1
	ctx.r[11].u32 = ctx.r[4].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831F1470: 7C86F050  subf r4, r6, r30
	ctx.r[4].s64 = ctx.r[30].s64 - ctx.r[6].s64;
	// 831F1474: 57E8103A  slwi r8, r31, 2
	ctx.r[8].u32 = ctx.r[31].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831F1478: 7CBF2850  subf r5, r31, r5
	ctx.r[5].s64 = ctx.r[5].s64 - ctx.r[31].s64;
	// 831F147C: 9081FF48  stw r4, -0xb8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-184 as u32), ctx.r[4].u32 ) };
	// 831F1480: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831F1484: 90A1FF40  stw r5, -0xc0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-192 as u32), ctx.r[5].u32 ) };
	// 831F1488: 38C30034  addi r6, r3, 0x34
	ctx.r[6].s64 = ctx.r[3].s64 + 52;
	// 831F148C: 7D484A14  add r10, r8, r9
	ctx.r[10].u64 = ctx.r[8].u64 + ctx.r[9].u64;
	// 831F1490: 7C005A2C  dcbt 0, r11
	// 831F1494: 39200001  li r9, 1
	ctx.r[9].s64 = 1;
	// 831F1498: C003002C  lfs f0, 0x2c(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F149C: 39030030  addi r8, r3, 0x30
	ctx.r[8].s64 = ctx.r[3].s64 + 48;
	// 831F14A0: 792707E6  rldicr r7, r9, 0x20, 0x3f
	ctx.r[7].u64 = (ctx.r[9].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 831F14A4: 39200028  li r9, 0x28
	ctx.r[9].s64 = 40;
	// 831F14A8: 9101FF54  stw r8, -0xac(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-172 as u32), ctx.r[8].u32 ) };
	// 831F14AC: F8E1FF68  std r7, -0x98(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-152 as u32), ctx.r[7].u64 ) };
	// 831F14B0: C9A1FF68  lfd f13, -0x98(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-152 as u32) ) };
	// 831F14B4: FD806E9C  fcfid f12, f13
	ctx.f[12].f64 = (ctx.f[13].s64 as f64);
	// 831F14B8: 3881FF40  addi r4, r1, -0xc0
	ctx.r[4].s64 = ctx.r[1].s64 + -192;
	// 831F14BC: C1680000  lfs f11, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831F14C0: 39030024  addi r8, r3, 0x24
	ctx.r[8].s64 = ctx.r[3].s64 + 36;
	// 831F14C4: FD4B0332  fmul f10, f11, f12
	ctx.f[10].f64 = ctx.f[11].f64 * ctx.f[12].f64;
	// 831F14C8: 13A34C07  vcmpneb. (lvlx128) v29, v3, v9
	tmp.u32 = ctx.r[3].u32 + ctx.r[9].u32;
	// load shuffled into ctx.v[61] using VectorMaskL[(tmp.u32 & 0xF)]
	// 831F14CC: 39200004  li r9, 4
	ctx.r[9].s64 = 4;
	// 831F14D0: 13E02407  vcmpneb. (lvlx128) v31, v0, v4
	tmp.u32 = ctx.r[4].u32;
	// load shuffled into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 831F14D4: 3BE1FF40  addi r31, r1, -0xc0
	ctx.r[31].s64 = ctx.r[1].s64 + -192;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F1A40(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F1A40 size=936
    let mut pc: u32 = 0x831F1A40;
    'dispatch: loop {
        match pc {
            0x831F1A40 => {
    //   block [0x831F1A40..0x831F1DE8)
	// 831F1A40: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831F1A44: 4BFB66FD  bl 0x831a8140
	ctx.lr = 0x831F1A48;
	sub_831A8130(ctx, base);
	// 831F1A48: 80830008  lwz r4, 8(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F1A4C: 3B43000D  addi r26, r3, 0xd
	ctx.r[26].s64 = ctx.r[3].s64 + 13;
	// 831F1A50: 80C3001C  lwz r6, 0x1c(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F1A54: 3AA30008  addi r21, r3, 8
	ctx.r[21].s64 = ctx.r[3].s64 + 8;
	// 831F1A58: 8963000D  lbz r11, 0xd(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F1A5C: 3A43001C  addi r18, r3, 0x1c
	ctx.r[18].s64 = ctx.r[3].s64 + 28;
	// 831F1A60: 80A30018  lwz r5, 0x18(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F1A64: 54C7103A  slwi r7, r6, 2
	ctx.r[7].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F1A68: 83E30004  lwz r31, 4(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F1A6C: 7D4459D6  mullw r10, r4, r11
	ctx.r[10].s64 = (ctx.r[4].s32 as i64) * (ctx.r[11].s32 as i64);
	// 831F1A70: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F1A74: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F1A78: 7CA62850  subf r5, r6, r5
	ctx.r[5].s64 = ctx.r[5].s64 - ctx.r[6].s64;
	// 831F1A7C: 7F64F850  subf r27, r4, r31
	ctx.r[27].s64 = ctx.r[31].s64 - ctx.r[4].s64;
	// 831F1A80: 3A630018  addi r19, r3, 0x18
	ctx.r[19].s64 = ctx.r[3].s64 + 24;
	// 831F1A84: 90A1FF70  stw r5, -0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-144 as u32), ctx.r[5].u32 ) };
	// 831F1A88: 3B230004  addi r25, r3, 4
	ctx.r[25].s64 = ctx.r[3].s64 + 4;
	// 831F1A8C: 3A830014  addi r20, r3, 0x14
	ctx.r[20].s64 = ctx.r[3].s64 + 20;
	// 831F1A90: 3AC30034  addi r22, r3, 0x34
	ctx.r[22].s64 = ctx.r[3].s64 + 52;
	// 831F1A94: 7CC95214  add r6, r9, r10
	ctx.r[6].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 831F1A98: 7C874214  add r4, r7, r8
	ctx.r[4].u64 = ctx.r[7].u64 + ctx.r[8].u64;
	// 831F1A9C: 7C00322C  dcbt 0, r6
	// 831F1AA0: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 831F1AA4: C0030030  lfs f0, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F1AA8: 38E00028  li r7, 0x28
	ctx.r[7].s64 = 40;
	// 831F1AAC: C1A3002C  lfs f13, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F1AB0: 794807E6  rldicr r8, r10, 0x20, 0x3f
	ctx.r[8].u64 = (ctx.r[10].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 831F1AB4: 3921FF70  addi r9, r1, -0x90
	ctx.r[9].s64 = ctx.r[1].s64 + -144;
	// 831F1AB8: F901FF78  std r8, -0x88(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-136 as u32), ctx.r[8].u64 ) };
	// 831F1ABC: C981FF78  lfd f12, -0x88(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-136 as u32) ) };
	// 831F1AC0: FD60669C  fcfid f11, f12
	ctx.f[11].f64 = (ctx.f[12].s64 as f64);
	// 831F1AC4: 39400004  li r10, 4
	ctx.r[10].s64 = 4;
	// 831F1AC8: FD4002F2  fmul f10, f0, f11
	ctx.f[10].f64 = ctx.f[0].f64 * ctx.f[11].f64;
	// 831F1ACC: 3BA1FF70  addi r29, r1, -0x90
	ctx.r[29].s64 = ctx.r[1].s64 + -144;
	// 831F1AD0: 13833C07  vcmpneb. (lvlx128) v28, v3, v7
	tmp.u32 = ctx.r[3].u32 + ctx.r[7].u32;
	// load shuffled into ctx.v[60] using VectorMaskL[(tmp.u32 & 0xF)]
	// 831F1AD4: FD2D02F2  fmul f9, f13, f11
	ctx.f[9].f64 = ctx.f[13].f64 * ctx.f[11].f64;
	// 831F1AD8: 13E04C07  vcmpneb. (lvlx128) v31, v0, v9
	tmp.u32 = ctx.r[9].u32;
	// load shuffled into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 831F1ADC: 3AE30024  addi r23, r3, 0x24
	ctx.r[23].s64 = ctx.r[3].s64 + 36;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F1DE8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F1DE8 size=824
    let mut pc: u32 = 0x831F1DE8;
    'dispatch: loop {
        match pc {
            0x831F1DE8 => {
    //   block [0x831F1DE8..0x831F2120)
	// 831F1DE8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831F1DEC: 4BFB6359  bl 0x831a8144
	ctx.lr = 0x831F1DF0;
	sub_831A8130(ctx, base);
	// 831F1DF0: 80A30008  lwz r5, 8(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F1DF4: 3AC30008  addi r22, r3, 8
	ctx.r[22].s64 = ctx.r[3].s64 + 8;
	// 831F1DF8: 8083001C  lwz r4, 0x1c(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F1DFC: 3B83000D  addi r28, r3, 0xd
	ctx.r[28].s64 = ctx.r[3].s64 + 13;
	// 831F1E00: 81230018  lwz r9, 0x18(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F1E04: 3A63001C  addi r19, r3, 0x1c
	ctx.r[19].s64 = ctx.r[3].s64 + 28;
	// 831F1E08: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F1E0C: 5486103A  slwi r6, r4, 2
	ctx.r[6].u32 = ctx.r[4].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831F1E10: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F1E14: 7CE44850  subf r7, r4, r9
	ctx.r[7].s64 = ctx.r[9].s64 - ctx.r[4].s64;
	// 831F1E18: 83E30004  lwz r31, 4(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F1E1C: 7D4A29D6  mullw r10, r10, r5
	ctx.r[10].s64 = (ctx.r[10].s32 as i64) * (ctx.r[5].s32 as i64);
	// 831F1E20: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F1E24: 90E1FF80  stw r7, -0x80(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-128 as u32), ctx.r[7].u32 ) };
	// 831F1E28: 3A830018  addi r20, r3, 0x18
	ctx.r[20].s64 = ctx.r[3].s64 + 24;
	// 831F1E2C: 3B630004  addi r27, r3, 4
	ctx.r[27].s64 = ctx.r[3].s64 + 4;
	// 831F1E30: 3AA30014  addi r21, r3, 0x14
	ctx.r[21].s64 = ctx.r[3].s64 + 20;
	// 831F1E34: 3BC30034  addi r30, r3, 0x34
	ctx.r[30].s64 = ctx.r[3].s64 + 52;
	// 831F1E38: 7D2A5A14  add r9, r10, r11
	ctx.r[9].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831F1E3C: 7F05F850  subf r24, r5, r31
	ctx.r[24].s64 = ctx.r[31].s64 - ctx.r[5].s64;
	// 831F1E40: 7D064214  add r8, r6, r8
	ctx.r[8].u64 = ctx.r[6].u64 + ctx.r[8].u64;
	// 831F1E44: 7C004A2C  dcbt 0, r9
	// 831F1E48: 38C00001  li r6, 1
	ctx.r[6].s64 = 1;
	// 831F1E4C: C0030030  lfs f0, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F1E50: 39600028  li r11, 0x28
	ctx.r[11].s64 = 40;
	// 831F1E54: C1A3002C  lfs f13, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F1E58: 78C407E6  rldicr r4, r6, 0x20, 0x3f
	ctx.r[4].u64 = (ctx.r[6].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 831F1E5C: 38A1FF80  addi r5, r1, -0x80
	ctx.r[5].s64 = ctx.r[1].s64 + -128;
	// 831F1E60: F881FF88  std r4, -0x78(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-120 as u32), ctx.r[4].u64 ) };
	// 831F1E64: C981FF88  lfd f12, -0x78(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-120 as u32) ) };
	// 831F1E68: FD60669C  fcfid f11, f12
	ctx.f[11].f64 = (ctx.f[12].s64 as f64);
	// 831F1E6C: 39400004  li r10, 4
	ctx.r[10].s64 = 4;
	// 831F1E70: FD4002F2  fmul f10, f0, f11
	ctx.f[10].f64 = ctx.f[0].f64 * ctx.f[11].f64;
	// 831F1E74: 3BA1FF80  addi r29, r1, -0x80
	ctx.r[29].s64 = ctx.r[1].s64 + -128;
	// 831F1E78: 13835C07  vcmpneb. (lvlx128) v28, v3, v11
	tmp.u32 = ctx.r[3].u32 + ctx.r[11].u32;
	// load shuffled into ctx.v[60] using VectorMaskL[(tmp.u32 & 0xF)]
	// 831F1E7C: FD2D02F2  fmul f9, f13, f11
	ctx.f[9].f64 = ctx.f[13].f64 * ctx.f[11].f64;
	// 831F1E80: 13E02C07  vcmpneb. (lvlx128) v31, v0, v5
	tmp.u32 = ctx.r[5].u32;
	// load shuffled into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 831F1E84: 3B230024  addi r25, r3, 0x24
	ctx.r[25].s64 = ctx.r[3].s64 + 36;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F2120(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F2120 size=980
    let mut pc: u32 = 0x831F2120;
    'dispatch: loop {
        match pc {
            0x831F2120 => {
    //   block [0x831F2120..0x831F24F4)
	// 831F2120: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831F2124: 4BFB601D  bl 0x831a8140
	ctx.lr = 0x831F2128;
	sub_831A8130(ctx, base);
	// 831F2128: 80A30008  lwz r5, 8(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F212C: 3AA30008  addi r21, r3, 8
	ctx.r[21].s64 = ctx.r[3].s64 + 8;
	// 831F2130: 8083001C  lwz r4, 0x1c(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F2134: 3B63000D  addi r27, r3, 0xd
	ctx.r[27].s64 = ctx.r[3].s64 + 13;
	// 831F2138: 81030018  lwz r8, 0x18(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F213C: 3A43001C  addi r18, r3, 0x1c
	ctx.r[18].s64 = ctx.r[3].s64 + 28;
	// 831F2140: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F2144: 5486103A  slwi r6, r4, 2
	ctx.r[6].u32 = ctx.r[4].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831F2148: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F214C: 7CE44050  subf r7, r4, r8
	ctx.r[7].s64 = ctx.r[8].s64 - ctx.r[4].s64;
	// 831F2150: 83E30004  lwz r31, 4(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F2154: 7D4A29D6  mullw r10, r10, r5
	ctx.r[10].s64 = (ctx.r[10].s32 as i64) * (ctx.r[5].s32 as i64);
	// 831F2158: 81230014  lwz r9, 0x14(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F215C: 90E1FF70  stw r7, -0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-144 as u32), ctx.r[7].u32 ) };
	// 831F2160: 3A630018  addi r19, r3, 0x18
	ctx.r[19].s64 = ctx.r[3].s64 + 24;
	// 831F2164: 3B430004  addi r26, r3, 4
	ctx.r[26].s64 = ctx.r[3].s64 + 4;
	// 831F2168: 3A830014  addi r20, r3, 0x14
	ctx.r[20].s64 = ctx.r[3].s64 + 20;
	// 831F216C: 3BA30034  addi r29, r3, 0x34
	ctx.r[29].s64 = ctx.r[3].s64 + 52;
	// 831F2170: 7D0A5A14  add r8, r10, r11
	ctx.r[8].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831F2174: 7EC5F850  subf r22, r5, r31
	ctx.r[22].s64 = ctx.r[31].s64 - ctx.r[5].s64;
	// 831F2178: 7D264A14  add r9, r6, r9
	ctx.r[9].u64 = ctx.r[6].u64 + ctx.r[9].u64;
	// 831F217C: 7C00422C  dcbt 0, r8
	// 831F2180: 38C00001  li r6, 1
	ctx.r[6].s64 = 1;
	// 831F2184: C0030030  lfs f0, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F2188: 39600028  li r11, 0x28
	ctx.r[11].s64 = 40;
	// 831F218C: C1A3002C  lfs f13, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F2190: 78C407E6  rldicr r4, r6, 0x20, 0x3f
	ctx.r[4].u64 = (ctx.r[6].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 831F2194: 38A1FF70  addi r5, r1, -0x90
	ctx.r[5].s64 = ctx.r[1].s64 + -144;
	// 831F2198: F881FF78  std r4, -0x88(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-136 as u32), ctx.r[4].u64 ) };
	// 831F219C: C981FF78  lfd f12, -0x88(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-136 as u32) ) };
	// 831F21A0: FD60669C  fcfid f11, f12
	ctx.f[11].f64 = (ctx.f[12].s64 as f64);
	// 831F21A4: 39400004  li r10, 4
	ctx.r[10].s64 = 4;
	// 831F21A8: FD4002F2  fmul f10, f0, f11
	ctx.f[10].f64 = ctx.f[0].f64 * ctx.f[11].f64;
	// 831F21AC: 3AE1FF70  addi r23, r1, -0x90
	ctx.r[23].s64 = ctx.r[1].s64 + -144;
	// 831F21B0: 13835C07  vcmpneb. (lvlx128) v28, v3, v11
	tmp.u32 = ctx.r[3].u32 + ctx.r[11].u32;
	// load shuffled into ctx.v[60] using VectorMaskL[(tmp.u32 & 0xF)]
	// 831F21B4: FD2D02F2  fmul f9, f13, f11
	ctx.f[9].f64 = ctx.f[13].f64 * ctx.f[11].f64;
	// 831F21B8: 13E02C07  vcmpneb. (lvlx128) v31, v0, v5
	tmp.u32 = ctx.r[5].u32;
	// load shuffled into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 831F21BC: 3B030024  addi r24, r3, 0x24
	ctx.r[24].s64 = ctx.r[3].s64 + 36;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F24F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F24F8 size=1312
    let mut pc: u32 = 0x831F24F8;
    'dispatch: loop {
        match pc {
            0x831F24F8 => {
    //   block [0x831F24F8..0x831F2A18)
	// 831F24F8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831F24FC: 4BFB5C49  bl 0x831a8144
	ctx.lr = 0x831F2500;
	sub_831A8130(ctx, base);
	// 831F2500: 39430008  addi r10, r3, 8
	ctx.r[10].s64 = ctx.r[3].s64 + 8;
	// 831F2504: 8883000D  lbz r4, 0xd(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F2508: 3923001C  addi r9, r3, 0x1c
	ctx.r[9].s64 = ctx.r[3].s64 + 28;
	// 831F250C: 83E30004  lwz r31, 4(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F2510: 38E30018  addi r7, r3, 0x18
	ctx.r[7].s64 = ctx.r[3].s64 + 24;
	// 831F2514: 9141FF7C  stw r10, -0x84(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-132 as u32), ctx.r[10].u32 ) };
	// 831F2518: 39030014  addi r8, r3, 0x14
	ctx.r[8].s64 = ctx.r[3].s64 + 20;
	// 831F251C: 9121FF60  stw r9, -0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-160 as u32), ctx.r[9].u32 ) };
	// 831F2520: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F2524: 3AC3000D  addi r22, r3, 0xd
	ctx.r[22].s64 = ctx.r[3].s64 + 13;
	// 831F2528: 80AA0000  lwz r5, 0(r10)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F252C: 3AA30004  addi r21, r3, 4
	ctx.r[21].s64 = ctx.r[3].s64 + 4;
	// 831F2530: 80C90000  lwz r6, 0(r9)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F2534: 7D4429D6  mullw r10, r4, r5
	ctx.r[10].s64 = (ctx.r[4].s32 as i64) * (ctx.r[5].s32 as i64);
	// 831F2538: 80870000  lwz r4, 0(r7)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F253C: 81280000  lwz r9, 0(r8)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F2540: 9101FF74  stw r8, -0x8c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-140 as u32), ctx.r[8].u32 ) };
	// 831F2544: 90E1FF78  stw r7, -0x88(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-136 as u32), ctx.r[7].u32 ) };
	// 831F2548: 54C8103A  slwi r8, r6, 2
	ctx.r[8].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831F254C: 7E65F850  subf r19, r5, r31
	ctx.r[19].s64 = ctx.r[31].s64 - ctx.r[5].s64;
	// 831F2550: 7CC62050  subf r6, r6, r4
	ctx.r[6].s64 = ctx.r[4].s64 - ctx.r[6].s64;
	// 831F2554: 7D4A5A14  add r10, r10, r11
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831F2558: 9261FF70  stw r19, -0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-144 as u32), ctx.r[19].u32 ) };
	// 831F255C: 90C1FF68  stw r6, -0x98(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-152 as u32), ctx.r[6].u32 ) };
	// 831F2560: 38A30034  addi r5, r3, 0x34
	ctx.r[5].s64 = ctx.r[3].s64 + 52;
	// 831F2564: 7D684A14  add r11, r8, r9
	ctx.r[11].u64 = ctx.r[8].u64 + ctx.r[9].u64;
	// 831F2568: 7C00522C  dcbt 0, r10
	// 831F256C: 39000001  li r8, 1
	ctx.r[8].s64 = 1;
	// 831F2570: C0030030  lfs f0, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F2574: 39230024  addi r9, r3, 0x24
	ctx.r[9].s64 = ctx.r[3].s64 + 36;
	// 831F2578: C1A3002C  lfs f13, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F257C: 790707E6  rldicr r7, r8, 0x20, 0x3f
	ctx.r[7].u64 = (ctx.r[8].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 831F2580: 39000028  li r8, 0x28
	ctx.r[8].s64 = 40;
	// 831F2584: F8E1FF80  std r7, -0x80(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-128 as u32), ctx.r[7].u64 ) };
	// 831F2588: C981FF80  lfd f12, -0x80(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-128 as u32) ) };
	// 831F258C: FD60669C  fcfid f11, f12
	ctx.f[11].f64 = (ctx.f[12].s64 as f64);
	// 831F2590: 3881FF68  addi r4, r1, -0x98
	ctx.r[4].s64 = ctx.r[1].s64 + -152;
	// 831F2594: FD4002F2  fmul f10, f0, f11
	ctx.f[10].f64 = ctx.f[0].f64 * ctx.f[11].f64;
	// 831F2598: 13834407  vcmpneb. (lvlx128) v28, v3, v8
	tmp.u32 = ctx.r[3].u32 + ctx.r[8].u32;
	// load shuffled into ctx.v[60] using VectorMaskL[(tmp.u32 & 0xF)]
	// 831F259C: 39000004  li r8, 4
	ctx.r[8].s64 = 4;
	// 831F25A0: 13E04C07  vcmpneb. (lvlx128) v31, v0, v9
	tmp.u32 = ctx.r[9].u32;
	// load shuffled into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 831F25A4: 3B81FF68  addi r28, r1, -0x98
	ctx.r[28].s64 = ctx.r[1].s64 + -152;
	// 831F25A8: 13C02407  vcmpneb. (lvlx128) v30, v0, v4
	tmp.u32 = ctx.r[4].u32;
	// load shuffled into ctx.v[62] using VectorMaskL[(tmp.u32 & 0xF)]
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F2A18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F2A18 size=1680
    let mut pc: u32 = 0x831F2A18;
    'dispatch: loop {
        match pc {
            0x831F2A18 => {
    //   block [0x831F2A18..0x831F30A8)
	// 831F2A18: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831F2A1C: 4BFB572D  bl 0x831a8148
	ctx.lr = 0x831F2A20;
	sub_831A8130(ctx, base);
	// 831F2A20: 39230008  addi r9, r3, 8
	ctx.r[9].s64 = ctx.r[3].s64 + 8;
	// 831F2A24: 81430000  lwz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F2A28: 3903001C  addi r8, r3, 0x1c
	ctx.r[8].s64 = ctx.r[3].s64 + 28;
	// 831F2A2C: 38E30004  addi r7, r3, 4
	ctx.r[7].s64 = ctx.r[3].s64 + 4;
	// 831F2A30: 9121FF80  stw r9, -0x80(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-128 as u32), ctx.r[9].u32 ) };
	// 831F2A34: 38830018  addi r4, r3, 0x18
	ctx.r[4].s64 = ctx.r[3].s64 + 24;
	// 831F2A38: 9101FF6C  stw r8, -0x94(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-148 as u32), ctx.r[8].u32 ) };
	// 831F2A3C: 38C30014  addi r6, r3, 0x14
	ctx.r[6].s64 = ctx.r[3].s64 + 20;
	// 831F2A40: 90E1FF70  stw r7, -0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-144 as u32), ctx.r[7].u32 ) };
	// 831F2A44: 80A90000  lwz r5, 0(r9)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F2A48: 3963000D  addi r11, r3, 0xd
	ctx.r[11].s64 = ctx.r[3].s64 + 13;
	// 831F2A4C: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F2A50: 9081FF7C  stw r4, -0x84(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-132 as u32), ctx.r[4].u32 ) };
	// 831F2A54: 83E80000  lwz r31, 0(r8)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F2A58: 7D6929D6  mullw r11, r9, r5
	ctx.r[11].s64 = (ctx.r[9].s32 as i64) * (ctx.r[5].s32 as i64);
	// 831F2A5C: 80840000  lwz r4, 0(r4)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F2A60: 83C70000  lwz r30, 0(r7)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F2A64: 81260000  lwz r9, 0(r6)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F2A68: 90C1FF78  stw r6, -0x88(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-136 as u32), ctx.r[6].u32 ) };
	// 831F2A6C: 7CE5F050  subf r7, r5, r30
	ctx.r[7].s64 = ctx.r[30].s64 - ctx.r[5].s64;
	// 831F2A70: 57E8103A  slwi r8, r31, 2
	ctx.r[8].u32 = ctx.r[31].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831F2A74: 7C9F2050  subf r4, r31, r4
	ctx.r[4].s64 = ctx.r[4].s64 - ctx.r[31].s64;
	// 831F2A78: 90E1FF68  stw r7, -0x98(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-152 as u32), ctx.r[7].u32 ) };
	// 831F2A7C: 7D4B5214  add r10, r11, r10
	ctx.r[10].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831F2A80: 9081FF60  stw r4, -0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-160 as u32), ctx.r[4].u32 ) };
	// 831F2A84: 38A30034  addi r5, r3, 0x34
	ctx.r[5].s64 = ctx.r[3].s64 + 52;
	// 831F2A88: 7D684A14  add r11, r8, r9
	ctx.r[11].u64 = ctx.r[8].u64 + ctx.r[9].u64;
	// 831F2A8C: 7C00522C  dcbt 0, r10
	// 831F2A90: 38C00001  li r6, 1
	ctx.r[6].s64 = 1;
	// 831F2A94: C003002C  lfs f0, 0x2c(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F2A98: 39230030  addi r9, r3, 0x30
	ctx.r[9].s64 = ctx.r[3].s64 + 48;
	// 831F2A9C: 78C807E6  rldicr r8, r6, 0x20, 0x3f
	ctx.r[8].u64 = (ctx.r[6].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 831F2AA0: 38C00028  li r6, 0x28
	ctx.r[6].s64 = 40;
	// 831F2AA4: 9121FF74  stw r9, -0x8c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-140 as u32), ctx.r[9].u32 ) };
	// 831F2AA8: F901FF88  std r8, -0x78(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-120 as u32), ctx.r[8].u64 ) };
	// 831F2AAC: C9A1FF88  lfd f13, -0x78(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-120 as u32) ) };
	// 831F2AB0: FD806E9C  fcfid f12, f13
	ctx.f[12].f64 = (ctx.f[13].s64 as f64);
	// 831F2AB4: 38E1FF60  addi r7, r1, -0xa0
	ctx.r[7].s64 = ctx.r[1].s64 + -160;
	// 831F2AB8: C1690000  lfs f11, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831F2ABC: FD400332  fmul f10, f0, f12
	ctx.f[10].f64 = ctx.f[0].f64 * ctx.f[12].f64;
	// 831F2AC0: FD2B0332  fmul f9, f11, f12
	ctx.f[9].f64 = ctx.f[11].f64 * ctx.f[12].f64;
	// 831F2AC4: 13A33407  vcmpneb. (lvlx128) v29, v3, v6
	tmp.u32 = ctx.r[3].u32 + ctx.r[6].u32;
	// load shuffled into ctx.v[61] using VectorMaskL[(tmp.u32 & 0xF)]
	// 831F2AC8: 38C00004  li r6, 4
	ctx.r[6].s64 = 4;
	// 831F2ACC: 13E03C07  vcmpneb. (lvlx128) v31, v0, v7
	tmp.u32 = ctx.r[7].u32;
	// load shuffled into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 831F2AD0: 3BE1FF88  addi r31, r1, -0x78
	ctx.r[31].s64 = ctx.r[1].s64 + -120;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F30A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F30A8 size=964
    let mut pc: u32 = 0x831F30A8;
    'dispatch: loop {
        match pc {
            0x831F30A8 => {
    //   block [0x831F30A8..0x831F346C)
	// 831F30A8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831F30AC: 4BFB508D  bl 0x831a8138
	ctx.lr = 0x831F30B0;
	sub_831A8130(ctx, base);
	// 831F30B0: 8963000D  lbz r11, 0xd(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F30B4: 3B03000D  addi r24, r3, 0xd
	ctx.r[24].s64 = ctx.r[3].s64 + 13;
	// 831F30B8: 80A30008  lwz r5, 8(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F30BC: 3A630008  addi r19, r3, 8
	ctx.r[19].s64 = ctx.r[3].s64 + 8;
	// 831F30C0: 7D675B78  mr r7, r11
	ctx.r[7].u64 = ctx.r[11].u64;
	// 831F30C4: 8083001C  lwz r4, 0x1c(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F30C8: 80C30018  lwz r6, 0x18(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F30CC: 7D6B29D6  mullw r11, r11, r5
	ctx.r[11].s64 = (ctx.r[11].s32 as i64) * (ctx.r[5].s32 as i64);
	// 831F30D0: 81430000  lwz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F30D4: 83C30004  lwz r30, 4(r3)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F30D8: 81230014  lwz r9, 0x14(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F30DC: 7FE43050  subf r31, r4, r6
	ctx.r[31].s64 = ctx.r[6].s64 - ctx.r[4].s64;
	// 831F30E0: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831F30E4: 5488103A  slwi r8, r4, 2
	ctx.r[8].u32 = ctx.r[4].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831F30E8: 93E1FF60  stw r31, -0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-160 as u32), ctx.r[31].u32 ) };
	// 831F30EC: 3A03001C  addi r16, r3, 0x1c
	ctx.r[16].s64 = ctx.r[3].s64 + 28;
	// 831F30F0: 3A230018  addi r17, r3, 0x18
	ctx.r[17].s64 = ctx.r[3].s64 + 24;
	// 831F30F4: 3AE30004  addi r23, r3, 4
	ctx.r[23].s64 = ctx.r[3].s64 + 4;
	// 831F30F8: 3A430014  addi r18, r3, 0x14
	ctx.r[18].s64 = ctx.r[3].s64 + 20;
	// 831F30FC: 3B230034  addi r25, r3, 0x34
	ctx.r[25].s64 = ctx.r[3].s64 + 52;
	// 831F3100: 7CCB5214  add r6, r11, r10
	ctx.r[6].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831F3104: 7EC5F050  subf r22, r5, r30
	ctx.r[22].s64 = ctx.r[30].s64 - ctx.r[5].s64;
	// 831F3108: 7C884A14  add r4, r8, r9
	ctx.r[4].u64 = ctx.r[8].u64 + ctx.r[9].u64;
	// 831F310C: 7C00322C  dcbt 0, r6
	// 831F3110: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 831F3114: C0030030  lfs f0, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F3118: 38A00028  li r5, 0x28
	ctx.r[5].s64 = 40;
	// 831F311C: C1A3002C  lfs f13, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F3120: 794807E6  rldicr r8, r10, 0x20, 0x3f
	ctx.r[8].u64 = (ctx.r[10].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 831F3124: 3921FF60  addi r9, r1, -0xa0
	ctx.r[9].s64 = ctx.r[1].s64 + -160;
	// 831F3128: F901FF68  std r8, -0x98(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-152 as u32), ctx.r[8].u64 ) };
	// 831F312C: C981FF68  lfd f12, -0x98(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-152 as u32) ) };
	// 831F3130: FD60669C  fcfid f11, f12
	ctx.f[11].f64 = (ctx.f[12].s64 as f64);
	// 831F3134: 39400004  li r10, 4
	ctx.r[10].s64 = 4;
	// 831F3138: FD4002F2  fmul f10, f0, f11
	ctx.f[10].f64 = ctx.f[0].f64 * ctx.f[11].f64;
	// 831F313C: 3B61FF60  addi r27, r1, -0xa0
	ctx.r[27].s64 = ctx.r[1].s64 + -160;
	// 831F3140: 13832C07  vcmpneb. (lvlx128) v28, v3, v5
	tmp.u32 = ctx.r[3].u32 + ctx.r[5].u32;
	// load shuffled into ctx.v[60] using VectorMaskL[(tmp.u32 & 0xF)]
	// 831F3144: FD2D02F2  fmul f9, f13, f11
	ctx.f[9].f64 = ctx.f[13].f64 * ctx.f[11].f64;
	// 831F3148: 13E04C07  vcmpneb. (lvlx128) v31, v0, v9
	tmp.u32 = ctx.r[9].u32;
	// load shuffled into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 831F314C: 3A830024  addi r20, r3, 0x24
	ctx.r[20].s64 = ctx.r[3].s64 + 36;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F3470(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F3470 size=816
    let mut pc: u32 = 0x831F3470;
    'dispatch: loop {
        match pc {
            0x831F3470 => {
    //   block [0x831F3470..0x831F37A0)
	// 831F3470: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831F3474: 4BFB4CC9  bl 0x831a813c
	ctx.lr = 0x831F3478;
	sub_831A8130(ctx, base);
	// 831F3478: 80A30008  lwz r5, 8(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F347C: 3AC30008  addi r22, r3, 8
	ctx.r[22].s64 = ctx.r[3].s64 + 8;
	// 831F3480: 8883000D  lbz r4, 0xd(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F3484: 3B83000D  addi r28, r3, 0xd
	ctx.r[28].s64 = ctx.r[3].s64 + 13;
	// 831F3488: 8123001C  lwz r9, 0x1c(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F348C: 3A63001C  addi r19, r3, 0x1c
	ctx.r[19].s64 = ctx.r[3].s64 + 28;
	// 831F3490: 7CC429D6  mullw r6, r4, r5
	ctx.r[6].s64 = (ctx.r[4].s32 as i64) * (ctx.r[5].s32 as i64);
	// 831F3494: 80E30018  lwz r7, 0x18(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F3498: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F349C: 80830004  lwz r4, 4(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F34A0: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F34A4: 54CA083C  slwi r10, r6, 1
	ctx.r[10].u32 = ctx.r[6].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F34A8: 5526103A  slwi r6, r9, 2
	ctx.r[6].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831F34AC: 7CE93850  subf r7, r9, r7
	ctx.r[7].s64 = ctx.r[7].s64 - ctx.r[9].s64;
	// 831F34B0: 3A830018  addi r20, r3, 0x18
	ctx.r[20].s64 = ctx.r[3].s64 + 24;
	// 831F34B4: 3B630004  addi r27, r3, 4
	ctx.r[27].s64 = ctx.r[3].s64 + 4;
	// 831F34B8: 90E1FF70  stw r7, -0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-144 as u32), ctx.r[7].u32 ) };
	// 831F34BC: 3AA30014  addi r21, r3, 0x14
	ctx.r[21].s64 = ctx.r[3].s64 + 20;
	// 831F34C0: 3BC30034  addi r30, r3, 0x34
	ctx.r[30].s64 = ctx.r[3].s64 + 52;
	// 831F34C4: 7D2A5A14  add r9, r10, r11
	ctx.r[9].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831F34C8: 7F052050  subf r24, r5, r4
	ctx.r[24].s64 = ctx.r[4].s64 - ctx.r[5].s64;
	// 831F34CC: 7D064214  add r8, r6, r8
	ctx.r[8].u64 = ctx.r[6].u64 + ctx.r[8].u64;
	// 831F34D0: 7C004A2C  dcbt 0, r9
	// 831F34D4: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 831F34D8: C0030030  lfs f0, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F34DC: 3941FF70  addi r10, r1, -0x90
	ctx.r[10].s64 = ctx.r[1].s64 + -144;
	// 831F34E0: C1A3002C  lfs f13, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F34E4: 796607E6  rldicr r6, r11, 0x20, 0x3f
	ctx.r[6].u64 = (ctx.r[11].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 831F34E8: 3AE1FF70  addi r23, r1, -0x90
	ctx.r[23].s64 = ctx.r[1].s64 + -144;
	// 831F34EC: F8C1FF78  std r6, -0x88(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-136 as u32), ctx.r[6].u64 ) };
	// 831F34F0: C981FF78  lfd f12, -0x88(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-136 as u32) ) };
	// 831F34F4: FD60669C  fcfid f11, f12
	ctx.f[11].f64 = (ctx.f[12].s64 as f64);
	// 831F34F8: 38C00004  li r6, 4
	ctx.r[6].s64 = 4;
	// 831F34FC: FD4002F2  fmul f10, f0, f11
	ctx.f[10].f64 = ctx.f[0].f64 * ctx.f[11].f64;
	// 831F3500: 13E05407  vcmpneb. (lvlx128) v31, v0, v10
	tmp.u32 = ctx.r[10].u32;
	// load shuffled into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F37A0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F37A0 size=956
    let mut pc: u32 = 0x831F37A0;
    'dispatch: loop {
        match pc {
            0x831F37A0 => {
    //   block [0x831F37A0..0x831F3B5C)
	// 831F37A0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831F37A4: 4BFB4999  bl 0x831a813c
	ctx.lr = 0x831F37A8;
	sub_831A8130(ctx, base);
	// 831F37A8: 80A30008  lwz r5, 8(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F37AC: 3A830008  addi r20, r3, 8
	ctx.r[20].s64 = ctx.r[3].s64 + 8;
	// 831F37B0: 8883000D  lbz r4, 0xd(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F37B4: 3B43000D  addi r26, r3, 0xd
	ctx.r[26].s64 = ctx.r[3].s64 + 13;
	// 831F37B8: 8103001C  lwz r8, 0x1c(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F37BC: 3A23001C  addi r17, r3, 0x1c
	ctx.r[17].s64 = ctx.r[3].s64 + 28;
	// 831F37C0: 7CE429D6  mullw r7, r4, r5
	ctx.r[7].s64 = (ctx.r[4].s32 as i64) * (ctx.r[5].s32 as i64);
	// 831F37C4: 80830018  lwz r4, 0x18(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F37C8: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F37CC: 83E30004  lwz r31, 4(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F37D0: 81230014  lwz r9, 0x14(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F37D4: 54EA083C  slwi r10, r7, 1
	ctx.r[10].u32 = ctx.r[7].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F37D8: 5506103A  slwi r6, r8, 2
	ctx.r[6].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831F37DC: 7CE82050  subf r7, r8, r4
	ctx.r[7].s64 = ctx.r[4].s64 - ctx.r[8].s64;
	// 831F37E0: 7D0A5A14  add r8, r10, r11
	ctx.r[8].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831F37E4: 3A430018  addi r18, r3, 0x18
	ctx.r[18].s64 = ctx.r[3].s64 + 24;
	// 831F37E8: 90E1FF70  stw r7, -0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-144 as u32), ctx.r[7].u32 ) };
	// 831F37EC: 3B230004  addi r25, r3, 4
	ctx.r[25].s64 = ctx.r[3].s64 + 4;
	// 831F37F0: 3A630014  addi r19, r3, 0x14
	ctx.r[19].s64 = ctx.r[3].s64 + 20;
	// 831F37F4: 3B830034  addi r28, r3, 0x34
	ctx.r[28].s64 = ctx.r[3].s64 + 52;
	// 831F37F8: 7EA5F850  subf r21, r5, r31
	ctx.r[21].s64 = ctx.r[31].s64 - ctx.r[5].s64;
	// 831F37FC: 7D464A14  add r10, r6, r9
	ctx.r[10].u64 = ctx.r[6].u64 + ctx.r[9].u64;
	// 831F3800: 7C00422C  dcbt 0, r8
	// 831F3804: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 831F3808: C0030030  lfs f0, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F380C: 3921FF70  addi r9, r1, -0x90
	ctx.r[9].s64 = ctx.r[1].s64 + -144;
	// 831F3810: C1A3002C  lfs f13, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F3814: 796607E6  rldicr r6, r11, 0x20, 0x3f
	ctx.r[6].u64 = (ctx.r[11].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 831F3818: 3D608205  lis r11, -0x7dfb
	ctx.r[11].s64 = -2113601536;
	// 831F381C: F8C1FF78  std r6, -0x88(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-136 as u32), ctx.r[6].u64 ) };
	// 831F3820: C981FF78  lfd f12, -0x88(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-136 as u32) ) };
	// 831F3824: FD60669C  fcfid f11, f12
	ctx.f[11].f64 = (ctx.f[12].s64 as f64);
	// 831F3828: 3BC1FF70  addi r30, r1, -0x90
	ctx.r[30].s64 = ctx.r[1].s64 + -144;
	// 831F382C: FD4002F2  fmul f10, f0, f11
	ctx.f[10].f64 = ctx.f[0].f64 * ctx.f[11].f64;
	// 831F3830: 13E04C07  vcmpneb. (lvlx128) v31, v0, v9
	tmp.u32 = ctx.r[9].u32;
	// load shuffled into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 831F3834: 39200004  li r9, 4
	ctx.r[9].s64 = 4;
	// 831F3838: C80BE3A0  lfd f0, -0x1c60(r11)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(-7264 as u32) ) };
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F3B60(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F3B60 size=1304
    let mut pc: u32 = 0x831F3B60;
    'dispatch: loop {
        match pc {
            0x831F3B60 => {
    //   block [0x831F3B60..0x831F4078)
	// 831F3B60: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831F3B64: 4BFB45D9  bl 0x831a813c
	ctx.lr = 0x831F3B68;
	sub_831A8130(ctx, base);
	// 831F3B68: 39430008  addi r10, r3, 8
	ctx.r[10].s64 = ctx.r[3].s64 + 8;
	// 831F3B6C: 88C3000D  lbz r6, 0xd(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F3B70: 3923001C  addi r9, r3, 0x1c
	ctx.r[9].s64 = ctx.r[3].s64 + 28;
	// 831F3B74: 80830004  lwz r4, 4(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F3B78: 9141FF64  stw r10, -0x9c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-156 as u32), ctx.r[10].u32 ) };
	// 831F3B7C: 39030018  addi r8, r3, 0x18
	ctx.r[8].s64 = ctx.r[3].s64 + 24;
	// 831F3B80: 9121FF54  stw r9, -0xac(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-172 as u32), ctx.r[9].u32 ) };
	// 831F3B84: 3AE3000D  addi r23, r3, 0xd
	ctx.r[23].s64 = ctx.r[3].s64 + 13;
	// 831F3B88: 9101FF68  stw r8, -0x98(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-152 as u32), ctx.r[8].u32 ) };
	// 831F3B8C: 3AC30004  addi r22, r3, 4
	ctx.r[22].s64 = ctx.r[3].s64 + 4;
	// 831F3B90: 80EA0000  lwz r7, 0(r10)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F3B94: 39430014  addi r10, r3, 0x14
	ctx.r[10].s64 = ctx.r[3].s64 + 20;
	// 831F3B98: 80A90000  lwz r5, 0(r9)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F3B9C: 7CC639D6  mullw r6, r6, r7
	ctx.r[6].s64 = (ctx.r[6].s32 as i64) * (ctx.r[7].s32 as i64);
	// 831F3BA0: 83E80000  lwz r31, 0(r8)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F3BA4: 9141FF60  stw r10, -0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-160 as u32), ctx.r[10].u32 ) };
	// 831F3BA8: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F3BAC: 812A0000  lwz r9, 0(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F3BB0: 54CA083C  slwi r10, r6, 1
	ctx.r[10].u32 = ctx.r[6].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F3BB4: 54A8103A  slwi r8, r5, 2
	ctx.r[8].u32 = ctx.r[5].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831F3BB8: 7C872050  subf r4, r7, r4
	ctx.r[4].s64 = ctx.r[4].s64 - ctx.r[7].s64;
	// 831F3BBC: 7CA5F850  subf r5, r5, r31
	ctx.r[5].s64 = ctx.r[31].s64 - ctx.r[5].s64;
	// 831F3BC0: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831F3BC4: 9081FF50  stw r4, -0xb0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-176 as u32), ctx.r[4].u32 ) };
	// 831F3BC8: 90A1FF58  stw r5, -0xa8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-168 as u32), ctx.r[5].u32 ) };
	// 831F3BCC: 38830034  addi r4, r3, 0x34
	ctx.r[4].s64 = ctx.r[3].s64 + 52;
	// 831F3BD0: 7D484A14  add r10, r8, r9
	ctx.r[10].u64 = ctx.r[8].u64 + ctx.r[9].u64;
	// 831F3BD4: 7C005A2C  dcbt 0, r11
	// 831F3BD8: 39200001  li r9, 1
	ctx.r[9].s64 = 1;
	// 831F3BDC: C0030030  lfs f0, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F3BE0: 3901FF58  addi r8, r1, -0xa8
	ctx.r[8].s64 = ctx.r[1].s64 + -168;
	// 831F3BE4: C1A3002C  lfs f13, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F3BE8: 792707E6  rldicr r7, r9, 0x20, 0x3f
	ctx.r[7].u64 = (ctx.r[9].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 831F3BEC: 3BA1FF58  addi r29, r1, -0xa8
	ctx.r[29].s64 = ctx.r[1].s64 + -168;
	// 831F3BF0: F8E1FF70  std r7, -0x90(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-144 as u32), ctx.r[7].u64 ) };
	// 831F3BF4: C981FF70  lfd f12, -0x90(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-144 as u32) ) };
	// 831F3BF8: FD60669C  fcfid f11, f12
	ctx.f[11].f64 = (ctx.f[12].s64 as f64);
	// 831F3BFC: 38E00004  li r7, 4
	ctx.r[7].s64 = 4;
	// 831F3C00: FD4002F2  fmul f10, f0, f11
	ctx.f[10].f64 = ctx.f[0].f64 * ctx.f[11].f64;
	// 831F3C04: 13E04407  vcmpneb. (lvlx128) v31, v0, v8
	tmp.u32 = ctx.r[8].u32;
	// load shuffled into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 831F3C08: 3D008205  lis r8, -0x7dfb
	ctx.r[8].s64 = -2113601536;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F4078(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F4078 size=1680
    let mut pc: u32 = 0x831F4078;
    'dispatch: loop {
        match pc {
            0x831F4078 => {
    //   block [0x831F4078..0x831F4708)
	// 831F4078: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831F407C: 4BFB40B9  bl 0x831a8134
	ctx.lr = 0x831F4080;
	sub_831A8130(ctx, base);
	// 831F4080: 39230008  addi r9, r3, 8
	ctx.r[9].s64 = ctx.r[3].s64 + 8;
	// 831F4084: 8883000D  lbz r4, 0xd(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F4088: 3903001C  addi r8, r3, 0x1c
	ctx.r[8].s64 = ctx.r[3].s64 + 28;
	// 831F408C: 81430000  lwz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F4090: 38E30004  addi r7, r3, 4
	ctx.r[7].s64 = ctx.r[3].s64 + 4;
	// 831F4094: 9121FF5C  stw r9, -0xa4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-164 as u32), ctx.r[9].u32 ) };
	// 831F4098: 38C30018  addi r6, r3, 0x18
	ctx.r[6].s64 = ctx.r[3].s64 + 24;
	// 831F409C: 9101FF4C  stw r8, -0xb4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-180 as u32), ctx.r[8].u32 ) };
	// 831F40A0: 3963000D  addi r11, r3, 0xd
	ctx.r[11].s64 = ctx.r[3].s64 + 13;
	// 831F40A4: 90E1FF50  stw r7, -0xb0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-176 as u32), ctx.r[7].u32 ) };
	// 831F40A8: 80A90000  lwz r5, 0(r9)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F40AC: 39230014  addi r9, r3, 0x14
	ctx.r[9].s64 = ctx.r[3].s64 + 20;
	// 831F40B0: 90C1FF60  stw r6, -0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-160 as u32), ctx.r[6].u32 ) };
	// 831F40B4: 7C8429D6  mullw r4, r4, r5
	ctx.r[4].s64 = (ctx.r[4].s32 as i64) * (ctx.r[5].s32 as i64);
	// 831F40B8: 83E80000  lwz r31, 0(r8)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F40BC: 80C60000  lwz r6, 0(r6)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F40C0: 83C70000  lwz r30, 0(r7)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F40C4: 9121FF58  stw r9, -0xa8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-168 as u32), ctx.r[9].u32 ) };
	// 831F40C8: 81290000  lwz r9, 0(r9)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F40CC: 548B083C  slwi r11, r4, 1
	ctx.r[11].u32 = ctx.r[4].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831F40D0: 7CE5F050  subf r7, r5, r30
	ctx.r[7].s64 = ctx.r[30].s64 - ctx.r[5].s64;
	// 831F40D4: 57E8103A  slwi r8, r31, 2
	ctx.r[8].u32 = ctx.r[31].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831F40D8: 7C9F3050  subf r4, r31, r6
	ctx.r[4].s64 = ctx.r[6].s64 - ctx.r[31].s64;
	// 831F40DC: 90E1FF48  stw r7, -0xb8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-184 as u32), ctx.r[7].u32 ) };
	// 831F40E0: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831F40E4: 9081FF40  stw r4, -0xc0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-192 as u32), ctx.r[4].u32 ) };
	// 831F40E8: 38A30034  addi r5, r3, 0x34
	ctx.r[5].s64 = ctx.r[3].s64 + 52;
	// 831F40EC: 7D484A14  add r10, r8, r9
	ctx.r[10].u64 = ctx.r[8].u64 + ctx.r[9].u64;
	// 831F40F0: 7C005A2C  dcbt 0, r11
	// 831F40F4: 38C00001  li r6, 1
	ctx.r[6].s64 = 1;
	// 831F40F8: C003002C  lfs f0, 0x2c(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F40FC: 39230030  addi r9, r3, 0x30
	ctx.r[9].s64 = ctx.r[3].s64 + 48;
	// 831F4100: 78C807E6  rldicr r8, r6, 0x20, 0x3f
	ctx.r[8].u64 = (ctx.r[6].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 831F4104: 38E1FF40  addi r7, r1, -0xc0
	ctx.r[7].s64 = ctx.r[1].s64 + -192;
	// 831F4108: 9121FF54  stw r9, -0xac(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-172 as u32), ctx.r[9].u32 ) };
	// 831F410C: F901FF68  std r8, -0x98(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-152 as u32), ctx.r[8].u64 ) };
	// 831F4110: C9A1FF68  lfd f13, -0x98(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-152 as u32) ) };
	// 831F4114: FD806E9C  fcfid f12, f13
	ctx.f[12].f64 = (ctx.f[13].s64 as f64);
	// 831F4118: 38C00028  li r6, 0x28
	ctx.r[6].s64 = 40;
	// 831F411C: C1690000  lfs f11, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831F4120: FD400332  fmul f10, f0, f12
	ctx.f[10].f64 = ctx.f[0].f64 * ctx.f[12].f64;
	// 831F4124: FD2B0332  fmul f9, f11, f12
	ctx.f[9].f64 = ctx.f[11].f64 * ctx.f[12].f64;
	// 831F4128: 13E03C07  vcmpneb. (lvlx128) v31, v0, v7
	tmp.u32 = ctx.r[7].u32;
	// load shuffled into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 831F412C: 3CE08205  lis r7, -0x7dfb
	ctx.r[7].s64 = -2113601536;
	// 831F4130: 13A33407  vcmpneb. (lvlx128) v29, v3, v6
	tmp.u32 = ctx.r[3].u32 + ctx.r[6].u32;
	// load shuffled into ctx.v[61] using VectorMaskL[(tmp.u32 & 0xF)]
	// 831F4134: 39000004  li r8, 4
	ctx.r[8].s64 = 4;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F4708(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F4708 size=280
    let mut pc: u32 = 0x831F4708;
    'dispatch: loop {
        match pc {
            0x831F4708 => {
    //   block [0x831F4708..0x831F4820)
	// 831F4708: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 831F470C: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F4710: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F4714: 88A3000D  lbz r5, 0xd(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F4718: 8083001C  lwz r4, 0x1c(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F471C: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F4720: 7D0559D6  mullw r8, r5, r11
	ctx.r[8].s64 = (ctx.r[5].s32 as i64) * (ctx.r[11].s32 as i64);
	// 831F4724: 83E30018  lwz r31, 0x18(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F4728: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F472C: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F4730: 7D4B5050  subf r10, r11, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 831F4734: 5486103A  slwi r6, r4, 2
	ctx.r[6].u32 = ctx.r[4].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831F4738: 5508103A  slwi r8, r8, 2
	ctx.r[8].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831F473C: 7D64F850  subf r11, r4, r31
	ctx.r[11].s64 = ctx.r[31].s64 - ctx.r[4].s64;
	// 831F4740: 7CE63A14  add r7, r6, r7
	ctx.r[7].u64 = ctx.r[6].u64 + ctx.r[7].u64;
	// 831F4744: 7D084A14  add r8, r8, r9
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[9].u64;
	// 831F4748: 7F0A5800  cmpw cr6, r10, r11
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[11].s32, &mut ctx.xer);
	// 831F474C: 7D465378  mr r6, r10
	ctx.r[6].u64 = ctx.r[10].u64;
	// 831F4750: 41980008  blt cr6, 0x831f4758
	if ctx.cr[6].lt {
	pc = 0x831F4758; continue 'dispatch;
	}
	// 831F4754: 7D665B78  mr r6, r11
	ctx.r[6].u64 = ctx.r[11].u64;
	// 831F4758: 7D6B07B4  extsw r11, r11
	ctx.r[11].s64 = ctx.r[11].s32 as i64;
	// 831F475C: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F4760: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F4764: 54A4103A  slwi r4, r5, 2
	ctx.r[4].u32 = ctx.r[5].u32.wrapping_shl(2);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 831F4768: F961FFF0  std r11, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[11].u64 ) };
	// 831F476C: C961FFF0  lfd f11, -0x10(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831F4770: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F4774: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F4778: EDAC4824  fdivs f13, f12, f9
	ctx.f[13].f64 = ((ctx.f[12].f64 / ctx.f[9].f64) as f32) as f64;
	// 831F477C: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 831F4780: 419A002C  beq cr6, 0x831f47ac
	if ctx.cr[6].eq {
	pc = 0x831F47AC; continue 'dispatch;
	}
	// 831F4784: 7CE93B78  mr r9, r7
	ctx.r[9].u64 = ctx.r[7].u64;
	// 831F4788: 7D0A4378  mr r10, r8
	ctx.r[10].u64 = ctx.r[8].u64;
	// 831F478C: 7CAB2B78  mr r11, r5
	ctx.r[11].u64 = ctx.r[5].u64;
	// 831F4790: C18A0000  lfs f12, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831F4794: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831F4798: ED6C0032  fmuls f11, f12, f0
	ctx.f[11].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F479C: D1690000  stfs f11, 0(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F47A0: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 831F47A4: 39290400  addi r9, r9, 0x400
	ctx.r[9].s64 = ctx.r[9].s64 + 1024;
	// 831F47A8: 4082FFE8  bne 0x831f4790
	if !ctx.cr[0].eq {
	pc = 0x831F4790; continue 'dispatch;
	}
	// 831F47AC: 34C6FFFF  addic. r6, r6, -1
	ctx.xer.ca = (ctx.r[6].u32 > (!(-1 as u32)));
	ctx.r[6].s64 = ctx.r[6].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[6].s32, 0, &mut ctx.xer);
	// 831F47B0: EC0D002A  fadds f0, f13, f0
	ctx.f[0].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F47B4: 7D044214  add r8, r4, r8
	ctx.r[8].u64 = ctx.r[4].u64 + ctx.r[8].u64;
	// 831F47B8: 38E70004  addi r7, r7, 4
	ctx.r[7].s64 = ctx.r[7].s64 + 4;
	// 831F47BC: 4082FFC0  bne 0x831f477c
	if !ctx.cr[0].eq {
	pc = 0x831F477C; continue 'dispatch;
	}
	// 831F47C0: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F47C4: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F47C8: 7D2B4050  subf r9, r11, r8
	ctx.r[9].s64 = ctx.r[8].s64 - ctx.r[11].s64;
	// 831F47CC: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F47D0: 5548103E  rotlwi r8, r10, 2
	ctx.r[8].u64 = ((ctx.r[10].u32).rotate_left(2)) as u64;
	// 831F47D4: 7D494396  divwu r10, r9, r8
	ctx.r[10].u32 = ctx.r[9].u32 / ctx.r[8].u32;
	// 831F47D8: 0CC80000  twi 6, r8, 0
	// 831F47DC: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F47E0: 41980008  blt cr6, 0x831f47e8
	if ctx.cr[6].lt {
	pc = 0x831F47E8; continue 'dispatch;
	}
	// 831F47E4: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 831F47E8: 81630014  lwz r11, 0x14(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F47EC: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F47F0: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831F47F4: 7D4B3850  subf r10, r11, r7
	ctx.r[10].s64 = ctx.r[7].s64 - ctx.r[11].s64;
	// 831F47F8: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F47FC: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F4800: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F4804: 40980010  bge cr6, 0x831f4814
	if !ctx.cr[6].lt {
	pc = 0x831F4814; continue 'dispatch;
	}
	// 831F4808: 9143001C  stw r10, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[10].u32 ) };
	// 831F480C: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F4810: 4E800020  blr
	return;
	// 831F4814: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F4818: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F481C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F4820(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F4820 size=284
    let mut pc: u32 = 0x831F4820;
    'dispatch: loop {
        match pc {
            0x831F4820 => {
    //   block [0x831F4820..0x831F493C)
	// 831F4820: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 831F4824: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F4828: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F482C: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F4830: 80C3001C  lwz r6, 0x1c(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F4834: 7C8A59D6  mullw r4, r10, r11
	ctx.r[4].s64 = (ctx.r[10].s32 as i64) * (ctx.r[11].s32 as i64);
	// 831F4838: 80A30004  lwz r5, 4(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F483C: 83E30018  lwz r31, 0x18(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F4840: 81430000  lwz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F4844: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F4848: 5489103A  slwi r9, r4, 2
	ctx.r[9].u32 = ctx.r[4].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831F484C: 54C7103A  slwi r7, r6, 2
	ctx.r[7].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F4850: 7D6B2850  subf r11, r11, r5
	ctx.r[11].s64 = ctx.r[5].s64 - ctx.r[11].s64;
	// 831F4854: 7CC6F850  subf r6, r6, r31
	ctx.r[6].s64 = ctx.r[31].s64 - ctx.r[6].s64;
	// 831F4858: 7D495214  add r10, r9, r10
	ctx.r[10].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 831F485C: 7CE74214  add r7, r7, r8
	ctx.r[7].u64 = ctx.r[7].u64 + ctx.r[8].u64;
	// 831F4860: 7F0B3000  cmpw cr6, r11, r6
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[6].s32, &mut ctx.xer);
	// 831F4864: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 831F4868: 41980008  blt cr6, 0x831f4870
	if ctx.cr[6].lt {
	pc = 0x831F4870; continue 'dispatch;
	}
	// 831F486C: 7CC93378  mr r9, r6
	ctx.r[9].u64 = ctx.r[6].u64;
	// 831F4870: 5528103A  slwi r8, r9, 2
	ctx.r[8].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831F4874: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831F4878: 3908007F  addi r8, r8, 0x7f
	ctx.r[8].s64 = ctx.r[8].s64 + 127;
	// 831F487C: 5508C9FE  srwi r8, r8, 7
	ctx.r[8].u32 = ctx.r[8].u32.wrapping_shr(7);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831F4880: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 831F4884: 419A0018  beq cr6, 0x831f489c
	if ctx.cr[6].eq {
	pc = 0x831F489C; continue 'dispatch;
	}
	// 831F4888: 55653830  slwi r5, r11, 7
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831F488C: 7C05522C  dcbt r5, r10
	// 831F4890: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831F4894: 7F0B4040  cmplw cr6, r11, r8
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831F4898: 4198FFF0  blt cr6, 0x831f4888
	if ctx.cr[6].lt {
	pc = 0x831F4888; continue 'dispatch;
	}
	// 831F489C: 7CCB07B4  extsw r11, r6
	ctx.r[11].s64 = ctx.r[6].s32 as i64;
	// 831F48A0: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F48A4: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F48A8: F961FFF0  std r11, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[11].u64 ) };
	// 831F48AC: C961FFF0  lfd f11, -0x10(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831F48B0: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F48B4: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F48B8: EDAC4824  fdivs f13, f12, f9
	ctx.f[13].f64 = ((ctx.f[12].f64 / ctx.f[9].f64) as f32) as f64;
	// 831F48BC: C18A0000  lfs f12, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831F48C0: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831F48C4: ED6C0032  fmuls f11, f12, f0
	ctx.f[11].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F48C8: D1670000  stfs f11, 0(r7)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F48CC: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 831F48D0: EC0D002A  fadds f0, f13, f0
	ctx.f[0].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F48D4: 38E70004  addi r7, r7, 4
	ctx.r[7].s64 = ctx.r[7].s64 + 4;
	// 831F48D8: 4082FFE4  bne 0x831f48bc
	if !ctx.cr[0].eq {
	pc = 0x831F48BC; continue 'dispatch;
	}
	// 831F48DC: 8963000D  lbz r11, 0xd(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F48E0: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F48E4: 5568103E  rotlwi r8, r11, 2
	ctx.r[8].u64 = ((ctx.r[11].u32).rotate_left(2)) as u64;
	// 831F48E8: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F48EC: 7CC95050  subf r6, r9, r10
	ctx.r[6].s64 = ctx.r[10].s64 - ctx.r[9].s64;
	// 831F48F0: 0CC80000  twi 6, r8, 0
	// 831F48F4: 7D464396  divwu r10, r6, r8
	ctx.r[10].u32 = ctx.r[6].u32 / ctx.r[8].u32;
	// 831F48F8: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F48FC: 41980008  blt cr6, 0x831f4904
	if ctx.cr[6].lt {
	pc = 0x831F4904; continue 'dispatch;
	}
	// 831F4900: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 831F4904: 81630014  lwz r11, 0x14(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F4908: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F490C: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831F4910: 7D4B3850  subf r10, r11, r7
	ctx.r[10].s64 = ctx.r[7].s64 - ctx.r[11].s64;
	// 831F4914: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F4918: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F491C: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F4920: 40980010  bge cr6, 0x831f4930
	if !ctx.cr[6].lt {
	pc = 0x831F4930; continue 'dispatch;
	}
	// 831F4924: 9143001C  stw r10, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[10].u32 ) };
	// 831F4928: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F492C: 4E800020  blr
	return;
	// 831F4930: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F4934: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F4938: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F4940(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F4940 size=296
    let mut pc: u32 = 0x831F4940;
    'dispatch: loop {
        match pc {
            0x831F4940 => {
    //   block [0x831F4940..0x831F4A68)
	// 831F4940: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 831F4944: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F4948: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F494C: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F4950: 80C3001C  lwz r6, 0x1c(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F4954: 7C8951D6  mullw r4, r9, r10
	ctx.r[4].s64 = (ctx.r[9].s32 as i64) * (ctx.r[10].s32 as i64);
	// 831F4958: 80A30004  lwz r5, 4(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F495C: 83E30018  lwz r31, 0x18(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F4960: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F4964: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F4968: 5489103A  slwi r9, r4, 2
	ctx.r[9].u32 = ctx.r[4].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831F496C: 54C7103A  slwi r7, r6, 2
	ctx.r[7].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F4970: 7D4A2850  subf r10, r10, r5
	ctx.r[10].s64 = ctx.r[5].s64 - ctx.r[10].s64;
	// 831F4974: 7CC6F850  subf r6, r6, r31
	ctx.r[6].s64 = ctx.r[31].s64 - ctx.r[6].s64;
	// 831F4978: 7D695A14  add r11, r9, r11
	ctx.r[11].u64 = ctx.r[9].u64 + ctx.r[11].u64;
	// 831F497C: 7D074214  add r8, r7, r8
	ctx.r[8].u64 = ctx.r[7].u64 + ctx.r[8].u64;
	// 831F4980: 7F0A3000  cmpw cr6, r10, r6
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[6].s32, &mut ctx.xer);
	// 831F4984: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 831F4988: 41980008  blt cr6, 0x831f4990
	if ctx.cr[6].lt {
	pc = 0x831F4990; continue 'dispatch;
	}
	// 831F498C: 7CC93378  mr r9, r6
	ctx.r[9].u64 = ctx.r[6].u64;
	// 831F4990: 55271838  slwi r7, r9, 3
	ctx.r[7].u32 = ctx.r[9].u32.wrapping_shl(3);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F4994: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831F4998: 38E7007F  addi r7, r7, 0x7f
	ctx.r[7].s64 = ctx.r[7].s64 + 127;
	// 831F499C: 54E7C9FE  srwi r7, r7, 7
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F49A0: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 831F49A4: 419A0018  beq cr6, 0x831f49bc
	if ctx.cr[6].eq {
	pc = 0x831F49BC; continue 'dispatch;
	}
	// 831F49A8: 55453830  slwi r5, r10, 7
	ctx.r[5].u32 = ctx.r[10].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831F49AC: 7C055A2C  dcbt r5, r11
	// 831F49B0: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 831F49B4: 7F0A3840  cmplw cr6, r10, r7
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831F49B8: 4198FFF0  blt cr6, 0x831f49a8
	if ctx.cr[6].lt {
	pc = 0x831F49A8; continue 'dispatch;
	}
	// 831F49BC: 7CCA07B4  extsw r10, r6
	ctx.r[10].s64 = ctx.r[6].s32 as i64;
	// 831F49C0: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F49C4: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F49C8: F941FFF0  std r10, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[10].u64 ) };
	// 831F49CC: C961FFF0  lfd f11, -0x10(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831F49D0: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F49D4: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F49D8: EDAC4824  fdivs f13, f12, f9
	ctx.f[13].f64 = ((ctx.f[12].f64 / ctx.f[9].f64) as f32) as f64;
	// 831F49DC: C18B0004  lfs f12, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831F49E0: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831F49E4: ED6C0032  fmuls f11, f12, f0
	ctx.f[11].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F49E8: D1680400  stfs f11, 0x400(r8)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 831F49EC: C14B0000  lfs f10, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831F49F0: ED2A0032  fmuls f9, f10, f0
	ctx.f[9].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F49F4: D1280000  stfs f9, 0(r8)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F49F8: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 831F49FC: EC0D002A  fadds f0, f13, f0
	ctx.f[0].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F4A00: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 831F4A04: 4082FFD8  bne 0x831f49dc
	if !ctx.cr[0].eq {
	pc = 0x831F49DC; continue 'dispatch;
	}
	// 831F4A08: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F4A0C: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F4A10: 5547103E  rotlwi r7, r10, 2
	ctx.r[7].u64 = ((ctx.r[10].u32).rotate_left(2)) as u64;
	// 831F4A14: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F4A18: 7CC95850  subf r6, r9, r11
	ctx.r[6].s64 = ctx.r[11].s64 - ctx.r[9].s64;
	// 831F4A1C: 0CC70000  twi 6, r7, 0
	// 831F4A20: 7D663B96  divwu r11, r6, r7
	ctx.r[11].u32 = ctx.r[6].u32 / ctx.r[7].u32;
	// 831F4A24: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831F4A28: 40980008  bge cr6, 0x831f4a30
	if !ctx.cr[6].lt {
	pc = 0x831F4A30; continue 'dispatch;
	}
	// 831F4A2C: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 831F4A30: 81630014  lwz r11, 0x14(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F4A34: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F4A38: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831F4A3C: 7D4B4050  subf r10, r11, r8
	ctx.r[10].s64 = ctx.r[8].s64 - ctx.r[11].s64;
	// 831F4A40: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F4A44: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F4A48: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F4A4C: 40980010  bge cr6, 0x831f4a5c
	if !ctx.cr[6].lt {
	pc = 0x831F4A5C; continue 'dispatch;
	}
	// 831F4A50: 9143001C  stw r10, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[10].u32 ) };
	// 831F4A54: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F4A58: 4E800020  blr
	return;
	// 831F4A5C: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F4A60: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F4A64: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F4A68(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F4A68 size=320
    let mut pc: u32 = 0x831F4A68;
    'dispatch: loop {
        match pc {
            0x831F4A68 => {
    //   block [0x831F4A68..0x831F4BA8)
	// 831F4A68: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 831F4A6C: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F4A70: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F4A74: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F4A78: 80C3001C  lwz r6, 0x1c(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F4A7C: 7CA951D6  mullw r5, r9, r10
	ctx.r[5].s64 = (ctx.r[9].s32 as i64) * (ctx.r[10].s32 as i64);
	// 831F4A80: 80830004  lwz r4, 4(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F4A84: 83E30018  lwz r31, 0x18(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F4A88: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F4A8C: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F4A90: 54A9103A  slwi r9, r5, 2
	ctx.r[9].u32 = ctx.r[5].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831F4A94: 54C7103A  slwi r7, r6, 2
	ctx.r[7].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F4A98: 7D4A2050  subf r10, r10, r4
	ctx.r[10].s64 = ctx.r[4].s64 - ctx.r[10].s64;
	// 831F4A9C: 7CC6F850  subf r6, r6, r31
	ctx.r[6].s64 = ctx.r[31].s64 - ctx.r[6].s64;
	// 831F4AA0: 7D695A14  add r11, r9, r11
	ctx.r[11].u64 = ctx.r[9].u64 + ctx.r[11].u64;
	// 831F4AA4: 7D274214  add r9, r7, r8
	ctx.r[9].u64 = ctx.r[7].u64 + ctx.r[8].u64;
	// 831F4AA8: 7F0A3000  cmpw cr6, r10, r6
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[6].s32, &mut ctx.xer);
	// 831F4AAC: 7D485378  mr r8, r10
	ctx.r[8].u64 = ctx.r[10].u64;
	// 831F4AB0: 41980008  blt cr6, 0x831f4ab8
	if ctx.cr[6].lt {
	pc = 0x831F4AB8; continue 'dispatch;
	}
	// 831F4AB4: 7CC83378  mr r8, r6
	ctx.r[8].u64 = ctx.r[6].u64;
	// 831F4AB8: 55072036  slwi r7, r8, 4
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(4);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F4ABC: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831F4AC0: 38E7007F  addi r7, r7, 0x7f
	ctx.r[7].s64 = ctx.r[7].s64 + 127;
	// 831F4AC4: 54E7C9FE  srwi r7, r7, 7
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F4AC8: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 831F4ACC: 419A0018  beq cr6, 0x831f4ae4
	if ctx.cr[6].eq {
	pc = 0x831F4AE4; continue 'dispatch;
	}
	// 831F4AD0: 55453830  slwi r5, r10, 7
	ctx.r[5].u32 = ctx.r[10].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831F4AD4: 7C055A2C  dcbt r5, r11
	// 831F4AD8: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 831F4ADC: 7F0A3840  cmplw cr6, r10, r7
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831F4AE0: 4198FFF0  blt cr6, 0x831f4ad0
	if ctx.cr[6].lt {
	pc = 0x831F4AD0; continue 'dispatch;
	}
	// 831F4AE4: 7CCA07B4  extsw r10, r6
	ctx.r[10].s64 = ctx.r[6].s32 as i64;
	// 831F4AE8: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F4AEC: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F4AF0: F941FFF0  std r10, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[10].u64 ) };
	// 831F4AF4: C961FFF0  lfd f11, -0x10(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831F4AF8: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F4AFC: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F4B00: EDAC4824  fdivs f13, f12, f9
	ctx.f[13].f64 = ((ctx.f[12].f64 / ctx.f[9].f64) as f32) as f64;
	// 831F4B04: C18B000C  lfs f12, 0xc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831F4B08: 3508FFFF  addic. r8, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 831F4B0C: ED6C0032  fmuls f11, f12, f0
	ctx.f[11].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F4B10: D1690C00  stfs f11, 0xc00(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(3072 as u32), tmp.u32 ) };
	// 831F4B14: C14B0008  lfs f10, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831F4B18: ED2A0032  fmuls f9, f10, f0
	ctx.f[9].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F4B1C: D1290800  stfs f9, 0x800(r9)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(2048 as u32), tmp.u32 ) };
	// 831F4B20: C10B0004  lfs f8, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831F4B24: ECE80032  fmuls f7, f8, f0
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F4B28: D0E90400  stfs f7, 0x400(r9)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 831F4B2C: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 831F4B30: ECA60032  fmuls f5, f6, f0
	ctx.f[5].f64 = (((ctx.f[6].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F4B34: D0A90000  stfs f5, 0(r9)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F4B38: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 831F4B3C: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 831F4B40: EC0D002A  fadds f0, f13, f0
	ctx.f[0].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F4B44: 4082FFC0  bne 0x831f4b04
	if !ctx.cr[0].eq {
	pc = 0x831F4B04; continue 'dispatch;
	}
	// 831F4B48: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F4B4C: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F4B50: 5547103E  rotlwi r7, r10, 2
	ctx.r[7].u64 = ((ctx.r[10].u32).rotate_left(2)) as u64;
	// 831F4B54: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F4B58: 7CC85850  subf r6, r8, r11
	ctx.r[6].s64 = ctx.r[11].s64 - ctx.r[8].s64;
	// 831F4B5C: 0CC70000  twi 6, r7, 0
	// 831F4B60: 7D663B96  divwu r11, r6, r7
	ctx.r[11].u32 = ctx.r[6].u32 / ctx.r[7].u32;
	// 831F4B64: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831F4B68: 40980008  bge cr6, 0x831f4b70
	if !ctx.cr[6].lt {
	pc = 0x831F4B70; continue 'dispatch;
	}
	// 831F4B6C: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 831F4B70: 81630014  lwz r11, 0x14(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F4B74: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F4B78: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831F4B7C: 7D4B4850  subf r10, r11, r9
	ctx.r[10].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 831F4B80: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F4B84: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F4B88: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F4B8C: 40980010  bge cr6, 0x831f4b9c
	if !ctx.cr[6].lt {
	pc = 0x831F4B9C; continue 'dispatch;
	}
	// 831F4B90: 9143001C  stw r10, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[10].u32 ) };
	// 831F4B94: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F4B98: 4E800020  blr
	return;
	// 831F4B9C: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F4BA0: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F4BA4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F4BA8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F4BA8 size=348
    let mut pc: u32 = 0x831F4BA8;
    'dispatch: loop {
        match pc {
            0x831F4BA8 => {
    //   block [0x831F4BA8..0x831F4D04)
	// 831F4BA8: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 831F4BAC: 81030008  lwz r8, 8(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F4BB0: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F4BB4: 88E3000D  lbz r7, 0xd(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F4BB8: 80C3001C  lwz r6, 0x1c(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F4BBC: 7CA741D6  mullw r5, r7, r8
	ctx.r[5].s64 = (ctx.r[7].s32 as i64) * (ctx.r[8].s32 as i64);
	// 831F4BC0: 80830004  lwz r4, 4(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F4BC4: 83E30018  lwz r31, 0x18(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F4BC8: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F4BCC: 81230014  lwz r9, 0x14(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F4BD0: 54AA103A  slwi r10, r5, 2
	ctx.r[10].u32 = ctx.r[5].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F4BD4: 54C7103A  slwi r7, r6, 2
	ctx.r[7].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F4BD8: 7D082050  subf r8, r8, r4
	ctx.r[8].s64 = ctx.r[4].s64 - ctx.r[8].s64;
	// 831F4BDC: 7CC6F850  subf r6, r6, r31
	ctx.r[6].s64 = ctx.r[31].s64 - ctx.r[6].s64;
	// 831F4BE0: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831F4BE4: 7D474A14  add r10, r7, r9
	ctx.r[10].u64 = ctx.r[7].u64 + ctx.r[9].u64;
	// 831F4BE8: 7F083000  cmpw cr6, r8, r6
	ctx.cr[6].compare_i32(ctx.r[8].s32, ctx.r[6].s32, &mut ctx.xer);
	// 831F4BEC: 41980008  blt cr6, 0x831f4bf4
	if ctx.cr[6].lt {
	pc = 0x831F4BF4; continue 'dispatch;
	}
	// 831F4BF0: 7CC83378  mr r8, r6
	ctx.r[8].u64 = ctx.r[6].u64;
	// 831F4BF4: 5507083C  slwi r7, r8, 1
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(1);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F4BF8: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 831F4BFC: 7CE83A14  add r7, r8, r7
	ctx.r[7].u64 = ctx.r[8].u64 + ctx.r[7].u64;
	// 831F4C00: 54E71838  slwi r7, r7, 3
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shl(3);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F4C04: 38A7007F  addi r5, r7, 0x7f
	ctx.r[5].s64 = ctx.r[7].s64 + 127;
	// 831F4C08: 54A7C9FE  srwi r7, r5, 7
	ctx.r[7].u32 = ctx.r[5].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F4C0C: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 831F4C10: 419A0018  beq cr6, 0x831f4c28
	if ctx.cr[6].eq {
	pc = 0x831F4C28; continue 'dispatch;
	}
	// 831F4C14: 55253830  slwi r5, r9, 7
	ctx.r[5].u32 = ctx.r[9].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831F4C18: 7C055A2C  dcbt r5, r11
	// 831F4C1C: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 831F4C20: 7F093840  cmplw cr6, r9, r7
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831F4C24: 4198FFF0  blt cr6, 0x831f4c14
	if ctx.cr[6].lt {
	pc = 0x831F4C14; continue 'dispatch;
	}
	// 831F4C28: 7CC907B4  extsw r9, r6
	ctx.r[9].s64 = ctx.r[6].s32 as i64;
	// 831F4C2C: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F4C30: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F4C34: F921FFF0  std r9, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[9].u64 ) };
	// 831F4C38: C961FFF0  lfd f11, -0x10(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831F4C3C: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F4C40: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F4C44: EDAC4824  fdivs f13, f12, f9
	ctx.f[13].f64 = ((ctx.f[12].f64 / ctx.f[9].f64) as f32) as f64;
	// 831F4C48: C18B0014  lfs f12, 0x14(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831F4C4C: 3508FFFF  addic. r8, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 831F4C50: ED6C0032  fmuls f11, f12, f0
	ctx.f[11].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F4C54: D16A1400  stfs f11, 0x1400(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(5120 as u32), tmp.u32 ) };
	// 831F4C58: C14B0010  lfs f10, 0x10(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831F4C5C: ED2A0032  fmuls f9, f10, f0
	ctx.f[9].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F4C60: D12A1000  stfs f9, 0x1000(r10)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4096 as u32), tmp.u32 ) };
	// 831F4C64: C10B000C  lfs f8, 0xc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831F4C68: ECE80032  fmuls f7, f8, f0
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F4C6C: D0EA0C00  stfs f7, 0xc00(r10)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(3072 as u32), tmp.u32 ) };
	// 831F4C70: C0CB0008  lfs f6, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 831F4C74: ECA60032  fmuls f5, f6, f0
	ctx.f[5].f64 = (((ctx.f[6].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F4C78: D0AA0800  stfs f5, 0x800(r10)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(2048 as u32), tmp.u32 ) };
	// 831F4C7C: C08B0004  lfs f4, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831F4C80: EC640032  fmuls f3, f4, f0
	ctx.f[3].f64 = (((ctx.f[4].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F4C84: D06A0400  stfs f3, 0x400(r10)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 831F4C88: C04B0000  lfs f2, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 831F4C8C: EC220032  fmuls f1, f2, f0
	ctx.f[1].f64 = (((ctx.f[2].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F4C90: D02A0000  stfs f1, 0(r10)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F4C94: 396B0018  addi r11, r11, 0x18
	ctx.r[11].s64 = ctx.r[11].s64 + 24;
	// 831F4C98: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 831F4C9C: EC0D002A  fadds f0, f13, f0
	ctx.f[0].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F4CA0: 4082FFA8  bne 0x831f4c48
	if !ctx.cr[0].eq {
	pc = 0x831F4C48; continue 'dispatch;
	}
	// 831F4CA4: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F4CA8: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F4CAC: 5527103E  rotlwi r7, r9, 2
	ctx.r[7].u64 = ((ctx.r[9].u32).rotate_left(2)) as u64;
	// 831F4CB0: 81230004  lwz r9, 4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F4CB4: 7CC85850  subf r6, r8, r11
	ctx.r[6].s64 = ctx.r[11].s64 - ctx.r[8].s64;
	// 831F4CB8: 0CC70000  twi 6, r7, 0
	// 831F4CBC: 7D663B96  divwu r11, r6, r7
	ctx.r[11].u32 = ctx.r[6].u32 / ctx.r[7].u32;
	// 831F4CC0: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831F4CC4: 40980008  bge cr6, 0x831f4ccc
	if !ctx.cr[6].lt {
	pc = 0x831F4CCC; continue 'dispatch;
	}
	// 831F4CC8: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 831F4CCC: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F4CD0: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F4CD4: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F4CD8: 7CE85050  subf r7, r8, r10
	ctx.r[7].s64 = ctx.r[10].s64 - ctx.r[8].s64;
	// 831F4CDC: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 831F4CE0: 54EAF0BE  srwi r10, r7, 2
	ctx.r[10].u32 = ctx.r[7].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F4CE4: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F4CE8: 40980010  bge cr6, 0x831f4cf8
	if !ctx.cr[6].lt {
	pc = 0x831F4CF8; continue 'dispatch;
	}
	// 831F4CEC: 9143001C  stw r10, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[10].u32 ) };
	// 831F4CF0: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F4CF4: 4E800020  blr
	return;
	// 831F4CF8: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F4CFC: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F4D00: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F4D08(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F4D08 size=312
    let mut pc: u32 = 0x831F4D08;
    'dispatch: loop {
        match pc {
            0x831F4D08 => {
    //   block [0x831F4D08..0x831F4E40)
	// 831F4D08: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 831F4D0C: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F4D10: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F4D14: 88A3000D  lbz r5, 0xd(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F4D18: 8083001C  lwz r4, 0x1c(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F4D1C: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F4D20: 7D0559D6  mullw r8, r5, r11
	ctx.r[8].s64 = (ctx.r[5].s32 as i64) * (ctx.r[11].s32 as i64);
	// 831F4D24: 83E30018  lwz r31, 0x18(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F4D28: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F4D2C: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F4D30: 7D4B5050  subf r10, r11, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 831F4D34: 5486103A  slwi r6, r4, 2
	ctx.r[6].u32 = ctx.r[4].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831F4D38: 5508083C  slwi r8, r8, 1
	ctx.r[8].u32 = ctx.r[8].u32.wrapping_shl(1);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831F4D3C: 7D64F850  subf r11, r4, r31
	ctx.r[11].s64 = ctx.r[31].s64 - ctx.r[4].s64;
	// 831F4D40: 7CE63A14  add r7, r6, r7
	ctx.r[7].u64 = ctx.r[6].u64 + ctx.r[7].u64;
	// 831F4D44: 7D084A14  add r8, r8, r9
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[9].u64;
	// 831F4D48: 7F0A5800  cmpw cr6, r10, r11
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[11].s32, &mut ctx.xer);
	// 831F4D4C: 7D465378  mr r6, r10
	ctx.r[6].u64 = ctx.r[10].u64;
	// 831F4D50: 41980008  blt cr6, 0x831f4d58
	if ctx.cr[6].lt {
	pc = 0x831F4D58; continue 'dispatch;
	}
	// 831F4D54: 7D665B78  mr r6, r11
	ctx.r[6].u64 = ctx.r[11].u64;
	// 831F4D58: 7D6B07B4  extsw r11, r11
	ctx.r[11].s64 = ctx.r[11].s32 as i64;
	// 831F4D5C: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F4D60: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F4D64: 54A4083C  slwi r4, r5, 1
	ctx.r[4].u32 = ctx.r[5].u32.wrapping_shl(1);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 831F4D68: F961FFF0  std r11, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[11].u64 ) };
	// 831F4D6C: C961FFF0  lfd f11, -0x10(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831F4D70: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F4D74: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 831F4D78: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F4D7C: C1AB7490  lfs f13, 0x7490(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(29840 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F4D80: ED8C4824  fdivs f12, f12, f9
	ctx.f[12].f64 = ((ctx.f[12].f64 / ctx.f[9].f64) as f32) as f64;
	// 831F4D84: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 831F4D88: 419A0044  beq cr6, 0x831f4dcc
	if ctx.cr[6].eq {
	pc = 0x831F4DCC; continue 'dispatch;
	}
	// 831F4D8C: 7CE93B78  mr r9, r7
	ctx.r[9].u64 = ctx.r[7].u64;
	// 831F4D90: 7D0A4378  mr r10, r8
	ctx.r[10].u64 = ctx.r[8].u64;
	// 831F4D94: 7CAB2B78  mr r11, r5
	ctx.r[11].u64 = ctx.r[5].u64;
	// 831F4D98: A3EA0000  lhz r31, 0(r10)
	ctx.r[31].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F4D9C: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831F4DA0: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 831F4DA4: 7FFF0734  extsh r31, r31
	ctx.r[31].s64 = ctx.r[31].s16 as i64;
	// 831F4DA8: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831F4DAC: C961FFF0  lfd f11, -0x10(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831F4DB0: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F4DB4: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F4DB8: ED090372  fmuls f8, f9, f13
	ctx.f[8].f64 = (((ctx.f[9].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F4DBC: ECE80032  fmuls f7, f8, f0
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F4DC0: D0E90000  stfs f7, 0(r9)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F4DC4: 39290400  addi r9, r9, 0x400
	ctx.r[9].s64 = ctx.r[9].s64 + 1024;
	// 831F4DC8: 4082FFD0  bne 0x831f4d98
	if !ctx.cr[0].eq {
	pc = 0x831F4D98; continue 'dispatch;
	}
	// 831F4DCC: 34C6FFFF  addic. r6, r6, -1
	ctx.xer.ca = (ctx.r[6].u32 > (!(-1 as u32)));
	ctx.r[6].s64 = ctx.r[6].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[6].s32, 0, &mut ctx.xer);
	// 831F4DD0: EC0C002A  fadds f0, f12, f0
	ctx.f[0].f64 = ((ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F4DD4: 7D044214  add r8, r4, r8
	ctx.r[8].u64 = ctx.r[4].u64 + ctx.r[8].u64;
	// 831F4DD8: 38E70004  addi r7, r7, 4
	ctx.r[7].s64 = ctx.r[7].s64 + 4;
	// 831F4DDC: 4082FFA8  bne 0x831f4d84
	if !ctx.cr[0].eq {
	pc = 0x831F4D84; continue 'dispatch;
	}
	// 831F4DE0: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F4DE4: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F4DE8: 7D2B4050  subf r9, r11, r8
	ctx.r[9].s64 = ctx.r[8].s64 - ctx.r[11].s64;
	// 831F4DEC: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F4DF0: 5548083E  rotlwi r8, r10, 1
	ctx.r[8].u64 = ((ctx.r[10].u32).rotate_left(1)) as u64;
	// 831F4DF4: 7D494396  divwu r10, r9, r8
	ctx.r[10].u32 = ctx.r[9].u32 / ctx.r[8].u32;
	// 831F4DF8: 0CC80000  twi 6, r8, 0
	// 831F4DFC: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F4E00: 41980008  blt cr6, 0x831f4e08
	if ctx.cr[6].lt {
	pc = 0x831F4E08; continue 'dispatch;
	}
	// 831F4E04: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 831F4E08: 81630014  lwz r11, 0x14(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F4E0C: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F4E10: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831F4E14: 7D4B3850  subf r10, r11, r7
	ctx.r[10].s64 = ctx.r[7].s64 - ctx.r[11].s64;
	// 831F4E18: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F4E1C: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F4E20: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F4E24: 40980010  bge cr6, 0x831f4e34
	if !ctx.cr[6].lt {
	pc = 0x831F4E34; continue 'dispatch;
	}
	// 831F4E28: 9143001C  stw r10, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[10].u32 ) };
	// 831F4E2C: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F4E30: 4E800020  blr
	return;
	// 831F4E34: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F4E38: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F4E3C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F4E40(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F4E40 size=316
    let mut pc: u32 = 0x831F4E40;
    'dispatch: loop {
        match pc {
            0x831F4E40 => {
    //   block [0x831F4E40..0x831F4F7C)
	// 831F4E40: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 831F4E44: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F4E48: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F4E4C: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F4E50: 80C3001C  lwz r6, 0x1c(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F4E54: 7C8A59D6  mullw r4, r10, r11
	ctx.r[4].s64 = (ctx.r[10].s32 as i64) * (ctx.r[11].s32 as i64);
	// 831F4E58: 80A30004  lwz r5, 4(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F4E5C: 83E30018  lwz r31, 0x18(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F4E60: 81430000  lwz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F4E64: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F4E68: 5489083C  slwi r9, r4, 1
	ctx.r[9].u32 = ctx.r[4].u32.wrapping_shl(1);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831F4E6C: 54C7103A  slwi r7, r6, 2
	ctx.r[7].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F4E70: 7D6B2850  subf r11, r11, r5
	ctx.r[11].s64 = ctx.r[5].s64 - ctx.r[11].s64;
	// 831F4E74: 7CC6F850  subf r6, r6, r31
	ctx.r[6].s64 = ctx.r[31].s64 - ctx.r[6].s64;
	// 831F4E78: 7D495214  add r10, r9, r10
	ctx.r[10].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 831F4E7C: 7CE74214  add r7, r7, r8
	ctx.r[7].u64 = ctx.r[7].u64 + ctx.r[8].u64;
	// 831F4E80: 7F0B3000  cmpw cr6, r11, r6
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[6].s32, &mut ctx.xer);
	// 831F4E84: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 831F4E88: 41980008  blt cr6, 0x831f4e90
	if ctx.cr[6].lt {
	pc = 0x831F4E90; continue 'dispatch;
	}
	// 831F4E8C: 7CC93378  mr r9, r6
	ctx.r[9].u64 = ctx.r[6].u64;
	// 831F4E90: 5528083C  slwi r8, r9, 1
	ctx.r[8].u32 = ctx.r[9].u32.wrapping_shl(1);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831F4E94: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831F4E98: 3908007F  addi r8, r8, 0x7f
	ctx.r[8].s64 = ctx.r[8].s64 + 127;
	// 831F4E9C: 5508C9FE  srwi r8, r8, 7
	ctx.r[8].u32 = ctx.r[8].u32.wrapping_shr(7);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831F4EA0: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 831F4EA4: 419A0018  beq cr6, 0x831f4ebc
	if ctx.cr[6].eq {
	pc = 0x831F4EBC; continue 'dispatch;
	}
	// 831F4EA8: 55653830  slwi r5, r11, 7
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831F4EAC: 7C05522C  dcbt r5, r10
	// 831F4EB0: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831F4EB4: 7F0B4040  cmplw cr6, r11, r8
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831F4EB8: 4198FFF0  blt cr6, 0x831f4ea8
	if ctx.cr[6].lt {
	pc = 0x831F4EA8; continue 'dispatch;
	}
	// 831F4EBC: 7CCB07B4  extsw r11, r6
	ctx.r[11].s64 = ctx.r[6].s32 as i64;
	// 831F4EC0: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F4EC4: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F4EC8: F961FFF0  std r11, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[11].u64 ) };
	// 831F4ECC: C961FFF0  lfd f11, -0x10(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831F4ED0: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F4ED4: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 831F4ED8: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F4EDC: C1AB7490  lfs f13, 0x7490(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(29840 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F4EE0: ED8C4824  fdivs f12, f12, f9
	ctx.f[12].f64 = ((ctx.f[12].f64 / ctx.f[9].f64) as f32) as f64;
	// 831F4EE4: A16A0000  lhz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F4EE8: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831F4EEC: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 831F4EF0: 7D660734  extsh r6, r11
	ctx.r[6].s64 = ctx.r[11].s16 as i64;
	// 831F4EF4: F8C1FFF0  std r6, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[6].u64 ) };
	// 831F4EF8: C961FFF0  lfd f11, -0x10(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831F4EFC: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F4F00: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F4F04: ED090372  fmuls f8, f9, f13
	ctx.f[8].f64 = (((ctx.f[9].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F4F08: ECE80032  fmuls f7, f8, f0
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F4F0C: D0E70000  stfs f7, 0(r7)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F4F10: 38E70004  addi r7, r7, 4
	ctx.r[7].s64 = ctx.r[7].s64 + 4;
	// 831F4F14: EC0C002A  fadds f0, f12, f0
	ctx.f[0].f64 = ((ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F4F18: 4082FFCC  bne 0x831f4ee4
	if !ctx.cr[0].eq {
	pc = 0x831F4EE4; continue 'dispatch;
	}
	// 831F4F1C: 8963000D  lbz r11, 0xd(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F4F20: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F4F24: 5568083E  rotlwi r8, r11, 1
	ctx.r[8].u64 = ((ctx.r[11].u32).rotate_left(1)) as u64;
	// 831F4F28: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F4F2C: 7CC95050  subf r6, r9, r10
	ctx.r[6].s64 = ctx.r[10].s64 - ctx.r[9].s64;
	// 831F4F30: 0CC80000  twi 6, r8, 0
	// 831F4F34: 7D464396  divwu r10, r6, r8
	ctx.r[10].u32 = ctx.r[6].u32 / ctx.r[8].u32;
	// 831F4F38: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F4F3C: 41980008  blt cr6, 0x831f4f44
	if ctx.cr[6].lt {
	pc = 0x831F4F44; continue 'dispatch;
	}
	// 831F4F40: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 831F4F44: 81630014  lwz r11, 0x14(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F4F48: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F4F4C: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831F4F50: 7D4B3850  subf r10, r11, r7
	ctx.r[10].s64 = ctx.r[7].s64 - ctx.r[11].s64;
	// 831F4F54: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F4F58: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F4F5C: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F4F60: 40980010  bge cr6, 0x831f4f70
	if !ctx.cr[6].lt {
	pc = 0x831F4F70; continue 'dispatch;
	}
	// 831F4F64: 9143001C  stw r10, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[10].u32 ) };
	// 831F4F68: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F4F6C: 4E800020  blr
	return;
	// 831F4F70: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F4F74: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F4F78: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F4F80(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F4F80 size=352
    let mut pc: u32 = 0x831F4F80;
    'dispatch: loop {
        match pc {
            0x831F4F80 => {
    //   block [0x831F4F80..0x831F50E0)
	// 831F4F80: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 831F4F84: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F4F88: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F4F8C: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F4F90: 80C3001C  lwz r6, 0x1c(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F4F94: 7C8951D6  mullw r4, r9, r10
	ctx.r[4].s64 = (ctx.r[9].s32 as i64) * (ctx.r[10].s32 as i64);
	// 831F4F98: 80A30004  lwz r5, 4(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F4F9C: 83E30018  lwz r31, 0x18(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F4FA0: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F4FA4: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F4FA8: 5489083C  slwi r9, r4, 1
	ctx.r[9].u32 = ctx.r[4].u32.wrapping_shl(1);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831F4FAC: 54C7103A  slwi r7, r6, 2
	ctx.r[7].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F4FB0: 7D4A2850  subf r10, r10, r5
	ctx.r[10].s64 = ctx.r[5].s64 - ctx.r[10].s64;
	// 831F4FB4: 7CC6F850  subf r6, r6, r31
	ctx.r[6].s64 = ctx.r[31].s64 - ctx.r[6].s64;
	// 831F4FB8: 7D695A14  add r11, r9, r11
	ctx.r[11].u64 = ctx.r[9].u64 + ctx.r[11].u64;
	// 831F4FBC: 7D074214  add r8, r7, r8
	ctx.r[8].u64 = ctx.r[7].u64 + ctx.r[8].u64;
	// 831F4FC0: 7F0A3000  cmpw cr6, r10, r6
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[6].s32, &mut ctx.xer);
	// 831F4FC4: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 831F4FC8: 41980008  blt cr6, 0x831f4fd0
	if ctx.cr[6].lt {
	pc = 0x831F4FD0; continue 'dispatch;
	}
	// 831F4FCC: 7CC93378  mr r9, r6
	ctx.r[9].u64 = ctx.r[6].u64;
	// 831F4FD0: 5527103A  slwi r7, r9, 2
	ctx.r[7].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F4FD4: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831F4FD8: 38E7007F  addi r7, r7, 0x7f
	ctx.r[7].s64 = ctx.r[7].s64 + 127;
	// 831F4FDC: 54E7C9FE  srwi r7, r7, 7
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F4FE0: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 831F4FE4: 419A0018  beq cr6, 0x831f4ffc
	if ctx.cr[6].eq {
	pc = 0x831F4FFC; continue 'dispatch;
	}
	// 831F4FE8: 55453830  slwi r5, r10, 7
	ctx.r[5].u32 = ctx.r[10].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831F4FEC: 7C055A2C  dcbt r5, r11
	// 831F4FF0: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 831F4FF4: 7F0A3840  cmplw cr6, r10, r7
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831F4FF8: 4198FFF0  blt cr6, 0x831f4fe8
	if ctx.cr[6].lt {
	pc = 0x831F4FE8; continue 'dispatch;
	}
	// 831F4FFC: 7CCA07B4  extsw r10, r6
	ctx.r[10].s64 = ctx.r[6].s32 as i64;
	// 831F5000: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F5004: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F5008: F941FFE0  std r10, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[10].u64 ) };
	// 831F500C: C961FFE0  lfd f11, -0x20(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 831F5010: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F5014: 3D40820C  lis r10, -0x7df4
	ctx.r[10].s64 = -2113142784;
	// 831F5018: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F501C: C1AA7490  lfs f13, 0x7490(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(29840 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F5020: ED8C4824  fdivs f12, f12, f9
	ctx.f[12].f64 = ((ctx.f[12].f64 / ctx.f[9].f64) as f32) as f64;
	// 831F5024: A14B0002  lhz r10, 2(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(2 as u32) ) } as u64;
	// 831F5028: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831F502C: 7D460734  extsh r6, r10
	ctx.r[6].s64 = ctx.r[10].s16 as i64;
	// 831F5030: F8C1FFE0  std r6, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[6].u64 ) };
	// 831F5034: C961FFE0  lfd f11, -0x20(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 831F5038: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F503C: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F5040: ED090372  fmuls f8, f9, f13
	ctx.f[8].f64 = (((ctx.f[9].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F5044: ECE80032  fmuls f7, f8, f0
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F5048: D0E80400  stfs f7, 0x400(r8)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 831F504C: A0AB0000  lhz r5, 0(r11)
	ctx.r[5].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F5050: 7CAA0734  extsh r10, r5
	ctx.r[10].s64 = ctx.r[5].s16 as i64;
	// 831F5054: F941FFE8  std r10, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[10].u64 ) };
	// 831F5058: C8C1FFE8  lfd f6, -0x18(r1)
	ctx.f[6].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831F505C: FCA0369C  fcfid f5, f6
	ctx.f[5].f64 = (ctx.f[6].s64 as f64);
	// 831F5060: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 831F5064: FC802818  frsp f4, f5
	ctx.f[4].f64 = (ctx.f[5].f64 as f32) as f64;
	// 831F5068: EC640372  fmuls f3, f4, f13
	ctx.f[3].f64 = (((ctx.f[4].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F506C: EC430032  fmuls f2, f3, f0
	ctx.f[2].f64 = (((ctx.f[3].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F5070: D0480000  stfs f2, 0(r8)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F5074: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 831F5078: EC0C002A  fadds f0, f12, f0
	ctx.f[0].f64 = ((ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F507C: 4082FFA8  bne 0x831f5024
	if !ctx.cr[0].eq {
	pc = 0x831F5024; continue 'dispatch;
	}
	// 831F5080: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F5084: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F5088: 5547083E  rotlwi r7, r10, 1
	ctx.r[7].u64 = ((ctx.r[10].u32).rotate_left(1)) as u64;
	// 831F508C: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F5090: 7CC95850  subf r6, r9, r11
	ctx.r[6].s64 = ctx.r[11].s64 - ctx.r[9].s64;
	// 831F5094: 0CC70000  twi 6, r7, 0
	// 831F5098: 7D663B96  divwu r11, r6, r7
	ctx.r[11].u32 = ctx.r[6].u32 / ctx.r[7].u32;
	// 831F509C: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831F50A0: 40980008  bge cr6, 0x831f50a8
	if !ctx.cr[6].lt {
	pc = 0x831F50A8; continue 'dispatch;
	}
	// 831F50A4: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 831F50A8: 81630014  lwz r11, 0x14(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F50AC: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F50B0: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831F50B4: 7D4B4050  subf r10, r11, r8
	ctx.r[10].s64 = ctx.r[8].s64 - ctx.r[11].s64;
	// 831F50B8: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F50BC: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F50C0: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F50C4: 40980010  bge cr6, 0x831f50d4
	if !ctx.cr[6].lt {
	pc = 0x831F50D4; continue 'dispatch;
	}
	// 831F50C8: 9143001C  stw r10, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[10].u32 ) };
	// 831F50CC: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F50D0: 4E800020  blr
	return;
	// 831F50D4: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F50D8: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F50DC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F50E0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F50E0 size=424
    let mut pc: u32 = 0x831F50E0;
    'dispatch: loop {
        match pc {
            0x831F50E0 => {
    //   block [0x831F50E0..0x831F5288)
	// 831F50E0: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 831F50E4: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F50E8: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F50EC: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F50F0: 80C3001C  lwz r6, 0x1c(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F50F4: 7CA951D6  mullw r5, r9, r10
	ctx.r[5].s64 = (ctx.r[9].s32 as i64) * (ctx.r[10].s32 as i64);
	// 831F50F8: 80830004  lwz r4, 4(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F50FC: 83E30018  lwz r31, 0x18(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F5100: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F5104: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F5108: 54A9083C  slwi r9, r5, 1
	ctx.r[9].u32 = ctx.r[5].u32.wrapping_shl(1);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831F510C: 54C7103A  slwi r7, r6, 2
	ctx.r[7].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F5110: 7D4A2050  subf r10, r10, r4
	ctx.r[10].s64 = ctx.r[4].s64 - ctx.r[10].s64;
	// 831F5114: 7CC6F850  subf r6, r6, r31
	ctx.r[6].s64 = ctx.r[31].s64 - ctx.r[6].s64;
	// 831F5118: 7D695A14  add r11, r9, r11
	ctx.r[11].u64 = ctx.r[9].u64 + ctx.r[11].u64;
	// 831F511C: 7D274214  add r9, r7, r8
	ctx.r[9].u64 = ctx.r[7].u64 + ctx.r[8].u64;
	// 831F5120: 7F0A3000  cmpw cr6, r10, r6
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[6].s32, &mut ctx.xer);
	// 831F5124: 7D485378  mr r8, r10
	ctx.r[8].u64 = ctx.r[10].u64;
	// 831F5128: 41980008  blt cr6, 0x831f5130
	if ctx.cr[6].lt {
	pc = 0x831F5130; continue 'dispatch;
	}
	// 831F512C: 7CC83378  mr r8, r6
	ctx.r[8].u64 = ctx.r[6].u64;
	// 831F5130: 55071838  slwi r7, r8, 3
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(3);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F5134: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831F5138: 38E7007F  addi r7, r7, 0x7f
	ctx.r[7].s64 = ctx.r[7].s64 + 127;
	// 831F513C: 54E7C9FE  srwi r7, r7, 7
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F5140: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 831F5144: 419A0018  beq cr6, 0x831f515c
	if ctx.cr[6].eq {
	pc = 0x831F515C; continue 'dispatch;
	}
	// 831F5148: 55453830  slwi r5, r10, 7
	ctx.r[5].u32 = ctx.r[10].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831F514C: 7C055A2C  dcbt r5, r11
	// 831F5150: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 831F5154: 7F0A3840  cmplw cr6, r10, r7
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831F5158: 4198FFF0  blt cr6, 0x831f5148
	if ctx.cr[6].lt {
	pc = 0x831F5148; continue 'dispatch;
	}
	// 831F515C: 7CCA07B4  extsw r10, r6
	ctx.r[10].s64 = ctx.r[6].s32 as i64;
	// 831F5160: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F5164: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F5168: F941FFD0  std r10, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[10].u64 ) };
	// 831F516C: C961FFD0  lfd f11, -0x30(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 831F5170: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F5174: 3D40820C  lis r10, -0x7df4
	ctx.r[10].s64 = -2113142784;
	// 831F5178: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F517C: C1AA7490  lfs f13, 0x7490(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(29840 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F5180: ED8C4824  fdivs f12, f12, f9
	ctx.f[12].f64 = ((ctx.f[12].f64 / ctx.f[9].f64) as f32) as f64;
	// 831F5184: A14B0006  lhz r10, 6(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(6 as u32) ) } as u64;
	// 831F5188: 3508FFFF  addic. r8, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 831F518C: 7D460734  extsh r6, r10
	ctx.r[6].s64 = ctx.r[10].s16 as i64;
	// 831F5190: F8C1FFD0  std r6, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[6].u64 ) };
	// 831F5194: C961FFD0  lfd f11, -0x30(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 831F5198: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F519C: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F51A0: ED090372  fmuls f8, f9, f13
	ctx.f[8].f64 = (((ctx.f[9].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F51A4: ECE80032  fmuls f7, f8, f0
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F51A8: D0E90C00  stfs f7, 0xc00(r9)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(3072 as u32), tmp.u32 ) };
	// 831F51AC: A0AB0004  lhz r5, 4(r11)
	ctx.r[5].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F51B0: 7CAA0734  extsh r10, r5
	ctx.r[10].s64 = ctx.r[5].s16 as i64;
	// 831F51B4: F941FFD8  std r10, -0x28(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), ctx.r[10].u64 ) };
	// 831F51B8: C8C1FFD8  lfd f6, -0x28(r1)
	ctx.f[6].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-40 as u32) ) };
	// 831F51BC: FCA0369C  fcfid f5, f6
	ctx.f[5].f64 = (ctx.f[6].s64 as f64);
	// 831F51C0: FC802818  frsp f4, f5
	ctx.f[4].f64 = (ctx.f[5].f64 as f32) as f64;
	// 831F51C4: EC640372  fmuls f3, f4, f13
	ctx.f[3].f64 = (((ctx.f[4].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F51C8: EC430032  fmuls f2, f3, f0
	ctx.f[2].f64 = (((ctx.f[3].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F51CC: D0490800  stfs f2, 0x800(r9)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(2048 as u32), tmp.u32 ) };
	// 831F51D0: A0EB0002  lhz r7, 2(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(2 as u32) ) } as u64;
	// 831F51D4: 7CE50734  extsh r5, r7
	ctx.r[5].s64 = ctx.r[7].s16 as i64;
	// 831F51D8: F8A1FFE0  std r5, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[5].u64 ) };
	// 831F51DC: C821FFE0  lfd f1, -0x20(r1)
	ctx.f[1].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 831F51E0: FD600E9C  fcfid f11, f1
	ctx.f[11].f64 = (ctx.f[1].s64 as f64);
	// 831F51E4: FD405818  frsp f10, f11
	ctx.f[10].f64 = (ctx.f[11].f64 as f32) as f64;
	// 831F51E8: ED2A0372  fmuls f9, f10, f13
	ctx.f[9].f64 = (((ctx.f[10].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F51EC: ED090032  fmuls f8, f9, f0
	ctx.f[8].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F51F0: D1090400  stfs f8, 0x400(r9)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 831F51F4: A08B0000  lhz r4, 0(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F51F8: 7C870734  extsh r7, r4
	ctx.r[7].s64 = ctx.r[4].s16 as i64;
	// 831F51FC: F8E1FFE8  std r7, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[7].u64 ) };
	// 831F5200: C8E1FFE8  lfd f7, -0x18(r1)
	ctx.f[7].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831F5204: FCC03E9C  fcfid f6, f7
	ctx.f[6].f64 = (ctx.f[7].s64 as f64);
	// 831F5208: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 831F520C: FCA03018  frsp f5, f6
	ctx.f[5].f64 = (ctx.f[6].f64 as f32) as f64;
	// 831F5210: EC850372  fmuls f4, f5, f13
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F5214: EC640032  fmuls f3, f4, f0
	ctx.f[3].f64 = (((ctx.f[4].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F5218: D0690000  stfs f3, 0(r9)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F521C: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 831F5220: EC0C002A  fadds f0, f12, f0
	ctx.f[0].f64 = ((ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F5224: 4082FF60  bne 0x831f5184
	if !ctx.cr[0].eq {
	pc = 0x831F5184; continue 'dispatch;
	}
	// 831F5228: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F522C: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F5230: 5547083E  rotlwi r7, r10, 1
	ctx.r[7].u64 = ((ctx.r[10].u32).rotate_left(1)) as u64;
	// 831F5234: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F5238: 7CC85850  subf r6, r8, r11
	ctx.r[6].s64 = ctx.r[11].s64 - ctx.r[8].s64;
	// 831F523C: 0CC70000  twi 6, r7, 0
	// 831F5240: 7D663B96  divwu r11, r6, r7
	ctx.r[11].u32 = ctx.r[6].u32 / ctx.r[7].u32;
	// 831F5244: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831F5248: 40980008  bge cr6, 0x831f5250
	if !ctx.cr[6].lt {
	pc = 0x831F5250; continue 'dispatch;
	}
	// 831F524C: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 831F5250: 81630014  lwz r11, 0x14(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F5254: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F5258: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831F525C: 7D4B4850  subf r10, r11, r9
	ctx.r[10].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 831F5260: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F5264: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F5268: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F526C: 40980010  bge cr6, 0x831f527c
	if !ctx.cr[6].lt {
	pc = 0x831F527C; continue 'dispatch;
	}
	// 831F5270: 9143001C  stw r10, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[10].u32 ) };
	// 831F5274: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F5278: 4E800020  blr
	return;
	// 831F527C: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F5280: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F5284: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F5288(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F5288 size=500
    let mut pc: u32 = 0x831F5288;
    'dispatch: loop {
        match pc {
            0x831F5288 => {
    //   block [0x831F5288..0x831F547C)
	// 831F5288: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 831F528C: 81030008  lwz r8, 8(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F5290: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F5294: 88E3000D  lbz r7, 0xd(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F5298: 80C3001C  lwz r6, 0x1c(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F529C: 7CA741D6  mullw r5, r7, r8
	ctx.r[5].s64 = (ctx.r[7].s32 as i64) * (ctx.r[8].s32 as i64);
	// 831F52A0: 80830004  lwz r4, 4(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F52A4: 83E30018  lwz r31, 0x18(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F52A8: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F52AC: 81230014  lwz r9, 0x14(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F52B0: 54AA083C  slwi r10, r5, 1
	ctx.r[10].u32 = ctx.r[5].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F52B4: 54C7103A  slwi r7, r6, 2
	ctx.r[7].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F52B8: 7D082050  subf r8, r8, r4
	ctx.r[8].s64 = ctx.r[4].s64 - ctx.r[8].s64;
	// 831F52BC: 7CC6F850  subf r6, r6, r31
	ctx.r[6].s64 = ctx.r[31].s64 - ctx.r[6].s64;
	// 831F52C0: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831F52C4: 7D474A14  add r10, r7, r9
	ctx.r[10].u64 = ctx.r[7].u64 + ctx.r[9].u64;
	// 831F52C8: 7F083000  cmpw cr6, r8, r6
	ctx.cr[6].compare_i32(ctx.r[8].s32, ctx.r[6].s32, &mut ctx.xer);
	// 831F52CC: 41980008  blt cr6, 0x831f52d4
	if ctx.cr[6].lt {
	pc = 0x831F52D4; continue 'dispatch;
	}
	// 831F52D0: 7CC83378  mr r8, r6
	ctx.r[8].u64 = ctx.r[6].u64;
	// 831F52D4: 5507083C  slwi r7, r8, 1
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(1);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F52D8: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 831F52DC: 7CE83A14  add r7, r8, r7
	ctx.r[7].u64 = ctx.r[8].u64 + ctx.r[7].u64;
	// 831F52E0: 54E7103A  slwi r7, r7, 2
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F52E4: 38A7007F  addi r5, r7, 0x7f
	ctx.r[5].s64 = ctx.r[7].s64 + 127;
	// 831F52E8: 54A7C9FE  srwi r7, r5, 7
	ctx.r[7].u32 = ctx.r[5].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F52EC: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 831F52F0: 419A0018  beq cr6, 0x831f5308
	if ctx.cr[6].eq {
	pc = 0x831F5308; continue 'dispatch;
	}
	// 831F52F4: 55253830  slwi r5, r9, 7
	ctx.r[5].u32 = ctx.r[9].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831F52F8: 7C055A2C  dcbt r5, r11
	// 831F52FC: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 831F5300: 7F093840  cmplw cr6, r9, r7
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831F5304: 4198FFF0  blt cr6, 0x831f52f4
	if ctx.cr[6].lt {
	pc = 0x831F52F4; continue 'dispatch;
	}
	// 831F5308: 7CC907B4  extsw r9, r6
	ctx.r[9].s64 = ctx.r[6].s32 as i64;
	// 831F530C: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F5310: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F5314: F921FFC0  std r9, -0x40(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-64 as u32), ctx.r[9].u64 ) };
	// 831F5318: C961FFC0  lfd f11, -0x40(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-64 as u32) ) };
	// 831F531C: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F5320: 3D20820C  lis r9, -0x7df4
	ctx.r[9].s64 = -2113142784;
	// 831F5324: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F5328: C1A97490  lfs f13, 0x7490(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(29840 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F532C: ED8C4824  fdivs f12, f12, f9
	ctx.f[12].f64 = ((ctx.f[12].f64 / ctx.f[9].f64) as f32) as f64;
	// 831F5330: A12B000A  lhz r9, 0xa(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(10 as u32) ) } as u64;
	// 831F5334: 3508FFFF  addic. r8, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 831F5338: 7D260734  extsh r6, r9
	ctx.r[6].s64 = ctx.r[9].s16 as i64;
	// 831F533C: F8C1FFC0  std r6, -0x40(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-64 as u32), ctx.r[6].u64 ) };
	// 831F5340: C961FFC0  lfd f11, -0x40(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-64 as u32) ) };
	// 831F5344: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F5348: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F534C: ED090372  fmuls f8, f9, f13
	ctx.f[8].f64 = (((ctx.f[9].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F5350: ECE80032  fmuls f7, f8, f0
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F5354: D0EA1400  stfs f7, 0x1400(r10)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(5120 as u32), tmp.u32 ) };
	// 831F5358: A0AB0008  lhz r5, 8(r11)
	ctx.r[5].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F535C: 7CA90734  extsh r9, r5
	ctx.r[9].s64 = ctx.r[5].s16 as i64;
	// 831F5360: F921FFC8  std r9, -0x38(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-56 as u32), ctx.r[9].u64 ) };
	// 831F5364: C8C1FFC8  lfd f6, -0x38(r1)
	ctx.f[6].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-56 as u32) ) };
	// 831F5368: FCA0369C  fcfid f5, f6
	ctx.f[5].f64 = (ctx.f[6].s64 as f64);
	// 831F536C: FC802818  frsp f4, f5
	ctx.f[4].f64 = (ctx.f[5].f64 as f32) as f64;
	// 831F5370: EC640372  fmuls f3, f4, f13
	ctx.f[3].f64 = (((ctx.f[4].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F5374: EC430032  fmuls f2, f3, f0
	ctx.f[2].f64 = (((ctx.f[3].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F5378: D04A1000  stfs f2, 0x1000(r10)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4096 as u32), tmp.u32 ) };
	// 831F537C: A0EB0006  lhz r7, 6(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(6 as u32) ) } as u64;
	// 831F5380: 7CE50734  extsh r5, r7
	ctx.r[5].s64 = ctx.r[7].s16 as i64;
	// 831F5384: F8A1FFD0  std r5, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[5].u64 ) };
	// 831F5388: C821FFD0  lfd f1, -0x30(r1)
	ctx.f[1].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 831F538C: FD600E9C  fcfid f11, f1
	ctx.f[11].f64 = (ctx.f[1].s64 as f64);
	// 831F5390: FD405818  frsp f10, f11
	ctx.f[10].f64 = (ctx.f[11].f64 as f32) as f64;
	// 831F5394: ED2A0372  fmuls f9, f10, f13
	ctx.f[9].f64 = (((ctx.f[10].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F5398: ED090032  fmuls f8, f9, f0
	ctx.f[8].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F539C: D10A0C00  stfs f8, 0xc00(r10)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(3072 as u32), tmp.u32 ) };
	// 831F53A0: A08B0004  lhz r4, 4(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F53A4: 7C870734  extsh r7, r4
	ctx.r[7].s64 = ctx.r[4].s16 as i64;
	// 831F53A8: F8E1FFD8  std r7, -0x28(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), ctx.r[7].u64 ) };
	// 831F53AC: C8E1FFD8  lfd f7, -0x28(r1)
	ctx.f[7].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-40 as u32) ) };
	// 831F53B0: FCC03E9C  fcfid f6, f7
	ctx.f[6].f64 = (ctx.f[7].s64 as f64);
	// 831F53B4: FCA03018  frsp f5, f6
	ctx.f[5].f64 = (ctx.f[6].f64 as f32) as f64;
	// 831F53B8: EC850372  fmuls f4, f5, f13
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F53BC: EC640032  fmuls f3, f4, f0
	ctx.f[3].f64 = (((ctx.f[4].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F53C0: D06A0800  stfs f3, 0x800(r10)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(2048 as u32), tmp.u32 ) };
	// 831F53C4: A0CB0002  lhz r6, 2(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(2 as u32) ) } as u64;
	// 831F53C8: 7CC40734  extsh r4, r6
	ctx.r[4].s64 = ctx.r[6].s16 as i64;
	// 831F53CC: F881FFE0  std r4, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[4].u64 ) };
	// 831F53D0: C841FFE0  lfd f2, -0x20(r1)
	ctx.f[2].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 831F53D4: FC20169C  fcfid f1, f2
	ctx.f[1].f64 = (ctx.f[2].s64 as f64);
	// 831F53D8: FD600818  frsp f11, f1
	ctx.f[11].f64 = (ctx.f[1].f64 as f32) as f64;
	// 831F53DC: ED4B0372  fmuls f10, f11, f13
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F53E0: ED2A0032  fmuls f9, f10, f0
	ctx.f[9].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F53E4: D12A0400  stfs f9, 0x400(r10)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 831F53E8: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F53EC: 7D260734  extsh r6, r9
	ctx.r[6].s64 = ctx.r[9].s16 as i64;
	// 831F53F0: F8C1FFE8  std r6, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[6].u64 ) };
	// 831F53F4: C901FFE8  lfd f8, -0x18(r1)
	ctx.f[8].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831F53F8: FCE0469C  fcfid f7, f8
	ctx.f[7].f64 = (ctx.f[8].s64 as f64);
	// 831F53FC: 396B000C  addi r11, r11, 0xc
	ctx.r[11].s64 = ctx.r[11].s64 + 12;
	// 831F5400: FCC03818  frsp f6, f7
	ctx.f[6].f64 = (ctx.f[7].f64 as f32) as f64;
	// 831F5404: ECA60372  fmuls f5, f6, f13
	ctx.f[5].f64 = (((ctx.f[6].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F5408: EC850032  fmuls f4, f5, f0
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F540C: D08A0000  stfs f4, 0(r10)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F5410: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 831F5414: EC0C002A  fadds f0, f12, f0
	ctx.f[0].f64 = ((ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F5418: 4082FF18  bne 0x831f5330
	if !ctx.cr[0].eq {
	pc = 0x831F5330; continue 'dispatch;
	}
	// 831F541C: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F5420: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F5424: 5527083E  rotlwi r7, r9, 1
	ctx.r[7].u64 = ((ctx.r[9].u32).rotate_left(1)) as u64;
	// 831F5428: 81230004  lwz r9, 4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F542C: 7CC85850  subf r6, r8, r11
	ctx.r[6].s64 = ctx.r[11].s64 - ctx.r[8].s64;
	// 831F5430: 0CC70000  twi 6, r7, 0
	// 831F5434: 7D663B96  divwu r11, r6, r7
	ctx.r[11].u32 = ctx.r[6].u32 / ctx.r[7].u32;
	// 831F5438: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831F543C: 40980008  bge cr6, 0x831f5444
	if !ctx.cr[6].lt {
	pc = 0x831F5444; continue 'dispatch;
	}
	// 831F5440: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 831F5444: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F5448: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F544C: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F5450: 7CE85050  subf r7, r8, r10
	ctx.r[7].s64 = ctx.r[10].s64 - ctx.r[8].s64;
	// 831F5454: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 831F5458: 54EAF0BE  srwi r10, r7, 2
	ctx.r[10].u32 = ctx.r[7].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F545C: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F5460: 40980010  bge cr6, 0x831f5470
	if !ctx.cr[6].lt {
	pc = 0x831F5470; continue 'dispatch;
	}
	// 831F5464: 9143001C  stw r10, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[10].u32 ) };
	// 831F5468: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F546C: 4E800020  blr
	return;
	// 831F5470: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F5474: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F5478: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F5480(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F5480 size=304
    let mut pc: u32 = 0x831F5480;
    'dispatch: loop {
        match pc {
            0x831F5480 => {
    //   block [0x831F5480..0x831F55B0)
	// 831F5480: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 831F5484: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F5488: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F548C: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F5490: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F5494: 80830004  lwz r4, 4(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F5498: 5545103A  slwi r5, r10, 2
	ctx.r[5].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831F549C: 83E30018  lwz r31, 0x18(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F54A0: 7CE959D6  mullw r7, r9, r11
	ctx.r[7].s64 = (ctx.r[9].s32 as i64) * (ctx.r[11].s32 as i64);
	// 831F54A4: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F54A8: 80C30014  lwz r6, 0x14(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F54AC: 7D6B2050  subf r11, r11, r4
	ctx.r[11].s64 = ctx.r[4].s64 - ctx.r[11].s64;
	// 831F54B0: 7D4AF850  subf r10, r10, r31
	ctx.r[10].s64 = ctx.r[31].s64 - ctx.r[10].s64;
	// 831F54B4: 7D074214  add r8, r7, r8
	ctx.r[8].u64 = ctx.r[7].u64 + ctx.r[8].u64;
	// 831F54B8: 7CC53214  add r6, r5, r6
	ctx.r[6].u64 = ctx.r[5].u64 + ctx.r[6].u64;
	// 831F54BC: 7F0B5000  cmpw cr6, r11, r10
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[10].s32, &mut ctx.xer);
	// 831F54C0: 7D675B78  mr r7, r11
	ctx.r[7].u64 = ctx.r[11].u64;
	// 831F54C4: 41980008  blt cr6, 0x831f54cc
	if ctx.cr[6].lt {
	pc = 0x831F54CC; continue 'dispatch;
	}
	// 831F54C8: 7D475378  mr r7, r10
	ctx.r[7].u64 = ctx.r[10].u64;
	// 831F54CC: 7D4B07B4  extsw r11, r10
	ctx.r[11].s64 = ctx.r[10].s32 as i64;
	// 831F54D0: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F54D4: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F54D8: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 831F54DC: F961FFF0  std r11, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[11].u64 ) };
	// 831F54E0: C961FFF0  lfd f11, -0x10(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831F54E4: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F54E8: 3D608213  lis r11, -0x7ded
	ctx.r[11].s64 = -2112684032;
	// 831F54EC: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F54F0: C1AA4E60  lfs f13, 0x4e60(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(20064 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F54F4: ED6C4824  fdivs f11, f12, f9
	ctx.f[11].f64 = ((ctx.f[12].f64 / ctx.f[9].f64) as f32) as f64;
	// 831F54F8: C18BB184  lfs f12, -0x4e7c(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-20092 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831F54FC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831F5500: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831F5504: 419A003C  beq cr6, 0x831f5540
	if ctx.cr[6].eq {
	pc = 0x831F5540; continue 'dispatch;
	}
	// 831F5508: 7CCA3378  mr r10, r6
	ctx.r[10].u64 = ctx.r[6].u64;
	// 831F550C: 7C8B40AE  lbzx r4, r11, r8
	ctx.r[4].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[8].u32)) } as u64;
	// 831F5510: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831F5514: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831F5518: F881FFF0  std r4, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[4].u64 ) };
	// 831F551C: C941FFF0  lfd f10, -0x10(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831F5520: FD20569C  fcfid f9, f10
	ctx.f[9].f64 = (ctx.f[10].s64 as f64);
	// 831F5524: FD004818  frsp f8, f9
	ctx.f[8].f64 = (ctx.f[9].f64 as f32) as f64;
	// 831F5528: ECE86828  fsubs f7, f8, f13
	ctx.f[7].f64 = (((ctx.f[8].f64 - ctx.f[13].f64) as f32) as f64);
	// 831F552C: ECC70332  fmuls f6, f7, f12
	ctx.f[6].f64 = (((ctx.f[7].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F5530: ECA60032  fmuls f5, f6, f0
	ctx.f[5].f64 = (((ctx.f[6].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F5534: D0AA0000  stfs f5, 0(r10)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F5538: 394A0400  addi r10, r10, 0x400
	ctx.r[10].s64 = ctx.r[10].s64 + 1024;
	// 831F553C: 4198FFD0  blt cr6, 0x831f550c
	if ctx.cr[6].lt {
	pc = 0x831F550C; continue 'dispatch;
	}
	// 831F5540: 34E7FFFF  addic. r7, r7, -1
	ctx.xer.ca = (ctx.r[7].u32 > (!(-1 as u32)));
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 831F5544: EC0B002A  fadds f0, f11, f0
	ctx.f[0].f64 = ((ctx.f[11].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F5548: 7D084A14  add r8, r8, r9
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[9].u64;
	// 831F554C: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 831F5550: 4082FFAC  bne 0x831f54fc
	if !ctx.cr[0].eq {
	pc = 0x831F54FC; continue 'dispatch;
	}
	// 831F5554: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F5558: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F555C: 7D2B4050  subf r9, r11, r8
	ctx.r[9].s64 = ctx.r[8].s64 - ctx.r[11].s64;
	// 831F5560: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F5564: 0CCA0000  twi 6, r10, 0
	// 831F5568: 7D495396  divwu r10, r9, r10
	ctx.r[10].u32 = ctx.r[9].u32 / ctx.r[10].u32;
	// 831F556C: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F5570: 41980008  blt cr6, 0x831f5578
	if ctx.cr[6].lt {
	pc = 0x831F5578; continue 'dispatch;
	}
	// 831F5574: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 831F5578: 81630014  lwz r11, 0x14(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F557C: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F5580: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831F5584: 7D4B3050  subf r10, r11, r6
	ctx.r[10].s64 = ctx.r[6].s64 - ctx.r[11].s64;
	// 831F5588: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F558C: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F5590: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F5594: 40980010  bge cr6, 0x831f55a4
	if !ctx.cr[6].lt {
	pc = 0x831F55A4; continue 'dispatch;
	}
	// 831F5598: 9143001C  stw r10, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[10].u32 ) };
	// 831F559C: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F55A0: 4E800020  blr
	return;
	// 831F55A4: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F55A8: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F55AC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F55B0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F55B0 size=312
    let mut pc: u32 = 0x831F55B0;
    'dispatch: loop {
        match pc {
            0x831F55B0 => {
    //   block [0x831F55B0..0x831F56E8)
	// 831F55B0: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 831F55B4: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F55B8: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F55BC: 80C3001C  lwz r6, 0x1c(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F55C0: 88A3000D  lbz r5, 0xd(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F55C4: 80830004  lwz r4, 4(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F55C8: 54C7103A  slwi r7, r6, 2
	ctx.r[7].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F55CC: 83E30018  lwz r31, 0x18(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F55D0: 7D2551D6  mullw r9, r5, r10
	ctx.r[9].s64 = (ctx.r[5].s32 as i64) * (ctx.r[10].s32 as i64);
	// 831F55D4: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F55D8: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F55DC: 7D4A2050  subf r10, r10, r4
	ctx.r[10].s64 = ctx.r[4].s64 - ctx.r[10].s64;
	// 831F55E0: 7CC6F850  subf r6, r6, r31
	ctx.r[6].s64 = ctx.r[31].s64 - ctx.r[6].s64;
	// 831F55E4: 7D695A14  add r11, r9, r11
	ctx.r[11].u64 = ctx.r[9].u64 + ctx.r[11].u64;
	// 831F55E8: 7CE74214  add r7, r7, r8
	ctx.r[7].u64 = ctx.r[7].u64 + ctx.r[8].u64;
	// 831F55EC: 7F0A3000  cmpw cr6, r10, r6
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[6].s32, &mut ctx.xer);
	// 831F55F0: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 831F55F4: 41980008  blt cr6, 0x831f55fc
	if ctx.cr[6].lt {
	pc = 0x831F55FC; continue 'dispatch;
	}
	// 831F55F8: 7CC93378  mr r9, r6
	ctx.r[9].u64 = ctx.r[6].u64;
	// 831F55FC: 3909007F  addi r8, r9, 0x7f
	ctx.r[8].s64 = ctx.r[9].s64 + 127;
	// 831F5600: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831F5604: 5508C9FE  srwi r8, r8, 7
	ctx.r[8].u32 = ctx.r[8].u32.wrapping_shr(7);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831F5608: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 831F560C: 419A0018  beq cr6, 0x831f5624
	if ctx.cr[6].eq {
	pc = 0x831F5624; continue 'dispatch;
	}
	// 831F5610: 55453830  slwi r5, r10, 7
	ctx.r[5].u32 = ctx.r[10].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831F5614: 7C055A2C  dcbt r5, r11
	// 831F5618: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 831F561C: 7F0A4040  cmplw cr6, r10, r8
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831F5620: 4198FFF0  blt cr6, 0x831f5610
	if ctx.cr[6].lt {
	pc = 0x831F5610; continue 'dispatch;
	}
	// 831F5624: 7CCA07B4  extsw r10, r6
	ctx.r[10].s64 = ctx.r[6].s32 as i64;
	// 831F5628: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F562C: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F5630: 3D00820D  lis r8, -0x7df3
	ctx.r[8].s64 = -2113077248;
	// 831F5634: F941FFF0  std r10, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[10].u64 ) };
	// 831F5638: C961FFF0  lfd f11, -0x10(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831F563C: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F5640: 3D408213  lis r10, -0x7ded
	ctx.r[10].s64 = -2112684032;
	// 831F5644: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F5648: C1A84E60  lfs f13, 0x4e60(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(20064 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F564C: ED6C4824  fdivs f11, f12, f9
	ctx.f[11].f64 = ((ctx.f[12].f64 / ctx.f[9].f64) as f32) as f64;
	// 831F5650: C18AB184  lfs f12, -0x4e7c(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-20092 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831F5654: 890B0000  lbz r8, 0(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F5658: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831F565C: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831F5660: F901FFF0  std r8, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[8].u64 ) };
	// 831F5664: C941FFF0  lfd f10, -0x10(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831F5668: FD20569C  fcfid f9, f10
	ctx.f[9].f64 = (ctx.f[10].s64 as f64);
	// 831F566C: FD004818  frsp f8, f9
	ctx.f[8].f64 = (ctx.f[9].f64 as f32) as f64;
	// 831F5670: ECE86828  fsubs f7, f8, f13
	ctx.f[7].f64 = (((ctx.f[8].f64 - ctx.f[13].f64) as f32) as f64);
	// 831F5674: ECC70332  fmuls f6, f7, f12
	ctx.f[6].f64 = (((ctx.f[7].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F5678: ECA60032  fmuls f5, f6, f0
	ctx.f[5].f64 = (((ctx.f[6].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F567C: D0A70000  stfs f5, 0(r7)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F5680: 38E70004  addi r7, r7, 4
	ctx.r[7].s64 = ctx.r[7].s64 + 4;
	// 831F5684: EC0B002A  fadds f0, f11, f0
	ctx.f[0].f64 = ((ctx.f[11].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F5688: 4082FFCC  bne 0x831f5654
	if !ctx.cr[0].eq {
	pc = 0x831F5654; continue 'dispatch;
	}
	// 831F568C: 81430000  lwz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F5690: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F5694: 7D0A5850  subf r8, r10, r11
	ctx.r[8].s64 = ctx.r[11].s64 - ctx.r[10].s64;
	// 831F5698: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F569C: 0CC90000  twi 6, r9, 0
	// 831F56A0: 7D484B96  divwu r10, r8, r9
	ctx.r[10].u32 = ctx.r[8].u32 / ctx.r[9].u32;
	// 831F56A4: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F56A8: 41980008  blt cr6, 0x831f56b0
	if ctx.cr[6].lt {
	pc = 0x831F56B0; continue 'dispatch;
	}
	// 831F56AC: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 831F56B0: 81630014  lwz r11, 0x14(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F56B4: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F56B8: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831F56BC: 7D4B3850  subf r10, r11, r7
	ctx.r[10].s64 = ctx.r[7].s64 - ctx.r[11].s64;
	// 831F56C0: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F56C4: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F56C8: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F56CC: 40980010  bge cr6, 0x831f56dc
	if !ctx.cr[6].lt {
	pc = 0x831F56DC; continue 'dispatch;
	}
	// 831F56D0: 9143001C  stw r10, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[10].u32 ) };
	// 831F56D4: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F56D8: 4E800020  blr
	return;
	// 831F56DC: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F56E0: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F56E4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F56E8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F56E8 size=352
    let mut pc: u32 = 0x831F56E8;
    'dispatch: loop {
        match pc {
            0x831F56E8 => {
    //   block [0x831F56E8..0x831F5848)
	// 831F56E8: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 831F56EC: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F56F0: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F56F4: 80C3001C  lwz r6, 0x1c(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F56F8: 88A3000D  lbz r5, 0xd(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F56FC: 80830004  lwz r4, 4(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F5700: 54C7103A  slwi r7, r6, 2
	ctx.r[7].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F5704: 83E30018  lwz r31, 0x18(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F5708: 7D2551D6  mullw r9, r5, r10
	ctx.r[9].s64 = (ctx.r[5].s32 as i64) * (ctx.r[10].s32 as i64);
	// 831F570C: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F5710: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F5714: 7D4A2050  subf r10, r10, r4
	ctx.r[10].s64 = ctx.r[4].s64 - ctx.r[10].s64;
	// 831F5718: 7CC6F850  subf r6, r6, r31
	ctx.r[6].s64 = ctx.r[31].s64 - ctx.r[6].s64;
	// 831F571C: 7D695A14  add r11, r9, r11
	ctx.r[11].u64 = ctx.r[9].u64 + ctx.r[11].u64;
	// 831F5720: 7D074214  add r8, r7, r8
	ctx.r[8].u64 = ctx.r[7].u64 + ctx.r[8].u64;
	// 831F5724: 7F0A3000  cmpw cr6, r10, r6
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[6].s32, &mut ctx.xer);
	// 831F5728: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 831F572C: 41980008  blt cr6, 0x831f5734
	if ctx.cr[6].lt {
	pc = 0x831F5734; continue 'dispatch;
	}
	// 831F5730: 7CC93378  mr r9, r6
	ctx.r[9].u64 = ctx.r[6].u64;
	// 831F5734: 5527083C  slwi r7, r9, 1
	ctx.r[7].u32 = ctx.r[9].u32.wrapping_shl(1);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F5738: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831F573C: 38E7007F  addi r7, r7, 0x7f
	ctx.r[7].s64 = ctx.r[7].s64 + 127;
	// 831F5740: 54E7C9FE  srwi r7, r7, 7
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F5744: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 831F5748: 419A0018  beq cr6, 0x831f5760
	if ctx.cr[6].eq {
	pc = 0x831F5760; continue 'dispatch;
	}
	// 831F574C: 55453830  slwi r5, r10, 7
	ctx.r[5].u32 = ctx.r[10].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831F5750: 7C055A2C  dcbt r5, r11
	// 831F5754: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 831F5758: 7F0A3840  cmplw cr6, r10, r7
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831F575C: 4198FFF0  blt cr6, 0x831f574c
	if ctx.cr[6].lt {
	pc = 0x831F574C; continue 'dispatch;
	}
	// 831F5760: 7CCA07B4  extsw r10, r6
	ctx.r[10].s64 = ctx.r[6].s32 as i64;
	// 831F5764: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F5768: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F576C: 3CE0820D  lis r7, -0x7df3
	ctx.r[7].s64 = -2113077248;
	// 831F5770: F941FFE0  std r10, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[10].u64 ) };
	// 831F5774: C961FFE0  lfd f11, -0x20(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 831F5778: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F577C: 3D408213  lis r10, -0x7ded
	ctx.r[10].s64 = -2112684032;
	// 831F5780: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F5784: C1A74E60  lfs f13, 0x4e60(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(20064 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F5788: ED6C4824  fdivs f11, f12, f9
	ctx.f[11].f64 = ((ctx.f[12].f64 / ctx.f[9].f64) as f32) as f64;
	// 831F578C: C18AB184  lfs f12, -0x4e7c(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-20092 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831F5790: 88EB0001  lbz r7, 1(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(1 as u32) ) } as u64;
	// 831F5794: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831F5798: F8E1FFE0  std r7, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[7].u64 ) };
	// 831F579C: C941FFE0  lfd f10, -0x20(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 831F57A0: FD20569C  fcfid f9, f10
	ctx.f[9].f64 = (ctx.f[10].s64 as f64);
	// 831F57A4: FD004818  frsp f8, f9
	ctx.f[8].f64 = (ctx.f[9].f64 as f32) as f64;
	// 831F57A8: ECE86828  fsubs f7, f8, f13
	ctx.f[7].f64 = (((ctx.f[8].f64 - ctx.f[13].f64) as f32) as f64);
	// 831F57AC: ECC70332  fmuls f6, f7, f12
	ctx.f[6].f64 = (((ctx.f[7].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F57B0: ECA60032  fmuls f5, f6, f0
	ctx.f[5].f64 = (((ctx.f[6].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F57B4: D0A80400  stfs f5, 0x400(r8)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 831F57B8: 88AB0000  lbz r5, 0(r11)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F57BC: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 831F57C0: F8A1FFE8  std r5, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[5].u64 ) };
	// 831F57C4: C881FFE8  lfd f4, -0x18(r1)
	ctx.f[4].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831F57C8: FC60269C  fcfid f3, f4
	ctx.f[3].f64 = (ctx.f[4].s64 as f64);
	// 831F57CC: FC401818  frsp f2, f3
	ctx.f[2].f64 = (ctx.f[3].f64 as f32) as f64;
	// 831F57D0: EC226828  fsubs f1, f2, f13
	ctx.f[1].f64 = (((ctx.f[2].f64 - ctx.f[13].f64) as f32) as f64);
	// 831F57D4: ED410332  fmuls f10, f1, f12
	ctx.f[10].f64 = (((ctx.f[1].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F57D8: ED2A0032  fmuls f9, f10, f0
	ctx.f[9].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F57DC: D1280000  stfs f9, 0(r8)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F57E0: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 831F57E4: EC0B002A  fadds f0, f11, f0
	ctx.f[0].f64 = ((ctx.f[11].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F57E8: 4082FFA8  bne 0x831f5790
	if !ctx.cr[0].eq {
	pc = 0x831F5790; continue 'dispatch;
	}
	// 831F57EC: 81430000  lwz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F57F0: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F57F4: 7CEA5850  subf r7, r10, r11
	ctx.r[7].s64 = ctx.r[11].s64 - ctx.r[10].s64;
	// 831F57F8: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F57FC: 0CC90000  twi 6, r9, 0
	// 831F5800: 7D474B96  divwu r10, r7, r9
	ctx.r[10].u32 = ctx.r[7].u32 / ctx.r[9].u32;
	// 831F5804: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F5808: 41980008  blt cr6, 0x831f5810
	if ctx.cr[6].lt {
	pc = 0x831F5810; continue 'dispatch;
	}
	// 831F580C: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 831F5810: 81630014  lwz r11, 0x14(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F5814: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F5818: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831F581C: 7D4B4050  subf r10, r11, r8
	ctx.r[10].s64 = ctx.r[8].s64 - ctx.r[11].s64;
	// 831F5820: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F5824: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F5828: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F582C: 40980010  bge cr6, 0x831f583c
	if !ctx.cr[6].lt {
	pc = 0x831F583C; continue 'dispatch;
	}
	// 831F5830: 9143001C  stw r10, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[10].u32 ) };
	// 831F5834: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F5838: 4E800020  blr
	return;
	// 831F583C: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F5840: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F5844: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F5848(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F5848 size=404
    let mut pc: u32 = 0x831F5848;
    'dispatch: loop {
        match pc {
            0x831F5848 => {
    //   block [0x831F5848..0x831F59DC)
	// 831F5848: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F584C: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F5850: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F5854: 80C3001C  lwz r6, 0x1c(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F5858: 80A30004  lwz r5, 4(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F585C: 7D2951D6  mullw r9, r9, r10
	ctx.r[9].s64 = (ctx.r[9].s32 as i64) * (ctx.r[10].s32 as i64);
	// 831F5860: 80830018  lwz r4, 0x18(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F5864: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F5868: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F586C: 54C7103A  slwi r7, r6, 2
	ctx.r[7].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F5870: 7D4A2850  subf r10, r10, r5
	ctx.r[10].s64 = ctx.r[5].s64 - ctx.r[10].s64;
	// 831F5874: 7CC62050  subf r6, r6, r4
	ctx.r[6].s64 = ctx.r[4].s64 - ctx.r[6].s64;
	// 831F5878: 7D695A14  add r11, r9, r11
	ctx.r[11].u64 = ctx.r[9].u64 + ctx.r[11].u64;
	// 831F587C: 7D274214  add r9, r7, r8
	ctx.r[9].u64 = ctx.r[7].u64 + ctx.r[8].u64;
	// 831F5880: 7F0A3000  cmpw cr6, r10, r6
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[6].s32, &mut ctx.xer);
	// 831F5884: 7D485378  mr r8, r10
	ctx.r[8].u64 = ctx.r[10].u64;
	// 831F5888: 41980008  blt cr6, 0x831f5890
	if ctx.cr[6].lt {
	pc = 0x831F5890; continue 'dispatch;
	}
	// 831F588C: 7CC83378  mr r8, r6
	ctx.r[8].u64 = ctx.r[6].u64;
	// 831F5890: 5507103A  slwi r7, r8, 2
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F5894: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831F5898: 38E7007F  addi r7, r7, 0x7f
	ctx.r[7].s64 = ctx.r[7].s64 + 127;
	// 831F589C: 54E7C9FE  srwi r7, r7, 7
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F58A0: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 831F58A4: 419A0018  beq cr6, 0x831f58bc
	if ctx.cr[6].eq {
	pc = 0x831F58BC; continue 'dispatch;
	}
	// 831F58A8: 55453830  slwi r5, r10, 7
	ctx.r[5].u32 = ctx.r[10].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831F58AC: 7C055A2C  dcbt r5, r11
	// 831F58B0: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 831F58B4: 7F0A3840  cmplw cr6, r10, r7
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831F58B8: 4198FFF0  blt cr6, 0x831f58a8
	if ctx.cr[6].lt {
	pc = 0x831F58A8; continue 'dispatch;
	}
	// 831F58BC: 7CCA07B4  extsw r10, r6
	ctx.r[10].s64 = ctx.r[6].s32 as i64;
	// 831F58C0: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F58C4: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F58C8: 3CE0820D  lis r7, -0x7df3
	ctx.r[7].s64 = -2113077248;
	// 831F58CC: F941FFE0  std r10, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[10].u64 ) };
	// 831F58D0: C961FFE0  lfd f11, -0x20(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 831F58D4: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F58D8: 3D408213  lis r10, -0x7ded
	ctx.r[10].s64 = -2112684032;
	// 831F58DC: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F58E0: C1A74E60  lfs f13, 0x4e60(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(20064 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F58E4: ED6C4824  fdivs f11, f12, f9
	ctx.f[11].f64 = ((ctx.f[12].f64 / ctx.f[9].f64) as f32) as f64;
	// 831F58E8: C18AB184  lfs f12, -0x4e7c(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-20092 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831F58EC: 88EB0003  lbz r7, 3(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(3 as u32) ) } as u64;
	// 831F58F0: 3508FFFF  addic. r8, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 831F58F4: F8E1FFE0  std r7, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[7].u64 ) };
	// 831F58F8: C941FFE0  lfd f10, -0x20(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 831F58FC: FD20569C  fcfid f9, f10
	ctx.f[9].f64 = (ctx.f[10].s64 as f64);
	// 831F5900: FD004818  frsp f8, f9
	ctx.f[8].f64 = (ctx.f[9].f64 as f32) as f64;
	// 831F5904: ECE86828  fsubs f7, f8, f13
	ctx.f[7].f64 = (((ctx.f[8].f64 - ctx.f[13].f64) as f32) as f64);
	// 831F5908: ECC70332  fmuls f6, f7, f12
	ctx.f[6].f64 = (((ctx.f[7].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F590C: ECA60032  fmuls f5, f6, f0
	ctx.f[5].f64 = (((ctx.f[6].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F5910: D0A90C00  stfs f5, 0xc00(r9)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(3072 as u32), tmp.u32 ) };
	// 831F5914: 88AB0002  lbz r5, 2(r11)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(2 as u32) ) } as u64;
	// 831F5918: F8A1FFE8  std r5, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[5].u64 ) };
	// 831F591C: C881FFE8  lfd f4, -0x18(r1)
	ctx.f[4].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831F5920: FC60269C  fcfid f3, f4
	ctx.f[3].f64 = (ctx.f[4].s64 as f64);
	// 831F5924: FC401818  frsp f2, f3
	ctx.f[2].f64 = (ctx.f[3].f64 as f32) as f64;
	// 831F5928: EC226828  fsubs f1, f2, f13
	ctx.f[1].f64 = (((ctx.f[2].f64 - ctx.f[13].f64) as f32) as f64);
	// 831F592C: ED410332  fmuls f10, f1, f12
	ctx.f[10].f64 = (((ctx.f[1].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F5930: ED2A0032  fmuls f9, f10, f0
	ctx.f[9].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F5934: D1290800  stfs f9, 0x800(r9)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(2048 as u32), tmp.u32 ) };
	// 831F5938: 894B0001  lbz r10, 1(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(1 as u32) ) } as u64;
	// 831F593C: F941FFF0  std r10, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[10].u64 ) };
	// 831F5940: C901FFF0  lfd f8, -0x10(r1)
	ctx.f[8].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831F5944: FCE0469C  fcfid f7, f8
	ctx.f[7].f64 = (ctx.f[8].s64 as f64);
	// 831F5948: FCC03818  frsp f6, f7
	ctx.f[6].f64 = (ctx.f[7].f64 as f32) as f64;
	// 831F594C: ECA66828  fsubs f5, f6, f13
	ctx.f[5].f64 = (((ctx.f[6].f64 - ctx.f[13].f64) as f32) as f64);
	// 831F5950: EC850332  fmuls f4, f5, f12
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F5954: EC640032  fmuls f3, f4, f0
	ctx.f[3].f64 = (((ctx.f[4].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F5958: D0690400  stfs f3, 0x400(r9)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 831F595C: 88CB0000  lbz r6, 0(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F5960: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 831F5964: F8C1FFF8  std r6, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[6].u64 ) };
	// 831F5968: C841FFF8  lfd f2, -8(r1)
	ctx.f[2].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F596C: FC20169C  fcfid f1, f2
	ctx.f[1].f64 = (ctx.f[2].s64 as f64);
	// 831F5970: FD400818  frsp f10, f1
	ctx.f[10].f64 = (ctx.f[1].f64 as f32) as f64;
	// 831F5974: ED2A6828  fsubs f9, f10, f13
	ctx.f[9].f64 = (((ctx.f[10].f64 - ctx.f[13].f64) as f32) as f64);
	// 831F5978: ED090332  fmuls f8, f9, f12
	ctx.f[8].f64 = (((ctx.f[9].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F597C: ECE80032  fmuls f7, f8, f0
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F5980: D0E90000  stfs f7, 0(r9)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F5984: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 831F5988: EC0B002A  fadds f0, f11, f0
	ctx.f[0].f64 = ((ctx.f[11].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F598C: 4082FF60  bne 0x831f58ec
	if !ctx.cr[0].eq {
	pc = 0x831F58EC; continue 'dispatch;
	}
	// 831F5990: 81430000  lwz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F5994: 8903000D  lbz r8, 0xd(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F5998: 7CEA5850  subf r7, r10, r11
	ctx.r[7].s64 = ctx.r[11].s64 - ctx.r[10].s64;
	// 831F599C: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F59A0: 0CC80000  twi 6, r8, 0
	// 831F59A4: 7D474396  divwu r10, r7, r8
	ctx.r[10].u32 = ctx.r[7].u32 / ctx.r[8].u32;
	// 831F59A8: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F59AC: 41980008  blt cr6, 0x831f59b4
	if ctx.cr[6].lt {
	pc = 0x831F59B4; continue 'dispatch;
	}
	// 831F59B0: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 831F59B4: 81630014  lwz r11, 0x14(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F59B8: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F59BC: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831F59C0: 7D4B4850  subf r10, r11, r9
	ctx.r[10].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 831F59C4: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F59C8: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F59CC: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F59D0: 4098000C  bge cr6, 0x831f59dc
	if !ctx.cr[6].lt {
		sub_831F59DC(ctx, base);
		return;
	}
	// 831F59D4: 9143001C  stw r10, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[10].u32 ) };
	// 831F59D8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F59DC(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831F59DC size=8
    let mut pc: u32 = 0x831F59DC;
    'dispatch: loop {
        match pc {
            0x831F59DC => {
    //   block [0x831F59DC..0x831F59E4)
	// 831F59DC: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F59E0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F59E8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F59E8 size=480
    let mut pc: u32 = 0x831F59E8;
    'dispatch: loop {
        match pc {
            0x831F59E8 => {
    //   block [0x831F59E8..0x831F5BC8)
	// 831F59E8: 81030008  lwz r8, 8(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F59EC: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F59F0: 88E3000D  lbz r7, 0xd(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F59F4: 80C3001C  lwz r6, 0x1c(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F59F8: 80A30004  lwz r5, 4(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F59FC: 7D4741D6  mullw r10, r7, r8
	ctx.r[10].s64 = (ctx.r[7].s32 as i64) * (ctx.r[8].s32 as i64);
	// 831F5A00: 80830018  lwz r4, 0x18(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F5A04: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F5A08: 81230014  lwz r9, 0x14(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F5A0C: 54C7103A  slwi r7, r6, 2
	ctx.r[7].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F5A10: 7D082850  subf r8, r8, r5
	ctx.r[8].s64 = ctx.r[5].s64 - ctx.r[8].s64;
	// 831F5A14: 7CC62050  subf r6, r6, r4
	ctx.r[6].s64 = ctx.r[4].s64 - ctx.r[6].s64;
	// 831F5A18: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831F5A1C: 7D474A14  add r10, r7, r9
	ctx.r[10].u64 = ctx.r[7].u64 + ctx.r[9].u64;
	// 831F5A20: 7F083000  cmpw cr6, r8, r6
	ctx.cr[6].compare_i32(ctx.r[8].s32, ctx.r[6].s32, &mut ctx.xer);
	// 831F5A24: 41980008  blt cr6, 0x831f5a2c
	if ctx.cr[6].lt {
	pc = 0x831F5A2C; continue 'dispatch;
	}
	// 831F5A28: 7CC83378  mr r8, r6
	ctx.r[8].u64 = ctx.r[6].u64;
	// 831F5A2C: 5507083C  slwi r7, r8, 1
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(1);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F5A30: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 831F5A34: 7CE83A14  add r7, r8, r7
	ctx.r[7].u64 = ctx.r[8].u64 + ctx.r[7].u64;
	// 831F5A38: 54E7083C  slwi r7, r7, 1
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shl(1);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F5A3C: 38A7007F  addi r5, r7, 0x7f
	ctx.r[5].s64 = ctx.r[7].s64 + 127;
	// 831F5A40: 54A7C9FE  srwi r7, r5, 7
	ctx.r[7].u32 = ctx.r[5].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F5A44: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 831F5A48: 419A0018  beq cr6, 0x831f5a60
	if ctx.cr[6].eq {
	pc = 0x831F5A60; continue 'dispatch;
	}
	// 831F5A4C: 55253830  slwi r5, r9, 7
	ctx.r[5].u32 = ctx.r[9].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831F5A50: 7C055A2C  dcbt r5, r11
	// 831F5A54: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 831F5A58: 7F093840  cmplw cr6, r9, r7
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831F5A5C: 4198FFF0  blt cr6, 0x831f5a4c
	if ctx.cr[6].lt {
	pc = 0x831F5A4C; continue 'dispatch;
	}
	// 831F5A60: 7CC907B4  extsw r9, r6
	ctx.r[9].s64 = ctx.r[6].s32 as i64;
	// 831F5A64: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F5A68: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F5A6C: 3CE0820D  lis r7, -0x7df3
	ctx.r[7].s64 = -2113077248;
	// 831F5A70: F921FFD0  std r9, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[9].u64 ) };
	// 831F5A74: C961FFD0  lfd f11, -0x30(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 831F5A78: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F5A7C: 3D208213  lis r9, -0x7ded
	ctx.r[9].s64 = -2112684032;
	// 831F5A80: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F5A84: C1A74E60  lfs f13, 0x4e60(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(20064 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F5A88: ED6C4824  fdivs f11, f12, f9
	ctx.f[11].f64 = ((ctx.f[12].f64 / ctx.f[9].f64) as f32) as f64;
	// 831F5A8C: C189B184  lfs f12, -0x4e7c(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-20092 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831F5A90: 88EB0005  lbz r7, 5(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(5 as u32) ) } as u64;
	// 831F5A94: 3508FFFF  addic. r8, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 831F5A98: F8E1FFD0  std r7, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[7].u64 ) };
	// 831F5A9C: C941FFD0  lfd f10, -0x30(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 831F5AA0: FD20569C  fcfid f9, f10
	ctx.f[9].f64 = (ctx.f[10].s64 as f64);
	// 831F5AA4: FD004818  frsp f8, f9
	ctx.f[8].f64 = (ctx.f[9].f64 as f32) as f64;
	// 831F5AA8: ECE86828  fsubs f7, f8, f13
	ctx.f[7].f64 = (((ctx.f[8].f64 - ctx.f[13].f64) as f32) as f64);
	// 831F5AAC: ECC70332  fmuls f6, f7, f12
	ctx.f[6].f64 = (((ctx.f[7].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F5AB0: ECA60032  fmuls f5, f6, f0
	ctx.f[5].f64 = (((ctx.f[6].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F5AB4: D0AA1400  stfs f5, 0x1400(r10)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(5120 as u32), tmp.u32 ) };
	// 831F5AB8: 88AB0004  lbz r5, 4(r11)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F5ABC: F8A1FFD8  std r5, -0x28(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), ctx.r[5].u64 ) };
	// 831F5AC0: C881FFD8  lfd f4, -0x28(r1)
	ctx.f[4].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-40 as u32) ) };
	// 831F5AC4: FC60269C  fcfid f3, f4
	ctx.f[3].f64 = (ctx.f[4].s64 as f64);
	// 831F5AC8: FC401818  frsp f2, f3
	ctx.f[2].f64 = (ctx.f[3].f64 as f32) as f64;
	// 831F5ACC: EC226828  fsubs f1, f2, f13
	ctx.f[1].f64 = (((ctx.f[2].f64 - ctx.f[13].f64) as f32) as f64);
	// 831F5AD0: ED410332  fmuls f10, f1, f12
	ctx.f[10].f64 = (((ctx.f[1].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F5AD4: ED2A0032  fmuls f9, f10, f0
	ctx.f[9].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F5AD8: D12A1000  stfs f9, 0x1000(r10)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4096 as u32), tmp.u32 ) };
	// 831F5ADC: 892B0003  lbz r9, 3(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(3 as u32) ) } as u64;
	// 831F5AE0: F921FFE0  std r9, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[9].u64 ) };
	// 831F5AE4: C901FFE0  lfd f8, -0x20(r1)
	ctx.f[8].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 831F5AE8: FCE0469C  fcfid f7, f8
	ctx.f[7].f64 = (ctx.f[8].s64 as f64);
	// 831F5AEC: FCC03818  frsp f6, f7
	ctx.f[6].f64 = (ctx.f[7].f64 as f32) as f64;
	// 831F5AF0: ECA66828  fsubs f5, f6, f13
	ctx.f[5].f64 = (((ctx.f[6].f64 - ctx.f[13].f64) as f32) as f64);
	// 831F5AF4: EC850332  fmuls f4, f5, f12
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F5AF8: EC640032  fmuls f3, f4, f0
	ctx.f[3].f64 = (((ctx.f[4].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F5AFC: D06A0C00  stfs f3, 0xc00(r10)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(3072 as u32), tmp.u32 ) };
	// 831F5B00: 88CB0002  lbz r6, 2(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(2 as u32) ) } as u64;
	// 831F5B04: F8C1FFE8  std r6, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[6].u64 ) };
	// 831F5B08: C841FFE8  lfd f2, -0x18(r1)
	ctx.f[2].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831F5B0C: FC20169C  fcfid f1, f2
	ctx.f[1].f64 = (ctx.f[2].s64 as f64);
	// 831F5B10: FD400818  frsp f10, f1
	ctx.f[10].f64 = (ctx.f[1].f64 as f32) as f64;
	// 831F5B14: ED2A6828  fsubs f9, f10, f13
	ctx.f[9].f64 = (((ctx.f[10].f64 - ctx.f[13].f64) as f32) as f64);
	// 831F5B18: ED090332  fmuls f8, f9, f12
	ctx.f[8].f64 = (((ctx.f[9].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F5B1C: ECE80032  fmuls f7, f8, f0
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F5B20: D0EA0800  stfs f7, 0x800(r10)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(2048 as u32), tmp.u32 ) };
	// 831F5B24: 888B0001  lbz r4, 1(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(1 as u32) ) } as u64;
	// 831F5B28: F881FFF0  std r4, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[4].u64 ) };
	// 831F5B2C: C8C1FFF0  lfd f6, -0x10(r1)
	ctx.f[6].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831F5B30: FCA0369C  fcfid f5, f6
	ctx.f[5].f64 = (ctx.f[6].s64 as f64);
	// 831F5B34: FC802818  frsp f4, f5
	ctx.f[4].f64 = (ctx.f[5].f64 as f32) as f64;
	// 831F5B38: EC646828  fsubs f3, f4, f13
	ctx.f[3].f64 = (((ctx.f[4].f64 - ctx.f[13].f64) as f32) as f64);
	// 831F5B3C: EC430332  fmuls f2, f3, f12
	ctx.f[2].f64 = (((ctx.f[3].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F5B40: EC220032  fmuls f1, f2, f0
	ctx.f[1].f64 = (((ctx.f[2].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F5B44: D02A0400  stfs f1, 0x400(r10)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 831F5B48: 88EB0000  lbz r7, 0(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F5B4C: 396B0006  addi r11, r11, 6
	ctx.r[11].s64 = ctx.r[11].s64 + 6;
	// 831F5B50: F8E1FFF8  std r7, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[7].u64 ) };
	// 831F5B54: C941FFF8  lfd f10, -8(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F5B58: FD20569C  fcfid f9, f10
	ctx.f[9].f64 = (ctx.f[10].s64 as f64);
	// 831F5B5C: FD004818  frsp f8, f9
	ctx.f[8].f64 = (ctx.f[9].f64 as f32) as f64;
	// 831F5B60: ECE86828  fsubs f7, f8, f13
	ctx.f[7].f64 = (((ctx.f[8].f64 - ctx.f[13].f64) as f32) as f64);
	// 831F5B64: ECC70332  fmuls f6, f7, f12
	ctx.f[6].f64 = (((ctx.f[7].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F5B68: ECA60032  fmuls f5, f6, f0
	ctx.f[5].f64 = (((ctx.f[6].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F5B6C: D0AA0000  stfs f5, 0(r10)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F5B70: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 831F5B74: EC0B002A  fadds f0, f11, f0
	ctx.f[0].f64 = ((ctx.f[11].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F5B78: 4082FF18  bne 0x831f5a90
	if !ctx.cr[0].eq {
	pc = 0x831F5A90; continue 'dispatch;
	}
	// 831F5B7C: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F5B80: 8903000D  lbz r8, 0xd(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F5B84: 7CE95850  subf r7, r9, r11
	ctx.r[7].s64 = ctx.r[11].s64 - ctx.r[9].s64;
	// 831F5B88: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F5B8C: 0CC80000  twi 6, r8, 0
	// 831F5B90: 7D274396  divwu r9, r7, r8
	ctx.r[9].u32 = ctx.r[7].u32 / ctx.r[8].u32;
	// 831F5B94: 7F095840  cmplw cr6, r9, r11
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F5B98: 41980008  blt cr6, 0x831f5ba0
	if ctx.cr[6].lt {
	pc = 0x831F5BA0; continue 'dispatch;
	}
	// 831F5B9C: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 831F5BA0: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F5BA4: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F5BA8: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F5BAC: 7CE85050  subf r7, r8, r10
	ctx.r[7].s64 = ctx.r[10].s64 - ctx.r[8].s64;
	// 831F5BB0: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 831F5BB4: 54EAF0BE  srwi r10, r7, 2
	ctx.r[10].u32 = ctx.r[7].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F5BB8: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F5BBC: 4098000C  bge cr6, 0x831f5bc8
	if !ctx.cr[6].lt {
		sub_831F5BC8(ctx, base);
		return;
	}
	// 831F5BC0: 9143001C  stw r10, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[10].u32 ) };
	// 831F5BC4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F5BC8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831F5BC8 size=8
    let mut pc: u32 = 0x831F5BC8;
    'dispatch: loop {
        match pc {
            0x831F5BC8 => {
    //   block [0x831F5BC8..0x831F5BD0)
	// 831F5BC8: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F5BCC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F5BD0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F5BD0 size=332
    let mut pc: u32 = 0x831F5BD0;
    'dispatch: loop {
        match pc {
            0x831F5BD0 => {
    //   block [0x831F5BD0..0x831F5D1C)
	// 831F5BD0: FBC1FFF0  std r30, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[30].u64 ) };
	// 831F5BD4: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 831F5BD8: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F5BDC: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F5BE0: 88A3000D  lbz r5, 0xd(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F5BE4: 8083001C  lwz r4, 0x1c(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F5BE8: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F5BEC: 7D0559D6  mullw r8, r5, r11
	ctx.r[8].s64 = (ctx.r[5].s32 as i64) * (ctx.r[11].s32 as i64);
	// 831F5BF0: 83E30018  lwz r31, 0x18(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F5BF4: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F5BF8: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F5BFC: 7D4B5050  subf r10, r11, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 831F5C00: 5486103A  slwi r6, r4, 2
	ctx.r[6].u32 = ctx.r[4].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831F5C04: 5508083C  slwi r8, r8, 1
	ctx.r[8].u32 = ctx.r[8].u32.wrapping_shl(1);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831F5C08: 7D64F850  subf r11, r4, r31
	ctx.r[11].s64 = ctx.r[31].s64 - ctx.r[4].s64;
	// 831F5C0C: 7CE63A14  add r7, r6, r7
	ctx.r[7].u64 = ctx.r[6].u64 + ctx.r[7].u64;
	// 831F5C10: 7D084A14  add r8, r8, r9
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[9].u64;
	// 831F5C14: 7F0A5800  cmpw cr6, r10, r11
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[11].s32, &mut ctx.xer);
	// 831F5C18: 7D465378  mr r6, r10
	ctx.r[6].u64 = ctx.r[10].u64;
	// 831F5C1C: 41980008  blt cr6, 0x831f5c24
	if ctx.cr[6].lt {
	pc = 0x831F5C24; continue 'dispatch;
	}
	// 831F5C20: 7D665B78  mr r6, r11
	ctx.r[6].u64 = ctx.r[11].u64;
	// 831F5C24: 7D6B07B4  extsw r11, r11
	ctx.r[11].s64 = ctx.r[11].s32 as i64;
	// 831F5C28: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F5C2C: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F5C30: 54A4083C  slwi r4, r5, 1
	ctx.r[4].u32 = ctx.r[5].u32.wrapping_shl(1);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 831F5C34: F961FFE0  std r11, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[11].u64 ) };
	// 831F5C38: C961FFE0  lfd f11, -0x20(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 831F5C3C: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F5C40: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 831F5C44: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F5C48: C1AB7490  lfs f13, 0x7490(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(29840 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F5C4C: ED8C4824  fdivs f12, f12, f9
	ctx.f[12].f64 = ((ctx.f[12].f64 / ctx.f[9].f64) as f32) as f64;
	// 831F5C50: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 831F5C54: 419A004C  beq cr6, 0x831f5ca0
	if ctx.cr[6].eq {
	pc = 0x831F5CA0; continue 'dispatch;
	}
	// 831F5C58: 7CE93B78  mr r9, r7
	ctx.r[9].u64 = ctx.r[7].u64;
	// 831F5C5C: 7D0A4378  mr r10, r8
	ctx.r[10].u64 = ctx.r[8].u64;
	// 831F5C60: 7CAB2B78  mr r11, r5
	ctx.r[11].u64 = ctx.r[5].u64;
	// 831F5C64: A3EA0000  lhz r31, 0(r10)
	ctx.r[31].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F5C68: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831F5C6C: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 831F5C70: 57FEC63E  rlwinm r30, r31, 0x18, 0x18, 0x1f
	ctx.r[30].u64 = ctx.r[31].u32 as u64 & 0x000000FFu64;
	// 831F5C74: 53FE442E  rlwimi r30, r31, 8, 0x10, 0x17
	ctx.r[30].u64 = (((ctx.r[31].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[30].u64 & 0xFFFFFFFFFFFF00FF);
	// 831F5C78: 7FDF0734  extsh r31, r30
	ctx.r[31].s64 = ctx.r[30].s16 as i64;
	// 831F5C7C: FBE1FFE0  std r31, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[31].u64 ) };
	// 831F5C80: C961FFE0  lfd f11, -0x20(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 831F5C84: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F5C88: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F5C8C: ED090372  fmuls f8, f9, f13
	ctx.f[8].f64 = (((ctx.f[9].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F5C90: ECE80032  fmuls f7, f8, f0
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F5C94: D0E90000  stfs f7, 0(r9)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F5C98: 39290400  addi r9, r9, 0x400
	ctx.r[9].s64 = ctx.r[9].s64 + 1024;
	// 831F5C9C: 4082FFC8  bne 0x831f5c64
	if !ctx.cr[0].eq {
	pc = 0x831F5C64; continue 'dispatch;
	}
	// 831F5CA0: 34C6FFFF  addic. r6, r6, -1
	ctx.xer.ca = (ctx.r[6].u32 > (!(-1 as u32)));
	ctx.r[6].s64 = ctx.r[6].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[6].s32, 0, &mut ctx.xer);
	// 831F5CA4: EC0C002A  fadds f0, f12, f0
	ctx.f[0].f64 = ((ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F5CA8: 7D044214  add r8, r4, r8
	ctx.r[8].u64 = ctx.r[4].u64 + ctx.r[8].u64;
	// 831F5CAC: 38E70004  addi r7, r7, 4
	ctx.r[7].s64 = ctx.r[7].s64 + 4;
	// 831F5CB0: 4082FFA0  bne 0x831f5c50
	if !ctx.cr[0].eq {
	pc = 0x831F5C50; continue 'dispatch;
	}
	// 831F5CB4: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F5CB8: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F5CBC: 7D2B4050  subf r9, r11, r8
	ctx.r[9].s64 = ctx.r[8].s64 - ctx.r[11].s64;
	// 831F5CC0: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F5CC4: 5548083E  rotlwi r8, r10, 1
	ctx.r[8].u64 = ((ctx.r[10].u32).rotate_left(1)) as u64;
	// 831F5CC8: 7D494396  divwu r10, r9, r8
	ctx.r[10].u32 = ctx.r[9].u32 / ctx.r[8].u32;
	// 831F5CCC: 0CC80000  twi 6, r8, 0
	// 831F5CD0: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F5CD4: 41980008  blt cr6, 0x831f5cdc
	if ctx.cr[6].lt {
	pc = 0x831F5CDC; continue 'dispatch;
	}
	// 831F5CD8: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 831F5CDC: 81630014  lwz r11, 0x14(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F5CE0: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F5CE4: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831F5CE8: 7D4B3850  subf r10, r11, r7
	ctx.r[10].s64 = ctx.r[7].s64 - ctx.r[11].s64;
	// 831F5CEC: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F5CF0: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F5CF4: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F5CF8: 40980014  bge cr6, 0x831f5d0c
	if !ctx.cr[6].lt {
	pc = 0x831F5D0C; continue 'dispatch;
	}
	// 831F5CFC: 9143001C  stw r10, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[10].u32 ) };
	// 831F5D00: EBC1FFF0  ld r30, -0x10(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831F5D04: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F5D08: 4E800020  blr
	return;
	// 831F5D0C: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F5D10: EBC1FFF0  ld r30, -0x10(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831F5D14: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F5D18: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F5D20(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F5D20 size=324
    let mut pc: u32 = 0x831F5D20;
    'dispatch: loop {
        match pc {
            0x831F5D20 => {
    //   block [0x831F5D20..0x831F5E64)
	// 831F5D20: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 831F5D24: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F5D28: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F5D2C: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F5D30: 80C3001C  lwz r6, 0x1c(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F5D34: 7C8A59D6  mullw r4, r10, r11
	ctx.r[4].s64 = (ctx.r[10].s32 as i64) * (ctx.r[11].s32 as i64);
	// 831F5D38: 80A30004  lwz r5, 4(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F5D3C: 83E30018  lwz r31, 0x18(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F5D40: 81430000  lwz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F5D44: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F5D48: 5489083C  slwi r9, r4, 1
	ctx.r[9].u32 = ctx.r[4].u32.wrapping_shl(1);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831F5D4C: 54C7103A  slwi r7, r6, 2
	ctx.r[7].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F5D50: 7D6B2850  subf r11, r11, r5
	ctx.r[11].s64 = ctx.r[5].s64 - ctx.r[11].s64;
	// 831F5D54: 7CC6F850  subf r6, r6, r31
	ctx.r[6].s64 = ctx.r[31].s64 - ctx.r[6].s64;
	// 831F5D58: 7D495214  add r10, r9, r10
	ctx.r[10].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 831F5D5C: 7CE74214  add r7, r7, r8
	ctx.r[7].u64 = ctx.r[7].u64 + ctx.r[8].u64;
	// 831F5D60: 7F0B3000  cmpw cr6, r11, r6
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[6].s32, &mut ctx.xer);
	// 831F5D64: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 831F5D68: 41980008  blt cr6, 0x831f5d70
	if ctx.cr[6].lt {
	pc = 0x831F5D70; continue 'dispatch;
	}
	// 831F5D6C: 7CC93378  mr r9, r6
	ctx.r[9].u64 = ctx.r[6].u64;
	// 831F5D70: 5528083C  slwi r8, r9, 1
	ctx.r[8].u32 = ctx.r[9].u32.wrapping_shl(1);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831F5D74: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831F5D78: 3908007F  addi r8, r8, 0x7f
	ctx.r[8].s64 = ctx.r[8].s64 + 127;
	// 831F5D7C: 5508C9FE  srwi r8, r8, 7
	ctx.r[8].u32 = ctx.r[8].u32.wrapping_shr(7);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831F5D80: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 831F5D84: 419A0018  beq cr6, 0x831f5d9c
	if ctx.cr[6].eq {
	pc = 0x831F5D9C; continue 'dispatch;
	}
	// 831F5D88: 55653830  slwi r5, r11, 7
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831F5D8C: 7C05522C  dcbt r5, r10
	// 831F5D90: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831F5D94: 7F0B4040  cmplw cr6, r11, r8
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831F5D98: 4198FFF0  blt cr6, 0x831f5d88
	if ctx.cr[6].lt {
	pc = 0x831F5D88; continue 'dispatch;
	}
	// 831F5D9C: 7CCB07B4  extsw r11, r6
	ctx.r[11].s64 = ctx.r[6].s32 as i64;
	// 831F5DA0: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F5DA4: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F5DA8: F961FFF0  std r11, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[11].u64 ) };
	// 831F5DAC: C961FFF0  lfd f11, -0x10(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831F5DB0: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F5DB4: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 831F5DB8: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F5DBC: C1AB7490  lfs f13, 0x7490(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(29840 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F5DC0: ED8C4824  fdivs f12, f12, f9
	ctx.f[12].f64 = ((ctx.f[12].f64 / ctx.f[9].f64) as f32) as f64;
	// 831F5DC4: A16A0000  lhz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F5DC8: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831F5DCC: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 831F5DD0: 5568C63E  rlwinm r8, r11, 0x18, 0x18, 0x1f
	ctx.r[8].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 831F5DD4: 5168442E  rlwimi r8, r11, 8, 0x10, 0x17
	ctx.r[8].u64 = (((ctx.r[11].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[8].u64 & 0xFFFFFFFFFFFF00FF);
	// 831F5DD8: 7D050734  extsh r5, r8
	ctx.r[5].s64 = ctx.r[8].s16 as i64;
	// 831F5DDC: F8A1FFF0  std r5, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[5].u64 ) };
	// 831F5DE0: C961FFF0  lfd f11, -0x10(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831F5DE4: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F5DE8: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F5DEC: ED090372  fmuls f8, f9, f13
	ctx.f[8].f64 = (((ctx.f[9].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F5DF0: ECE80032  fmuls f7, f8, f0
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F5DF4: D0E70000  stfs f7, 0(r7)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F5DF8: 38E70004  addi r7, r7, 4
	ctx.r[7].s64 = ctx.r[7].s64 + 4;
	// 831F5DFC: EC0C002A  fadds f0, f12, f0
	ctx.f[0].f64 = ((ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F5E00: 4082FFC4  bne 0x831f5dc4
	if !ctx.cr[0].eq {
	pc = 0x831F5DC4; continue 'dispatch;
	}
	// 831F5E04: 8963000D  lbz r11, 0xd(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F5E08: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F5E0C: 5568083E  rotlwi r8, r11, 1
	ctx.r[8].u64 = ((ctx.r[11].u32).rotate_left(1)) as u64;
	// 831F5E10: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F5E14: 7CC95050  subf r6, r9, r10
	ctx.r[6].s64 = ctx.r[10].s64 - ctx.r[9].s64;
	// 831F5E18: 0CC80000  twi 6, r8, 0
	// 831F5E1C: 7D464396  divwu r10, r6, r8
	ctx.r[10].u32 = ctx.r[6].u32 / ctx.r[8].u32;
	// 831F5E20: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F5E24: 41980008  blt cr6, 0x831f5e2c
	if ctx.cr[6].lt {
	pc = 0x831F5E2C; continue 'dispatch;
	}
	// 831F5E28: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 831F5E2C: 81630014  lwz r11, 0x14(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F5E30: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F5E34: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831F5E38: 7D4B3850  subf r10, r11, r7
	ctx.r[10].s64 = ctx.r[7].s64 - ctx.r[11].s64;
	// 831F5E3C: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F5E40: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F5E44: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F5E48: 40980010  bge cr6, 0x831f5e58
	if !ctx.cr[6].lt {
	pc = 0x831F5E58; continue 'dispatch;
	}
	// 831F5E4C: 9143001C  stw r10, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[10].u32 ) };
	// 831F5E50: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F5E54: 4E800020  blr
	return;
	// 831F5E58: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F5E5C: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F5E60: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F5E68(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F5E68 size=368
    let mut pc: u32 = 0x831F5E68;
    'dispatch: loop {
        match pc {
            0x831F5E68 => {
    //   block [0x831F5E68..0x831F5FD8)
	// 831F5E68: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 831F5E6C: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F5E70: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F5E74: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F5E78: 80C3001C  lwz r6, 0x1c(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F5E7C: 7C8951D6  mullw r4, r9, r10
	ctx.r[4].s64 = (ctx.r[9].s32 as i64) * (ctx.r[10].s32 as i64);
	// 831F5E80: 80A30004  lwz r5, 4(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F5E84: 83E30018  lwz r31, 0x18(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F5E88: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F5E8C: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F5E90: 5489083C  slwi r9, r4, 1
	ctx.r[9].u32 = ctx.r[4].u32.wrapping_shl(1);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831F5E94: 54C7103A  slwi r7, r6, 2
	ctx.r[7].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F5E98: 7D4A2850  subf r10, r10, r5
	ctx.r[10].s64 = ctx.r[5].s64 - ctx.r[10].s64;
	// 831F5E9C: 7CC6F850  subf r6, r6, r31
	ctx.r[6].s64 = ctx.r[31].s64 - ctx.r[6].s64;
	// 831F5EA0: 7D695A14  add r11, r9, r11
	ctx.r[11].u64 = ctx.r[9].u64 + ctx.r[11].u64;
	// 831F5EA4: 7D074214  add r8, r7, r8
	ctx.r[8].u64 = ctx.r[7].u64 + ctx.r[8].u64;
	// 831F5EA8: 7F0A3000  cmpw cr6, r10, r6
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[6].s32, &mut ctx.xer);
	// 831F5EAC: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 831F5EB0: 41980008  blt cr6, 0x831f5eb8
	if ctx.cr[6].lt {
	pc = 0x831F5EB8; continue 'dispatch;
	}
	// 831F5EB4: 7CC93378  mr r9, r6
	ctx.r[9].u64 = ctx.r[6].u64;
	// 831F5EB8: 5527103A  slwi r7, r9, 2
	ctx.r[7].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F5EBC: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831F5EC0: 38E7007F  addi r7, r7, 0x7f
	ctx.r[7].s64 = ctx.r[7].s64 + 127;
	// 831F5EC4: 54E7C9FE  srwi r7, r7, 7
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F5EC8: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 831F5ECC: 419A0018  beq cr6, 0x831f5ee4
	if ctx.cr[6].eq {
	pc = 0x831F5EE4; continue 'dispatch;
	}
	// 831F5ED0: 55453830  slwi r5, r10, 7
	ctx.r[5].u32 = ctx.r[10].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831F5ED4: 7C055A2C  dcbt r5, r11
	// 831F5ED8: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 831F5EDC: 7F0A3840  cmplw cr6, r10, r7
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831F5EE0: 4198FFF0  blt cr6, 0x831f5ed0
	if ctx.cr[6].lt {
	pc = 0x831F5ED0; continue 'dispatch;
	}
	// 831F5EE4: 7CCA07B4  extsw r10, r6
	ctx.r[10].s64 = ctx.r[6].s32 as i64;
	// 831F5EE8: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F5EEC: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F5EF0: F941FFE0  std r10, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[10].u64 ) };
	// 831F5EF4: C961FFE0  lfd f11, -0x20(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 831F5EF8: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F5EFC: 3D40820C  lis r10, -0x7df4
	ctx.r[10].s64 = -2113142784;
	// 831F5F00: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F5F04: C1AA7490  lfs f13, 0x7490(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(29840 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F5F08: ED8C4824  fdivs f12, f12, f9
	ctx.f[12].f64 = ((ctx.f[12].f64 / ctx.f[9].f64) as f32) as f64;
	// 831F5F0C: A14B0002  lhz r10, 2(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(2 as u32) ) } as u64;
	// 831F5F10: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831F5F14: 5547C63E  rlwinm r7, r10, 0x18, 0x18, 0x1f
	ctx.r[7].u64 = ctx.r[10].u32 as u64 & 0x000000FFu64;
	// 831F5F18: 5147442E  rlwimi r7, r10, 8, 0x10, 0x17
	ctx.r[7].u64 = (((ctx.r[10].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[7].u64 & 0xFFFFFFFFFFFF00FF);
	// 831F5F1C: 7CE50734  extsh r5, r7
	ctx.r[5].s64 = ctx.r[7].s16 as i64;
	// 831F5F20: F8A1FFE0  std r5, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[5].u64 ) };
	// 831F5F24: C961FFE0  lfd f11, -0x20(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 831F5F28: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F5F2C: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F5F30: ED090372  fmuls f8, f9, f13
	ctx.f[8].f64 = (((ctx.f[9].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F5F34: ECE80032  fmuls f7, f8, f0
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F5F38: D0E80400  stfs f7, 0x400(r8)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 831F5F3C: A08B0000  lhz r4, 0(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F5F40: 548AC63E  rlwinm r10, r4, 0x18, 0x18, 0x1f
	ctx.r[10].u64 = ctx.r[4].u32 as u64 & 0x000000FFu64;
	// 831F5F44: 508A442E  rlwimi r10, r4, 8, 0x10, 0x17
	ctx.r[10].u64 = (((ctx.r[4].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[10].u64 & 0xFFFFFFFFFFFF00FF);
	// 831F5F48: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 831F5F4C: 7D460734  extsh r6, r10
	ctx.r[6].s64 = ctx.r[10].s16 as i64;
	// 831F5F50: F8C1FFE8  std r6, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[6].u64 ) };
	// 831F5F54: C8C1FFE8  lfd f6, -0x18(r1)
	ctx.f[6].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831F5F58: FCA0369C  fcfid f5, f6
	ctx.f[5].f64 = (ctx.f[6].s64 as f64);
	// 831F5F5C: FC802818  frsp f4, f5
	ctx.f[4].f64 = (ctx.f[5].f64 as f32) as f64;
	// 831F5F60: EC640372  fmuls f3, f4, f13
	ctx.f[3].f64 = (((ctx.f[4].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F5F64: EC430032  fmuls f2, f3, f0
	ctx.f[2].f64 = (((ctx.f[3].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F5F68: D0480000  stfs f2, 0(r8)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F5F6C: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 831F5F70: EC0C002A  fadds f0, f12, f0
	ctx.f[0].f64 = ((ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F5F74: 4082FF98  bne 0x831f5f0c
	if !ctx.cr[0].eq {
	pc = 0x831F5F0C; continue 'dispatch;
	}
	// 831F5F78: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F5F7C: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F5F80: 5547083E  rotlwi r7, r10, 1
	ctx.r[7].u64 = ((ctx.r[10].u32).rotate_left(1)) as u64;
	// 831F5F84: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F5F88: 7CC95850  subf r6, r9, r11
	ctx.r[6].s64 = ctx.r[11].s64 - ctx.r[9].s64;
	// 831F5F8C: 0CC70000  twi 6, r7, 0
	// 831F5F90: 7D663B96  divwu r11, r6, r7
	ctx.r[11].u32 = ctx.r[6].u32 / ctx.r[7].u32;
	// 831F5F94: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831F5F98: 40980008  bge cr6, 0x831f5fa0
	if !ctx.cr[6].lt {
	pc = 0x831F5FA0; continue 'dispatch;
	}
	// 831F5F9C: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 831F5FA0: 81630014  lwz r11, 0x14(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F5FA4: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F5FA8: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831F5FAC: 7D4B4050  subf r10, r11, r8
	ctx.r[10].s64 = ctx.r[8].s64 - ctx.r[11].s64;
	// 831F5FB0: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F5FB4: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F5FB8: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F5FBC: 40980010  bge cr6, 0x831f5fcc
	if !ctx.cr[6].lt {
	pc = 0x831F5FCC; continue 'dispatch;
	}
	// 831F5FC0: 9143001C  stw r10, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[10].u32 ) };
	// 831F5FC4: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F5FC8: 4E800020  blr
	return;
	// 831F5FCC: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F5FD0: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F5FD4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F5FD8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F5FD8 size=456
    let mut pc: u32 = 0x831F5FD8;
    'dispatch: loop {
        match pc {
            0x831F5FD8 => {
    //   block [0x831F5FD8..0x831F61A0)
	// 831F5FD8: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 831F5FDC: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F5FE0: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F5FE4: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F5FE8: 80C3001C  lwz r6, 0x1c(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F5FEC: 7CA951D6  mullw r5, r9, r10
	ctx.r[5].s64 = (ctx.r[9].s32 as i64) * (ctx.r[10].s32 as i64);
	// 831F5FF0: 80830004  lwz r4, 4(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F5FF4: 83E30018  lwz r31, 0x18(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F5FF8: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F5FFC: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F6000: 54A9083C  slwi r9, r5, 1
	ctx.r[9].u32 = ctx.r[5].u32.wrapping_shl(1);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831F6004: 54C7103A  slwi r7, r6, 2
	ctx.r[7].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F6008: 7D4A2050  subf r10, r10, r4
	ctx.r[10].s64 = ctx.r[4].s64 - ctx.r[10].s64;
	// 831F600C: 7CC6F850  subf r6, r6, r31
	ctx.r[6].s64 = ctx.r[31].s64 - ctx.r[6].s64;
	// 831F6010: 7D695A14  add r11, r9, r11
	ctx.r[11].u64 = ctx.r[9].u64 + ctx.r[11].u64;
	// 831F6014: 7D274214  add r9, r7, r8
	ctx.r[9].u64 = ctx.r[7].u64 + ctx.r[8].u64;
	// 831F6018: 7F0A3000  cmpw cr6, r10, r6
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[6].s32, &mut ctx.xer);
	// 831F601C: 7D485378  mr r8, r10
	ctx.r[8].u64 = ctx.r[10].u64;
	// 831F6020: 41980008  blt cr6, 0x831f6028
	if ctx.cr[6].lt {
	pc = 0x831F6028; continue 'dispatch;
	}
	// 831F6024: 7CC83378  mr r8, r6
	ctx.r[8].u64 = ctx.r[6].u64;
	// 831F6028: 55071838  slwi r7, r8, 3
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(3);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F602C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831F6030: 38E7007F  addi r7, r7, 0x7f
	ctx.r[7].s64 = ctx.r[7].s64 + 127;
	// 831F6034: 54E7C9FE  srwi r7, r7, 7
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F6038: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 831F603C: 419A0018  beq cr6, 0x831f6054
	if ctx.cr[6].eq {
	pc = 0x831F6054; continue 'dispatch;
	}
	// 831F6040: 55453830  slwi r5, r10, 7
	ctx.r[5].u32 = ctx.r[10].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831F6044: 7C055A2C  dcbt r5, r11
	// 831F6048: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 831F604C: 7F0A3840  cmplw cr6, r10, r7
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831F6050: 4198FFF0  blt cr6, 0x831f6040
	if ctx.cr[6].lt {
	pc = 0x831F6040; continue 'dispatch;
	}
	// 831F6054: 7CCA07B4  extsw r10, r6
	ctx.r[10].s64 = ctx.r[6].s32 as i64;
	// 831F6058: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F605C: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F6060: F941FFD0  std r10, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[10].u64 ) };
	// 831F6064: C961FFD0  lfd f11, -0x30(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 831F6068: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F606C: 3D40820C  lis r10, -0x7df4
	ctx.r[10].s64 = -2113142784;
	// 831F6070: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F6074: C1AA7490  lfs f13, 0x7490(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(29840 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F6078: ED8C4824  fdivs f12, f12, f9
	ctx.f[12].f64 = ((ctx.f[12].f64 / ctx.f[9].f64) as f32) as f64;
	// 831F607C: A14B0006  lhz r10, 6(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(6 as u32) ) } as u64;
	// 831F6080: 3508FFFF  addic. r8, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 831F6084: 5547C63E  rlwinm r7, r10, 0x18, 0x18, 0x1f
	ctx.r[7].u64 = ctx.r[10].u32 as u64 & 0x000000FFu64;
	// 831F6088: 5147442E  rlwimi r7, r10, 8, 0x10, 0x17
	ctx.r[7].u64 = (((ctx.r[10].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[7].u64 & 0xFFFFFFFFFFFF00FF);
	// 831F608C: 7CE50734  extsh r5, r7
	ctx.r[5].s64 = ctx.r[7].s16 as i64;
	// 831F6090: F8A1FFD0  std r5, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[5].u64 ) };
	// 831F6094: C961FFD0  lfd f11, -0x30(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 831F6098: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F609C: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F60A0: ED090372  fmuls f8, f9, f13
	ctx.f[8].f64 = (((ctx.f[9].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F60A4: ECE80032  fmuls f7, f8, f0
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F60A8: D0E90C00  stfs f7, 0xc00(r9)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(3072 as u32), tmp.u32 ) };
	// 831F60AC: A08B0004  lhz r4, 4(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F60B0: 548AC63E  rlwinm r10, r4, 0x18, 0x18, 0x1f
	ctx.r[10].u64 = ctx.r[4].u32 as u64 & 0x000000FFu64;
	// 831F60B4: 508A442E  rlwimi r10, r4, 8, 0x10, 0x17
	ctx.r[10].u64 = (((ctx.r[4].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[10].u64 & 0xFFFFFFFFFFFF00FF);
	// 831F60B8: 7D460734  extsh r6, r10
	ctx.r[6].s64 = ctx.r[10].s16 as i64;
	// 831F60BC: F8C1FFD8  std r6, -0x28(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), ctx.r[6].u64 ) };
	// 831F60C0: C8C1FFD8  lfd f6, -0x28(r1)
	ctx.f[6].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-40 as u32) ) };
	// 831F60C4: FCA0369C  fcfid f5, f6
	ctx.f[5].f64 = (ctx.f[6].s64 as f64);
	// 831F60C8: FC802818  frsp f4, f5
	ctx.f[4].f64 = (ctx.f[5].f64 as f32) as f64;
	// 831F60CC: EC640372  fmuls f3, f4, f13
	ctx.f[3].f64 = (((ctx.f[4].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F60D0: EC430032  fmuls f2, f3, f0
	ctx.f[2].f64 = (((ctx.f[3].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F60D4: D0490800  stfs f2, 0x800(r9)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(2048 as u32), tmp.u32 ) };
	// 831F60D8: A0AB0002  lhz r5, 2(r11)
	ctx.r[5].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(2 as u32) ) } as u64;
	// 831F60DC: 54A4C63E  rlwinm r4, r5, 0x18, 0x18, 0x1f
	ctx.r[4].u64 = ctx.r[5].u32 as u64 & 0x000000FFu64;
	// 831F60E0: 50A4442E  rlwimi r4, r5, 8, 0x10, 0x17
	ctx.r[4].u64 = (((ctx.r[5].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[4].u64 & 0xFFFFFFFFFFFF00FF);
	// 831F60E4: 7C870734  extsh r7, r4
	ctx.r[7].s64 = ctx.r[4].s16 as i64;
	// 831F60E8: F8E1FFE0  std r7, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[7].u64 ) };
	// 831F60EC: C821FFE0  lfd f1, -0x20(r1)
	ctx.f[1].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 831F60F0: FD600E9C  fcfid f11, f1
	ctx.f[11].f64 = (ctx.f[1].s64 as f64);
	// 831F60F4: FD405818  frsp f10, f11
	ctx.f[10].f64 = (ctx.f[11].f64 as f32) as f64;
	// 831F60F8: ED2A0372  fmuls f9, f10, f13
	ctx.f[9].f64 = (((ctx.f[10].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F60FC: ED090032  fmuls f8, f9, f0
	ctx.f[8].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F6100: D1090400  stfs f8, 0x400(r9)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 831F6104: A0CB0000  lhz r6, 0(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F6108: 54C5C63E  rlwinm r5, r6, 0x18, 0x18, 0x1f
	ctx.r[5].u64 = ctx.r[6].u32 as u64 & 0x000000FFu64;
	// 831F610C: 50C5442E  rlwimi r5, r6, 8, 0x10, 0x17
	ctx.r[5].u64 = (((ctx.r[6].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[5].u64 & 0xFFFFFFFFFFFF00FF);
	// 831F6110: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 831F6114: 7CAA0734  extsh r10, r5
	ctx.r[10].s64 = ctx.r[5].s16 as i64;
	// 831F6118: F941FFE8  std r10, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[10].u64 ) };
	// 831F611C: C8E1FFE8  lfd f7, -0x18(r1)
	ctx.f[7].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831F6120: FCC03E9C  fcfid f6, f7
	ctx.f[6].f64 = (ctx.f[7].s64 as f64);
	// 831F6124: FCA03018  frsp f5, f6
	ctx.f[5].f64 = (ctx.f[6].f64 as f32) as f64;
	// 831F6128: EC850372  fmuls f4, f5, f13
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F612C: EC640032  fmuls f3, f4, f0
	ctx.f[3].f64 = (((ctx.f[4].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F6130: D0690000  stfs f3, 0(r9)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F6134: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 831F6138: EC0C002A  fadds f0, f12, f0
	ctx.f[0].f64 = ((ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F613C: 4082FF40  bne 0x831f607c
	if !ctx.cr[0].eq {
	pc = 0x831F607C; continue 'dispatch;
	}
	// 831F6140: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F6144: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F6148: 5547083E  rotlwi r7, r10, 1
	ctx.r[7].u64 = ((ctx.r[10].u32).rotate_left(1)) as u64;
	// 831F614C: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F6150: 7CC85850  subf r6, r8, r11
	ctx.r[6].s64 = ctx.r[11].s64 - ctx.r[8].s64;
	// 831F6154: 0CC70000  twi 6, r7, 0
	// 831F6158: 7D663B96  divwu r11, r6, r7
	ctx.r[11].u32 = ctx.r[6].u32 / ctx.r[7].u32;
	// 831F615C: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831F6160: 40980008  bge cr6, 0x831f6168
	if !ctx.cr[6].lt {
	pc = 0x831F6168; continue 'dispatch;
	}
	// 831F6164: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 831F6168: 81630014  lwz r11, 0x14(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F616C: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F6170: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831F6174: 7D4B4850  subf r10, r11, r9
	ctx.r[10].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 831F6178: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F617C: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F6180: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F6184: 40980010  bge cr6, 0x831f6194
	if !ctx.cr[6].lt {
	pc = 0x831F6194; continue 'dispatch;
	}
	// 831F6188: 9143001C  stw r10, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[10].u32 ) };
	// 831F618C: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F6190: 4E800020  blr
	return;
	// 831F6194: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F6198: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F619C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F61A0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F61A0 size=548
    let mut pc: u32 = 0x831F61A0;
    'dispatch: loop {
        match pc {
            0x831F61A0 => {
    //   block [0x831F61A0..0x831F63C4)
	// 831F61A0: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 831F61A4: 81030008  lwz r8, 8(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F61A8: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F61AC: 88E3000D  lbz r7, 0xd(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F61B0: 80C3001C  lwz r6, 0x1c(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F61B4: 7CA741D6  mullw r5, r7, r8
	ctx.r[5].s64 = (ctx.r[7].s32 as i64) * (ctx.r[8].s32 as i64);
	// 831F61B8: 80830004  lwz r4, 4(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F61BC: 83E30018  lwz r31, 0x18(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F61C0: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F61C4: 81230014  lwz r9, 0x14(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F61C8: 54AA083C  slwi r10, r5, 1
	ctx.r[10].u32 = ctx.r[5].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F61CC: 54C7103A  slwi r7, r6, 2
	ctx.r[7].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F61D0: 7D082050  subf r8, r8, r4
	ctx.r[8].s64 = ctx.r[4].s64 - ctx.r[8].s64;
	// 831F61D4: 7CC6F850  subf r6, r6, r31
	ctx.r[6].s64 = ctx.r[31].s64 - ctx.r[6].s64;
	// 831F61D8: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831F61DC: 7D474A14  add r10, r7, r9
	ctx.r[10].u64 = ctx.r[7].u64 + ctx.r[9].u64;
	// 831F61E0: 7F083000  cmpw cr6, r8, r6
	ctx.cr[6].compare_i32(ctx.r[8].s32, ctx.r[6].s32, &mut ctx.xer);
	// 831F61E4: 41980008  blt cr6, 0x831f61ec
	if ctx.cr[6].lt {
	pc = 0x831F61EC; continue 'dispatch;
	}
	// 831F61E8: 7CC83378  mr r8, r6
	ctx.r[8].u64 = ctx.r[6].u64;
	// 831F61EC: 5507083C  slwi r7, r8, 1
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(1);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F61F0: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 831F61F4: 7CE83A14  add r7, r8, r7
	ctx.r[7].u64 = ctx.r[8].u64 + ctx.r[7].u64;
	// 831F61F8: 54E7103A  slwi r7, r7, 2
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F61FC: 38A7007F  addi r5, r7, 0x7f
	ctx.r[5].s64 = ctx.r[7].s64 + 127;
	// 831F6200: 54A7C9FE  srwi r7, r5, 7
	ctx.r[7].u32 = ctx.r[5].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F6204: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 831F6208: 419A0018  beq cr6, 0x831f6220
	if ctx.cr[6].eq {
	pc = 0x831F6220; continue 'dispatch;
	}
	// 831F620C: 55253830  slwi r5, r9, 7
	ctx.r[5].u32 = ctx.r[9].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831F6210: 7C055A2C  dcbt r5, r11
	// 831F6214: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 831F6218: 7F093840  cmplw cr6, r9, r7
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831F621C: 4198FFF0  blt cr6, 0x831f620c
	if ctx.cr[6].lt {
	pc = 0x831F620C; continue 'dispatch;
	}
	// 831F6220: 7CC907B4  extsw r9, r6
	ctx.r[9].s64 = ctx.r[6].s32 as i64;
	// 831F6224: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F6228: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F622C: F921FFC0  std r9, -0x40(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-64 as u32), ctx.r[9].u64 ) };
	// 831F6230: C961FFC0  lfd f11, -0x40(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-64 as u32) ) };
	// 831F6234: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F6238: 3D20820C  lis r9, -0x7df4
	ctx.r[9].s64 = -2113142784;
	// 831F623C: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F6240: C1A97490  lfs f13, 0x7490(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(29840 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F6244: ED8C4824  fdivs f12, f12, f9
	ctx.f[12].f64 = ((ctx.f[12].f64 / ctx.f[9].f64) as f32) as f64;
	// 831F6248: A12B000A  lhz r9, 0xa(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(10 as u32) ) } as u64;
	// 831F624C: 3508FFFF  addic. r8, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 831F6250: 5527C63E  rlwinm r7, r9, 0x18, 0x18, 0x1f
	ctx.r[7].u64 = ctx.r[9].u32 as u64 & 0x000000FFu64;
	// 831F6254: 5127442E  rlwimi r7, r9, 8, 0x10, 0x17
	ctx.r[7].u64 = (((ctx.r[9].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[7].u64 & 0xFFFFFFFFFFFF00FF);
	// 831F6258: 7CE50734  extsh r5, r7
	ctx.r[5].s64 = ctx.r[7].s16 as i64;
	// 831F625C: F8A1FFC0  std r5, -0x40(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-64 as u32), ctx.r[5].u64 ) };
	// 831F6260: C961FFC0  lfd f11, -0x40(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-64 as u32) ) };
	// 831F6264: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F6268: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F626C: ED090372  fmuls f8, f9, f13
	ctx.f[8].f64 = (((ctx.f[9].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F6270: ECE80032  fmuls f7, f8, f0
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F6274: D0EA1400  stfs f7, 0x1400(r10)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(5120 as u32), tmp.u32 ) };
	// 831F6278: A08B0008  lhz r4, 8(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F627C: 5489C63E  rlwinm r9, r4, 0x18, 0x18, 0x1f
	ctx.r[9].u64 = ctx.r[4].u32 as u64 & 0x000000FFu64;
	// 831F6280: 5089442E  rlwimi r9, r4, 8, 0x10, 0x17
	ctx.r[9].u64 = (((ctx.r[4].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[9].u64 & 0xFFFFFFFFFFFF00FF);
	// 831F6284: 7D260734  extsh r6, r9
	ctx.r[6].s64 = ctx.r[9].s16 as i64;
	// 831F6288: F8C1FFC8  std r6, -0x38(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-56 as u32), ctx.r[6].u64 ) };
	// 831F628C: C8C1FFC8  lfd f6, -0x38(r1)
	ctx.f[6].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-56 as u32) ) };
	// 831F6290: FCA0369C  fcfid f5, f6
	ctx.f[5].f64 = (ctx.f[6].s64 as f64);
	// 831F6294: FC802818  frsp f4, f5
	ctx.f[4].f64 = (ctx.f[5].f64 as f32) as f64;
	// 831F6298: EC640372  fmuls f3, f4, f13
	ctx.f[3].f64 = (((ctx.f[4].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F629C: EC430032  fmuls f2, f3, f0
	ctx.f[2].f64 = (((ctx.f[3].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F62A0: D04A1000  stfs f2, 0x1000(r10)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4096 as u32), tmp.u32 ) };
	// 831F62A4: A0AB0006  lhz r5, 6(r11)
	ctx.r[5].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(6 as u32) ) } as u64;
	// 831F62A8: 54A4C63E  rlwinm r4, r5, 0x18, 0x18, 0x1f
	ctx.r[4].u64 = ctx.r[5].u32 as u64 & 0x000000FFu64;
	// 831F62AC: 50A4442E  rlwimi r4, r5, 8, 0x10, 0x17
	ctx.r[4].u64 = (((ctx.r[5].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[4].u64 & 0xFFFFFFFFFFFF00FF);
	// 831F62B0: 7C870734  extsh r7, r4
	ctx.r[7].s64 = ctx.r[4].s16 as i64;
	// 831F62B4: F8E1FFD0  std r7, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[7].u64 ) };
	// 831F62B8: C821FFD0  lfd f1, -0x30(r1)
	ctx.f[1].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 831F62BC: FD600E9C  fcfid f11, f1
	ctx.f[11].f64 = (ctx.f[1].s64 as f64);
	// 831F62C0: FD405818  frsp f10, f11
	ctx.f[10].f64 = (ctx.f[11].f64 as f32) as f64;
	// 831F62C4: ED2A0372  fmuls f9, f10, f13
	ctx.f[9].f64 = (((ctx.f[10].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F62C8: ED090032  fmuls f8, f9, f0
	ctx.f[8].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F62CC: D10A0C00  stfs f8, 0xc00(r10)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(3072 as u32), tmp.u32 ) };
	// 831F62D0: A0CB0004  lhz r6, 4(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F62D4: 54C5C63E  rlwinm r5, r6, 0x18, 0x18, 0x1f
	ctx.r[5].u64 = ctx.r[6].u32 as u64 & 0x000000FFu64;
	// 831F62D8: 50C5442E  rlwimi r5, r6, 8, 0x10, 0x17
	ctx.r[5].u64 = (((ctx.r[6].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[5].u64 & 0xFFFFFFFFFFFF00FF);
	// 831F62DC: 7CA90734  extsh r9, r5
	ctx.r[9].s64 = ctx.r[5].s16 as i64;
	// 831F62E0: F921FFD8  std r9, -0x28(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), ctx.r[9].u64 ) };
	// 831F62E4: C8E1FFD8  lfd f7, -0x28(r1)
	ctx.f[7].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-40 as u32) ) };
	// 831F62E8: FCC03E9C  fcfid f6, f7
	ctx.f[6].f64 = (ctx.f[7].s64 as f64);
	// 831F62EC: FCA03018  frsp f5, f6
	ctx.f[5].f64 = (ctx.f[6].f64 as f32) as f64;
	// 831F62F0: EC850372  fmuls f4, f5, f13
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F62F4: EC640032  fmuls f3, f4, f0
	ctx.f[3].f64 = (((ctx.f[4].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F62F8: D06A0800  stfs f3, 0x800(r10)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(2048 as u32), tmp.u32 ) };
	// 831F62FC: A0EB0002  lhz r7, 2(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(2 as u32) ) } as u64;
	// 831F6300: 54E6C63E  rlwinm r6, r7, 0x18, 0x18, 0x1f
	ctx.r[6].u64 = ctx.r[7].u32 as u64 & 0x000000FFu64;
	// 831F6304: 50E6442E  rlwimi r6, r7, 8, 0x10, 0x17
	ctx.r[6].u64 = (((ctx.r[7].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[6].u64 & 0xFFFFFFFFFFFF00FF);
	// 831F6308: 7CC40734  extsh r4, r6
	ctx.r[4].s64 = ctx.r[6].s16 as i64;
	// 831F630C: F881FFE0  std r4, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[4].u64 ) };
	// 831F6310: C841FFE0  lfd f2, -0x20(r1)
	ctx.f[2].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 831F6314: FC20169C  fcfid f1, f2
	ctx.f[1].f64 = (ctx.f[2].s64 as f64);
	// 831F6318: FD600818  frsp f11, f1
	ctx.f[11].f64 = (ctx.f[1].f64 as f32) as f64;
	// 831F631C: ED4B0372  fmuls f10, f11, f13
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F6320: ED2A0032  fmuls f9, f10, f0
	ctx.f[9].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F6324: D12A0400  stfs f9, 0x400(r10)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 831F6328: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F632C: 5527C63E  rlwinm r7, r9, 0x18, 0x18, 0x1f
	ctx.r[7].u64 = ctx.r[9].u32 as u64 & 0x000000FFu64;
	// 831F6330: 5127442E  rlwimi r7, r9, 8, 0x10, 0x17
	ctx.r[7].u64 = (((ctx.r[9].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[7].u64 & 0xFFFFFFFFFFFF00FF);
	// 831F6334: 396B000C  addi r11, r11, 0xc
	ctx.r[11].s64 = ctx.r[11].s64 + 12;
	// 831F6338: 7CE50734  extsh r5, r7
	ctx.r[5].s64 = ctx.r[7].s16 as i64;
	// 831F633C: F8A1FFE8  std r5, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[5].u64 ) };
	// 831F6340: C901FFE8  lfd f8, -0x18(r1)
	ctx.f[8].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831F6344: FCE0469C  fcfid f7, f8
	ctx.f[7].f64 = (ctx.f[8].s64 as f64);
	// 831F6348: FCC03818  frsp f6, f7
	ctx.f[6].f64 = (ctx.f[7].f64 as f32) as f64;
	// 831F634C: ECA60372  fmuls f5, f6, f13
	ctx.f[5].f64 = (((ctx.f[6].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F6350: EC850032  fmuls f4, f5, f0
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F6354: D08A0000  stfs f4, 0(r10)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F6358: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 831F635C: EC0C002A  fadds f0, f12, f0
	ctx.f[0].f64 = ((ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F6360: 4082FEE8  bne 0x831f6248
	if !ctx.cr[0].eq {
	pc = 0x831F6248; continue 'dispatch;
	}
	// 831F6364: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F6368: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F636C: 5527083E  rotlwi r7, r9, 1
	ctx.r[7].u64 = ((ctx.r[9].u32).rotate_left(1)) as u64;
	// 831F6370: 81230004  lwz r9, 4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F6374: 7CC85850  subf r6, r8, r11
	ctx.r[6].s64 = ctx.r[11].s64 - ctx.r[8].s64;
	// 831F6378: 0CC70000  twi 6, r7, 0
	// 831F637C: 7D663B96  divwu r11, r6, r7
	ctx.r[11].u32 = ctx.r[6].u32 / ctx.r[7].u32;
	// 831F6380: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831F6384: 40980008  bge cr6, 0x831f638c
	if !ctx.cr[6].lt {
	pc = 0x831F638C; continue 'dispatch;
	}
	// 831F6388: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 831F638C: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F6390: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F6394: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F6398: 7CE85050  subf r7, r8, r10
	ctx.r[7].s64 = ctx.r[10].s64 - ctx.r[8].s64;
	// 831F639C: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 831F63A0: 54EAF0BE  srwi r10, r7, 2
	ctx.r[10].u32 = ctx.r[7].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F63A4: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F63A8: 40980010  bge cr6, 0x831f63b8
	if !ctx.cr[6].lt {
	pc = 0x831F63B8; continue 'dispatch;
	}
	// 831F63AC: 9143001C  stw r10, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[10].u32 ) };
	// 831F63B0: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F63B4: 4E800020  blr
	return;
	// 831F63B8: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F63BC: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F63C0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F63C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F63C8 size=400
    let mut pc: u32 = 0x831F63C8;
    'dispatch: loop {
        match pc {
            0x831F63C8 => {
    //   block [0x831F63C8..0x831F6558)
	// 831F63C8: FBC1FFF0  std r30, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[30].u64 ) };
	// 831F63CC: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 831F63D0: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F63D4: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F63D8: 81430018  lwz r10, 0x18(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F63DC: 3BE30034  addi r31, r3, 0x34
	ctx.r[31].s64 = ctx.r[3].s64 + 52;
	// 831F63E0: 5566103A  slwi r6, r11, 2
	ctx.r[6].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831F63E4: 80A30008  lwz r5, 8(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F63E8: 8883000D  lbz r4, 0xd(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F63EC: 7D6B5050  subf r11, r11, r10
	ctx.r[11].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 831F63F0: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F63F4: 7D0429D6  mullw r8, r4, r5
	ctx.r[8].s64 = (ctx.r[4].s32 as i64) * (ctx.r[5].s32 as i64);
	// 831F63F8: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F63FC: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F6400: 7D6B0E70  srawi r11, r11, 1
	ctx.xer.ca = (ctx.r[11].s32 < 0) && ((ctx.r[11].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[11].s64 = (ctx.r[11].s32 >> 1) as i64;
	// 831F6404: 7D455050  subf r10, r5, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[5].s64;
	// 831F6408: 5508103A  slwi r8, r8, 2
	ctx.r[8].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831F640C: 7D6B0194  addze r11, r11
	tmp.s64 = ctx.r[11].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[11].u32);
	ctx.r[11].s64 = tmp.s64;
	// 831F6410: 7CE63A14  add r7, r6, r7
	ctx.r[7].u64 = ctx.r[6].u64 + ctx.r[7].u64;
	// 831F6414: 7CA84A14  add r5, r8, r9
	ctx.r[5].u64 = ctx.r[8].u64 + ctx.r[9].u64;
	// 831F6418: 7F0A5800  cmpw cr6, r10, r11
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[11].s32, &mut ctx.xer);
	// 831F641C: 7D465378  mr r6, r10
	ctx.r[6].u64 = ctx.r[10].u64;
	// 831F6420: 41980008  blt cr6, 0x831f6428
	if ctx.cr[6].lt {
	pc = 0x831F6428; continue 'dispatch;
	}
	// 831F6424: 7D665B78  mr r6, r11
	ctx.r[6].u64 = ctx.r[11].u64;
	// 831F6428: 7D6B07B4  extsw r11, r11
	ctx.r[11].s64 = ctx.r[11].s32 as i64;
	// 831F642C: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F6430: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F6434: 3D408201  lis r10, -0x7dff
	ctx.r[10].s64 = -2113863680;
	// 831F6438: F961FFE0  std r11, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[11].u64 ) };
	// 831F643C: C961FFE0  lfd f11, -0x20(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 831F6440: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F6444: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 831F6448: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F644C: C1AA9524  lfs f13, -0x6adc(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-27356 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F6450: ED6C4824  fdivs f11, f12, f9
	ctx.f[11].f64 = ((ctx.f[12].f64 / ctx.f[9].f64) as f32) as f64;
	// 831F6454: ED4B0372  fmuls f10, f11, f13
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F6458: 419A0018  beq cr6, 0x831f6470
	if ctx.cr[6].eq {
	pc = 0x831F6470; continue 'dispatch;
	}
	// 831F645C: 7FEAFB78  mr r10, r31
	ctx.r[10].u64 = ctx.r[31].u64;
	// 831F6460: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 831F6464: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831F6468: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 831F646C: 4082FFF8  bne 0x831f6464
	if !ctx.cr[0].eq {
	pc = 0x831F6464; continue 'dispatch;
	}
	// 831F6470: 3D608201  lis r11, -0x7dff
	ctx.r[11].s64 = -2113863680;
	// 831F6474: 549E103A  slwi r30, r4, 2
	ctx.r[30].u32 = ctx.r[4].u32.wrapping_shl(2);
	ctx.r[30].u64 = ctx.r[30].u32 as u64;
	// 831F6478: C18B9450  lfs f12, -0x6bb0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-27568 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831F647C: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 831F6480: 419A004C  beq cr6, 0x831f64cc
	if ctx.cr[6].eq {
	pc = 0x831F64CC; continue 'dispatch;
	}
	// 831F6484: EDAB002A  fadds f13, f11, f0
	ctx.f[13].f64 = ((ctx.f[11].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F6488: 7CEA3B78  mr r10, r7
	ctx.r[10].u64 = ctx.r[7].u64;
	// 831F648C: 7FEBFB78  mr r11, r31
	ctx.r[11].u64 = ctx.r[31].u64;
	// 831F6490: 7D1F2850  subf r8, r31, r5
	ctx.r[8].s64 = ctx.r[5].s64 - ctx.r[31].s64;
	// 831F6494: 7C892378  mr r9, r4
	ctx.r[9].u64 = ctx.r[4].u64;
	// 831F6498: 7D285C2E  lfsx f9, r8, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[8].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831F649C: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831F64A0: C10B0000  lfs f8, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831F64A4: ECED0272  fmuls f7, f13, f9
	ctx.f[7].f64 = (((ctx.f[13].f64 * ctx.f[9].f64) as f32) as f64);
	// 831F64A8: ECC9402A  fadds f6, f9, f8
	ctx.f[6].f64 = ((ctx.f[9].f64 + ctx.f[8].f64) as f32) as f64;
	// 831F64AC: D12B0000  stfs f9, 0(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F64B0: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 831F64B4: ECA60032  fmuls f5, f6, f0
	ctx.f[5].f64 = (((ctx.f[6].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F64B8: EC850332  fmuls f4, f5, f12
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F64BC: D08A0000  stfs f4, 0(r10)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F64C0: D0EA0004  stfs f7, 4(r10)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831F64C4: 394A0400  addi r10, r10, 0x400
	ctx.r[10].s64 = ctx.r[10].s64 + 1024;
	// 831F64C8: 4082FFD0  bne 0x831f6498
	if !ctx.cr[0].eq {
	pc = 0x831F6498; continue 'dispatch;
	}
	// 831F64CC: 34C6FFFF  addic. r6, r6, -1
	ctx.xer.ca = (ctx.r[6].u32 > (!(-1 as u32)));
	ctx.r[6].s64 = ctx.r[6].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[6].s32, 0, &mut ctx.xer);
	// 831F64D0: EC0A002A  fadds f0, f10, f0
	ctx.f[0].f64 = ((ctx.f[10].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F64D4: 7CBE2A14  add r5, r30, r5
	ctx.r[5].u64 = ctx.r[30].u64 + ctx.r[5].u64;
	// 831F64D8: 38E70008  addi r7, r7, 8
	ctx.r[7].s64 = ctx.r[7].s64 + 8;
	// 831F64DC: 4082FFA0  bne 0x831f647c
	if !ctx.cr[0].eq {
	pc = 0x831F647C; continue 'dispatch;
	}
	// 831F64E0: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F64E4: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F64E8: 7D2B2850  subf r9, r11, r5
	ctx.r[9].s64 = ctx.r[5].s64 - ctx.r[11].s64;
	// 831F64EC: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F64F0: 5548103E  rotlwi r8, r10, 2
	ctx.r[8].u64 = ((ctx.r[10].u32).rotate_left(2)) as u64;
	// 831F64F4: 7D494396  divwu r10, r9, r8
	ctx.r[10].u32 = ctx.r[9].u32 / ctx.r[8].u32;
	// 831F64F8: 0CC80000  twi 6, r8, 0
	// 831F64FC: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F6500: 41980008  blt cr6, 0x831f6508
	if ctx.cr[6].lt {
	pc = 0x831F6508; continue 'dispatch;
	}
	// 831F6504: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 831F6508: 81630014  lwz r11, 0x14(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F650C: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831F6510: 7D4B3850  subf r10, r11, r7
	ctx.r[10].s64 = ctx.r[7].s64 - ctx.r[11].s64;
	// 831F6514: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F6518: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F651C: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F6520: 40980008  bge cr6, 0x831f6528
	if !ctx.cr[6].lt {
	pc = 0x831F6528; continue 'dispatch;
	}
	// 831F6524: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 831F6528: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F652C: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F6530: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 831F6534: 419A0018  beq cr6, 0x831f654c
	if ctx.cr[6].eq {
	pc = 0x831F654C; continue 'dispatch;
	}
	// 831F6538: 7FEAFB78  mr r10, r31
	ctx.r[10].u64 = ctx.r[31].u64;
	// 831F653C: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 831F6540: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831F6544: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 831F6548: 4082FFF8  bne 0x831f6540
	if !ctx.cr[0].eq {
	pc = 0x831F6540; continue 'dispatch;
	}
	// 831F654C: EBC1FFF0  ld r30, -0x10(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831F6550: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F6554: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F6558(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F6558 size=316
    let mut pc: u32 = 0x831F6558;
    'dispatch: loop {
        match pc {
            0x831F6558 => {
    //   block [0x831F6558..0x831F6694)
	// 831F6558: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F655C: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F6560: 81430018  lwz r10, 0x18(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F6564: 81230008  lwz r9, 8(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F6568: 5566103A  slwi r6, r11, 2
	ctx.r[6].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831F656C: 8903000D  lbz r8, 0xd(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F6570: 7CAB5050  subf r5, r11, r10
	ctx.r[5].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 831F6574: 80830004  lwz r4, 4(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F6578: 7D4849D6  mullw r10, r8, r9
	ctx.r[10].s64 = (ctx.r[8].s32 as i64) * (ctx.r[9].s32 as i64);
	// 831F657C: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F6580: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F6584: 7CA50E70  srawi r5, r5, 1
	ctx.xer.ca = (ctx.r[5].s32 < 0) && ((ctx.r[5].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[5].s64 = (ctx.r[5].s32 >> 1) as i64;
	// 831F6588: 5548103A  slwi r8, r10, 2
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831F658C: 7D292050  subf r9, r9, r4
	ctx.r[9].s64 = ctx.r[4].s64 - ctx.r[9].s64;
	// 831F6590: 7D450194  addze r10, r5
	tmp.s64 = ctx.r[5].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[5].u32);
	ctx.r[10].s64 = tmp.s64;
	// 831F6594: 7D685A14  add r11, r8, r11
	ctx.r[11].u64 = ctx.r[8].u64 + ctx.r[11].u64;
	// 831F6598: 7D063A14  add r8, r6, r7
	ctx.r[8].u64 = ctx.r[6].u64 + ctx.r[7].u64;
	// 831F659C: 7F095000  cmpw cr6, r9, r10
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[10].s32, &mut ctx.xer);
	// 831F65A0: 41980008  blt cr6, 0x831f65a8
	if ctx.cr[6].lt {
	pc = 0x831F65A8; continue 'dispatch;
	}
	// 831F65A4: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 831F65A8: 7D4707B4  extsw r7, r10
	ctx.r[7].s64 = ctx.r[10].s32 as i64;
	// 831F65AC: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F65B0: ED6D0028  fsubs f11, f13, f0
	ctx.f[11].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F65B4: 552A103A  slwi r10, r9, 2
	ctx.r[10].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F65B8: F8E1FFF0  std r7, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[7].u64 ) };
	// 831F65BC: C941FFF0  lfd f10, -0x10(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831F65C0: FD20569C  fcfid f9, f10
	ctx.f[9].f64 = (ctx.f[10].s64 as f64);
	// 831F65C4: 3CC08201  lis r6, -0x7dff
	ctx.r[6].s64 = -2113863680;
	// 831F65C8: FD004818  frsp f8, f9
	ctx.f[8].f64 = (ctx.f[9].f64 as f32) as f64;
	// 831F65CC: 38AA007F  addi r5, r10, 0x7f
	ctx.r[5].s64 = ctx.r[10].s64 + 127;
	// 831F65D0: C1869524  lfs f12, -0x6adc(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(-27356 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831F65D4: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831F65D8: 54A7C9FE  srwi r7, r5, 7
	ctx.r[7].u32 = ctx.r[5].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F65DC: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 831F65E0: EDAB4024  fdivs f13, f11, f8
	ctx.f[13].f64 = ((ctx.f[11].f64 / ctx.f[8].f64) as f32) as f64;
	// 831F65E4: ED8D0332  fmuls f12, f13, f12
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F65E8: 419A0018  beq cr6, 0x831f6600
	if ctx.cr[6].eq {
	pc = 0x831F6600; continue 'dispatch;
	}
	// 831F65EC: 55463830  slwi r6, r10, 7
	ctx.r[6].u32 = ctx.r[10].u32.wrapping_shl(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831F65F0: 7C065A2C  dcbt r6, r11
	// 831F65F4: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 831F65F8: 7F0A3840  cmplw cr6, r10, r7
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831F65FC: 4198FFF0  blt cr6, 0x831f65ec
	if ctx.cr[6].lt {
	pc = 0x831F65EC; continue 'dispatch;
	}
	// 831F6600: 3D408201  lis r10, -0x7dff
	ctx.r[10].s64 = -2113863680;
	// 831F6604: C16A9450  lfs f11, -0x6bb0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-27568 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831F6608: C14B0000  lfs f10, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831F660C: ED2D002A  fadds f9, f13, f0
	ctx.f[9].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F6610: C1030034  lfs f8, 0x34(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(52 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831F6614: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831F6618: ECEA402A  fadds f7, f10, f8
	ctx.f[7].f64 = ((ctx.f[10].f64 + ctx.f[8].f64) as f32) as f64;
	// 831F661C: D1430034  stfs f10, 0x34(r3)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 831F6620: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 831F6624: ECC902B2  fmuls f6, f9, f10
	ctx.f[6].f64 = (((ctx.f[9].f64 * ctx.f[10].f64) as f32) as f64);
	// 831F6628: ECA70032  fmuls f5, f7, f0
	ctx.f[5].f64 = (((ctx.f[7].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F662C: EC0C002A  fadds f0, f12, f0
	ctx.f[0].f64 = ((ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F6630: EC8502F2  fmuls f4, f5, f11
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[11].f64) as f32) as f64);
	// 831F6634: D0880000  stfs f4, 0(r8)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F6638: D0C80004  stfs f6, 4(r8)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831F663C: 39080008  addi r8, r8, 8
	ctx.r[8].s64 = ctx.r[8].s64 + 8;
	// 831F6640: 4082FFC8  bne 0x831f6608
	if !ctx.cr[0].eq {
	pc = 0x831F6608; continue 'dispatch;
	}
	// 831F6644: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F6648: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F664C: 5547103E  rotlwi r7, r10, 2
	ctx.r[7].u64 = ((ctx.r[10].u32).rotate_left(2)) as u64;
	// 831F6650: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F6654: 7CC95850  subf r6, r9, r11
	ctx.r[6].s64 = ctx.r[11].s64 - ctx.r[9].s64;
	// 831F6658: 0CC70000  twi 6, r7, 0
	// 831F665C: 7D663B96  divwu r11, r6, r7
	ctx.r[11].u32 = ctx.r[6].u32 / ctx.r[7].u32;
	// 831F6660: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831F6664: 40980008  bge cr6, 0x831f666c
	if !ctx.cr[6].lt {
	pc = 0x831F666C; continue 'dispatch;
	}
	// 831F6668: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 831F666C: 81630014  lwz r11, 0x14(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F6670: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F6674: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831F6678: 7D4B4050  subf r10, r11, r8
	ctx.r[10].s64 = ctx.r[8].s64 - ctx.r[11].s64;
	// 831F667C: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F6680: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F6684: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F6688: 4098000C  bge cr6, 0x831f6694
	if !ctx.cr[6].lt {
		sub_831F6694(ctx, base);
		return;
	}
	// 831F668C: 9143001C  stw r10, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[10].u32 ) };
	// 831F6690: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F6694(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831F6694 size=8
    let mut pc: u32 = 0x831F6694;
    'dispatch: loop {
        match pc {
            0x831F6694 => {
    //   block [0x831F6694..0x831F669C)
	// 831F6694: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F6698: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F66A0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F66A0 size=404
    let mut pc: u32 = 0x831F66A0;
    'dispatch: loop {
        match pc {
            0x831F66A0 => {
    //   block [0x831F66A0..0x831F6834)
	// 831F66A0: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 831F66A4: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F66A8: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F66AC: 81430018  lwz r10, 0x18(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F66B0: 38A30034  addi r5, r3, 0x34
	ctx.r[5].s64 = ctx.r[3].s64 + 52;
	// 831F66B4: 81230008  lwz r9, 8(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F66B8: 5566103A  slwi r6, r11, 2
	ctx.r[6].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831F66BC: 8903000D  lbz r8, 0xd(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F66C0: 7C8B5050  subf r4, r11, r10
	ctx.r[4].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 831F66C4: 83E30004  lwz r31, 4(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F66C8: 7D4849D6  mullw r10, r8, r9
	ctx.r[10].s64 = (ctx.r[8].s32 as i64) * (ctx.r[9].s32 as i64);
	// 831F66CC: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F66D0: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F66D4: 7C840E70  srawi r4, r4, 1
	ctx.xer.ca = (ctx.r[4].s32 < 0) && ((ctx.r[4].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[4].s64 = (ctx.r[4].s32 >> 1) as i64;
	// 831F66D8: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F66DC: 7D09F850  subf r8, r9, r31
	ctx.r[8].s64 = ctx.r[31].s64 - ctx.r[9].s64;
	// 831F66E0: 7D240194  addze r9, r4
	tmp.s64 = ctx.r[4].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[4].u32);
	ctx.r[9].s64 = tmp.s64;
	// 831F66E4: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831F66E8: 7D463A14  add r10, r6, r7
	ctx.r[10].u64 = ctx.r[6].u64 + ctx.r[7].u64;
	// 831F66EC: 7F084800  cmpw cr6, r8, r9
	ctx.cr[6].compare_i32(ctx.r[8].s32, ctx.r[9].s32, &mut ctx.xer);
	// 831F66F0: 41980008  blt cr6, 0x831f66f8
	if ctx.cr[6].lt {
	pc = 0x831F66F8; continue 'dispatch;
	}
	// 831F66F4: 7D284B78  mr r8, r9
	ctx.r[8].u64 = ctx.r[9].u64;
	// 831F66F8: 7D2707B4  extsw r7, r9
	ctx.r[7].s64 = ctx.r[9].s32 as i64;
	// 831F66FC: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F6700: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F6704: 55091838  slwi r9, r8, 3
	ctx.r[9].u32 = ctx.r[8].u32.wrapping_shl(3);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831F6708: F8E1FFF0  std r7, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[7].u64 ) };
	// 831F670C: C961FFF0  lfd f11, -0x10(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831F6710: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F6714: 3CC08201  lis r6, -0x7dff
	ctx.r[6].s64 = -2113863680;
	// 831F6718: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F671C: 3889007F  addi r4, r9, 0x7f
	ctx.r[4].s64 = ctx.r[9].s64 + 127;
	// 831F6720: C1A69524  lfs f13, -0x6adc(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(-27356 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F6724: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 831F6728: 5487C9FE  srwi r7, r4, 7
	ctx.r[7].u32 = ctx.r[4].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F672C: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 831F6730: ED8C4824  fdivs f12, f12, f9
	ctx.f[12].f64 = ((ctx.f[12].f64 / ctx.f[9].f64) as f32) as f64;
	// 831F6734: ED6C0372  fmuls f11, f12, f13
	ctx.f[11].f64 = (((ctx.f[12].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F6738: 419A0018  beq cr6, 0x831f6750
	if ctx.cr[6].eq {
	pc = 0x831F6750; continue 'dispatch;
	}
	// 831F673C: 55263830  slwi r6, r9, 7
	ctx.r[6].u32 = ctx.r[9].u32.wrapping_shl(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831F6740: 7C065A2C  dcbt r6, r11
	// 831F6744: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 831F6748: 7F093840  cmplw cr6, r9, r7
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831F674C: 4198FFF0  blt cr6, 0x831f673c
	if ctx.cr[6].lt {
	pc = 0x831F673C; continue 'dispatch;
	}
	// 831F6750: 7CA72B78  mr r7, r5
	ctx.r[7].u64 = ctx.r[5].u64;
	// 831F6754: 39200002  li r9, 2
	ctx.r[9].s64 = 2;
	// 831F6758: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831F675C: 38E70004  addi r7, r7, 4
	ctx.r[7].s64 = ctx.r[7].s64 + 4;
	// 831F6760: 4082FFF8  bne 0x831f6758
	if !ctx.cr[0].eq {
	pc = 0x831F6758; continue 'dispatch;
	}
	// 831F6764: 3D208201  lis r9, -0x7dff
	ctx.r[9].s64 = -2113863680;
	// 831F6768: C1A99450  lfs f13, -0x6bb0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-27568 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F676C: C14B0004  lfs f10, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831F6770: ED2C002A  fadds f9, f12, f0
	ctx.f[9].f64 = ((ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F6774: C1050004  lfs f8, 4(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831F6778: 3508FFFF  addic. r8, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 831F677C: ECEA402A  fadds f7, f10, f8
	ctx.f[7].f64 = ((ctx.f[10].f64 + ctx.f[8].f64) as f32) as f64;
	// 831F6780: D1450004  stfs f10, 4(r5)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831F6784: ECC902B2  fmuls f6, f9, f10
	ctx.f[6].f64 = (((ctx.f[9].f64 * ctx.f[10].f64) as f32) as f64);
	// 831F6788: ECA70032  fmuls f5, f7, f0
	ctx.f[5].f64 = (((ctx.f[7].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F678C: EC850372  fmuls f4, f5, f13
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F6790: D08A0400  stfs f4, 0x400(r10)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 831F6794: D0CA0404  stfs f6, 0x404(r10)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(1028 as u32), tmp.u32 ) };
	// 831F6798: C0250000  lfs f1, 0(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831F679C: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 831F67A0: EC4900F2  fmuls f2, f9, f3
	ctx.f[2].f64 = (((ctx.f[9].f64 * ctx.f[3].f64) as f32) as f64);
	// 831F67A4: ED43082A  fadds f10, f3, f1
	ctx.f[10].f64 = ((ctx.f[3].f64 + ctx.f[1].f64) as f32) as f64;
	// 831F67A8: D0650000  stfs f3, 0(r5)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F67AC: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 831F67B0: ED2A0032  fmuls f9, f10, f0
	ctx.f[9].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F67B4: EC0B002A  fadds f0, f11, f0
	ctx.f[0].f64 = ((ctx.f[11].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F67B8: ED090372  fmuls f8, f9, f13
	ctx.f[8].f64 = (((ctx.f[9].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F67BC: D10A0000  stfs f8, 0(r10)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F67C0: D04A0004  stfs f2, 4(r10)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831F67C4: 394A0008  addi r10, r10, 8
	ctx.r[10].s64 = ctx.r[10].s64 + 8;
	// 831F67C8: 4082FFA4  bne 0x831f676c
	if !ctx.cr[0].eq {
	pc = 0x831F676C; continue 'dispatch;
	}
	// 831F67CC: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F67D0: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F67D4: 5527103E  rotlwi r7, r9, 2
	ctx.r[7].u64 = ((ctx.r[9].u32).rotate_left(2)) as u64;
	// 831F67D8: 81230004  lwz r9, 4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F67DC: 7CC85850  subf r6, r8, r11
	ctx.r[6].s64 = ctx.r[11].s64 - ctx.r[8].s64;
	// 831F67E0: 0CC70000  twi 6, r7, 0
	// 831F67E4: 7D663B96  divwu r11, r6, r7
	ctx.r[11].u32 = ctx.r[6].u32 / ctx.r[7].u32;
	// 831F67E8: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831F67EC: 40980008  bge cr6, 0x831f67f4
	if !ctx.cr[6].lt {
	pc = 0x831F67F4; continue 'dispatch;
	}
	// 831F67F0: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 831F67F4: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F67F8: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F67FC: 7CE85050  subf r7, r8, r10
	ctx.r[7].s64 = ctx.r[10].s64 - ctx.r[8].s64;
	// 831F6800: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 831F6804: 54EAF0BE  srwi r10, r7, 2
	ctx.r[10].u32 = ctx.r[7].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F6808: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F680C: 40980008  bge cr6, 0x831f6814
	if !ctx.cr[6].lt {
	pc = 0x831F6814; continue 'dispatch;
	}
	// 831F6810: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 831F6814: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F6818: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F681C: 39600002  li r11, 2
	ctx.r[11].s64 = 2;
	// 831F6820: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831F6824: 38A50004  addi r5, r5, 4
	ctx.r[5].s64 = ctx.r[5].s64 + 4;
	// 831F6828: 4082FFF8  bne 0x831f6820
	if !ctx.cr[0].eq {
	pc = 0x831F6820; continue 'dispatch;
	}
	// 831F682C: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F6830: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F6838(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F6838 size=476
    let mut pc: u32 = 0x831F6838;
    'dispatch: loop {
        match pc {
            0x831F6838 => {
    //   block [0x831F6838..0x831F6A14)
	// 831F6838: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 831F683C: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F6840: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F6844: 81430018  lwz r10, 0x18(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F6848: 39230034  addi r9, r3, 0x34
	ctx.r[9].s64 = ctx.r[3].s64 + 52;
	// 831F684C: 81030008  lwz r8, 8(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F6850: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831F6854: 88E3000D  lbz r7, 0xd(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F6858: 7C8B5050  subf r4, r11, r10
	ctx.r[4].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 831F685C: 83E30004  lwz r31, 4(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F6860: 7D4741D6  mullw r10, r7, r8
	ctx.r[10].s64 = (ctx.r[7].s32 as i64) * (ctx.r[8].s32 as i64);
	// 831F6864: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F6868: 80C30014  lwz r6, 0x14(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F686C: 7C840E70  srawi r4, r4, 1
	ctx.xer.ca = (ctx.r[4].s32 < 0) && ((ctx.r[4].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[4].s64 = (ctx.r[4].s32 >> 1) as i64;
	// 831F6870: 7CE8F850  subf r7, r8, r31
	ctx.r[7].s64 = ctx.r[31].s64 - ctx.r[8].s64;
	// 831F6874: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F6878: 7D040194  addze r8, r4
	tmp.s64 = ctx.r[4].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[4].u32);
	ctx.r[8].s64 = tmp.s64;
	// 831F687C: 7D4A5A14  add r10, r10, r11
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831F6880: 7D653214  add r11, r5, r6
	ctx.r[11].u64 = ctx.r[5].u64 + ctx.r[6].u64;
	// 831F6884: 7F074000  cmpw cr6, r7, r8
	ctx.cr[6].compare_i32(ctx.r[7].s32, ctx.r[8].s32, &mut ctx.xer);
	// 831F6888: 41980008  blt cr6, 0x831f6890
	if ctx.cr[6].lt {
	pc = 0x831F6890; continue 'dispatch;
	}
	// 831F688C: 7D074378  mr r7, r8
	ctx.r[7].u64 = ctx.r[8].u64;
	// 831F6890: 7D0607B4  extsw r6, r8
	ctx.r[6].s64 = ctx.r[8].s32 as i64;
	// 831F6894: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F6898: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F689C: 54E82036  slwi r8, r7, 4
	ctx.r[8].u32 = ctx.r[7].u32.wrapping_shl(4);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831F68A0: F8C1FFF0  std r6, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[6].u64 ) };
	// 831F68A4: C961FFF0  lfd f11, -0x10(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831F68A8: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F68AC: 3CA08201  lis r5, -0x7dff
	ctx.r[5].s64 = -2113863680;
	// 831F68B0: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F68B4: 3888007F  addi r4, r8, 0x7f
	ctx.r[4].s64 = ctx.r[8].s64 + 127;
	// 831F68B8: C1A59524  lfs f13, -0x6adc(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(-27356 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F68BC: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 831F68C0: 5486C9FE  srwi r6, r4, 7
	ctx.r[6].u32 = ctx.r[4].u32.wrapping_shr(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831F68C4: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 831F68C8: ED8C4824  fdivs f12, f12, f9
	ctx.f[12].f64 = ((ctx.f[12].f64 / ctx.f[9].f64) as f32) as f64;
	// 831F68CC: ED6C0372  fmuls f11, f12, f13
	ctx.f[11].f64 = (((ctx.f[12].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F68D0: 419A0018  beq cr6, 0x831f68e8
	if ctx.cr[6].eq {
	pc = 0x831F68E8; continue 'dispatch;
	}
	// 831F68D4: 55053830  slwi r5, r8, 7
	ctx.r[5].u32 = ctx.r[8].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831F68D8: 7C05522C  dcbt r5, r10
	// 831F68DC: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 831F68E0: 7F083040  cmplw cr6, r8, r6
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[6].u32, &mut ctx.xer);
	// 831F68E4: 4198FFF0  blt cr6, 0x831f68d4
	if ctx.cr[6].lt {
	pc = 0x831F68D4; continue 'dispatch;
	}
	// 831F68E8: 7D264B78  mr r6, r9
	ctx.r[6].u64 = ctx.r[9].u64;
	// 831F68EC: 39000004  li r8, 4
	ctx.r[8].s64 = 4;
	// 831F68F0: 3508FFFF  addic. r8, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 831F68F4: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 831F68F8: 4082FFF8  bne 0x831f68f0
	if !ctx.cr[0].eq {
	pc = 0x831F68F0; continue 'dispatch;
	}
	// 831F68FC: 3D008201  lis r8, -0x7dff
	ctx.r[8].s64 = -2113863680;
	// 831F6900: C1A89450  lfs f13, -0x6bb0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(-27568 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F6904: C14A000C  lfs f10, 0xc(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(12 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831F6908: ED2C002A  fadds f9, f12, f0
	ctx.f[9].f64 = ((ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F690C: C109000C  lfs f8, 0xc(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(12 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831F6910: 34E7FFFF  addic. r7, r7, -1
	ctx.xer.ca = (ctx.r[7].u32 > (!(-1 as u32)));
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 831F6914: ECEA402A  fadds f7, f10, f8
	ctx.f[7].f64 = ((ctx.f[10].f64 + ctx.f[8].f64) as f32) as f64;
	// 831F6918: D149000C  stfs f10, 0xc(r9)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831F691C: ECC902B2  fmuls f6, f9, f10
	ctx.f[6].f64 = (((ctx.f[9].f64 * ctx.f[10].f64) as f32) as f64);
	// 831F6920: ECA70032  fmuls f5, f7, f0
	ctx.f[5].f64 = (((ctx.f[7].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F6924: EC850372  fmuls f4, f5, f13
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F6928: D08B0C00  stfs f4, 0xc00(r11)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(3072 as u32), tmp.u32 ) };
	// 831F692C: D0CB0C04  stfs f6, 0xc04(r11)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(3076 as u32), tmp.u32 ) };
	// 831F6930: C06A0008  lfs f3, 8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 831F6934: EC4900F2  fmuls f2, f9, f3
	ctx.f[2].f64 = (((ctx.f[9].f64 * ctx.f[3].f64) as f32) as f64);
	// 831F6938: C0290008  lfs f1, 8(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831F693C: ED43082A  fadds f10, f3, f1
	ctx.f[10].f64 = ((ctx.f[3].f64 + ctx.f[1].f64) as f32) as f64;
	// 831F6940: ED0A0032  fmuls f8, f10, f0
	ctx.f[8].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F6944: D0690008  stfs f3, 8(r9)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831F6948: ECE80372  fmuls f7, f8, f13
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F694C: D0EB0800  stfs f7, 0x800(r11)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(2048 as u32), tmp.u32 ) };
	// 831F6950: D04B0804  stfs f2, 0x804(r11)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(2052 as u32), tmp.u32 ) };
	// 831F6954: C0CA0004  lfs f6, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 831F6958: ECA901B2  fmuls f5, f9, f6
	ctx.f[5].f64 = (((ctx.f[9].f64 * ctx.f[6].f64) as f32) as f64);
	// 831F695C: C0890004  lfs f4, 4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831F6960: EC66202A  fadds f3, f6, f4
	ctx.f[3].f64 = ((ctx.f[6].f64 + ctx.f[4].f64) as f32) as f64;
	// 831F6964: EC430032  fmuls f2, f3, f0
	ctx.f[2].f64 = (((ctx.f[3].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F6968: D0C90004  stfs f6, 4(r9)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831F696C: EC220372  fmuls f1, f2, f13
	ctx.f[1].f64 = (((ctx.f[2].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F6970: D02B0400  stfs f1, 0x400(r11)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 831F6974: D0AB0404  stfs f5, 0x404(r11)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(1028 as u32), tmp.u32 ) };
	// 831F6978: C14A0000  lfs f10, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831F697C: ED2902B2  fmuls f9, f9, f10
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[10].f64) as f32) as f64);
	// 831F6980: C1090000  lfs f8, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831F6984: ECEA402A  fadds f7, f10, f8
	ctx.f[7].f64 = ((ctx.f[10].f64 + ctx.f[8].f64) as f32) as f64;
	// 831F6988: ECC70032  fmuls f6, f7, f0
	ctx.f[6].f64 = (((ctx.f[7].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F698C: D1490000  stfs f10, 0(r9)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F6990: 394A0010  addi r10, r10, 0x10
	ctx.r[10].s64 = ctx.r[10].s64 + 16;
	// 831F6994: EC0B002A  fadds f0, f11, f0
	ctx.f[0].f64 = ((ctx.f[11].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F6998: ECA60372  fmuls f5, f6, f13
	ctx.f[5].f64 = (((ctx.f[6].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F699C: D0AB0000  stfs f5, 0(r11)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F69A0: D12B0004  stfs f9, 4(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831F69A4: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 831F69A8: 4082FF5C  bne 0x831f6904
	if !ctx.cr[0].eq {
	pc = 0x831F6904; continue 'dispatch;
	}
	// 831F69AC: 8903000D  lbz r8, 0xd(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F69B0: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F69B4: 5506103E  rotlwi r6, r8, 2
	ctx.r[6].u64 = ((ctx.r[8].u32).rotate_left(2)) as u64;
	// 831F69B8: 81030004  lwz r8, 4(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F69BC: 7CA75050  subf r5, r7, r10
	ctx.r[5].s64 = ctx.r[10].s64 - ctx.r[7].s64;
	// 831F69C0: 0CC60000  twi 6, r6, 0
	// 831F69C4: 7D453396  divwu r10, r5, r6
	ctx.r[10].u32 = ctx.r[5].u32 / ctx.r[6].u32;
	// 831F69C8: 7F0A4040  cmplw cr6, r10, r8
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831F69CC: 40980008  bge cr6, 0x831f69d4
	if !ctx.cr[6].lt {
	pc = 0x831F69D4; continue 'dispatch;
	}
	// 831F69D0: 7D485378  mr r8, r10
	ctx.r[8].u64 = ctx.r[10].u64;
	// 831F69D4: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F69D8: 81430018  lwz r10, 0x18(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F69DC: 7CC75850  subf r6, r7, r11
	ctx.r[6].s64 = ctx.r[11].s64 - ctx.r[7].s64;
	// 831F69E0: 91030008  stw r8, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 831F69E4: 54CBF0BE  srwi r11, r6, 2
	ctx.r[11].u32 = ctx.r[6].u32.wrapping_shr(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831F69E8: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831F69EC: 41980008  blt cr6, 0x831f69f4
	if ctx.cr[6].lt {
	pc = 0x831F69F4; continue 'dispatch;
	}
	// 831F69F0: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 831F69F4: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F69F8: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F69FC: 39600004  li r11, 4
	ctx.r[11].s64 = 4;
	// 831F6A00: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831F6A04: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 831F6A08: 4082FFF8  bne 0x831f6a00
	if !ctx.cr[0].eq {
	pc = 0x831F6A00; continue 'dispatch;
	}
	// 831F6A0C: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F6A10: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F6A18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F6A18 size=556
    let mut pc: u32 = 0x831F6A18;
    'dispatch: loop {
        match pc {
            0x831F6A18 => {
    //   block [0x831F6A18..0x831F6C44)
	// 831F6A18: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 831F6A1C: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F6A20: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F6A24: 81230018  lwz r9, 0x18(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F6A28: 39430034  addi r10, r3, 0x34
	ctx.r[10].s64 = ctx.r[3].s64 + 52;
	// 831F6A2C: 81030008  lwz r8, 8(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F6A30: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831F6A34: 88E3000D  lbz r7, 0xd(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F6A38: 7C8B4850  subf r4, r11, r9
	ctx.r[4].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 831F6A3C: 83E30004  lwz r31, 4(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F6A40: 7D2741D6  mullw r9, r7, r8
	ctx.r[9].s64 = (ctx.r[7].s32 as i64) * (ctx.r[8].s32 as i64);
	// 831F6A44: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F6A48: 80C30014  lwz r6, 0x14(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F6A4C: 7C840E70  srawi r4, r4, 1
	ctx.xer.ca = (ctx.r[4].s32 < 0) && ((ctx.r[4].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[4].s64 = (ctx.r[4].s32 >> 1) as i64;
	// 831F6A50: 7CE8F850  subf r7, r8, r31
	ctx.r[7].s64 = ctx.r[31].s64 - ctx.r[8].s64;
	// 831F6A54: 5529103A  slwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831F6A58: 7D040194  addze r8, r4
	tmp.s64 = ctx.r[4].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[4].u32);
	ctx.r[8].s64 = tmp.s64;
	// 831F6A5C: 7D295A14  add r9, r9, r11
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[11].u64;
	// 831F6A60: 7D653214  add r11, r5, r6
	ctx.r[11].u64 = ctx.r[5].u64 + ctx.r[6].u64;
	// 831F6A64: 7F074000  cmpw cr6, r7, r8
	ctx.cr[6].compare_i32(ctx.r[7].s32, ctx.r[8].s32, &mut ctx.xer);
	// 831F6A68: 41980008  blt cr6, 0x831f6a70
	if ctx.cr[6].lt {
	pc = 0x831F6A70; continue 'dispatch;
	}
	// 831F6A6C: 7D074378  mr r7, r8
	ctx.r[7].u64 = ctx.r[8].u64;
	// 831F6A70: 7D0607B4  extsw r6, r8
	ctx.r[6].s64 = ctx.r[8].s32 as i64;
	// 831F6A74: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F6A78: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F6A7C: 54E8083C  slwi r8, r7, 1
	ctx.r[8].u32 = ctx.r[7].u32.wrapping_shl(1);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831F6A80: F8C1FFF0  std r6, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[6].u64 ) };
	// 831F6A84: C961FFF0  lfd f11, -0x10(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831F6A88: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F6A8C: 7CA74214  add r5, r7, r8
	ctx.r[5].u64 = ctx.r[7].u64 + ctx.r[8].u64;
	// 831F6A90: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F6A94: 54A81838  slwi r8, r5, 3
	ctx.r[8].u32 = ctx.r[5].u32.wrapping_shl(3);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831F6A98: 3C808201  lis r4, -0x7dff
	ctx.r[4].s64 = -2113863680;
	// 831F6A9C: 38C8007F  addi r6, r8, 0x7f
	ctx.r[6].s64 = ctx.r[8].s64 + 127;
	// 831F6AA0: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 831F6AA4: 54C6C9FE  srwi r6, r6, 7
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shr(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831F6AA8: C1A49524  lfs f13, -0x6adc(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(-27356 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F6AAC: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 831F6AB0: ED8C4824  fdivs f12, f12, f9
	ctx.f[12].f64 = ((ctx.f[12].f64 / ctx.f[9].f64) as f32) as f64;
	// 831F6AB4: ED6C0372  fmuls f11, f12, f13
	ctx.f[11].f64 = (((ctx.f[12].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F6AB8: 419A0018  beq cr6, 0x831f6ad0
	if ctx.cr[6].eq {
	pc = 0x831F6AD0; continue 'dispatch;
	}
	// 831F6ABC: 55053830  slwi r5, r8, 7
	ctx.r[5].u32 = ctx.r[8].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831F6AC0: 7C054A2C  dcbt r5, r9
	// 831F6AC4: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 831F6AC8: 7F083040  cmplw cr6, r8, r6
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[6].u32, &mut ctx.xer);
	// 831F6ACC: 4198FFF0  blt cr6, 0x831f6abc
	if ctx.cr[6].lt {
	pc = 0x831F6ABC; continue 'dispatch;
	}
	// 831F6AD0: 7D465378  mr r6, r10
	ctx.r[6].u64 = ctx.r[10].u64;
	// 831F6AD4: 39000006  li r8, 6
	ctx.r[8].s64 = 6;
	// 831F6AD8: 3508FFFF  addic. r8, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 831F6ADC: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 831F6AE0: 4082FFF8  bne 0x831f6ad8
	if !ctx.cr[0].eq {
	pc = 0x831F6AD8; continue 'dispatch;
	}
	// 831F6AE4: 3D008201  lis r8, -0x7dff
	ctx.r[8].s64 = -2113863680;
	// 831F6AE8: C1A89450  lfs f13, -0x6bb0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(-27568 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F6AEC: C1490014  lfs f10, 0x14(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(20 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831F6AF0: ED2C002A  fadds f9, f12, f0
	ctx.f[9].f64 = ((ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F6AF4: C10A0014  lfs f8, 0x14(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(20 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831F6AF8: 34E7FFFF  addic. r7, r7, -1
	ctx.xer.ca = (ctx.r[7].u32 > (!(-1 as u32)));
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 831F6AFC: ECEA402A  fadds f7, f10, f8
	ctx.f[7].f64 = ((ctx.f[10].f64 + ctx.f[8].f64) as f32) as f64;
	// 831F6B00: D14A0014  stfs f10, 0x14(r10)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831F6B04: ECC902B2  fmuls f6, f9, f10
	ctx.f[6].f64 = (((ctx.f[9].f64 * ctx.f[10].f64) as f32) as f64);
	// 831F6B08: ECA70032  fmuls f5, f7, f0
	ctx.f[5].f64 = (((ctx.f[7].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F6B0C: EC850372  fmuls f4, f5, f13
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F6B10: D08B1400  stfs f4, 0x1400(r11)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(5120 as u32), tmp.u32 ) };
	// 831F6B14: D0CB1404  stfs f6, 0x1404(r11)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(5124 as u32), tmp.u32 ) };
	// 831F6B18: C0690010  lfs f3, 0x10(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(16 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 831F6B1C: EC4900F2  fmuls f2, f9, f3
	ctx.f[2].f64 = (((ctx.f[9].f64 * ctx.f[3].f64) as f32) as f64);
	// 831F6B20: C02A0010  lfs f1, 0x10(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(16 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831F6B24: ED43082A  fadds f10, f3, f1
	ctx.f[10].f64 = ((ctx.f[3].f64 + ctx.f[1].f64) as f32) as f64;
	// 831F6B28: ED0A0032  fmuls f8, f10, f0
	ctx.f[8].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F6B2C: D06A0010  stfs f3, 0x10(r10)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831F6B30: ECE80372  fmuls f7, f8, f13
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F6B34: D0EB1000  stfs f7, 0x1000(r11)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4096 as u32), tmp.u32 ) };
	// 831F6B38: D04B1004  stfs f2, 0x1004(r11)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4100 as u32), tmp.u32 ) };
	// 831F6B3C: C0C9000C  lfs f6, 0xc(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(12 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 831F6B40: ECA901B2  fmuls f5, f9, f6
	ctx.f[5].f64 = (((ctx.f[9].f64 * ctx.f[6].f64) as f32) as f64);
	// 831F6B44: C08A000C  lfs f4, 0xc(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(12 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831F6B48: EC66202A  fadds f3, f6, f4
	ctx.f[3].f64 = ((ctx.f[6].f64 + ctx.f[4].f64) as f32) as f64;
	// 831F6B4C: EC430032  fmuls f2, f3, f0
	ctx.f[2].f64 = (((ctx.f[3].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F6B50: D0CA000C  stfs f6, 0xc(r10)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831F6B54: EC220372  fmuls f1, f2, f13
	ctx.f[1].f64 = (((ctx.f[2].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F6B58: D02B0C00  stfs f1, 0xc00(r11)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(3072 as u32), tmp.u32 ) };
	// 831F6B5C: D0AB0C04  stfs f5, 0xc04(r11)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(3076 as u32), tmp.u32 ) };
	// 831F6B60: C1490008  lfs f10, 8(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831F6B64: ED0902B2  fmuls f8, f9, f10
	ctx.f[8].f64 = (((ctx.f[9].f64 * ctx.f[10].f64) as f32) as f64);
	// 831F6B68: C0EA0008  lfs f7, 8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831F6B6C: ECCA382A  fadds f6, f10, f7
	ctx.f[6].f64 = ((ctx.f[10].f64 + ctx.f[7].f64) as f32) as f64;
	// 831F6B70: ECA60032  fmuls f5, f6, f0
	ctx.f[5].f64 = (((ctx.f[6].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F6B74: D14A0008  stfs f10, 8(r10)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831F6B78: EC850372  fmuls f4, f5, f13
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F6B7C: D08B0800  stfs f4, 0x800(r11)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(2048 as u32), tmp.u32 ) };
	// 831F6B80: D10B0804  stfs f8, 0x804(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(2052 as u32), tmp.u32 ) };
	// 831F6B84: C0690004  lfs f3, 4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 831F6B88: EC4900F2  fmuls f2, f9, f3
	ctx.f[2].f64 = (((ctx.f[9].f64 * ctx.f[3].f64) as f32) as f64);
	// 831F6B8C: C02A0004  lfs f1, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831F6B90: ED43082A  fadds f10, f3, f1
	ctx.f[10].f64 = ((ctx.f[3].f64 + ctx.f[1].f64) as f32) as f64;
	// 831F6B94: ED0A0032  fmuls f8, f10, f0
	ctx.f[8].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F6B98: D06A0004  stfs f3, 4(r10)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831F6B9C: ECE80372  fmuls f7, f8, f13
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F6BA0: D0EB0400  stfs f7, 0x400(r11)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 831F6BA4: D04B0404  stfs f2, 0x404(r11)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(1028 as u32), tmp.u32 ) };
	// 831F6BA8: C0C90000  lfs f6, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 831F6BAC: ECA901B2  fmuls f5, f9, f6
	ctx.f[5].f64 = (((ctx.f[9].f64 * ctx.f[6].f64) as f32) as f64);
	// 831F6BB0: C08A0000  lfs f4, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831F6BB4: EC66202A  fadds f3, f6, f4
	ctx.f[3].f64 = ((ctx.f[6].f64 + ctx.f[4].f64) as f32) as f64;
	// 831F6BB8: EC430032  fmuls f2, f3, f0
	ctx.f[2].f64 = (((ctx.f[3].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F6BBC: D0CA0000  stfs f6, 0(r10)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F6BC0: 39290018  addi r9, r9, 0x18
	ctx.r[9].s64 = ctx.r[9].s64 + 24;
	// 831F6BC4: EC0B002A  fadds f0, f11, f0
	ctx.f[0].f64 = ((ctx.f[11].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F6BC8: EC220372  fmuls f1, f2, f13
	ctx.f[1].f64 = (((ctx.f[2].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F6BCC: D02B0000  stfs f1, 0(r11)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F6BD0: D0AB0004  stfs f5, 4(r11)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831F6BD4: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 831F6BD8: 4082FF14  bne 0x831f6aec
	if !ctx.cr[0].eq {
	pc = 0x831F6AEC; continue 'dispatch;
	}
	// 831F6BDC: 8903000D  lbz r8, 0xd(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F6BE0: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F6BE4: 5506103E  rotlwi r6, r8, 2
	ctx.r[6].u64 = ((ctx.r[8].u32).rotate_left(2)) as u64;
	// 831F6BE8: 81030004  lwz r8, 4(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F6BEC: 7CA74850  subf r5, r7, r9
	ctx.r[5].s64 = ctx.r[9].s64 - ctx.r[7].s64;
	// 831F6BF0: 0CC60000  twi 6, r6, 0
	// 831F6BF4: 7D253396  divwu r9, r5, r6
	ctx.r[9].u32 = ctx.r[5].u32 / ctx.r[6].u32;
	// 831F6BF8: 7F094040  cmplw cr6, r9, r8
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831F6BFC: 40980008  bge cr6, 0x831f6c04
	if !ctx.cr[6].lt {
	pc = 0x831F6C04; continue 'dispatch;
	}
	// 831F6C00: 7D284B78  mr r8, r9
	ctx.r[8].u64 = ctx.r[9].u64;
	// 831F6C04: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F6C08: 81230018  lwz r9, 0x18(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F6C0C: 7CC75850  subf r6, r7, r11
	ctx.r[6].s64 = ctx.r[11].s64 - ctx.r[7].s64;
	// 831F6C10: 91030008  stw r8, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 831F6C14: 54CBF0BE  srwi r11, r6, 2
	ctx.r[11].u32 = ctx.r[6].u32.wrapping_shr(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831F6C18: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831F6C1C: 41980008  blt cr6, 0x831f6c24
	if ctx.cr[6].lt {
	pc = 0x831F6C24; continue 'dispatch;
	}
	// 831F6C20: 7D2B4B78  mr r11, r9
	ctx.r[11].u64 = ctx.r[9].u64;
	// 831F6C24: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F6C28: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F6C2C: 39600006  li r11, 6
	ctx.r[11].s64 = 6;
	// 831F6C30: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831F6C34: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 831F6C38: 4082FFF8  bne 0x831f6c30
	if !ctx.cr[0].eq {
	pc = 0x831F6C30; continue 'dispatch;
	}
	// 831F6C3C: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F6C40: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F6C48(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F6C48 size=528
    let mut pc: u32 = 0x831F6C48;
    'dispatch: loop {
        match pc {
            0x831F6C48 => {
    //   block [0x831F6C48..0x831F6E58)
	// 831F6C48: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831F6C4C: 4BFB1521  bl 0x831a816c
	ctx.lr = 0x831F6C50;
	sub_831A8130(ctx, base);
	// 831F6C50: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F6C54: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F6C58: 81430018  lwz r10, 0x18(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F6C5C: 3BC30034  addi r30, r3, 0x34
	ctx.r[30].s64 = ctx.r[3].s64 + 52;
	// 831F6C60: 5566103A  slwi r6, r11, 2
	ctx.r[6].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831F6C64: 80A30008  lwz r5, 8(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F6C68: 8883000D  lbz r4, 0xd(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F6C6C: 7D6B5050  subf r11, r11, r10
	ctx.r[11].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 831F6C70: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F6C74: 7D0429D6  mullw r8, r4, r5
	ctx.r[8].s64 = (ctx.r[4].s32 as i64) * (ctx.r[5].s32 as i64);
	// 831F6C78: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F6C7C: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F6C80: 7D6B0E70  srawi r11, r11, 1
	ctx.xer.ca = (ctx.r[11].s32 < 0) && ((ctx.r[11].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[11].s64 = (ctx.r[11].s32 >> 1) as i64;
	// 831F6C84: 7D455050  subf r10, r5, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[5].s64;
	// 831F6C88: 5508083C  slwi r8, r8, 1
	ctx.r[8].u32 = ctx.r[8].u32.wrapping_shl(1);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831F6C8C: 7D6B0194  addze r11, r11
	tmp.s64 = ctx.r[11].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[11].u32);
	ctx.r[11].s64 = tmp.s64;
	// 831F6C90: 7CE63A14  add r7, r6, r7
	ctx.r[7].u64 = ctx.r[6].u64 + ctx.r[7].u64;
	// 831F6C94: 7CA84A14  add r5, r8, r9
	ctx.r[5].u64 = ctx.r[8].u64 + ctx.r[9].u64;
	// 831F6C98: 7F0A5800  cmpw cr6, r10, r11
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[11].s32, &mut ctx.xer);
	// 831F6C9C: 7D465378  mr r6, r10
	ctx.r[6].u64 = ctx.r[10].u64;
	// 831F6CA0: 41980008  blt cr6, 0x831f6ca8
	if ctx.cr[6].lt {
	pc = 0x831F6CA8; continue 'dispatch;
	}
	// 831F6CA4: 7D665B78  mr r6, r11
	ctx.r[6].u64 = ctx.r[11].u64;
	// 831F6CA8: 7D6B07B4  extsw r11, r11
	ctx.r[11].s64 = ctx.r[11].s32 as i64;
	// 831F6CAC: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F6CB0: ED6D0028  fsubs f11, f13, f0
	ctx.f[11].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F6CB4: 3D408201  lis r10, -0x7dff
	ctx.r[10].s64 = -2113863680;
	// 831F6CB8: F961FFD0  std r11, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[11].u64 ) };
	// 831F6CBC: C941FFD0  lfd f10, -0x30(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 831F6CC0: FD20569C  fcfid f9, f10
	ctx.f[9].f64 = (ctx.f[10].s64 as f64);
	// 831F6CC4: 3D20820C  lis r9, -0x7df4
	ctx.r[9].s64 = -2113142784;
	// 831F6CC8: FD004818  frsp f8, f9
	ctx.f[8].f64 = (ctx.f[9].f64 as f32) as f64;
	// 831F6CCC: C1AA9524  lfs f13, -0x6adc(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-27356 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F6CD0: C1897490  lfs f12, 0x7490(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(29840 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831F6CD4: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 831F6CD8: ED4B4024  fdivs f10, f11, f8
	ctx.f[10].f64 = ((ctx.f[11].f64 / ctx.f[8].f64) as f32) as f64;
	// 831F6CDC: ED2A0372  fmuls f9, f10, f13
	ctx.f[9].f64 = (((ctx.f[10].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F6CE0: 419A0038  beq cr6, 0x831f6d18
	if ctx.cr[6].eq {
	pc = 0x831F6D18; continue 'dispatch;
	}
	// 831F6CE4: 7FCBF378  mr r11, r30
	ctx.r[11].u64 = ctx.r[30].u64;
	// 831F6CE8: 7C8A2378  mr r10, r4
	ctx.r[10].u64 = ctx.r[4].u64;
	// 831F6CEC: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F6CF0: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831F6CF4: 7D290734  extsh r9, r9
	ctx.r[9].s64 = ctx.r[9].s16 as i64;
	// 831F6CF8: F921FFD0  std r9, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[9].u64 ) };
	// 831F6CFC: C9A1FFD0  lfd f13, -0x30(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 831F6D00: FD606E9C  fcfid f11, f13
	ctx.f[11].f64 = (ctx.f[13].s64 as f64);
	// 831F6D04: FD005818  frsp f8, f11
	ctx.f[8].f64 = (ctx.f[11].f64 as f32) as f64;
	// 831F6D08: ECE80332  fmuls f7, f8, f12
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F6D0C: D0EB0000  stfs f7, 0(r11)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F6D10: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 831F6D14: 4082FFD8  bne 0x831f6cec
	if !ctx.cr[0].eq {
	pc = 0x831F6CEC; continue 'dispatch;
	}
	// 831F6D18: 3D608201  lis r11, -0x7dff
	ctx.r[11].s64 = -2113863680;
	// 831F6D1C: 549F083C  slwi r31, r4, 1
	ctx.r[31].u32 = ctx.r[4].u32.wrapping_shl(1);
	ctx.r[31].u64 = ctx.r[31].u32 as u64;
	// 831F6D20: C16B9450  lfs f11, -0x6bb0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-27568 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831F6D24: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 831F6D28: 419A0068  beq cr6, 0x831f6d90
	if ctx.cr[6].eq {
	pc = 0x831F6D90; continue 'dispatch;
	}
	// 831F6D2C: EDAA002A  fadds f13, f10, f0
	ctx.f[13].f64 = ((ctx.f[10].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F6D30: 7CEA3B78  mr r10, r7
	ctx.r[10].u64 = ctx.r[7].u64;
	// 831F6D34: 7FCBF378  mr r11, r30
	ctx.r[11].u64 = ctx.r[30].u64;
	// 831F6D38: 7CA82B78  mr r8, r5
	ctx.r[8].u64 = ctx.r[5].u64;
	// 831F6D3C: 7C892378  mr r9, r4
	ctx.r[9].u64 = ctx.r[4].u64;
	// 831F6D40: A3A80000  lhz r29, 0(r8)
	ctx.r[29].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F6D44: C10B0000  lfs f8, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831F6D48: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831F6D4C: 7FBD0734  extsh r29, r29
	ctx.r[29].s64 = ctx.r[29].s16 as i64;
	// 831F6D50: 39080002  addi r8, r8, 2
	ctx.r[8].s64 = ctx.r[8].s64 + 2;
	// 831F6D54: FBA1FFD0  std r29, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[29].u64 ) };
	// 831F6D58: C8E1FFD0  lfd f7, -0x30(r1)
	ctx.f[7].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 831F6D5C: FCC03E9C  fcfid f6, f7
	ctx.f[6].f64 = (ctx.f[7].s64 as f64);
	// 831F6D60: FCA03018  frsp f5, f6
	ctx.f[5].f64 = (ctx.f[6].f64 as f32) as f64;
	// 831F6D64: EC850332  fmuls f4, f5, f12
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F6D68: D08B0000  stfs f4, 0(r11)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F6D6C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 831F6D70: EC64402A  fadds f3, f4, f8
	ctx.f[3].f64 = ((ctx.f[4].f64 + ctx.f[8].f64) as f32) as f64;
	// 831F6D74: EC4D0132  fmuls f2, f13, f4
	ctx.f[2].f64 = (((ctx.f[13].f64 * ctx.f[4].f64) as f32) as f64);
	// 831F6D78: EC230032  fmuls f1, f3, f0
	ctx.f[1].f64 = (((ctx.f[3].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F6D7C: ED0102F2  fmuls f8, f1, f11
	ctx.f[8].f64 = (((ctx.f[1].f64 * ctx.f[11].f64) as f32) as f64);
	// 831F6D80: D10A0000  stfs f8, 0(r10)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F6D84: D04A0004  stfs f2, 4(r10)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831F6D88: 394A0400  addi r10, r10, 0x400
	ctx.r[10].s64 = ctx.r[10].s64 + 1024;
	// 831F6D8C: 4082FFB4  bne 0x831f6d40
	if !ctx.cr[0].eq {
	pc = 0x831F6D40; continue 'dispatch;
	}
	// 831F6D90: 34C6FFFF  addic. r6, r6, -1
	ctx.xer.ca = (ctx.r[6].u32 > (!(-1 as u32)));
	ctx.r[6].s64 = ctx.r[6].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[6].s32, 0, &mut ctx.xer);
	// 831F6D94: EC09002A  fadds f0, f9, f0
	ctx.f[0].f64 = ((ctx.f[9].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F6D98: 7CBF2A14  add r5, r31, r5
	ctx.r[5].u64 = ctx.r[31].u64 + ctx.r[5].u64;
	// 831F6D9C: 38E70008  addi r7, r7, 8
	ctx.r[7].s64 = ctx.r[7].s64 + 8;
	// 831F6DA0: 4082FF84  bne 0x831f6d24
	if !ctx.cr[0].eq {
	pc = 0x831F6D24; continue 'dispatch;
	}
	// 831F6DA4: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F6DA8: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F6DAC: 7D2B2850  subf r9, r11, r5
	ctx.r[9].s64 = ctx.r[5].s64 - ctx.r[11].s64;
	// 831F6DB0: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F6DB4: 5548083E  rotlwi r8, r10, 1
	ctx.r[8].u64 = ((ctx.r[10].u32).rotate_left(1)) as u64;
	// 831F6DB8: 7D494396  divwu r10, r9, r8
	ctx.r[10].u32 = ctx.r[9].u32 / ctx.r[8].u32;
	// 831F6DBC: 0CC80000  twi 6, r8, 0
	// 831F6DC0: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F6DC4: 41980008  blt cr6, 0x831f6dcc
	if ctx.cr[6].lt {
	pc = 0x831F6DCC; continue 'dispatch;
	}
	// 831F6DC8: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 831F6DCC: 81630014  lwz r11, 0x14(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F6DD0: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831F6DD4: 7D4B3850  subf r10, r11, r7
	ctx.r[10].s64 = ctx.r[7].s64 - ctx.r[11].s64;
	// 831F6DD8: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F6DDC: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F6DE0: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F6DE4: 40980008  bge cr6, 0x831f6dec
	if !ctx.cr[6].lt {
	pc = 0x831F6DEC; continue 'dispatch;
	}
	// 831F6DE8: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 831F6DEC: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F6DF0: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F6DF4: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 831F6DF8: 419A005C  beq cr6, 0x831f6e54
	if ctx.cr[6].eq {
	pc = 0x831F6E54; continue 'dispatch;
	}
	// 831F6DFC: 3D40820C  lis r10, -0x7df4
	ctx.r[10].s64 = -2113142784;
	// 831F6E00: 7FCBF378  mr r11, r30
	ctx.r[11].u64 = ctx.r[30].u64;
	// 831F6E04: 39007FFF  li r8, 0x7fff
	ctx.r[8].s64 = 32767;
	// 831F6E08: 3920801E  li r9, -0x7fe2
	ctx.r[9].s64 = -32738;
	// 831F6E0C: C00A6AB0  lfs f0, 0x6ab0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(27312 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F6E10: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F6E14: ED8D0032  fmuls f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F6E18: FD60601E  fctiwz f11, f12
	ctx.f[11].s64 = if ctx.f[12].f64 > (i32::MAX as f64) { i32::MAX as i64 } else { ctx.f[12].f64.trunc() as i32 as i64 };
	// 831F6E1C: D961FFD0  stfd f11, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.f[11].u64 ) };
	// 831F6E20: 8141FFD4  lwz r10, -0x2c(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-44 as u32) ) } as u64;
	// 831F6E24: 2F0A7FFF  cmpwi cr6, r10, 0x7fff
	ctx.cr[6].compare_i32(ctx.r[10].s32, 32767, &mut ctx.xer);
	// 831F6E28: 4198000C  blt cr6, 0x831f6e34
	if ctx.cr[6].lt {
	pc = 0x831F6E34; continue 'dispatch;
	}
	// 831F6E2C: B10B0000  sth r8, 0(r11)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[8].u16 ) };
	// 831F6E30: 48000018  b 0x831f6e48
	pc = 0x831F6E48; continue 'dispatch;
	// 831F6E34: 2F0A8000  cmpwi cr6, r10, -0x8000
	ctx.cr[6].compare_i32(ctx.r[10].s32, -32768, &mut ctx.xer);
	// 831F6E38: 4199000C  bgt cr6, 0x831f6e44
	if ctx.cr[6].gt {
	pc = 0x831F6E44; continue 'dispatch;
	}
	// 831F6E3C: B12B0000  sth r9, 0(r11)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u16 ) };
	// 831F6E40: 48000008  b 0x831f6e48
	pc = 0x831F6E48; continue 'dispatch;
	// 831F6E44: B14B0000  sth r10, 0(r11)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u16 ) };
	// 831F6E48: 3484FFFF  addic. r4, r4, -1
	ctx.xer.ca = (ctx.r[4].u32 > (!(-1 as u32)));
	ctx.r[4].s64 = ctx.r[4].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[4].s32, 0, &mut ctx.xer);
	// 831F6E4C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 831F6E50: 4082FFC0  bne 0x831f6e10
	if !ctx.cr[0].eq {
	pc = 0x831F6E10; continue 'dispatch;
	}
	// 831F6E54: 4BFB1368  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F6E58(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F6E58 size=428
    let mut pc: u32 = 0x831F6E58;
    'dispatch: loop {
        match pc {
            0x831F6E58 => {
    //   block [0x831F6E58..0x831F7004)
	// 831F6E58: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F6E5C: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F6E60: 81430018  lwz r10, 0x18(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F6E64: 81230008  lwz r9, 8(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F6E68: 5566103A  slwi r6, r11, 2
	ctx.r[6].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831F6E6C: 8903000D  lbz r8, 0xd(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F6E70: 7CAB5050  subf r5, r11, r10
	ctx.r[5].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 831F6E74: 80830004  lwz r4, 4(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F6E78: 7D4849D6  mullw r10, r8, r9
	ctx.r[10].s64 = (ctx.r[8].s32 as i64) * (ctx.r[9].s32 as i64);
	// 831F6E7C: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F6E80: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F6E84: 7CA50E70  srawi r5, r5, 1
	ctx.xer.ca = (ctx.r[5].s32 < 0) && ((ctx.r[5].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[5].s64 = (ctx.r[5].s32 >> 1) as i64;
	// 831F6E88: 5548083C  slwi r8, r10, 1
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shl(1);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831F6E8C: 7D292050  subf r9, r9, r4
	ctx.r[9].s64 = ctx.r[4].s64 - ctx.r[9].s64;
	// 831F6E90: 7D450194  addze r10, r5
	tmp.s64 = ctx.r[5].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[5].u32);
	ctx.r[10].s64 = tmp.s64;
	// 831F6E94: 7D685A14  add r11, r8, r11
	ctx.r[11].u64 = ctx.r[8].u64 + ctx.r[11].u64;
	// 831F6E98: 7D063A14  add r8, r6, r7
	ctx.r[8].u64 = ctx.r[6].u64 + ctx.r[7].u64;
	// 831F6E9C: 7F095000  cmpw cr6, r9, r10
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[10].s32, &mut ctx.xer);
	// 831F6EA0: 41980008  blt cr6, 0x831f6ea8
	if ctx.cr[6].lt {
	pc = 0x831F6EA8; continue 'dispatch;
	}
	// 831F6EA4: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 831F6EA8: 7D4707B4  extsw r7, r10
	ctx.r[7].s64 = ctx.r[10].s32 as i64;
	// 831F6EAC: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F6EB0: ED6D0028  fsubs f11, f13, f0
	ctx.f[11].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F6EB4: 552A083C  slwi r10, r9, 1
	ctx.r[10].u32 = ctx.r[9].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F6EB8: F8E1FFF0  std r7, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[7].u64 ) };
	// 831F6EBC: C941FFF0  lfd f10, -0x10(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831F6EC0: FD20569C  fcfid f9, f10
	ctx.f[9].f64 = (ctx.f[10].s64 as f64);
	// 831F6EC4: 3CC08201  lis r6, -0x7dff
	ctx.r[6].s64 = -2113863680;
	// 831F6EC8: FD004818  frsp f8, f9
	ctx.f[8].f64 = (ctx.f[9].f64 as f32) as f64;
	// 831F6ECC: 38AA007F  addi r5, r10, 0x7f
	ctx.r[5].s64 = ctx.r[10].s64 + 127;
	// 831F6ED0: C1869524  lfs f12, -0x6adc(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(-27356 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831F6ED4: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831F6ED8: 54A7C9FE  srwi r7, r5, 7
	ctx.r[7].u32 = ctx.r[5].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F6EDC: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 831F6EE0: EDAB4024  fdivs f13, f11, f8
	ctx.f[13].f64 = ((ctx.f[11].f64 / ctx.f[8].f64) as f32) as f64;
	// 831F6EE4: ED8D0332  fmuls f12, f13, f12
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F6EE8: 419A0018  beq cr6, 0x831f6f00
	if ctx.cr[6].eq {
	pc = 0x831F6F00; continue 'dispatch;
	}
	// 831F6EEC: 55463830  slwi r6, r10, 7
	ctx.r[6].u32 = ctx.r[10].u32.wrapping_shl(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831F6EF0: 7C065A2C  dcbt r6, r11
	// 831F6EF4: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 831F6EF8: 7F0A3840  cmplw cr6, r10, r7
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831F6EFC: 4198FFF0  blt cr6, 0x831f6eec
	if ctx.cr[6].lt {
	pc = 0x831F6EEC; continue 'dispatch;
	}
	// 831F6F00: A1430034  lhz r10, 0x34(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(52 as u32) ) } as u64;
	// 831F6F04: 3CE0820C  lis r7, -0x7df4
	ctx.r[7].s64 = -2113142784;
	// 831F6F08: 7D450734  extsh r5, r10
	ctx.r[5].s64 = ctx.r[10].s16 as i64;
	// 831F6F0C: 3D408201  lis r10, -0x7dff
	ctx.r[10].s64 = -2113863680;
	// 831F6F10: F8A1FFF0  std r5, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[5].u64 ) };
	// 831F6F14: C1477490  lfs f10, 0x7490(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(29840 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831F6F18: C961FFF0  lfd f11, -0x10(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831F6F1C: FD205E9C  fcfid f9, f11
	ctx.f[9].f64 = (ctx.f[11].s64 as f64);
	// 831F6F20: C16A9450  lfs f11, -0x6bb0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-27568 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831F6F24: FD004818  frsp f8, f9
	ctx.f[8].f64 = (ctx.f[9].f64 as f32) as f64;
	// 831F6F28: ECE802B2  fmuls f7, f8, f10
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[10].f64) as f32) as f64);
	// 831F6F2C: D0E30034  stfs f7, 0x34(r3)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 831F6F30: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F6F34: C1230034  lfs f9, 0x34(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(52 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831F6F38: ED0D002A  fadds f8, f13, f0
	ctx.f[8].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F6F3C: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831F6F40: 7D460734  extsh r6, r10
	ctx.r[6].s64 = ctx.r[10].s16 as i64;
	// 831F6F44: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 831F6F48: F8C1FFF0  std r6, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[6].u64 ) };
	// 831F6F4C: C8E1FFF0  lfd f7, -0x10(r1)
	ctx.f[7].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831F6F50: FCC03E9C  fcfid f6, f7
	ctx.f[6].f64 = (ctx.f[7].s64 as f64);
	// 831F6F54: FCA03018  frsp f5, f6
	ctx.f[5].f64 = (ctx.f[6].f64 as f32) as f64;
	// 831F6F58: EC8502B2  fmuls f4, f5, f10
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[10].f64) as f32) as f64);
	// 831F6F5C: D0830034  stfs f4, 0x34(r3)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 831F6F60: EC64482A  fadds f3, f4, f9
	ctx.f[3].f64 = ((ctx.f[4].f64 + ctx.f[9].f64) as f32) as f64;
	// 831F6F64: EC480132  fmuls f2, f8, f4
	ctx.f[2].f64 = (((ctx.f[8].f64 * ctx.f[4].f64) as f32) as f64);
	// 831F6F68: EC230032  fmuls f1, f3, f0
	ctx.f[1].f64 = (((ctx.f[3].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F6F6C: EC0C002A  fadds f0, f12, f0
	ctx.f[0].f64 = ((ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F6F70: ED2102F2  fmuls f9, f1, f11
	ctx.f[9].f64 = (((ctx.f[1].f64 * ctx.f[11].f64) as f32) as f64);
	// 831F6F74: D1280000  stfs f9, 0(r8)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F6F78: D0480004  stfs f2, 4(r8)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831F6F7C: 39080008  addi r8, r8, 8
	ctx.r[8].s64 = ctx.r[8].s64 + 8;
	// 831F6F80: 4082FFB0  bne 0x831f6f30
	if !ctx.cr[0].eq {
	pc = 0x831F6F30; continue 'dispatch;
	}
	// 831F6F84: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F6F88: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F6F8C: 5547083E  rotlwi r7, r10, 1
	ctx.r[7].u64 = ((ctx.r[10].u32).rotate_left(1)) as u64;
	// 831F6F90: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F6F94: 7CC95850  subf r6, r9, r11
	ctx.r[6].s64 = ctx.r[11].s64 - ctx.r[9].s64;
	// 831F6F98: 0CC70000  twi 6, r7, 0
	// 831F6F9C: 7D663B96  divwu r11, r6, r7
	ctx.r[11].u32 = ctx.r[6].u32 / ctx.r[7].u32;
	// 831F6FA0: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831F6FA4: 40980008  bge cr6, 0x831f6fac
	if !ctx.cr[6].lt {
	pc = 0x831F6FAC; continue 'dispatch;
	}
	// 831F6FA8: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 831F6FAC: 81630014  lwz r11, 0x14(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F6FB0: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831F6FB4: 7D4B4050  subf r10, r11, r8
	ctx.r[10].s64 = ctx.r[8].s64 - ctx.r[11].s64;
	// 831F6FB8: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F6FBC: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F6FC0: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F6FC4: 40980008  bge cr6, 0x831f6fcc
	if !ctx.cr[6].lt {
	pc = 0x831F6FCC; continue 'dispatch;
	}
	// 831F6FC8: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 831F6FCC: 3D40820C  lis r10, -0x7df4
	ctx.r[10].s64 = -2113142784;
	// 831F6FD0: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F6FD4: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F6FD8: C1A30034  lfs f13, 0x34(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(52 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F6FDC: C00A6AB0  lfs f0, 0x6ab0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(27312 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F6FE0: ED8D0032  fmuls f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F6FE4: FD60601E  fctiwz f11, f12
	ctx.f[11].s64 = if ctx.f[12].f64 > (i32::MAX as f64) { i32::MAX as i64 } else { ctx.f[12].f64.trunc() as i32 as i64 };
	// 831F6FE8: D961FFF0  stfd f11, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.f[11].u64 ) };
	// 831F6FEC: 8161FFF4  lwz r11, -0xc(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-12 as u32) ) } as u64;
	// 831F6FF0: 2F0B7FFF  cmpwi cr6, r11, 0x7fff
	ctx.cr[6].compare_i32(ctx.r[11].s32, 32767, &mut ctx.xer);
	// 831F6FF4: 41980010  blt cr6, 0x831f7004
	if ctx.cr[6].lt {
		sub_831F7004(ctx, base);
		return;
	}
	// 831F6FF8: 39607FFF  li r11, 0x7fff
	ctx.r[11].s64 = 32767;
	// 831F6FFC: B1630034  sth r11, 0x34(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), ctx.r[11].u16 ) };
	// 831F7000: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F7004(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831F7004 size=20
    let mut pc: u32 = 0x831F7004;
    'dispatch: loop {
        match pc {
            0x831F7004 => {
    //   block [0x831F7004..0x831F7018)
	// 831F7004: 2F0B8000  cmpwi cr6, r11, -0x8000
	ctx.cr[6].compare_i32(ctx.r[11].s32, -32768, &mut ctx.xer);
	// 831F7008: 41990008  bgt cr6, 0x831f7010
	if ctx.cr[6].gt {
	pc = 0x831F7010; continue 'dispatch;
	}
	// 831F700C: 3960801E  li r11, -0x7fe2
	ctx.r[11].s64 = -32738;
	// 831F7010: B1630034  sth r11, 0x34(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), ctx.r[11].u16 ) };
	// 831F7014: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F7018(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F7018 size=568
    let mut pc: u32 = 0x831F7018;
    'dispatch: loop {
        match pc {
            0x831F7018 => {
    //   block [0x831F7018..0x831F7250)
	// 831F7018: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 831F701C: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F7020: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F7024: 81430018  lwz r10, 0x18(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F7028: 38A30034  addi r5, r3, 0x34
	ctx.r[5].s64 = ctx.r[3].s64 + 52;
	// 831F702C: 81230008  lwz r9, 8(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F7030: 5566103A  slwi r6, r11, 2
	ctx.r[6].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831F7034: 8903000D  lbz r8, 0xd(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F7038: 7C8B5050  subf r4, r11, r10
	ctx.r[4].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 831F703C: 83E30004  lwz r31, 4(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F7040: 7D4849D6  mullw r10, r8, r9
	ctx.r[10].s64 = (ctx.r[8].s32 as i64) * (ctx.r[9].s32 as i64);
	// 831F7044: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F7048: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F704C: 7C840E70  srawi r4, r4, 1
	ctx.xer.ca = (ctx.r[4].s32 < 0) && ((ctx.r[4].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[4].s64 = (ctx.r[4].s32 >> 1) as i64;
	// 831F7050: 554A083C  slwi r10, r10, 1
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F7054: 7D09F850  subf r8, r9, r31
	ctx.r[8].s64 = ctx.r[31].s64 - ctx.r[9].s64;
	// 831F7058: 7D240194  addze r9, r4
	tmp.s64 = ctx.r[4].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[4].u32);
	ctx.r[9].s64 = tmp.s64;
	// 831F705C: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831F7060: 7D463A14  add r10, r6, r7
	ctx.r[10].u64 = ctx.r[6].u64 + ctx.r[7].u64;
	// 831F7064: 7F084800  cmpw cr6, r8, r9
	ctx.cr[6].compare_i32(ctx.r[8].s32, ctx.r[9].s32, &mut ctx.xer);
	// 831F7068: 41980008  blt cr6, 0x831f7070
	if ctx.cr[6].lt {
	pc = 0x831F7070; continue 'dispatch;
	}
	// 831F706C: 7D284B78  mr r8, r9
	ctx.r[8].u64 = ctx.r[9].u64;
	// 831F7070: 7D2707B4  extsw r7, r9
	ctx.r[7].s64 = ctx.r[9].s32 as i64;
	// 831F7074: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F7078: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F707C: 5509103A  slwi r9, r8, 2
	ctx.r[9].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831F7080: F8E1FFE0  std r7, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[7].u64 ) };
	// 831F7084: C961FFE0  lfd f11, -0x20(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 831F7088: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F708C: 3CC08201  lis r6, -0x7dff
	ctx.r[6].s64 = -2113863680;
	// 831F7090: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F7094: 3889007F  addi r4, r9, 0x7f
	ctx.r[4].s64 = ctx.r[9].s64 + 127;
	// 831F7098: C1A69524  lfs f13, -0x6adc(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(-27356 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F709C: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 831F70A0: 5487C9FE  srwi r7, r4, 7
	ctx.r[7].u32 = ctx.r[4].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F70A4: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 831F70A8: ED6C4824  fdivs f11, f12, f9
	ctx.f[11].f64 = ((ctx.f[12].f64 / ctx.f[9].f64) as f32) as f64;
	// 831F70AC: ED4B0372  fmuls f10, f11, f13
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F70B0: 419A0018  beq cr6, 0x831f70c8
	if ctx.cr[6].eq {
	pc = 0x831F70C8; continue 'dispatch;
	}
	// 831F70B4: 55263830  slwi r6, r9, 7
	ctx.r[6].u32 = ctx.r[9].u32.wrapping_shl(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831F70B8: 7C065A2C  dcbt r6, r11
	// 831F70BC: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 831F70C0: 7F093840  cmplw cr6, r9, r7
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831F70C4: 4198FFF0  blt cr6, 0x831f70b4
	if ctx.cr[6].lt {
	pc = 0x831F70B4; continue 'dispatch;
	}
	// 831F70C8: 3CC0820C  lis r6, -0x7df4
	ctx.r[6].s64 = -2113142784;
	// 831F70CC: 7CA92B78  mr r9, r5
	ctx.r[9].u64 = ctx.r[5].u64;
	// 831F70D0: 38E00002  li r7, 2
	ctx.r[7].s64 = 2;
	// 831F70D4: C1A67490  lfs f13, 0x7490(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(29840 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F70D8: A0C90000  lhz r6, 0(r9)
	ctx.r[6].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F70DC: 34E7FFFF  addic. r7, r7, -1
	ctx.xer.ca = (ctx.r[7].u32 > (!(-1 as u32)));
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 831F70E0: 7CC60734  extsh r6, r6
	ctx.r[6].s64 = ctx.r[6].s16 as i64;
	// 831F70E4: F8C1FFE0  std r6, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[6].u64 ) };
	// 831F70E8: C981FFE0  lfd f12, -0x20(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 831F70EC: FD20669C  fcfid f9, f12
	ctx.f[9].f64 = (ctx.f[12].s64 as f64);
	// 831F70F0: FD004818  frsp f8, f9
	ctx.f[8].f64 = (ctx.f[9].f64 as f32) as f64;
	// 831F70F4: ECE80372  fmuls f7, f8, f13
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F70F8: D0E90000  stfs f7, 0(r9)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F70FC: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 831F7100: 4082FFD8  bne 0x831f70d8
	if !ctx.cr[0].eq {
	pc = 0x831F70D8; continue 'dispatch;
	}
	// 831F7104: 3D208201  lis r9, -0x7dff
	ctx.r[9].s64 = -2113863680;
	// 831F7108: C1899450  lfs f12, -0x6bb0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-27568 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831F710C: A12B0002  lhz r9, 2(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(2 as u32) ) } as u64;
	// 831F7110: C1250004  lfs f9, 4(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831F7114: ED0B002A  fadds f8, f11, f0
	ctx.f[8].f64 = ((ctx.f[11].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F7118: 3508FFFF  addic. r8, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 831F711C: 7D260734  extsh r6, r9
	ctx.r[6].s64 = ctx.r[9].s16 as i64;
	// 831F7120: F8C1FFE0  std r6, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[6].u64 ) };
	// 831F7124: C8E1FFE0  lfd f7, -0x20(r1)
	ctx.f[7].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 831F7128: FCC03E9C  fcfid f6, f7
	ctx.f[6].f64 = (ctx.f[7].s64 as f64);
	// 831F712C: FCA03018  frsp f5, f6
	ctx.f[5].f64 = (ctx.f[6].f64 as f32) as f64;
	// 831F7130: EC850372  fmuls f4, f5, f13
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F7134: D0850004  stfs f4, 4(r5)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831F7138: EC64482A  fadds f3, f4, f9
	ctx.f[3].f64 = ((ctx.f[4].f64 + ctx.f[9].f64) as f32) as f64;
	// 831F713C: EC480132  fmuls f2, f8, f4
	ctx.f[2].f64 = (((ctx.f[8].f64 * ctx.f[4].f64) as f32) as f64);
	// 831F7140: EC230032  fmuls f1, f3, f0
	ctx.f[1].f64 = (((ctx.f[3].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F7144: ED210332  fmuls f9, f1, f12
	ctx.f[9].f64 = (((ctx.f[1].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F7148: D12A0400  stfs f9, 0x400(r10)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 831F714C: D04A0404  stfs f2, 0x404(r10)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(1028 as u32), tmp.u32 ) };
	// 831F7150: A08B0000  lhz r4, 0(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F7154: 7C870734  extsh r7, r4
	ctx.r[7].s64 = ctx.r[4].s16 as i64;
	// 831F7158: F8E1FFE8  std r7, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[7].u64 ) };
	// 831F715C: C8C1FFE8  lfd f6, -0x18(r1)
	ctx.f[6].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831F7160: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 831F7164: FCA0369C  fcfid f5, f6
	ctx.f[5].f64 = (ctx.f[6].s64 as f64);
	// 831F7168: C0E50000  lfs f7, 0(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831F716C: FC802818  frsp f4, f5
	ctx.f[4].f64 = (ctx.f[5].f64 as f32) as f64;
	// 831F7170: EC640372  fmuls f3, f4, f13
	ctx.f[3].f64 = (((ctx.f[4].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F7174: D0650000  stfs f3, 0(r5)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F7178: EC43382A  fadds f2, f3, f7
	ctx.f[2].f64 = ((ctx.f[3].f64 + ctx.f[7].f64) as f32) as f64;
	// 831F717C: ED220032  fmuls f9, f2, f0
	ctx.f[9].f64 = (((ctx.f[2].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F7180: EC2800F2  fmuls f1, f8, f3
	ctx.f[1].f64 = (((ctx.f[8].f64 * ctx.f[3].f64) as f32) as f64);
	// 831F7184: EC0A002A  fadds f0, f10, f0
	ctx.f[0].f64 = ((ctx.f[10].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F7188: ED090332  fmuls f8, f9, f12
	ctx.f[8].f64 = (((ctx.f[9].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F718C: D10A0000  stfs f8, 0(r10)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F7190: D02A0004  stfs f1, 4(r10)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831F7194: 394A0008  addi r10, r10, 8
	ctx.r[10].s64 = ctx.r[10].s64 + 8;
	// 831F7198: 4082FF74  bne 0x831f710c
	if !ctx.cr[0].eq {
	pc = 0x831F710C; continue 'dispatch;
	}
	// 831F719C: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F71A0: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F71A4: 5527083E  rotlwi r7, r9, 1
	ctx.r[7].u64 = ((ctx.r[9].u32).rotate_left(1)) as u64;
	// 831F71A8: 81230004  lwz r9, 4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F71AC: 7CC85850  subf r6, r8, r11
	ctx.r[6].s64 = ctx.r[11].s64 - ctx.r[8].s64;
	// 831F71B0: 0CC70000  twi 6, r7, 0
	// 831F71B4: 7D663B96  divwu r11, r6, r7
	ctx.r[11].u32 = ctx.r[6].u32 / ctx.r[7].u32;
	// 831F71B8: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831F71BC: 40980008  bge cr6, 0x831f71c4
	if !ctx.cr[6].lt {
	pc = 0x831F71C4; continue 'dispatch;
	}
	// 831F71C0: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 831F71C4: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F71C8: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F71CC: 7CE85050  subf r7, r8, r10
	ctx.r[7].s64 = ctx.r[10].s64 - ctx.r[8].s64;
	// 831F71D0: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 831F71D4: 54EAF0BE  srwi r10, r7, 2
	ctx.r[10].u32 = ctx.r[7].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F71D8: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F71DC: 40980008  bge cr6, 0x831f71e4
	if !ctx.cr[6].lt {
	pc = 0x831F71E4; continue 'dispatch;
	}
	// 831F71E0: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 831F71E4: 3D40820C  lis r10, -0x7df4
	ctx.r[10].s64 = -2113142784;
	// 831F71E8: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F71EC: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F71F0: 7CAB2B78  mr r11, r5
	ctx.r[11].u64 = ctx.r[5].u64;
	// 831F71F4: 39200002  li r9, 2
	ctx.r[9].s64 = 2;
	// 831F71F8: 38E07FFF  li r7, 0x7fff
	ctx.r[7].s64 = 32767;
	// 831F71FC: 3900801E  li r8, -0x7fe2
	ctx.r[8].s64 = -32738;
	// 831F7200: C00A6AB0  lfs f0, 0x6ab0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(27312 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F7204: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F7208: ED8D0032  fmuls f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F720C: FD60601E  fctiwz f11, f12
	ctx.f[11].s64 = if ctx.f[12].f64 > (i32::MAX as f64) { i32::MAX as i64 } else { ctx.f[12].f64.trunc() as i32 as i64 };
	// 831F7210: D961FFE8  stfd f11, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.f[11].u64 ) };
	// 831F7214: 8141FFEC  lwz r10, -0x14(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-20 as u32) ) } as u64;
	// 831F7218: 2F0A7FFF  cmpwi cr6, r10, 0x7fff
	ctx.cr[6].compare_i32(ctx.r[10].s32, 32767, &mut ctx.xer);
	// 831F721C: 4198000C  blt cr6, 0x831f7228
	if ctx.cr[6].lt {
	pc = 0x831F7228; continue 'dispatch;
	}
	// 831F7220: B0EB0000  sth r7, 0(r11)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[7].u16 ) };
	// 831F7224: 48000018  b 0x831f723c
	pc = 0x831F723C; continue 'dispatch;
	// 831F7228: 2F0A8000  cmpwi cr6, r10, -0x8000
	ctx.cr[6].compare_i32(ctx.r[10].s32, -32768, &mut ctx.xer);
	// 831F722C: 4199000C  bgt cr6, 0x831f7238
	if ctx.cr[6].gt {
	pc = 0x831F7238; continue 'dispatch;
	}
	// 831F7230: B10B0000  sth r8, 0(r11)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[8].u16 ) };
	// 831F7234: 48000008  b 0x831f723c
	pc = 0x831F723C; continue 'dispatch;
	// 831F7238: B14B0000  sth r10, 0(r11)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u16 ) };
	// 831F723C: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831F7240: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 831F7244: 4082FFC0  bne 0x831f7204
	if !ctx.cr[0].eq {
	pc = 0x831F7204; continue 'dispatch;
	}
	// 831F7248: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F724C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F7250(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F7250 size=684
    let mut pc: u32 = 0x831F7250;
    'dispatch: loop {
        match pc {
            0x831F7250 => {
    //   block [0x831F7250..0x831F74FC)
	// 831F7250: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 831F7254: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F7258: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F725C: 81430018  lwz r10, 0x18(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F7260: 39230034  addi r9, r3, 0x34
	ctx.r[9].s64 = ctx.r[3].s64 + 52;
	// 831F7264: 81030008  lwz r8, 8(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F7268: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831F726C: 88E3000D  lbz r7, 0xd(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F7270: 7C8B5050  subf r4, r11, r10
	ctx.r[4].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 831F7274: 83E30004  lwz r31, 4(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F7278: 7D4741D6  mullw r10, r7, r8
	ctx.r[10].s64 = (ctx.r[7].s32 as i64) * (ctx.r[8].s32 as i64);
	// 831F727C: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F7280: 80C30014  lwz r6, 0x14(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F7284: 7C840E70  srawi r4, r4, 1
	ctx.xer.ca = (ctx.r[4].s32 < 0) && ((ctx.r[4].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[4].s64 = (ctx.r[4].s32 >> 1) as i64;
	// 831F7288: 7CE8F850  subf r7, r8, r31
	ctx.r[7].s64 = ctx.r[31].s64 - ctx.r[8].s64;
	// 831F728C: 554A083C  slwi r10, r10, 1
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F7290: 7D040194  addze r8, r4
	tmp.s64 = ctx.r[4].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[4].u32);
	ctx.r[8].s64 = tmp.s64;
	// 831F7294: 7D4A5A14  add r10, r10, r11
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831F7298: 7D653214  add r11, r5, r6
	ctx.r[11].u64 = ctx.r[5].u64 + ctx.r[6].u64;
	// 831F729C: 7F074000  cmpw cr6, r7, r8
	ctx.cr[6].compare_i32(ctx.r[7].s32, ctx.r[8].s32, &mut ctx.xer);
	// 831F72A0: 41980008  blt cr6, 0x831f72a8
	if ctx.cr[6].lt {
	pc = 0x831F72A8; continue 'dispatch;
	}
	// 831F72A4: 7D074378  mr r7, r8
	ctx.r[7].u64 = ctx.r[8].u64;
	// 831F72A8: 7D0607B4  extsw r6, r8
	ctx.r[6].s64 = ctx.r[8].s32 as i64;
	// 831F72AC: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F72B0: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F72B4: 54E81838  slwi r8, r7, 3
	ctx.r[8].u32 = ctx.r[7].u32.wrapping_shl(3);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831F72B8: F8C1FFD0  std r6, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[6].u64 ) };
	// 831F72BC: C961FFD0  lfd f11, -0x30(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 831F72C0: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F72C4: 3CA08201  lis r5, -0x7dff
	ctx.r[5].s64 = -2113863680;
	// 831F72C8: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F72CC: 3888007F  addi r4, r8, 0x7f
	ctx.r[4].s64 = ctx.r[8].s64 + 127;
	// 831F72D0: C1A59524  lfs f13, -0x6adc(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(-27356 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F72D4: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 831F72D8: 5486C9FE  srwi r6, r4, 7
	ctx.r[6].u32 = ctx.r[4].u32.wrapping_shr(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831F72DC: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 831F72E0: ED6C4824  fdivs f11, f12, f9
	ctx.f[11].f64 = ((ctx.f[12].f64 / ctx.f[9].f64) as f32) as f64;
	// 831F72E4: ED4B0372  fmuls f10, f11, f13
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F72E8: 419A0018  beq cr6, 0x831f7300
	if ctx.cr[6].eq {
	pc = 0x831F7300; continue 'dispatch;
	}
	// 831F72EC: 55053830  slwi r5, r8, 7
	ctx.r[5].u32 = ctx.r[8].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831F72F0: 7C05522C  dcbt r5, r10
	// 831F72F4: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 831F72F8: 7F083040  cmplw cr6, r8, r6
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[6].u32, &mut ctx.xer);
	// 831F72FC: 4198FFF0  blt cr6, 0x831f72ec
	if ctx.cr[6].lt {
	pc = 0x831F72EC; continue 'dispatch;
	}
	// 831F7300: 3CA0820C  lis r5, -0x7df4
	ctx.r[5].s64 = -2113142784;
	// 831F7304: 7D284B78  mr r8, r9
	ctx.r[8].u64 = ctx.r[9].u64;
	// 831F7308: 38C00004  li r6, 4
	ctx.r[6].s64 = 4;
	// 831F730C: C1A57490  lfs f13, 0x7490(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(29840 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F7310: A0A80000  lhz r5, 0(r8)
	ctx.r[5].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F7314: 34C6FFFF  addic. r6, r6, -1
	ctx.xer.ca = (ctx.r[6].u32 > (!(-1 as u32)));
	ctx.r[6].s64 = ctx.r[6].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[6].s32, 0, &mut ctx.xer);
	// 831F7318: 7CA50734  extsh r5, r5
	ctx.r[5].s64 = ctx.r[5].s16 as i64;
	// 831F731C: F8A1FFD0  std r5, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[5].u64 ) };
	// 831F7320: C981FFD0  lfd f12, -0x30(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 831F7324: FD20669C  fcfid f9, f12
	ctx.f[9].f64 = (ctx.f[12].s64 as f64);
	// 831F7328: FD004818  frsp f8, f9
	ctx.f[8].f64 = (ctx.f[9].f64 as f32) as f64;
	// 831F732C: ECE80372  fmuls f7, f8, f13
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F7330: D0E80000  stfs f7, 0(r8)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F7334: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 831F7338: 4082FFD8  bne 0x831f7310
	if !ctx.cr[0].eq {
	pc = 0x831F7310; continue 'dispatch;
	}
	// 831F733C: 3D008201  lis r8, -0x7dff
	ctx.r[8].s64 = -2113863680;
	// 831F7340: C1889450  lfs f12, -0x6bb0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(-27568 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831F7344: A10A0006  lhz r8, 6(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(6 as u32) ) } as u64;
	// 831F7348: C129000C  lfs f9, 0xc(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(12 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831F734C: ED0B002A  fadds f8, f11, f0
	ctx.f[8].f64 = ((ctx.f[11].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F7350: 34E7FFFF  addic. r7, r7, -1
	ctx.xer.ca = (ctx.r[7].u32 > (!(-1 as u32)));
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 831F7354: 7D050734  extsh r5, r8
	ctx.r[5].s64 = ctx.r[8].s16 as i64;
	// 831F7358: F8A1FFD0  std r5, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[5].u64 ) };
	// 831F735C: C8E1FFD0  lfd f7, -0x30(r1)
	ctx.f[7].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 831F7360: FCC03E9C  fcfid f6, f7
	ctx.f[6].f64 = (ctx.f[7].s64 as f64);
	// 831F7364: FCA03018  frsp f5, f6
	ctx.f[5].f64 = (ctx.f[6].f64 as f32) as f64;
	// 831F7368: EC850372  fmuls f4, f5, f13
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F736C: D089000C  stfs f4, 0xc(r9)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831F7370: EC64482A  fadds f3, f4, f9
	ctx.f[3].f64 = ((ctx.f[4].f64 + ctx.f[9].f64) as f32) as f64;
	// 831F7374: EC480132  fmuls f2, f8, f4
	ctx.f[2].f64 = (((ctx.f[8].f64 * ctx.f[4].f64) as f32) as f64);
	// 831F7378: EC230032  fmuls f1, f3, f0
	ctx.f[1].f64 = (((ctx.f[3].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F737C: ED210332  fmuls f9, f1, f12
	ctx.f[9].f64 = (((ctx.f[1].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F7380: D12B0C00  stfs f9, 0xc00(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(3072 as u32), tmp.u32 ) };
	// 831F7384: D04B0C04  stfs f2, 0xc04(r11)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(3076 as u32), tmp.u32 ) };
	// 831F7388: A08A0004  lhz r4, 4(r10)
	ctx.r[4].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F738C: 7C860734  extsh r6, r4
	ctx.r[6].s64 = ctx.r[4].s16 as i64;
	// 831F7390: F8C1FFD8  std r6, -0x28(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), ctx.r[6].u64 ) };
	// 831F7394: C8C1FFD8  lfd f6, -0x28(r1)
	ctx.f[6].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-40 as u32) ) };
	// 831F7398: FCA0369C  fcfid f5, f6
	ctx.f[5].f64 = (ctx.f[6].s64 as f64);
	// 831F739C: C0E90008  lfs f7, 8(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831F73A0: FC802818  frsp f4, f5
	ctx.f[4].f64 = (ctx.f[5].f64 as f32) as f64;
	// 831F73A4: EC640372  fmuls f3, f4, f13
	ctx.f[3].f64 = (((ctx.f[4].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F73A8: D0690008  stfs f3, 8(r9)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831F73AC: EC43382A  fadds f2, f3, f7
	ctx.f[2].f64 = ((ctx.f[3].f64 + ctx.f[7].f64) as f32) as f64;
	// 831F73B0: ED220032  fmuls f9, f2, f0
	ctx.f[9].f64 = (((ctx.f[2].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F73B4: EC2800F2  fmuls f1, f8, f3
	ctx.f[1].f64 = (((ctx.f[8].f64 * ctx.f[3].f64) as f32) as f64);
	// 831F73B8: ECE90332  fmuls f7, f9, f12
	ctx.f[7].f64 = (((ctx.f[9].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F73BC: D0EB0800  stfs f7, 0x800(r11)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(2048 as u32), tmp.u32 ) };
	// 831F73C0: D02B0804  stfs f1, 0x804(r11)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(2052 as u32), tmp.u32 ) };
	// 831F73C4: A0AA0002  lhz r5, 2(r10)
	ctx.r[5].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(2 as u32) ) } as u64;
	// 831F73C8: 7CA80734  extsh r8, r5
	ctx.r[8].s64 = ctx.r[5].s16 as i64;
	// 831F73CC: F901FFE0  std r8, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[8].u64 ) };
	// 831F73D0: C8A1FFE0  lfd f5, -0x20(r1)
	ctx.f[5].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 831F73D4: FC802E9C  fcfid f4, f5
	ctx.f[4].f64 = (ctx.f[5].s64 as f64);
	// 831F73D8: C0C90004  lfs f6, 4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 831F73DC: FC602018  frsp f3, f4
	ctx.f[3].f64 = (ctx.f[4].f64 as f32) as f64;
	// 831F73E0: EC430372  fmuls f2, f3, f13
	ctx.f[2].f64 = (((ctx.f[3].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F73E4: D0490004  stfs f2, 4(r9)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831F73E8: EC22302A  fadds f1, f2, f6
	ctx.f[1].f64 = ((ctx.f[2].f64 + ctx.f[6].f64) as f32) as f64;
	// 831F73EC: ECE10032  fmuls f7, f1, f0
	ctx.f[7].f64 = (((ctx.f[1].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F73F0: ED2800B2  fmuls f9, f8, f2
	ctx.f[9].f64 = (((ctx.f[8].f64 * ctx.f[2].f64) as f32) as f64);
	// 831F73F4: ECC70332  fmuls f6, f7, f12
	ctx.f[6].f64 = (((ctx.f[7].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F73F8: D0CB0400  stfs f6, 0x400(r11)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 831F73FC: D12B0404  stfs f9, 0x404(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(1028 as u32), tmp.u32 ) };
	// 831F7400: A0CA0000  lhz r6, 0(r10)
	ctx.r[6].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F7404: 7CC40734  extsh r4, r6
	ctx.r[4].s64 = ctx.r[6].s16 as i64;
	// 831F7408: F881FFE8  std r4, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[4].u64 ) };
	// 831F740C: C881FFE8  lfd f4, -0x18(r1)
	ctx.f[4].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831F7410: 394A0008  addi r10, r10, 8
	ctx.r[10].s64 = ctx.r[10].s64 + 8;
	// 831F7414: FC60269C  fcfid f3, f4
	ctx.f[3].f64 = (ctx.f[4].s64 as f64);
	// 831F7418: C0A90000  lfs f5, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831F741C: FC401818  frsp f2, f3
	ctx.f[2].f64 = (ctx.f[3].f64 as f32) as f64;
	// 831F7420: EC220372  fmuls f1, f2, f13
	ctx.f[1].f64 = (((ctx.f[2].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F7424: D0290000  stfs f1, 0(r9)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F7428: ED21282A  fadds f9, f1, f5
	ctx.f[9].f64 = ((ctx.f[1].f64 + ctx.f[5].f64) as f32) as f64;
	// 831F742C: ECE90032  fmuls f7, f9, f0
	ctx.f[7].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F7430: ED080072  fmuls f8, f8, f1
	ctx.f[8].f64 = (((ctx.f[8].f64 * ctx.f[1].f64) as f32) as f64);
	// 831F7434: EC0A002A  fadds f0, f10, f0
	ctx.f[0].f64 = ((ctx.f[10].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F7438: ECC70332  fmuls f6, f7, f12
	ctx.f[6].f64 = (((ctx.f[7].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F743C: D0CB0000  stfs f6, 0(r11)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F7440: D10B0004  stfs f8, 4(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831F7444: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 831F7448: 4082FEFC  bne 0x831f7344
	if !ctx.cr[0].eq {
	pc = 0x831F7344; continue 'dispatch;
	}
	// 831F744C: 8903000D  lbz r8, 0xd(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F7450: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F7454: 5506083E  rotlwi r6, r8, 1
	ctx.r[6].u64 = ((ctx.r[8].u32).rotate_left(1)) as u64;
	// 831F7458: 81030004  lwz r8, 4(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F745C: 7CA75050  subf r5, r7, r10
	ctx.r[5].s64 = ctx.r[10].s64 - ctx.r[7].s64;
	// 831F7460: 0CC60000  twi 6, r6, 0
	// 831F7464: 7D453396  divwu r10, r5, r6
	ctx.r[10].u32 = ctx.r[5].u32 / ctx.r[6].u32;
	// 831F7468: 7F0A4040  cmplw cr6, r10, r8
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831F746C: 40980008  bge cr6, 0x831f7474
	if !ctx.cr[6].lt {
	pc = 0x831F7474; continue 'dispatch;
	}
	// 831F7470: 7D485378  mr r8, r10
	ctx.r[8].u64 = ctx.r[10].u64;
	// 831F7474: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F7478: 81430018  lwz r10, 0x18(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F747C: 7CC75850  subf r6, r7, r11
	ctx.r[6].s64 = ctx.r[11].s64 - ctx.r[7].s64;
	// 831F7480: 91030008  stw r8, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 831F7484: 54CBF0BE  srwi r11, r6, 2
	ctx.r[11].u32 = ctx.r[6].u32.wrapping_shr(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831F7488: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831F748C: 41980008  blt cr6, 0x831f7494
	if ctx.cr[6].lt {
	pc = 0x831F7494; continue 'dispatch;
	}
	// 831F7490: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 831F7494: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F7498: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 831F749C: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F74A0: 39400004  li r10, 4
	ctx.r[10].s64 = 4;
	// 831F74A4: 38E07FFF  li r7, 0x7fff
	ctx.r[7].s64 = 32767;
	// 831F74A8: 3900801E  li r8, -0x7fe2
	ctx.r[8].s64 = -32738;
	// 831F74AC: C00B6AB0  lfs f0, 0x6ab0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(27312 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F74B0: C1A90000  lfs f13, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F74B4: ED8D0032  fmuls f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F74B8: FD60601E  fctiwz f11, f12
	ctx.f[11].s64 = if ctx.f[12].f64 > (i32::MAX as f64) { i32::MAX as i64 } else { ctx.f[12].f64.trunc() as i32 as i64 };
	// 831F74BC: D961FFE8  stfd f11, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.f[11].u64 ) };
	// 831F74C0: 8161FFEC  lwz r11, -0x14(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-20 as u32) ) } as u64;
	// 831F74C4: 2F0B7FFF  cmpwi cr6, r11, 0x7fff
	ctx.cr[6].compare_i32(ctx.r[11].s32, 32767, &mut ctx.xer);
	// 831F74C8: 4198000C  blt cr6, 0x831f74d4
	if ctx.cr[6].lt {
	pc = 0x831F74D4; continue 'dispatch;
	}
	// 831F74CC: B0E90000  sth r7, 0(r9)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[7].u16 ) };
	// 831F74D0: 48000018  b 0x831f74e8
	pc = 0x831F74E8; continue 'dispatch;
	// 831F74D4: 2F0B8000  cmpwi cr6, r11, -0x8000
	ctx.cr[6].compare_i32(ctx.r[11].s32, -32768, &mut ctx.xer);
	// 831F74D8: 4199000C  bgt cr6, 0x831f74e4
	if ctx.cr[6].gt {
	pc = 0x831F74E4; continue 'dispatch;
	}
	// 831F74DC: B1090000  sth r8, 0(r9)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[8].u16 ) };
	// 831F74E0: 48000008  b 0x831f74e8
	pc = 0x831F74E8; continue 'dispatch;
	// 831F74E4: B1690000  sth r11, 0(r9)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[11].u16 ) };
	// 831F74E8: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831F74EC: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 831F74F0: 4082FFC0  bne 0x831f74b0
	if !ctx.cr[0].eq {
	pc = 0x831F74B0; continue 'dispatch;
	}
	// 831F74F4: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F74F8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F7500(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F7500 size=812
    let mut pc: u32 = 0x831F7500;
    'dispatch: loop {
        match pc {
            0x831F7500 => {
    //   block [0x831F7500..0x831F782C)
	// 831F7500: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 831F7504: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F7508: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F750C: 81230018  lwz r9, 0x18(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F7510: 39430034  addi r10, r3, 0x34
	ctx.r[10].s64 = ctx.r[3].s64 + 52;
	// 831F7514: 81030008  lwz r8, 8(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F7518: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831F751C: 88E3000D  lbz r7, 0xd(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F7520: 7C8B4850  subf r4, r11, r9
	ctx.r[4].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 831F7524: 83E30004  lwz r31, 4(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F7528: 7D2741D6  mullw r9, r7, r8
	ctx.r[9].s64 = (ctx.r[7].s32 as i64) * (ctx.r[8].s32 as i64);
	// 831F752C: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F7530: 80C30014  lwz r6, 0x14(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F7534: 7C840E70  srawi r4, r4, 1
	ctx.xer.ca = (ctx.r[4].s32 < 0) && ((ctx.r[4].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[4].s64 = (ctx.r[4].s32 >> 1) as i64;
	// 831F7538: 7CE8F850  subf r7, r8, r31
	ctx.r[7].s64 = ctx.r[31].s64 - ctx.r[8].s64;
	// 831F753C: 5529083C  slwi r9, r9, 1
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(1);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831F7540: 7D040194  addze r8, r4
	tmp.s64 = ctx.r[4].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[4].u32);
	ctx.r[8].s64 = tmp.s64;
	// 831F7544: 7D295A14  add r9, r9, r11
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[11].u64;
	// 831F7548: 7D653214  add r11, r5, r6
	ctx.r[11].u64 = ctx.r[5].u64 + ctx.r[6].u64;
	// 831F754C: 7F074000  cmpw cr6, r7, r8
	ctx.cr[6].compare_i32(ctx.r[7].s32, ctx.r[8].s32, &mut ctx.xer);
	// 831F7550: 41980008  blt cr6, 0x831f7558
	if ctx.cr[6].lt {
	pc = 0x831F7558; continue 'dispatch;
	}
	// 831F7554: 7D074378  mr r7, r8
	ctx.r[7].u64 = ctx.r[8].u64;
	// 831F7558: 7D0607B4  extsw r6, r8
	ctx.r[6].s64 = ctx.r[8].s32 as i64;
	// 831F755C: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F7560: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F7564: 54E8083C  slwi r8, r7, 1
	ctx.r[8].u32 = ctx.r[7].u32.wrapping_shl(1);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831F7568: F8C1FFC0  std r6, -0x40(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-64 as u32), ctx.r[6].u64 ) };
	// 831F756C: C961FFC0  lfd f11, -0x40(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-64 as u32) ) };
	// 831F7570: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F7574: 7CA74214  add r5, r7, r8
	ctx.r[5].u64 = ctx.r[7].u64 + ctx.r[8].u64;
	// 831F7578: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F757C: 54A8103A  slwi r8, r5, 2
	ctx.r[8].u32 = ctx.r[5].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831F7580: 3C808201  lis r4, -0x7dff
	ctx.r[4].s64 = -2113863680;
	// 831F7584: 38C8007F  addi r6, r8, 0x7f
	ctx.r[6].s64 = ctx.r[8].s64 + 127;
	// 831F7588: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 831F758C: 54C6C9FE  srwi r6, r6, 7
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shr(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831F7590: C1A49524  lfs f13, -0x6adc(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(-27356 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F7594: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 831F7598: ED6C4824  fdivs f11, f12, f9
	ctx.f[11].f64 = ((ctx.f[12].f64 / ctx.f[9].f64) as f32) as f64;
	// 831F759C: ED4B0372  fmuls f10, f11, f13
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F75A0: 419A0018  beq cr6, 0x831f75b8
	if ctx.cr[6].eq {
	pc = 0x831F75B8; continue 'dispatch;
	}
	// 831F75A4: 55053830  slwi r5, r8, 7
	ctx.r[5].u32 = ctx.r[8].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831F75A8: 7C054A2C  dcbt r5, r9
	// 831F75AC: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 831F75B0: 7F083040  cmplw cr6, r8, r6
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[6].u32, &mut ctx.xer);
	// 831F75B4: 4198FFF0  blt cr6, 0x831f75a4
	if ctx.cr[6].lt {
	pc = 0x831F75A4; continue 'dispatch;
	}
	// 831F75B8: 3CA0820C  lis r5, -0x7df4
	ctx.r[5].s64 = -2113142784;
	// 831F75BC: 7D485378  mr r8, r10
	ctx.r[8].u64 = ctx.r[10].u64;
	// 831F75C0: 38C00006  li r6, 6
	ctx.r[6].s64 = 6;
	// 831F75C4: C1A57490  lfs f13, 0x7490(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(29840 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F75C8: A0A80000  lhz r5, 0(r8)
	ctx.r[5].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F75CC: 34C6FFFF  addic. r6, r6, -1
	ctx.xer.ca = (ctx.r[6].u32 > (!(-1 as u32)));
	ctx.r[6].s64 = ctx.r[6].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[6].s32, 0, &mut ctx.xer);
	// 831F75D0: 7CA50734  extsh r5, r5
	ctx.r[5].s64 = ctx.r[5].s16 as i64;
	// 831F75D4: F8A1FFC0  std r5, -0x40(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-64 as u32), ctx.r[5].u64 ) };
	// 831F75D8: C981FFC0  lfd f12, -0x40(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-64 as u32) ) };
	// 831F75DC: FD20669C  fcfid f9, f12
	ctx.f[9].f64 = (ctx.f[12].s64 as f64);
	// 831F75E0: FD004818  frsp f8, f9
	ctx.f[8].f64 = (ctx.f[9].f64 as f32) as f64;
	// 831F75E4: ECE80372  fmuls f7, f8, f13
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F75E8: D0E80000  stfs f7, 0(r8)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F75EC: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 831F75F0: 4082FFD8  bne 0x831f75c8
	if !ctx.cr[0].eq {
	pc = 0x831F75C8; continue 'dispatch;
	}
	// 831F75F4: 3D008201  lis r8, -0x7dff
	ctx.r[8].s64 = -2113863680;
	// 831F75F8: C1889450  lfs f12, -0x6bb0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(-27568 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831F75FC: A109000A  lhz r8, 0xa(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(10 as u32) ) } as u64;
	// 831F7600: C12A0014  lfs f9, 0x14(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(20 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831F7604: ED0B002A  fadds f8, f11, f0
	ctx.f[8].f64 = ((ctx.f[11].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F7608: 34E7FFFF  addic. r7, r7, -1
	ctx.xer.ca = (ctx.r[7].u32 > (!(-1 as u32)));
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 831F760C: 7D050734  extsh r5, r8
	ctx.r[5].s64 = ctx.r[8].s16 as i64;
	// 831F7610: F8A1FFC0  std r5, -0x40(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-64 as u32), ctx.r[5].u64 ) };
	// 831F7614: C8E1FFC0  lfd f7, -0x40(r1)
	ctx.f[7].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-64 as u32) ) };
	// 831F7618: FCC03E9C  fcfid f6, f7
	ctx.f[6].f64 = (ctx.f[7].s64 as f64);
	// 831F761C: FCA03018  frsp f5, f6
	ctx.f[5].f64 = (ctx.f[6].f64 as f32) as f64;
	// 831F7620: EC850372  fmuls f4, f5, f13
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F7624: D08A0014  stfs f4, 0x14(r10)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831F7628: EC64482A  fadds f3, f4, f9
	ctx.f[3].f64 = ((ctx.f[4].f64 + ctx.f[9].f64) as f32) as f64;
	// 831F762C: EC480132  fmuls f2, f8, f4
	ctx.f[2].f64 = (((ctx.f[8].f64 * ctx.f[4].f64) as f32) as f64);
	// 831F7630: EC230032  fmuls f1, f3, f0
	ctx.f[1].f64 = (((ctx.f[3].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F7634: ED210332  fmuls f9, f1, f12
	ctx.f[9].f64 = (((ctx.f[1].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F7638: D12B1400  stfs f9, 0x1400(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(5120 as u32), tmp.u32 ) };
	// 831F763C: D04B1404  stfs f2, 0x1404(r11)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(5124 as u32), tmp.u32 ) };
	// 831F7640: A0890008  lhz r4, 8(r9)
	ctx.r[4].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F7644: 7C860734  extsh r6, r4
	ctx.r[6].s64 = ctx.r[4].s16 as i64;
	// 831F7648: F8C1FFC8  std r6, -0x38(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-56 as u32), ctx.r[6].u64 ) };
	// 831F764C: C8C1FFC8  lfd f6, -0x38(r1)
	ctx.f[6].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-56 as u32) ) };
	// 831F7650: FCA0369C  fcfid f5, f6
	ctx.f[5].f64 = (ctx.f[6].s64 as f64);
	// 831F7654: C0EA0010  lfs f7, 0x10(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(16 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831F7658: FC802818  frsp f4, f5
	ctx.f[4].f64 = (ctx.f[5].f64 as f32) as f64;
	// 831F765C: EC640372  fmuls f3, f4, f13
	ctx.f[3].f64 = (((ctx.f[4].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F7660: D06A0010  stfs f3, 0x10(r10)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831F7664: EC43382A  fadds f2, f3, f7
	ctx.f[2].f64 = ((ctx.f[3].f64 + ctx.f[7].f64) as f32) as f64;
	// 831F7668: ED220032  fmuls f9, f2, f0
	ctx.f[9].f64 = (((ctx.f[2].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F766C: EC2800F2  fmuls f1, f8, f3
	ctx.f[1].f64 = (((ctx.f[8].f64 * ctx.f[3].f64) as f32) as f64);
	// 831F7670: ECE90332  fmuls f7, f9, f12
	ctx.f[7].f64 = (((ctx.f[9].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F7674: D0EB1000  stfs f7, 0x1000(r11)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4096 as u32), tmp.u32 ) };
	// 831F7678: D02B1004  stfs f1, 0x1004(r11)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4100 as u32), tmp.u32 ) };
	// 831F767C: A0A90006  lhz r5, 6(r9)
	ctx.r[5].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(6 as u32) ) } as u64;
	// 831F7680: 7CA80734  extsh r8, r5
	ctx.r[8].s64 = ctx.r[5].s16 as i64;
	// 831F7684: F901FFD0  std r8, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[8].u64 ) };
	// 831F7688: C8A1FFD0  lfd f5, -0x30(r1)
	ctx.f[5].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 831F768C: FC802E9C  fcfid f4, f5
	ctx.f[4].f64 = (ctx.f[5].s64 as f64);
	// 831F7690: C0CA000C  lfs f6, 0xc(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(12 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 831F7694: FC602018  frsp f3, f4
	ctx.f[3].f64 = (ctx.f[4].f64 as f32) as f64;
	// 831F7698: EC430372  fmuls f2, f3, f13
	ctx.f[2].f64 = (((ctx.f[3].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F769C: D04A000C  stfs f2, 0xc(r10)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831F76A0: EC22302A  fadds f1, f2, f6
	ctx.f[1].f64 = ((ctx.f[2].f64 + ctx.f[6].f64) as f32) as f64;
	// 831F76A4: ECE10032  fmuls f7, f1, f0
	ctx.f[7].f64 = (((ctx.f[1].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F76A8: ED2800B2  fmuls f9, f8, f2
	ctx.f[9].f64 = (((ctx.f[8].f64 * ctx.f[2].f64) as f32) as f64);
	// 831F76AC: ECC70332  fmuls f6, f7, f12
	ctx.f[6].f64 = (((ctx.f[7].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F76B0: D0CB0C00  stfs f6, 0xc00(r11)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(3072 as u32), tmp.u32 ) };
	// 831F76B4: D12B0C04  stfs f9, 0xc04(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(3076 as u32), tmp.u32 ) };
	// 831F76B8: A0C90004  lhz r6, 4(r9)
	ctx.r[6].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F76BC: 7CC40734  extsh r4, r6
	ctx.r[4].s64 = ctx.r[6].s16 as i64;
	// 831F76C0: F881FFD8  std r4, -0x28(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), ctx.r[4].u64 ) };
	// 831F76C4: C881FFD8  lfd f4, -0x28(r1)
	ctx.f[4].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-40 as u32) ) };
	// 831F76C8: FC60269C  fcfid f3, f4
	ctx.f[3].f64 = (ctx.f[4].s64 as f64);
	// 831F76CC: C0AA0008  lfs f5, 8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831F76D0: FC401818  frsp f2, f3
	ctx.f[2].f64 = (ctx.f[3].f64 as f32) as f64;
	// 831F76D4: EC220372  fmuls f1, f2, f13
	ctx.f[1].f64 = (((ctx.f[2].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F76D8: D02A0008  stfs f1, 8(r10)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831F76DC: ED21282A  fadds f9, f1, f5
	ctx.f[9].f64 = ((ctx.f[1].f64 + ctx.f[5].f64) as f32) as f64;
	// 831F76E0: ECC90032  fmuls f6, f9, f0
	ctx.f[6].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F76E4: ECE80072  fmuls f7, f8, f1
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[1].f64) as f32) as f64);
	// 831F76E8: ECA60332  fmuls f5, f6, f12
	ctx.f[5].f64 = (((ctx.f[6].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F76EC: D0AB0800  stfs f5, 0x800(r11)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(2048 as u32), tmp.u32 ) };
	// 831F76F0: D0EB0804  stfs f7, 0x804(r11)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(2052 as u32), tmp.u32 ) };
	// 831F76F4: A1090002  lhz r8, 2(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(2 as u32) ) } as u64;
	// 831F76F8: 7D050734  extsh r5, r8
	ctx.r[5].s64 = ctx.r[8].s16 as i64;
	// 831F76FC: F8A1FFE0  std r5, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[5].u64 ) };
	// 831F7700: C861FFE0  lfd f3, -0x20(r1)
	ctx.f[3].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 831F7704: FC401E9C  fcfid f2, f3
	ctx.f[2].f64 = (ctx.f[3].s64 as f64);
	// 831F7708: C08A0004  lfs f4, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831F770C: FC201018  frsp f1, f2
	ctx.f[1].f64 = (ctx.f[2].f64 as f32) as f64;
	// 831F7710: ED210372  fmuls f9, f1, f13
	ctx.f[9].f64 = (((ctx.f[1].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F7714: D12A0004  stfs f9, 4(r10)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831F7718: ECE9202A  fadds f7, f9, f4
	ctx.f[7].f64 = ((ctx.f[9].f64 + ctx.f[4].f64) as f32) as f64;
	// 831F771C: ECA70032  fmuls f5, f7, f0
	ctx.f[5].f64 = (((ctx.f[7].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F7720: ECC80272  fmuls f6, f8, f9
	ctx.f[6].f64 = (((ctx.f[8].f64 * ctx.f[9].f64) as f32) as f64);
	// 831F7724: EC850332  fmuls f4, f5, f12
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F7728: D08B0400  stfs f4, 0x400(r11)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 831F772C: D0CB0404  stfs f6, 0x404(r11)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(1028 as u32), tmp.u32 ) };
	// 831F7730: A0890000  lhz r4, 0(r9)
	ctx.r[4].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F7734: C06A0000  lfs f3, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 831F7738: 3929000C  addi r9, r9, 0xc
	ctx.r[9].s64 = ctx.r[9].s64 + 12;
	// 831F773C: 7C860734  extsh r6, r4
	ctx.r[6].s64 = ctx.r[4].s16 as i64;
	// 831F7740: F8C1FFE8  std r6, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[6].u64 ) };
	// 831F7744: C841FFE8  lfd f2, -0x18(r1)
	ctx.f[2].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831F7748: FC20169C  fcfid f1, f2
	ctx.f[1].f64 = (ctx.f[2].s64 as f64);
	// 831F774C: FD200818  frsp f9, f1
	ctx.f[9].f64 = (ctx.f[1].f64 as f32) as f64;
	// 831F7750: ECE90372  fmuls f7, f9, f13
	ctx.f[7].f64 = (((ctx.f[9].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F7754: D0EA0000  stfs f7, 0(r10)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F7758: ECC7182A  fadds f6, f7, f3
	ctx.f[6].f64 = ((ctx.f[7].f64 + ctx.f[3].f64) as f32) as f64;
	// 831F775C: ECA801F2  fmuls f5, f8, f7
	ctx.f[5].f64 = (((ctx.f[8].f64 * ctx.f[7].f64) as f32) as f64);
	// 831F7760: EC860032  fmuls f4, f6, f0
	ctx.f[4].f64 = (((ctx.f[6].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F7764: EC0A002A  fadds f0, f10, f0
	ctx.f[0].f64 = ((ctx.f[10].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F7768: EC640332  fmuls f3, f4, f12
	ctx.f[3].f64 = (((ctx.f[4].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F776C: D06B0000  stfs f3, 0(r11)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F7770: D0AB0004  stfs f5, 4(r11)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831F7774: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 831F7778: 4082FE84  bne 0x831f75fc
	if !ctx.cr[0].eq {
	pc = 0x831F75FC; continue 'dispatch;
	}
	// 831F777C: 8903000D  lbz r8, 0xd(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F7780: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F7784: 5506083E  rotlwi r6, r8, 1
	ctx.r[6].u64 = ((ctx.r[8].u32).rotate_left(1)) as u64;
	// 831F7788: 81030004  lwz r8, 4(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F778C: 7CA74850  subf r5, r7, r9
	ctx.r[5].s64 = ctx.r[9].s64 - ctx.r[7].s64;
	// 831F7790: 0CC60000  twi 6, r6, 0
	// 831F7794: 7D253396  divwu r9, r5, r6
	ctx.r[9].u32 = ctx.r[5].u32 / ctx.r[6].u32;
	// 831F7798: 7F094040  cmplw cr6, r9, r8
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831F779C: 40980008  bge cr6, 0x831f77a4
	if !ctx.cr[6].lt {
	pc = 0x831F77A4; continue 'dispatch;
	}
	// 831F77A0: 7D284B78  mr r8, r9
	ctx.r[8].u64 = ctx.r[9].u64;
	// 831F77A4: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F77A8: 81230018  lwz r9, 0x18(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F77AC: 7CC75850  subf r6, r7, r11
	ctx.r[6].s64 = ctx.r[11].s64 - ctx.r[7].s64;
	// 831F77B0: 91030008  stw r8, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 831F77B4: 54CBF0BE  srwi r11, r6, 2
	ctx.r[11].u32 = ctx.r[6].u32.wrapping_shr(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831F77B8: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831F77BC: 41980008  blt cr6, 0x831f77c4
	if ctx.cr[6].lt {
	pc = 0x831F77C4; continue 'dispatch;
	}
	// 831F77C0: 7D2B4B78  mr r11, r9
	ctx.r[11].u64 = ctx.r[9].u64;
	// 831F77C4: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F77C8: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 831F77CC: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F77D0: 39200006  li r9, 6
	ctx.r[9].s64 = 6;
	// 831F77D4: 38E07FFF  li r7, 0x7fff
	ctx.r[7].s64 = 32767;
	// 831F77D8: 3900801E  li r8, -0x7fe2
	ctx.r[8].s64 = -32738;
	// 831F77DC: C00B6AB0  lfs f0, 0x6ab0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(27312 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F77E0: C1AA0000  lfs f13, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F77E4: ED8D0032  fmuls f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F77E8: FD60601E  fctiwz f11, f12
	ctx.f[11].s64 = if ctx.f[12].f64 > (i32::MAX as f64) { i32::MAX as i64 } else { ctx.f[12].f64.trunc() as i32 as i64 };
	// 831F77EC: D961FFE8  stfd f11, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.f[11].u64 ) };
	// 831F77F0: 8161FFEC  lwz r11, -0x14(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-20 as u32) ) } as u64;
	// 831F77F4: 2F0B7FFF  cmpwi cr6, r11, 0x7fff
	ctx.cr[6].compare_i32(ctx.r[11].s32, 32767, &mut ctx.xer);
	// 831F77F8: 4198000C  blt cr6, 0x831f7804
	if ctx.cr[6].lt {
	pc = 0x831F7804; continue 'dispatch;
	}
	// 831F77FC: B0EA0000  sth r7, 0(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[7].u16 ) };
	// 831F7800: 48000018  b 0x831f7818
	pc = 0x831F7818; continue 'dispatch;
	// 831F7804: 2F0B8000  cmpwi cr6, r11, -0x8000
	ctx.cr[6].compare_i32(ctx.r[11].s32, -32768, &mut ctx.xer);
	// 831F7808: 4199000C  bgt cr6, 0x831f7814
	if ctx.cr[6].gt {
	pc = 0x831F7814; continue 'dispatch;
	}
	// 831F780C: B10A0000  sth r8, 0(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[8].u16 ) };
	// 831F7810: 48000008  b 0x831f7818
	pc = 0x831F7818; continue 'dispatch;
	// 831F7814: B16A0000  sth r11, 0(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[11].u16 ) };
	// 831F7818: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831F781C: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 831F7820: 4082FFC0  bne 0x831f77e0
	if !ctx.cr[0].eq {
	pc = 0x831F77E0; continue 'dispatch;
	}
	// 831F7824: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F7828: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F7830(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F7830 size=532
    let mut pc: u32 = 0x831F7830;
    'dispatch: loop {
        match pc {
            0x831F7830 => {
    //   block [0x831F7830..0x831F7A44)
	// 831F7830: FBC1FFF0  std r30, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[30].u64 ) };
	// 831F7834: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 831F7838: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F783C: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F7840: 81430018  lwz r10, 0x18(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F7844: 38830034  addi r4, r3, 0x34
	ctx.r[4].s64 = ctx.r[3].s64 + 52;
	// 831F7848: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831F784C: 83E30008  lwz r31, 8(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F7850: 7D2B5050  subf r9, r11, r10
	ctx.r[9].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 831F7854: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F7858: 8903000D  lbz r8, 0xd(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F785C: 7D3E0E70  srawi r30, r9, 1
	ctx.xer.ca = (ctx.r[9].s32 < 0) && ((ctx.r[9].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[30].s64 = (ctx.r[9].s32 >> 1) as i64;
	// 831F7860: 80C30014  lwz r6, 0x14(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F7864: 7D5F5850  subf r10, r31, r11
	ctx.r[10].s64 = ctx.r[11].s64 - ctx.r[31].s64;
	// 831F7868: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F786C: 7CE8F9D6  mullw r7, r8, r31
	ctx.r[7].s64 = (ctx.r[8].s32 as i64) * (ctx.r[31].s32 as i64);
	// 831F7870: 7D7E0194  addze r11, r30
	tmp.s64 = ctx.r[30].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[30].u32);
	ctx.r[11].s64 = tmp.s64;
	// 831F7874: 7CC53214  add r6, r5, r6
	ctx.r[6].u64 = ctx.r[5].u64 + ctx.r[6].u64;
	// 831F7878: 7CE74A14  add r7, r7, r9
	ctx.r[7].u64 = ctx.r[7].u64 + ctx.r[9].u64;
	// 831F787C: 7F0A5800  cmpw cr6, r10, r11
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[11].s32, &mut ctx.xer);
	// 831F7880: 7D455378  mr r5, r10
	ctx.r[5].u64 = ctx.r[10].u64;
	// 831F7884: 41980008  blt cr6, 0x831f788c
	if ctx.cr[6].lt {
	pc = 0x831F788C; continue 'dispatch;
	}
	// 831F7888: 7D655B78  mr r5, r11
	ctx.r[5].u64 = ctx.r[11].u64;
	// 831F788C: 7D6B07B4  extsw r11, r11
	ctx.r[11].s64 = ctx.r[11].s32 as i64;
	// 831F7890: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F7894: ED4D0028  fsubs f10, f13, f0
	ctx.f[10].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F7898: 3D408201  lis r10, -0x7dff
	ctx.r[10].s64 = -2113863680;
	// 831F789C: F961FFE0  std r11, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[11].u64 ) };
	// 831F78A0: C921FFE0  lfd f9, -0x20(r1)
	ctx.f[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 831F78A4: FD004E9C  fcfid f8, f9
	ctx.f[8].f64 = (ctx.f[9].s64 as f64);
	// 831F78A8: 3D208213  lis r9, -0x7ded
	ctx.r[9].s64 = -2112684032;
	// 831F78AC: FCE04018  frsp f7, f8
	ctx.f[7].f64 = (ctx.f[8].f64 as f32) as f64;
	// 831F78B0: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 831F78B4: C1AA9524  lfs f13, -0x6adc(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-27356 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F78B8: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 831F78BC: C169B184  lfs f11, -0x4e7c(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-20092 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831F78C0: C18B4E60  lfs f12, 0x4e60(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20064 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831F78C4: ED2A3824  fdivs f9, f10, f7
	ctx.f[9].f64 = ((ctx.f[10].f64 / ctx.f[7].f64) as f32) as f64;
	// 831F78C8: ED090372  fmuls f8, f9, f13
	ctx.f[8].f64 = (((ctx.f[9].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F78CC: 419A0038  beq cr6, 0x831f7904
	if ctx.cr[6].eq {
	pc = 0x831F7904; continue 'dispatch;
	}
	// 831F78D0: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 831F78D4: 7D0A4378  mr r10, r8
	ctx.r[10].u64 = ctx.r[8].u64;
	// 831F78D8: 892B0000  lbz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F78DC: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831F78E0: F921FFE0  std r9, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[9].u64 ) };
	// 831F78E4: C9A1FFE0  lfd f13, -0x20(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 831F78E8: FD406E9C  fcfid f10, f13
	ctx.f[10].f64 = (ctx.f[13].s64 as f64);
	// 831F78EC: FCE05018  frsp f7, f10
	ctx.f[7].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F78F0: ECC76028  fsubs f6, f7, f12
	ctx.f[6].f64 = (((ctx.f[7].f64 - ctx.f[12].f64) as f32) as f64);
	// 831F78F4: ECA602F2  fmuls f5, f6, f11
	ctx.f[5].f64 = (((ctx.f[6].f64 * ctx.f[11].f64) as f32) as f64);
	// 831F78F8: D0AB0000  stfs f5, 0(r11)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F78FC: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 831F7900: 4082FFD8  bne 0x831f78d8
	if !ctx.cr[0].eq {
	pc = 0x831F78D8; continue 'dispatch;
	}
	// 831F7904: 3D608201  lis r11, -0x7dff
	ctx.r[11].s64 = -2113863680;
	// 831F7908: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 831F790C: C14B9450  lfs f10, -0x6bb0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-27568 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831F7910: 7FE9FB78  mr r9, r31
	ctx.r[9].u64 = ctx.r[31].u64;
	// 831F7914: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 831F7918: 419A0060  beq cr6, 0x831f7978
	if ctx.cr[6].eq {
	pc = 0x831F7978; continue 'dispatch;
	}
	// 831F791C: EDA9002A  fadds f13, f9, f0
	ctx.f[13].f64 = ((ctx.f[9].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F7920: 7CCA3378  mr r10, r6
	ctx.r[10].u64 = ctx.r[6].u64;
	// 831F7924: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 831F7928: 7FC938AE  lbzx r30, r9, r7
	ctx.r[30].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[7].u32)) } as u64;
	// 831F792C: C0EB0000  lfs f7, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831F7930: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 831F7934: 7F094040  cmplw cr6, r9, r8
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831F7938: FBC1FFE0  std r30, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[30].u64 ) };
	// 831F793C: C8C1FFE0  lfd f6, -0x20(r1)
	ctx.f[6].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 831F7940: FCA0369C  fcfid f5, f6
	ctx.f[5].f64 = (ctx.f[6].s64 as f64);
	// 831F7944: FC802818  frsp f4, f5
	ctx.f[4].f64 = (ctx.f[5].f64 as f32) as f64;
	// 831F7948: EC646028  fsubs f3, f4, f12
	ctx.f[3].f64 = (((ctx.f[4].f64 - ctx.f[12].f64) as f32) as f64);
	// 831F794C: EC4302F2  fmuls f2, f3, f11
	ctx.f[2].f64 = (((ctx.f[3].f64 * ctx.f[11].f64) as f32) as f64);
	// 831F7950: D04B0000  stfs f2, 0(r11)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F7954: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 831F7958: EC22382A  fadds f1, f2, f7
	ctx.f[1].f64 = ((ctx.f[2].f64 + ctx.f[7].f64) as f32) as f64;
	// 831F795C: ECED00B2  fmuls f7, f13, f2
	ctx.f[7].f64 = (((ctx.f[13].f64 * ctx.f[2].f64) as f32) as f64);
	// 831F7960: ECC10032  fmuls f6, f1, f0
	ctx.f[6].f64 = (((ctx.f[1].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F7964: ECA602B2  fmuls f5, f6, f10
	ctx.f[5].f64 = (((ctx.f[6].f64 * ctx.f[10].f64) as f32) as f64);
	// 831F7968: D0AA0000  stfs f5, 0(r10)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F796C: D0EA0004  stfs f7, 4(r10)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831F7970: 394A0400  addi r10, r10, 0x400
	ctx.r[10].s64 = ctx.r[10].s64 + 1024;
	// 831F7974: 4198FFB4  blt cr6, 0x831f7928
	if ctx.cr[6].lt {
	pc = 0x831F7928; continue 'dispatch;
	}
	// 831F7978: 34A5FFFF  addic. r5, r5, -1
	ctx.xer.ca = (ctx.r[5].u32 > (!(-1 as u32)));
	ctx.r[5].s64 = ctx.r[5].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[5].s32, 0, &mut ctx.xer);
	// 831F797C: EC08002A  fadds f0, f8, f0
	ctx.f[0].f64 = ((ctx.f[8].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F7980: 7CE74214  add r7, r7, r8
	ctx.r[7].u64 = ctx.r[7].u64 + ctx.r[8].u64;
	// 831F7984: 38C60008  addi r6, r6, 8
	ctx.r[6].s64 = ctx.r[6].s64 + 8;
	// 831F7988: 4082FF88  bne 0x831f7910
	if !ctx.cr[0].eq {
	pc = 0x831F7910; continue 'dispatch;
	}
	// 831F798C: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F7990: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F7994: 7D2B3850  subf r9, r11, r7
	ctx.r[9].s64 = ctx.r[7].s64 - ctx.r[11].s64;
	// 831F7998: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F799C: 0CCA0000  twi 6, r10, 0
	// 831F79A0: 7D495396  divwu r10, r9, r10
	ctx.r[10].u32 = ctx.r[9].u32 / ctx.r[10].u32;
	// 831F79A4: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F79A8: 41980008  blt cr6, 0x831f79b0
	if ctx.cr[6].lt {
	pc = 0x831F79B0; continue 'dispatch;
	}
	// 831F79AC: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 831F79B0: 81630014  lwz r11, 0x14(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F79B4: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831F79B8: 7D4B3050  subf r10, r11, r6
	ctx.r[10].s64 = ctx.r[6].s64 - ctx.r[11].s64;
	// 831F79BC: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F79C0: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F79C4: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F79C8: 40980008  bge cr6, 0x831f79d0
	if !ctx.cr[6].lt {
	pc = 0x831F79D0; continue 'dispatch;
	}
	// 831F79CC: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 831F79D0: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F79D4: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F79D8: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 831F79DC: 419A005C  beq cr6, 0x831f7a38
	if ctx.cr[6].eq {
	pc = 0x831F7A38; continue 'dispatch;
	}
	// 831F79E0: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831F79E4: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 831F79E8: 392000FF  li r9, 0xff
	ctx.r[9].s64 = 255;
	// 831F79EC: C00A28A0  lfs f0, 0x28a0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(10400 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F79F0: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F79F4: ED8D0032  fmuls f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F79F8: FD60601E  fctiwz f11, f12
	ctx.f[11].s64 = if ctx.f[12].f64 > (i32::MAX as f64) { i32::MAX as i64 } else { ctx.f[12].f64.trunc() as i32 as i64 };
	// 831F79FC: D961FFE0  stfd f11, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.f[11].u64 ) };
	// 831F7A00: 8141FFE4  lwz r10, -0x1c(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-28 as u32) ) } as u64;
	// 831F7A04: 214A0080  subfic r10, r10, 0x80
	ctx.xer.ca = ctx.r[10].u32 <= 128 as u32;
	ctx.r[10].s64 = (128 as i64) - ctx.r[10].s64;
	// 831F7A08: 2F0A00FF  cmpwi cr6, r10, 0xff
	ctx.cr[6].compare_i32(ctx.r[10].s32, 255, &mut ctx.xer);
	// 831F7A0C: 4198000C  blt cr6, 0x831f7a18
	if ctx.cr[6].lt {
	pc = 0x831F7A18; continue 'dispatch;
	}
	// 831F7A10: 992B0000  stb r9, 0(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u8 ) };
	// 831F7A14: 48000018  b 0x831f7a2c
	pc = 0x831F7A2C; continue 'dispatch;
	// 831F7A18: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831F7A1C: 4199000C  bgt cr6, 0x831f7a28
	if ctx.cr[6].gt {
	pc = 0x831F7A28; continue 'dispatch;
	}
	// 831F7A20: 9BEB0000  stb r31, 0(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[31].u8 ) };
	// 831F7A24: 48000008  b 0x831f7a2c
	pc = 0x831F7A2C; continue 'dispatch;
	// 831F7A28: 994B0000  stb r10, 0(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u8 ) };
	// 831F7A2C: 3508FFFF  addic. r8, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 831F7A30: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 831F7A34: 4082FFBC  bne 0x831f79f0
	if !ctx.cr[0].eq {
	pc = 0x831F79F0; continue 'dispatch;
	}
	// 831F7A38: EBC1FFF0  ld r30, -0x10(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831F7A3C: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F7A40: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F7A48(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F7A48 size=428
    let mut pc: u32 = 0x831F7A48;
    'dispatch: loop {
        match pc {
            0x831F7A48 => {
    //   block [0x831F7A48..0x831F7BF4)
	// 831F7A48: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F7A4C: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F7A50: 81430018  lwz r10, 0x18(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F7A54: 81230008  lwz r9, 8(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F7A58: 5566103A  slwi r6, r11, 2
	ctx.r[6].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831F7A5C: 7D0B5050  subf r8, r11, r10
	ctx.r[8].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 831F7A60: 88E3000D  lbz r7, 0xd(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F7A64: 80A30004  lwz r5, 4(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F7A68: 7D040E70  srawi r4, r8, 1
	ctx.xer.ca = (ctx.r[8].s32 < 0) && ((ctx.r[8].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[4].s64 = (ctx.r[8].s32 >> 1) as i64;
	// 831F7A6C: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F7A70: 7D0749D6  mullw r8, r7, r9
	ctx.r[8].s64 = (ctx.r[7].s32 as i64) * (ctx.r[9].s32 as i64);
	// 831F7A74: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F7A78: 7D292850  subf r9, r9, r5
	ctx.r[9].s64 = ctx.r[5].s64 - ctx.r[9].s64;
	// 831F7A7C: 7D440194  addze r10, r4
	tmp.s64 = ctx.r[4].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[4].u32);
	ctx.r[10].s64 = tmp.s64;
	// 831F7A80: 7D685A14  add r11, r8, r11
	ctx.r[11].u64 = ctx.r[8].u64 + ctx.r[11].u64;
	// 831F7A84: 7D063A14  add r8, r6, r7
	ctx.r[8].u64 = ctx.r[6].u64 + ctx.r[7].u64;
	// 831F7A88: 7F095000  cmpw cr6, r9, r10
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[10].s32, &mut ctx.xer);
	// 831F7A8C: 41980008  blt cr6, 0x831f7a94
	if ctx.cr[6].lt {
	pc = 0x831F7A94; continue 'dispatch;
	}
	// 831F7A90: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 831F7A94: 7D4A07B4  extsw r10, r10
	ctx.r[10].s64 = ctx.r[10].s32 as i64;
	// 831F7A98: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F7A9C: ED6D0028  fsubs f11, f13, f0
	ctx.f[11].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F7AA0: 3CC08201  lis r6, -0x7dff
	ctx.r[6].s64 = -2113863680;
	// 831F7AA4: F941FFF0  std r10, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[10].u64 ) };
	// 831F7AA8: C941FFF0  lfd f10, -0x10(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831F7AAC: FD20569C  fcfid f9, f10
	ctx.f[9].f64 = (ctx.f[10].s64 as f64);
	// 831F7AB0: 38A9007F  addi r5, r9, 0x7f
	ctx.r[5].s64 = ctx.r[9].s64 + 127;
	// 831F7AB4: FD004818  frsp f8, f9
	ctx.f[8].f64 = (ctx.f[9].f64 as f32) as f64;
	// 831F7AB8: 54A7C9FE  srwi r7, r5, 7
	ctx.r[7].u32 = ctx.r[5].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F7ABC: C1869524  lfs f12, -0x6adc(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(-27356 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831F7AC0: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831F7AC4: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 831F7AC8: EDAB4024  fdivs f13, f11, f8
	ctx.f[13].f64 = ((ctx.f[11].f64 / ctx.f[8].f64) as f32) as f64;
	// 831F7ACC: ED2D0332  fmuls f9, f13, f12
	ctx.f[9].f64 = (((ctx.f[13].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F7AD0: 419A0018  beq cr6, 0x831f7ae8
	if ctx.cr[6].eq {
	pc = 0x831F7AE8; continue 'dispatch;
	}
	// 831F7AD4: 55463830  slwi r6, r10, 7
	ctx.r[6].u32 = ctx.r[10].u32.wrapping_shl(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831F7AD8: 7C065A2C  dcbt r6, r11
	// 831F7ADC: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 831F7AE0: 7F0A3840  cmplw cr6, r10, r7
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831F7AE4: 4198FFF0  blt cr6, 0x831f7ad4
	if ctx.cr[6].lt {
	pc = 0x831F7AD4; continue 'dispatch;
	}
	// 831F7AE8: 88A30034  lbz r5, 0x34(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(52 as u32) ) } as u64;
	// 831F7AEC: 3CE0820D  lis r7, -0x7df3
	ctx.r[7].s64 = -2113077248;
	// 831F7AF0: 3CC08213  lis r6, -0x7ded
	ctx.r[6].s64 = -2112684032;
	// 831F7AF4: 3D408201  lis r10, -0x7dff
	ctx.r[10].s64 = -2113863680;
	// 831F7AF8: F8A1FFF0  std r5, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[5].u64 ) };
	// 831F7AFC: C941FFF0  lfd f10, -0x10(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831F7B00: FD00569C  fcfid f8, f10
	ctx.f[8].f64 = (ctx.f[10].s64 as f64);
	// 831F7B04: C1874E60  lfs f12, 0x4e60(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(20064 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831F7B08: FCE04018  frsp f7, f8
	ctx.f[7].f64 = (ctx.f[8].f64 as f32) as f64;
	// 831F7B0C: C166B184  lfs f11, -0x4e7c(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(-20092 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831F7B10: C14A9450  lfs f10, -0x6bb0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-27568 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831F7B14: ECC76028  fsubs f6, f7, f12
	ctx.f[6].f64 = (((ctx.f[7].f64 - ctx.f[12].f64) as f32) as f64);
	// 831F7B18: ECA602F2  fmuls f5, f6, f11
	ctx.f[5].f64 = (((ctx.f[6].f64 * ctx.f[11].f64) as f32) as f64);
	// 831F7B1C: D0A30034  stfs f5, 0x34(r3)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 831F7B20: 88EB0000  lbz r7, 0(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F7B24: C1030034  lfs f8, 0x34(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(52 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831F7B28: ECED002A  fadds f7, f13, f0
	ctx.f[7].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F7B2C: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831F7B30: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831F7B34: F8E1FFF0  std r7, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[7].u64 ) };
	// 831F7B38: C8C1FFF0  lfd f6, -0x10(r1)
	ctx.f[6].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831F7B3C: FCA0369C  fcfid f5, f6
	ctx.f[5].f64 = (ctx.f[6].s64 as f64);
	// 831F7B40: FC802818  frsp f4, f5
	ctx.f[4].f64 = (ctx.f[5].f64 as f32) as f64;
	// 831F7B44: EC646028  fsubs f3, f4, f12
	ctx.f[3].f64 = (((ctx.f[4].f64 - ctx.f[12].f64) as f32) as f64);
	// 831F7B48: EC4302F2  fmuls f2, f3, f11
	ctx.f[2].f64 = (((ctx.f[3].f64 * ctx.f[11].f64) as f32) as f64);
	// 831F7B4C: D0430034  stfs f2, 0x34(r3)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 831F7B50: EC22402A  fadds f1, f2, f8
	ctx.f[1].f64 = ((ctx.f[2].f64 + ctx.f[8].f64) as f32) as f64;
	// 831F7B54: ED0700B2  fmuls f8, f7, f2
	ctx.f[8].f64 = (((ctx.f[7].f64 * ctx.f[2].f64) as f32) as f64);
	// 831F7B58: ECE10032  fmuls f7, f1, f0
	ctx.f[7].f64 = (((ctx.f[1].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F7B5C: EC09002A  fadds f0, f9, f0
	ctx.f[0].f64 = ((ctx.f[9].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F7B60: ECC702B2  fmuls f6, f7, f10
	ctx.f[6].f64 = (((ctx.f[7].f64 * ctx.f[10].f64) as f32) as f64);
	// 831F7B64: D0C80000  stfs f6, 0(r8)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F7B68: D1080004  stfs f8, 4(r8)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831F7B6C: 39080008  addi r8, r8, 8
	ctx.r[8].s64 = ctx.r[8].s64 + 8;
	// 831F7B70: 4082FFB0  bne 0x831f7b20
	if !ctx.cr[0].eq {
	pc = 0x831F7B20; continue 'dispatch;
	}
	// 831F7B74: 81430000  lwz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F7B78: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F7B7C: 7CEA5850  subf r7, r10, r11
	ctx.r[7].s64 = ctx.r[11].s64 - ctx.r[10].s64;
	// 831F7B80: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F7B84: 0CC90000  twi 6, r9, 0
	// 831F7B88: 7D474B96  divwu r10, r7, r9
	ctx.r[10].u32 = ctx.r[7].u32 / ctx.r[9].u32;
	// 831F7B8C: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F7B90: 41980008  blt cr6, 0x831f7b98
	if ctx.cr[6].lt {
	pc = 0x831F7B98; continue 'dispatch;
	}
	// 831F7B94: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 831F7B98: 81630014  lwz r11, 0x14(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F7B9C: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831F7BA0: 7D4B4050  subf r10, r11, r8
	ctx.r[10].s64 = ctx.r[8].s64 - ctx.r[11].s64;
	// 831F7BA4: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F7BA8: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F7BAC: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F7BB0: 40980008  bge cr6, 0x831f7bb8
	if !ctx.cr[6].lt {
	pc = 0x831F7BB8; continue 'dispatch;
	}
	// 831F7BB4: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 831F7BB8: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F7BBC: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831F7BC0: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F7BC4: C00A28A0  lfs f0, 0x28a0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(10400 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F7BC8: C1A30034  lfs f13, 0x34(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(52 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F7BCC: ED8D0032  fmuls f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F7BD0: FD60601E  fctiwz f11, f12
	ctx.f[11].s64 = if ctx.f[12].f64 > (i32::MAX as f64) { i32::MAX as i64 } else { ctx.f[12].f64.trunc() as i32 as i64 };
	// 831F7BD4: D961FFF0  stfd f11, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.f[11].u64 ) };
	// 831F7BD8: 8121FFF4  lwz r9, -0xc(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-12 as u32) ) } as u64;
	// 831F7BDC: 21690080  subfic r11, r9, 0x80
	ctx.xer.ca = ctx.r[9].u32 <= 128 as u32;
	ctx.r[11].s64 = (128 as i64) - ctx.r[9].s64;
	// 831F7BE0: 2F0B00FF  cmpwi cr6, r11, 0xff
	ctx.cr[6].compare_i32(ctx.r[11].s32, 255, &mut ctx.xer);
	// 831F7BE4: 41980010  blt cr6, 0x831f7bf4
	if ctx.cr[6].lt {
		sub_831F7BF4(ctx, base);
		return;
	}
	// 831F7BE8: 396000FF  li r11, 0xff
	ctx.r[11].s64 = 255;
	// 831F7BEC: 99630034  stb r11, 0x34(r3)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), ctx.r[11].u8 ) };
	// 831F7BF0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F7BF4(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831F7BF4 size=20
    let mut pc: u32 = 0x831F7BF4;
    'dispatch: loop {
        match pc {
            0x831F7BF4 => {
    //   block [0x831F7BF4..0x831F7C08)
	// 831F7BF4: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831F7BF8: 41990008  bgt cr6, 0x831f7c00
	if ctx.cr[6].gt {
	pc = 0x831F7C00; continue 'dispatch;
	}
	// 831F7BFC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831F7C00: 99630034  stb r11, 0x34(r3)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), ctx.r[11].u8 ) };
	// 831F7C04: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F7C08(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F7C08 size=572
    let mut pc: u32 = 0x831F7C08;
    'dispatch: loop {
        match pc {
            0x831F7C08 => {
    //   block [0x831F7C08..0x831F7E44)
	// 831F7C08: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 831F7C0C: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F7C10: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F7C14: 81430018  lwz r10, 0x18(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F7C18: 38A30034  addi r5, r3, 0x34
	ctx.r[5].s64 = ctx.r[3].s64 + 52;
	// 831F7C1C: 81030008  lwz r8, 8(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F7C20: 5566103A  slwi r6, r11, 2
	ctx.r[6].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831F7C24: 7CEB5050  subf r7, r11, r10
	ctx.r[7].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 831F7C28: 8883000D  lbz r4, 0xd(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F7C2C: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F7C30: 7CFF0E70  srawi r31, r7, 1
	ctx.xer.ca = (ctx.r[7].s32 < 0) && ((ctx.r[7].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[31].s64 = (ctx.r[7].s32 >> 1) as i64;
	// 831F7C34: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F7C38: 7D2441D6  mullw r9, r4, r8
	ctx.r[9].s64 = (ctx.r[4].s32 as i64) * (ctx.r[8].s32 as i64);
	// 831F7C3C: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F7C40: 7D085050  subf r8, r8, r10
	ctx.r[8].s64 = ctx.r[10].s64 - ctx.r[8].s64;
	// 831F7C44: 7D5F0194  addze r10, r31
	tmp.s64 = ctx.r[31].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[31].u32);
	ctx.r[10].s64 = tmp.s64;
	// 831F7C48: 7D695A14  add r11, r9, r11
	ctx.r[11].u64 = ctx.r[9].u64 + ctx.r[11].u64;
	// 831F7C4C: 7D263A14  add r9, r6, r7
	ctx.r[9].u64 = ctx.r[6].u64 + ctx.r[7].u64;
	// 831F7C50: 7F085000  cmpw cr6, r8, r10
	ctx.cr[6].compare_i32(ctx.r[8].s32, ctx.r[10].s32, &mut ctx.xer);
	// 831F7C54: 41980008  blt cr6, 0x831f7c5c
	if ctx.cr[6].lt {
	pc = 0x831F7C5C; continue 'dispatch;
	}
	// 831F7C58: 7D485378  mr r8, r10
	ctx.r[8].u64 = ctx.r[10].u64;
	// 831F7C5C: 7D4707B4  extsw r7, r10
	ctx.r[7].s64 = ctx.r[10].s32 as i64;
	// 831F7C60: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F7C64: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F7C68: 550A083C  slwi r10, r8, 1
	ctx.r[10].u32 = ctx.r[8].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F7C6C: F8E1FFE0  std r7, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[7].u64 ) };
	// 831F7C70: C961FFE0  lfd f11, -0x20(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 831F7C74: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F7C78: 3C808201  lis r4, -0x7dff
	ctx.r[4].s64 = -2113863680;
	// 831F7C7C: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F7C80: 394A007F  addi r10, r10, 0x7f
	ctx.r[10].s64 = ctx.r[10].s64 + 127;
	// 831F7C84: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 831F7C88: C1A49524  lfs f13, -0x6adc(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(-27356 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F7C8C: 5547C9FE  srwi r7, r10, 7
	ctx.r[7].u32 = ctx.r[10].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831F7C90: 7CCA3378  mr r10, r6
	ctx.r[10].u64 = ctx.r[6].u64;
	// 831F7C94: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 831F7C98: ED4C4824  fdivs f10, f12, f9
	ctx.f[10].f64 = ((ctx.f[12].f64 / ctx.f[9].f64) as f32) as f64;
	// 831F7C9C: ED2A0372  fmuls f9, f10, f13
	ctx.f[9].f64 = (((ctx.f[10].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F7CA0: 419A0018  beq cr6, 0x831f7cb8
	if ctx.cr[6].eq {
	pc = 0x831F7CB8; continue 'dispatch;
	}
	// 831F7CA4: 55443830  slwi r4, r10, 7
	ctx.r[4].u32 = ctx.r[10].u32.wrapping_shl(7);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 831F7CA8: 7C045A2C  dcbt r4, r11
	// 831F7CAC: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 831F7CB0: 7F0A3840  cmplw cr6, r10, r7
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831F7CB4: 4198FFF0  blt cr6, 0x831f7ca4
	if ctx.cr[6].lt {
	pc = 0x831F7CA4; continue 'dispatch;
	}
	// 831F7CB8: 3C808213  lis r4, -0x7ded
	ctx.r[4].s64 = -2112684032;
	// 831F7CBC: 3FE0820D  lis r31, -0x7df3
	ctx.r[31].s64 = -2113077248;
	// 831F7CC0: 7CAA2B78  mr r10, r5
	ctx.r[10].u64 = ctx.r[5].u64;
	// 831F7CC4: 38E00002  li r7, 2
	ctx.r[7].s64 = 2;
	// 831F7CC8: C184B184  lfs f12, -0x4e7c(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(-20092 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831F7CCC: C1BF4E60  lfs f13, 0x4e60(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20064 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F7CD0: 888A0000  lbz r4, 0(r10)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F7CD4: 34E7FFFF  addic. r7, r7, -1
	ctx.xer.ca = (ctx.r[7].u32 > (!(-1 as u32)));
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 831F7CD8: F881FFE0  std r4, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[4].u64 ) };
	// 831F7CDC: C961FFE0  lfd f11, -0x20(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 831F7CE0: FD005E9C  fcfid f8, f11
	ctx.f[8].f64 = (ctx.f[11].s64 as f64);
	// 831F7CE4: FCE04018  frsp f7, f8
	ctx.f[7].f64 = (ctx.f[8].f64 as f32) as f64;
	// 831F7CE8: ECC76828  fsubs f6, f7, f13
	ctx.f[6].f64 = (((ctx.f[7].f64 - ctx.f[13].f64) as f32) as f64);
	// 831F7CEC: ECA60332  fmuls f5, f6, f12
	ctx.f[5].f64 = (((ctx.f[6].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F7CF0: D0AA0000  stfs f5, 0(r10)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F7CF4: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 831F7CF8: 4082FFD8  bne 0x831f7cd0
	if !ctx.cr[0].eq {
	pc = 0x831F7CD0; continue 'dispatch;
	}
	// 831F7CFC: 3D408201  lis r10, -0x7dff
	ctx.r[10].s64 = -2113863680;
	// 831F7D00: C16A9450  lfs f11, -0x6bb0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-27568 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831F7D04: 88EB0001  lbz r7, 1(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(1 as u32) ) } as u64;
	// 831F7D08: C1050004  lfs f8, 4(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831F7D0C: ECEA002A  fadds f7, f10, f0
	ctx.f[7].f64 = ((ctx.f[10].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F7D10: 3508FFFF  addic. r8, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 831F7D14: F8E1FFE0  std r7, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[7].u64 ) };
	// 831F7D18: C8C1FFE0  lfd f6, -0x20(r1)
	ctx.f[6].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 831F7D1C: FCA0369C  fcfid f5, f6
	ctx.f[5].f64 = (ctx.f[6].s64 as f64);
	// 831F7D20: FC802818  frsp f4, f5
	ctx.f[4].f64 = (ctx.f[5].f64 as f32) as f64;
	// 831F7D24: EC646828  fsubs f3, f4, f13
	ctx.f[3].f64 = (((ctx.f[4].f64 - ctx.f[13].f64) as f32) as f64);
	// 831F7D28: EC430332  fmuls f2, f3, f12
	ctx.f[2].f64 = (((ctx.f[3].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F7D2C: D0450004  stfs f2, 4(r5)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831F7D30: EC22402A  fadds f1, f2, f8
	ctx.f[1].f64 = ((ctx.f[2].f64 + ctx.f[8].f64) as f32) as f64;
	// 831F7D34: ED0700B2  fmuls f8, f7, f2
	ctx.f[8].f64 = (((ctx.f[7].f64 * ctx.f[2].f64) as f32) as f64);
	// 831F7D38: ECC10032  fmuls f6, f1, f0
	ctx.f[6].f64 = (((ctx.f[1].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F7D3C: ECA602F2  fmuls f5, f6, f11
	ctx.f[5].f64 = (((ctx.f[6].f64 * ctx.f[11].f64) as f32) as f64);
	// 831F7D40: D0A90400  stfs f5, 0x400(r9)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 831F7D44: D1090404  stfs f8, 0x404(r9)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(1028 as u32), tmp.u32 ) };
	// 831F7D48: 894B0000  lbz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F7D4C: F941FFE8  std r10, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[10].u64 ) };
	// 831F7D50: C0450000  lfs f2, 0(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 831F7D54: C881FFE8  lfd f4, -0x18(r1)
	ctx.f[4].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831F7D58: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 831F7D5C: FC60269C  fcfid f3, f4
	ctx.f[3].f64 = (ctx.f[4].s64 as f64);
	// 831F7D60: FC201818  frsp f1, f3
	ctx.f[1].f64 = (ctx.f[3].f64 as f32) as f64;
	// 831F7D64: ED016828  fsubs f8, f1, f13
	ctx.f[8].f64 = (((ctx.f[1].f64 - ctx.f[13].f64) as f32) as f64);
	// 831F7D68: ECC80332  fmuls f6, f8, f12
	ctx.f[6].f64 = (((ctx.f[8].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F7D6C: D0C50000  stfs f6, 0(r5)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F7D70: ECA6102A  fadds f5, f6, f2
	ctx.f[5].f64 = ((ctx.f[6].f64 + ctx.f[2].f64) as f32) as f64;
	// 831F7D74: EC6701B2  fmuls f3, f7, f6
	ctx.f[3].f64 = (((ctx.f[7].f64 * ctx.f[6].f64) as f32) as f64);
	// 831F7D78: EC850032  fmuls f4, f5, f0
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F7D7C: EC09002A  fadds f0, f9, f0
	ctx.f[0].f64 = ((ctx.f[9].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F7D80: EC4402F2  fmuls f2, f4, f11
	ctx.f[2].f64 = (((ctx.f[4].f64 * ctx.f[11].f64) as f32) as f64);
	// 831F7D84: D0490000  stfs f2, 0(r9)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F7D88: D0690004  stfs f3, 4(r9)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831F7D8C: 39290008  addi r9, r9, 8
	ctx.r[9].s64 = ctx.r[9].s64 + 8;
	// 831F7D90: 4082FF74  bne 0x831f7d04
	if !ctx.cr[0].eq {
	pc = 0x831F7D04; continue 'dispatch;
	}
	// 831F7D94: 81430000  lwz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F7D98: 8903000D  lbz r8, 0xd(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F7D9C: 7CEA5850  subf r7, r10, r11
	ctx.r[7].s64 = ctx.r[11].s64 - ctx.r[10].s64;
	// 831F7DA0: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F7DA4: 0CC80000  twi 6, r8, 0
	// 831F7DA8: 7D474396  divwu r10, r7, r8
	ctx.r[10].u32 = ctx.r[7].u32 / ctx.r[8].u32;
	// 831F7DAC: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F7DB0: 41980008  blt cr6, 0x831f7db8
	if ctx.cr[6].lt {
	pc = 0x831F7DB8; continue 'dispatch;
	}
	// 831F7DB4: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 831F7DB8: 81630014  lwz r11, 0x14(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F7DBC: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831F7DC0: 7D4B4850  subf r10, r11, r9
	ctx.r[10].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 831F7DC4: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F7DC8: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831F7DCC: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831F7DD0: 40980008  bge cr6, 0x831f7dd8
	if !ctx.cr[6].lt {
	pc = 0x831F7DD8; continue 'dispatch;
	}
	// 831F7DD4: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 831F7DD8: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831F7DDC: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F7DE0: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F7DE4: 7CAB2B78  mr r11, r5
	ctx.r[11].u64 = ctx.r[5].u64;
	// 831F7DE8: 39200002  li r9, 2
	ctx.r[9].s64 = 2;
	// 831F7DEC: 390000FF  li r8, 0xff
	ctx.r[8].s64 = 255;
	// 831F7DF0: C00A28A0  lfs f0, 0x28a0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(10400 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F7DF4: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F7DF8: ED8D0032  fmuls f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F7DFC: FD60601E  fctiwz f11, f12
	ctx.f[11].s64 = if ctx.f[12].f64 > (i32::MAX as f64) { i32::MAX as i64 } else { ctx.f[12].f64.trunc() as i32 as i64 };
	// 831F7E00: D961FFE8  stfd f11, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.f[11].u64 ) };
	// 831F7E04: 8141FFEC  lwz r10, -0x14(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-20 as u32) ) } as u64;
	// 831F7E08: 214A0080  subfic r10, r10, 0x80
	ctx.xer.ca = ctx.r[10].u32 <= 128 as u32;
	ctx.r[10].s64 = (128 as i64) - ctx.r[10].s64;
	// 831F7E0C: 2F0A00FF  cmpwi cr6, r10, 0xff
	ctx.cr[6].compare_i32(ctx.r[10].s32, 255, &mut ctx.xer);
	// 831F7E10: 4198000C  blt cr6, 0x831f7e1c
	if ctx.cr[6].lt {
	pc = 0x831F7E1C; continue 'dispatch;
	}
	// 831F7E14: 990B0000  stb r8, 0(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[8].u8 ) };
	// 831F7E18: 48000018  b 0x831f7e30
	pc = 0x831F7E30; continue 'dispatch;
	// 831F7E1C: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831F7E20: 4199000C  bgt cr6, 0x831f7e2c
	if ctx.cr[6].gt {
	pc = 0x831F7E2C; continue 'dispatch;
	}
	// 831F7E24: 98CB0000  stb r6, 0(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[6].u8 ) };
	// 831F7E28: 48000008  b 0x831f7e30
	pc = 0x831F7E30; continue 'dispatch;
	// 831F7E2C: 994B0000  stb r10, 0(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u8 ) };
	// 831F7E30: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831F7E34: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 831F7E38: 4082FFBC  bne 0x831f7df4
	if !ctx.cr[0].eq {
	pc = 0x831F7DF4; continue 'dispatch;
	}
	// 831F7E3C: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F7E40: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F7E48(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F7E48 size=688
    let mut pc: u32 = 0x831F7E48;
    'dispatch: loop {
        match pc {
            0x831F7E48 => {
    //   block [0x831F7E48..0x831F80F8)
	// 831F7E48: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 831F7E4C: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F7E50: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F7E54: 81430018  lwz r10, 0x18(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F7E58: 39230034  addi r9, r3, 0x34
	ctx.r[9].s64 = ctx.r[3].s64 + 52;
	// 831F7E5C: 81030008  lwz r8, 8(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F7E60: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831F7E64: 7CEB5050  subf r7, r11, r10
	ctx.r[7].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 831F7E68: 88C3000D  lbz r6, 0xd(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F7E6C: 80830004  lwz r4, 4(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F7E70: 7CFF0E70  srawi r31, r7, 1
	ctx.xer.ca = (ctx.r[7].s32 < 0) && ((ctx.r[7].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[31].s64 = (ctx.r[7].s32 >> 1) as i64;
	// 831F7E74: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F7E78: 7D4641D6  mullw r10, r6, r8
	ctx.r[10].s64 = (ctx.r[6].s32 as i64) * (ctx.r[8].s32 as i64);
	// 831F7E7C: 80C30014  lwz r6, 0x14(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F7E80: 7CE82050  subf r7, r8, r4
	ctx.r[7].s64 = ctx.r[4].s64 - ctx.r[8].s64;
	// 831F7E84: 7D1F0194  addze r8, r31
	tmp.s64 = ctx.r[31].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[31].u32);
	ctx.r[8].s64 = tmp.s64;
	// 831F7E88: 7D4A5A14  add r10, r10, r11
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831F7E8C: 7D653214  add r11, r5, r6
	ctx.r[11].u64 = ctx.r[5].u64 + ctx.r[6].u64;
	// 831F7E90: 7F074000  cmpw cr6, r7, r8
	ctx.cr[6].compare_i32(ctx.r[7].s32, ctx.r[8].s32, &mut ctx.xer);
	// 831F7E94: 41980008  blt cr6, 0x831f7e9c
	if ctx.cr[6].lt {
	pc = 0x831F7E9C; continue 'dispatch;
	}
	// 831F7E98: 7D074378  mr r7, r8
	ctx.r[7].u64 = ctx.r[8].u64;
	// 831F7E9C: 7D0607B4  extsw r6, r8
	ctx.r[6].s64 = ctx.r[8].s32 as i64;
	// 831F7EA0: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F7EA4: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F7EA8: 54E8103A  slwi r8, r7, 2
	ctx.r[8].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831F7EAC: F8C1FFD0  std r6, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[6].u64 ) };
	// 831F7EB0: C961FFD0  lfd f11, -0x30(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 831F7EB4: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F7EB8: 3C808201  lis r4, -0x7dff
	ctx.r[4].s64 = -2113863680;
	// 831F7EBC: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F7EC0: 3908007F  addi r8, r8, 0x7f
	ctx.r[8].s64 = ctx.r[8].s64 + 127;
	// 831F7EC4: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 831F7EC8: C1A49524  lfs f13, -0x6adc(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(-27356 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F7ECC: 5506C9FE  srwi r6, r8, 7
	ctx.r[6].u32 = ctx.r[8].u32.wrapping_shr(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831F7ED0: 7CA82B78  mr r8, r5
	ctx.r[8].u64 = ctx.r[5].u64;
	// 831F7ED4: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 831F7ED8: ED4C4824  fdivs f10, f12, f9
	ctx.f[10].f64 = ((ctx.f[12].f64 / ctx.f[9].f64) as f32) as f64;
	// 831F7EDC: ED2A0372  fmuls f9, f10, f13
	ctx.f[9].f64 = (((ctx.f[10].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F7EE0: 419A0018  beq cr6, 0x831f7ef8
	if ctx.cr[6].eq {
	pc = 0x831F7EF8; continue 'dispatch;
	}
	// 831F7EE4: 55043830  slwi r4, r8, 7
	ctx.r[4].u32 = ctx.r[8].u32.wrapping_shl(7);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 831F7EE8: 7C04522C  dcbt r4, r10
	// 831F7EEC: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 831F7EF0: 7F083040  cmplw cr6, r8, r6
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[6].u32, &mut ctx.xer);
	// 831F7EF4: 4198FFF0  blt cr6, 0x831f7ee4
	if ctx.cr[6].lt {
	pc = 0x831F7EE4; continue 'dispatch;
	}
	// 831F7EF8: 3C808213  lis r4, -0x7ded
	ctx.r[4].s64 = -2112684032;
	// 831F7EFC: 3FE0820D  lis r31, -0x7df3
	ctx.r[31].s64 = -2113077248;
	// 831F7F00: 7D284B78  mr r8, r9
	ctx.r[8].u64 = ctx.r[9].u64;
	// 831F7F04: 38C00004  li r6, 4
	ctx.r[6].s64 = 4;
	// 831F7F08: C184B184  lfs f12, -0x4e7c(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(-20092 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831F7F0C: C1BF4E60  lfs f13, 0x4e60(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20064 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F7F10: 88880000  lbz r4, 0(r8)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F7F14: 34C6FFFF  addic. r6, r6, -1
	ctx.xer.ca = (ctx.r[6].u32 > (!(-1 as u32)));
	ctx.r[6].s64 = ctx.r[6].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[6].s32, 0, &mut ctx.xer);
	// 831F7F18: F881FFD0  std r4, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[4].u64 ) };
	// 831F7F1C: C961FFD0  lfd f11, -0x30(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 831F7F20: FD005E9C  fcfid f8, f11
	ctx.f[8].f64 = (ctx.f[11].s64 as f64);
	// 831F7F24: FCE04018  frsp f7, f8
	ctx.f[7].f64 = (ctx.f[8].f64 as f32) as f64;
	// 831F7F28: ECC76828  fsubs f6, f7, f13
	ctx.f[6].f64 = (((ctx.f[7].f64 - ctx.f[13].f64) as f32) as f64);
	// 831F7F2C: ECA60332  fmuls f5, f6, f12
	ctx.f[5].f64 = (((ctx.f[6].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F7F30: D0A80000  stfs f5, 0(r8)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F7F34: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 831F7F38: 4082FFD8  bne 0x831f7f10
	if !ctx.cr[0].eq {
	pc = 0x831F7F10; continue 'dispatch;
	}
	// 831F7F3C: 3D008201  lis r8, -0x7dff
	ctx.r[8].s64 = -2113863680;
	// 831F7F40: C1689450  lfs f11, -0x6bb0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(-27568 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831F7F44: 88CA0003  lbz r6, 3(r10)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(3 as u32) ) } as u64;
	// 831F7F48: C109000C  lfs f8, 0xc(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(12 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831F7F4C: ECEA002A  fadds f7, f10, f0
	ctx.f[7].f64 = ((ctx.f[10].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F7F50: 34E7FFFF  addic. r7, r7, -1
	ctx.xer.ca = (ctx.r[7].u32 > (!(-1 as u32)));
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 831F7F54: F8C1FFD0  std r6, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[6].u64 ) };
	// 831F7F58: C8C1FFD0  lfd f6, -0x30(r1)
	ctx.f[6].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 831F7F5C: FCA0369C  fcfid f5, f6
	ctx.f[5].f64 = (ctx.f[6].s64 as f64);
	// 831F7F60: FC802818  frsp f4, f5
	ctx.f[4].f64 = (ctx.f[5].f64 as f32) as f64;
	// 831F7F64: EC646828  fsubs f3, f4, f13
	ctx.f[3].f64 = (((ctx.f[4].f64 - ctx.f[13].f64) as f32) as f64);
	// 831F7F68: EC430332  fmuls f2, f3, f12
	ctx.f[2].f64 = (((ctx.f[3].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F7F6C: D049000C  stfs f2, 0xc(r9)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831F7F70: EC22402A  fadds f1, f2, f8
	ctx.f[1].f64 = ((ctx.f[2].f64 + ctx.f[8].f64) as f32) as f64;
	// 831F7F74: ED0700B2  fmuls f8, f7, f2
	ctx.f[8].f64 = (((ctx.f[7].f64 * ctx.f[2].f64) as f32) as f64);
	// 831F7F78: ECC10032  fmuls f6, f1, f0
	ctx.f[6].f64 = (((ctx.f[1].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F7F7C: ECA602F2  fmuls f5, f6, f11
	ctx.f[5].f64 = (((ctx.f[6].f64 * ctx.f[11].f64) as f32) as f64);
	// 831F7F80: D0AB0C00  stfs f5, 0xc00(r11)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(3072 as u32), tmp.u32 ) };
	// 831F7F84: D10B0C04  stfs f8, 0xc04(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(3076 as u32), tmp.u32 ) };
	// 831F7F88: 890A0002  lbz r8, 2(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(2 as u32) ) } as u64;
	// 831F7F8C: F901FFD8  std r8, -0x28(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), ctx.r[8].u64 ) };
	// 831F7F90: C0490008  lfs f2, 8(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 831F7F94: C881FFD8  lfd f4, -0x28(r1)
	ctx.f[4].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-40 as u32) ) };
	// 831F7F98: FC60269C  fcfid f3, f4
	ctx.f[3].f64 = (ctx.f[4].s64 as f64);
	// 831F7F9C: FC201818  frsp f1, f3
	ctx.f[1].f64 = (ctx.f[3].f64 as f32) as f64;
	// 831F7FA0: ED016828  fsubs f8, f1, f13
	ctx.f[8].f64 = (((ctx.f[1].f64 - ctx.f[13].f64) as f32) as f64);
	// 831F7FA4: ECC80332  fmuls f6, f8, f12
	ctx.f[6].f64 = (((ctx.f[8].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F7FA8: D0C90008  stfs f6, 8(r9)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831F7FAC: ECA6102A  fadds f5, f6, f2
	ctx.f[5].f64 = ((ctx.f[6].f64 + ctx.f[2].f64) as f32) as f64;
	// 831F7FB0: EC6701B2  fmuls f3, f7, f6
	ctx.f[3].f64 = (((ctx.f[7].f64 * ctx.f[6].f64) as f32) as f64);
	// 831F7FB4: EC850032  fmuls f4, f5, f0
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F7FB8: EC4402F2  fmuls f2, f4, f11
	ctx.f[2].f64 = (((ctx.f[4].f64 * ctx.f[11].f64) as f32) as f64);
	// 831F7FBC: D04B0800  stfs f2, 0x800(r11)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(2048 as u32), tmp.u32 ) };
	// 831F7FC0: D06B0804  stfs f3, 0x804(r11)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(2052 as u32), tmp.u32 ) };
	// 831F7FC4: 888A0001  lbz r4, 1(r10)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(1 as u32) ) } as u64;
	// 831F7FC8: F881FFE0  std r4, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[4].u64 ) };
	// 831F7FCC: C0C90004  lfs f6, 4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 831F7FD0: C821FFE0  lfd f1, -0x20(r1)
	ctx.f[1].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 831F7FD4: FD000E9C  fcfid f8, f1
	ctx.f[8].f64 = (ctx.f[1].s64 as f64);
	// 831F7FD8: FCA04018  frsp f5, f8
	ctx.f[5].f64 = (ctx.f[8].f64 as f32) as f64;
	// 831F7FDC: EC856828  fsubs f4, f5, f13
	ctx.f[4].f64 = (((ctx.f[5].f64 - ctx.f[13].f64) as f32) as f64);
	// 831F7FE0: EC640332  fmuls f3, f4, f12
	ctx.f[3].f64 = (((ctx.f[4].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F7FE4: D0690004  stfs f3, 4(r9)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831F7FE8: EC43302A  fadds f2, f3, f6
	ctx.f[2].f64 = ((ctx.f[3].f64 + ctx.f[6].f64) as f32) as f64;
	// 831F7FEC: ED0700F2  fmuls f8, f7, f3
	ctx.f[8].f64 = (((ctx.f[7].f64 * ctx.f[3].f64) as f32) as f64);
	// 831F7FF0: EC220032  fmuls f1, f2, f0
	ctx.f[1].f64 = (((ctx.f[2].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F7FF4: ECC102F2  fmuls f6, f1, f11
	ctx.f[6].f64 = (((ctx.f[1].f64 * ctx.f[11].f64) as f32) as f64);
	// 831F7FF8: D0CB0400  stfs f6, 0x400(r11)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 831F7FFC: D10B0404  stfs f8, 0x404(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(1028 as u32), tmp.u32 ) };
	// 831F8000: 88CA0000  lbz r6, 0(r10)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F8004: F8C1FFE8  std r6, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[6].u64 ) };
	// 831F8008: C0690000  lfs f3, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 831F800C: C8A1FFE8  lfd f5, -0x18(r1)
	ctx.f[5].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831F8010: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 831F8014: FC802E9C  fcfid f4, f5
	ctx.f[4].f64 = (ctx.f[5].s64 as f64);
	// 831F8018: FC402018  frsp f2, f4
	ctx.f[2].f64 = (ctx.f[4].f64 as f32) as f64;
	// 831F801C: EC226828  fsubs f1, f2, f13
	ctx.f[1].f64 = (((ctx.f[2].f64 - ctx.f[13].f64) as f32) as f64);
	// 831F8020: ED010332  fmuls f8, f1, f12
	ctx.f[8].f64 = (((ctx.f[1].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F8024: D1090000  stfs f8, 0(r9)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F8028: ECC8182A  fadds f6, f8, f3
	ctx.f[6].f64 = ((ctx.f[8].f64 + ctx.f[3].f64) as f32) as f64;
	// 831F802C: EC870232  fmuls f4, f7, f8
	ctx.f[4].f64 = (((ctx.f[7].f64 * ctx.f[8].f64) as f32) as f64);
	// 831F8030: ECA60032  fmuls f5, f6, f0
	ctx.f[5].f64 = (((ctx.f[6].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F8034: EC09002A  fadds f0, f9, f0
	ctx.f[0].f64 = ((ctx.f[9].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F8038: EC6502F2  fmuls f3, f5, f11
	ctx.f[3].f64 = (((ctx.f[5].f64 * ctx.f[11].f64) as f32) as f64);
	// 831F803C: D06B0000  stfs f3, 0(r11)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F8040: D08B0004  stfs f4, 4(r11)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831F8044: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 831F8048: 4082FEFC  bne 0x831f7f44
	if !ctx.cr[0].eq {
	pc = 0x831F7F44; continue 'dispatch;
	}
	// 831F804C: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F8050: 88E3000D  lbz r7, 0xd(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F8054: 7CC85050  subf r6, r8, r10
	ctx.r[6].s64 = ctx.r[10].s64 - ctx.r[8].s64;
	// 831F8058: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F805C: 0CC70000  twi 6, r7, 0
	// 831F8060: 7D063B96  divwu r8, r6, r7
	ctx.r[8].u32 = ctx.r[6].u32 / ctx.r[7].u32;
	// 831F8064: 7F085040  cmplw cr6, r8, r10
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831F8068: 41980008  blt cr6, 0x831f8070
	if ctx.cr[6].lt {
	pc = 0x831F8070; continue 'dispatch;
	}
	// 831F806C: 7D485378  mr r8, r10
	ctx.r[8].u64 = ctx.r[10].u64;
	// 831F8070: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F8074: 81430018  lwz r10, 0x18(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F8078: 7CC75850  subf r6, r7, r11
	ctx.r[6].s64 = ctx.r[11].s64 - ctx.r[7].s64;
	// 831F807C: 91030008  stw r8, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 831F8080: 54CBF0BE  srwi r11, r6, 2
	ctx.r[11].u32 = ctx.r[6].u32.wrapping_shr(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831F8084: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831F8088: 41980008  blt cr6, 0x831f8090
	if ctx.cr[6].lt {
	pc = 0x831F8090; continue 'dispatch;
	}
	// 831F808C: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 831F8090: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F8094: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831F8098: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F809C: 39400004  li r10, 4
	ctx.r[10].s64 = 4;
	// 831F80A0: 390000FF  li r8, 0xff
	ctx.r[8].s64 = 255;
	// 831F80A4: C00B28A0  lfs f0, 0x28a0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(10400 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F80A8: C1A90000  lfs f13, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F80AC: ED8D0032  fmuls f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F80B0: FD60601E  fctiwz f11, f12
	ctx.f[11].s64 = if ctx.f[12].f64 > (i32::MAX as f64) { i32::MAX as i64 } else { ctx.f[12].f64.trunc() as i32 as i64 };
	// 831F80B4: D961FFE8  stfd f11, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.f[11].u64 ) };
	// 831F80B8: 8161FFEC  lwz r11, -0x14(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-20 as u32) ) } as u64;
	// 831F80BC: 216B0080  subfic r11, r11, 0x80
	ctx.xer.ca = ctx.r[11].u32 <= 128 as u32;
	ctx.r[11].s64 = (128 as i64) - ctx.r[11].s64;
	// 831F80C0: 2F0B00FF  cmpwi cr6, r11, 0xff
	ctx.cr[6].compare_i32(ctx.r[11].s32, 255, &mut ctx.xer);
	// 831F80C4: 4198000C  blt cr6, 0x831f80d0
	if ctx.cr[6].lt {
	pc = 0x831F80D0; continue 'dispatch;
	}
	// 831F80C8: 99090000  stb r8, 0(r9)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[8].u8 ) };
	// 831F80CC: 48000018  b 0x831f80e4
	pc = 0x831F80E4; continue 'dispatch;
	// 831F80D0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831F80D4: 4199000C  bgt cr6, 0x831f80e0
	if ctx.cr[6].gt {
	pc = 0x831F80E0; continue 'dispatch;
	}
	// 831F80D8: 98A90000  stb r5, 0(r9)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[5].u8 ) };
	// 831F80DC: 48000008  b 0x831f80e4
	pc = 0x831F80E4; continue 'dispatch;
	// 831F80E0: 99690000  stb r11, 0(r9)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[11].u8 ) };
	// 831F80E4: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831F80E8: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 831F80EC: 4082FFBC  bne 0x831f80a8
	if !ctx.cr[0].eq {
	pc = 0x831F80A8; continue 'dispatch;
	}
	// 831F80F0: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F80F4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831F80F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831F80F8 size=816
    let mut pc: u32 = 0x831F80F8;
    'dispatch: loop {
        match pc {
            0x831F80F8 => {
    //   block [0x831F80F8..0x831F8428)
	// 831F80F8: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 831F80FC: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 831F8100: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F8104: 81230018  lwz r9, 0x18(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F8108: 39430034  addi r10, r3, 0x34
	ctx.r[10].s64 = ctx.r[3].s64 + 52;
	// 831F810C: 81030008  lwz r8, 8(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831F8110: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831F8114: 7CEB4850  subf r7, r11, r9
	ctx.r[7].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 831F8118: 88C3000D  lbz r6, 0xd(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F811C: 80830004  lwz r4, 4(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F8120: 7CFF0E70  srawi r31, r7, 1
	ctx.xer.ca = (ctx.r[7].s32 < 0) && ((ctx.r[7].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[31].s64 = (ctx.r[7].s32 >> 1) as i64;
	// 831F8124: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F8128: 7D2641D6  mullw r9, r6, r8
	ctx.r[9].s64 = (ctx.r[6].s32 as i64) * (ctx.r[8].s32 as i64);
	// 831F812C: 80C30014  lwz r6, 0x14(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F8130: 7CE82050  subf r7, r8, r4
	ctx.r[7].s64 = ctx.r[4].s64 - ctx.r[8].s64;
	// 831F8134: 7D1F0194  addze r8, r31
	tmp.s64 = ctx.r[31].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[31].u32);
	ctx.r[8].s64 = tmp.s64;
	// 831F8138: 7D295A14  add r9, r9, r11
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[11].u64;
	// 831F813C: 7D653214  add r11, r5, r6
	ctx.r[11].u64 = ctx.r[5].u64 + ctx.r[6].u64;
	// 831F8140: 7F074000  cmpw cr6, r7, r8
	ctx.cr[6].compare_i32(ctx.r[7].s32, ctx.r[8].s32, &mut ctx.xer);
	// 831F8144: 41980008  blt cr6, 0x831f814c
	if ctx.cr[6].lt {
	pc = 0x831F814C; continue 'dispatch;
	}
	// 831F8148: 7D074378  mr r7, r8
	ctx.r[7].u64 = ctx.r[8].u64;
	// 831F814C: 7D0607B4  extsw r6, r8
	ctx.r[6].s64 = ctx.r[8].s32 as i64;
	// 831F8150: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F8154: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831F8158: 54E8083C  slwi r8, r7, 1
	ctx.r[8].u32 = ctx.r[7].u32.wrapping_shl(1);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831F815C: F8C1FFC0  std r6, -0x40(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-64 as u32), ctx.r[6].u64 ) };
	// 831F8160: C961FFC0  lfd f11, -0x40(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-64 as u32) ) };
	// 831F8164: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831F8168: 7CA74214  add r5, r7, r8
	ctx.r[5].u64 = ctx.r[7].u64 + ctx.r[8].u64;
	// 831F816C: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831F8170: 54A8083C  slwi r8, r5, 1
	ctx.r[8].u32 = ctx.r[5].u32.wrapping_shl(1);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831F8174: 3C808201  lis r4, -0x7dff
	ctx.r[4].s64 = -2113863680;
	// 831F8178: 3908007F  addi r8, r8, 0x7f
	ctx.r[8].s64 = ctx.r[8].s64 + 127;
	// 831F817C: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 831F8180: 5506C9FE  srwi r6, r8, 7
	ctx.r[6].u32 = ctx.r[8].u32.wrapping_shr(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831F8184: 7CA82B78  mr r8, r5
	ctx.r[8].u64 = ctx.r[5].u64;
	// 831F8188: C1A49524  lfs f13, -0x6adc(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(-27356 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F818C: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 831F8190: ED4C4824  fdivs f10, f12, f9
	ctx.f[10].f64 = ((ctx.f[12].f64 / ctx.f[9].f64) as f32) as f64;
	// 831F8194: ED2A0372  fmuls f9, f10, f13
	ctx.f[9].f64 = (((ctx.f[10].f64 * ctx.f[13].f64) as f32) as f64);
	// 831F8198: 419A0018  beq cr6, 0x831f81b0
	if ctx.cr[6].eq {
	pc = 0x831F81B0; continue 'dispatch;
	}
	// 831F819C: 55043830  slwi r4, r8, 7
	ctx.r[4].u32 = ctx.r[8].u32.wrapping_shl(7);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 831F81A0: 7C044A2C  dcbt r4, r9
	// 831F81A4: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 831F81A8: 7F083040  cmplw cr6, r8, r6
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[6].u32, &mut ctx.xer);
	// 831F81AC: 4198FFF0  blt cr6, 0x831f819c
	if ctx.cr[6].lt {
	pc = 0x831F819C; continue 'dispatch;
	}
	// 831F81B0: 3C808213  lis r4, -0x7ded
	ctx.r[4].s64 = -2112684032;
	// 831F81B4: 3FE0820D  lis r31, -0x7df3
	ctx.r[31].s64 = -2113077248;
	// 831F81B8: 7D485378  mr r8, r10
	ctx.r[8].u64 = ctx.r[10].u64;
	// 831F81BC: 38C00006  li r6, 6
	ctx.r[6].s64 = 6;
	// 831F81C0: C184B184  lfs f12, -0x4e7c(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(-20092 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831F81C4: C1BF4E60  lfs f13, 0x4e60(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20064 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F81C8: 88880000  lbz r4, 0(r8)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F81CC: 34C6FFFF  addic. r6, r6, -1
	ctx.xer.ca = (ctx.r[6].u32 > (!(-1 as u32)));
	ctx.r[6].s64 = ctx.r[6].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[6].s32, 0, &mut ctx.xer);
	// 831F81D0: F881FFC0  std r4, -0x40(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-64 as u32), ctx.r[4].u64 ) };
	// 831F81D4: C961FFC0  lfd f11, -0x40(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-64 as u32) ) };
	// 831F81D8: FD005E9C  fcfid f8, f11
	ctx.f[8].f64 = (ctx.f[11].s64 as f64);
	// 831F81DC: FCE04018  frsp f7, f8
	ctx.f[7].f64 = (ctx.f[8].f64 as f32) as f64;
	// 831F81E0: ECC76828  fsubs f6, f7, f13
	ctx.f[6].f64 = (((ctx.f[7].f64 - ctx.f[13].f64) as f32) as f64);
	// 831F81E4: ECA60332  fmuls f5, f6, f12
	ctx.f[5].f64 = (((ctx.f[6].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F81E8: D0A80000  stfs f5, 0(r8)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F81EC: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 831F81F0: 4082FFD8  bne 0x831f81c8
	if !ctx.cr[0].eq {
	pc = 0x831F81C8; continue 'dispatch;
	}
	// 831F81F4: 3D008201  lis r8, -0x7dff
	ctx.r[8].s64 = -2113863680;
	// 831F81F8: C1689450  lfs f11, -0x6bb0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(-27568 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831F81FC: 88C90005  lbz r6, 5(r9)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[9].u32.wrapping_add(5 as u32) ) } as u64;
	// 831F8200: C10A0014  lfs f8, 0x14(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(20 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831F8204: ECEA002A  fadds f7, f10, f0
	ctx.f[7].f64 = ((ctx.f[10].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F8208: 34E7FFFF  addic. r7, r7, -1
	ctx.xer.ca = (ctx.r[7].u32 > (!(-1 as u32)));
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 831F820C: F8C1FFC0  std r6, -0x40(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-64 as u32), ctx.r[6].u64 ) };
	// 831F8210: C8C1FFC0  lfd f6, -0x40(r1)
	ctx.f[6].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-64 as u32) ) };
	// 831F8214: FCA0369C  fcfid f5, f6
	ctx.f[5].f64 = (ctx.f[6].s64 as f64);
	// 831F8218: FC802818  frsp f4, f5
	ctx.f[4].f64 = (ctx.f[5].f64 as f32) as f64;
	// 831F821C: EC646828  fsubs f3, f4, f13
	ctx.f[3].f64 = (((ctx.f[4].f64 - ctx.f[13].f64) as f32) as f64);
	// 831F8220: EC430332  fmuls f2, f3, f12
	ctx.f[2].f64 = (((ctx.f[3].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F8224: D04A0014  stfs f2, 0x14(r10)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831F8228: EC22402A  fadds f1, f2, f8
	ctx.f[1].f64 = ((ctx.f[2].f64 + ctx.f[8].f64) as f32) as f64;
	// 831F822C: ED0700B2  fmuls f8, f7, f2
	ctx.f[8].f64 = (((ctx.f[7].f64 * ctx.f[2].f64) as f32) as f64);
	// 831F8230: ECC10032  fmuls f6, f1, f0
	ctx.f[6].f64 = (((ctx.f[1].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F8234: ECA602F2  fmuls f5, f6, f11
	ctx.f[5].f64 = (((ctx.f[6].f64 * ctx.f[11].f64) as f32) as f64);
	// 831F8238: D0AB1400  stfs f5, 0x1400(r11)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(5120 as u32), tmp.u32 ) };
	// 831F823C: D10B1404  stfs f8, 0x1404(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(5124 as u32), tmp.u32 ) };
	// 831F8240: 89090004  lbz r8, 4(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F8244: F901FFC8  std r8, -0x38(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-56 as u32), ctx.r[8].u64 ) };
	// 831F8248: C04A0010  lfs f2, 0x10(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(16 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 831F824C: C881FFC8  lfd f4, -0x38(r1)
	ctx.f[4].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-56 as u32) ) };
	// 831F8250: FC60269C  fcfid f3, f4
	ctx.f[3].f64 = (ctx.f[4].s64 as f64);
	// 831F8254: FC201818  frsp f1, f3
	ctx.f[1].f64 = (ctx.f[3].f64 as f32) as f64;
	// 831F8258: ED016828  fsubs f8, f1, f13
	ctx.f[8].f64 = (((ctx.f[1].f64 - ctx.f[13].f64) as f32) as f64);
	// 831F825C: ECC80332  fmuls f6, f8, f12
	ctx.f[6].f64 = (((ctx.f[8].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F8260: D0CA0010  stfs f6, 0x10(r10)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831F8264: ECA6102A  fadds f5, f6, f2
	ctx.f[5].f64 = ((ctx.f[6].f64 + ctx.f[2].f64) as f32) as f64;
	// 831F8268: EC6701B2  fmuls f3, f7, f6
	ctx.f[3].f64 = (((ctx.f[7].f64 * ctx.f[6].f64) as f32) as f64);
	// 831F826C: EC850032  fmuls f4, f5, f0
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F8270: EC4402F2  fmuls f2, f4, f11
	ctx.f[2].f64 = (((ctx.f[4].f64 * ctx.f[11].f64) as f32) as f64);
	// 831F8274: D04B1000  stfs f2, 0x1000(r11)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4096 as u32), tmp.u32 ) };
	// 831F8278: D06B1004  stfs f3, 0x1004(r11)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4100 as u32), tmp.u32 ) };
	// 831F827C: 88890003  lbz r4, 3(r9)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[9].u32.wrapping_add(3 as u32) ) } as u64;
	// 831F8280: F881FFD0  std r4, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[4].u64 ) };
	// 831F8284: C0CA000C  lfs f6, 0xc(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(12 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 831F8288: C821FFD0  lfd f1, -0x30(r1)
	ctx.f[1].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 831F828C: FD000E9C  fcfid f8, f1
	ctx.f[8].f64 = (ctx.f[1].s64 as f64);
	// 831F8290: FCA04018  frsp f5, f8
	ctx.f[5].f64 = (ctx.f[8].f64 as f32) as f64;
	// 831F8294: EC856828  fsubs f4, f5, f13
	ctx.f[4].f64 = (((ctx.f[5].f64 - ctx.f[13].f64) as f32) as f64);
	// 831F8298: EC640332  fmuls f3, f4, f12
	ctx.f[3].f64 = (((ctx.f[4].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F829C: D06A000C  stfs f3, 0xc(r10)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831F82A0: EC43302A  fadds f2, f3, f6
	ctx.f[2].f64 = ((ctx.f[3].f64 + ctx.f[6].f64) as f32) as f64;
	// 831F82A4: ED0700F2  fmuls f8, f7, f3
	ctx.f[8].f64 = (((ctx.f[7].f64 * ctx.f[3].f64) as f32) as f64);
	// 831F82A8: EC220032  fmuls f1, f2, f0
	ctx.f[1].f64 = (((ctx.f[2].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F82AC: ECC102F2  fmuls f6, f1, f11
	ctx.f[6].f64 = (((ctx.f[1].f64 * ctx.f[11].f64) as f32) as f64);
	// 831F82B0: D0CB0C00  stfs f6, 0xc00(r11)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(3072 as u32), tmp.u32 ) };
	// 831F82B4: D10B0C04  stfs f8, 0xc04(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(3076 as u32), tmp.u32 ) };
	// 831F82B8: 88C90002  lbz r6, 2(r9)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[9].u32.wrapping_add(2 as u32) ) } as u64;
	// 831F82BC: F8C1FFD8  std r6, -0x28(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), ctx.r[6].u64 ) };
	// 831F82C0: C06A0008  lfs f3, 8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 831F82C4: C8A1FFD8  lfd f5, -0x28(r1)
	ctx.f[5].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-40 as u32) ) };
	// 831F82C8: FC802E9C  fcfid f4, f5
	ctx.f[4].f64 = (ctx.f[5].s64 as f64);
	// 831F82CC: FC402018  frsp f2, f4
	ctx.f[2].f64 = (ctx.f[4].f64 as f32) as f64;
	// 831F82D0: EC226828  fsubs f1, f2, f13
	ctx.f[1].f64 = (((ctx.f[2].f64 - ctx.f[13].f64) as f32) as f64);
	// 831F82D4: ED010332  fmuls f8, f1, f12
	ctx.f[8].f64 = (((ctx.f[1].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F82D8: D10A0008  stfs f8, 8(r10)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831F82DC: ECC8182A  fadds f6, f8, f3
	ctx.f[6].f64 = ((ctx.f[8].f64 + ctx.f[3].f64) as f32) as f64;
	// 831F82E0: EC870232  fmuls f4, f7, f8
	ctx.f[4].f64 = (((ctx.f[7].f64 * ctx.f[8].f64) as f32) as f64);
	// 831F82E4: ECA60032  fmuls f5, f6, f0
	ctx.f[5].f64 = (((ctx.f[6].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F82E8: EC6502F2  fmuls f3, f5, f11
	ctx.f[3].f64 = (((ctx.f[5].f64 * ctx.f[11].f64) as f32) as f64);
	// 831F82EC: D06B0800  stfs f3, 0x800(r11)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(2048 as u32), tmp.u32 ) };
	// 831F82F0: D08B0804  stfs f4, 0x804(r11)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(2052 as u32), tmp.u32 ) };
	// 831F82F4: 89090001  lbz r8, 1(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[9].u32.wrapping_add(1 as u32) ) } as u64;
	// 831F82F8: F901FFE0  std r8, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[8].u64 ) };
	// 831F82FC: C10A0004  lfs f8, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831F8300: C841FFE0  lfd f2, -0x20(r1)
	ctx.f[2].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 831F8304: FC20169C  fcfid f1, f2
	ctx.f[1].f64 = (ctx.f[2].s64 as f64);
	// 831F8308: FCC00818  frsp f6, f1
	ctx.f[6].f64 = (ctx.f[1].f64 as f32) as f64;
	// 831F830C: ECA66828  fsubs f5, f6, f13
	ctx.f[5].f64 = (((ctx.f[6].f64 - ctx.f[13].f64) as f32) as f64);
	// 831F8310: EC850332  fmuls f4, f5, f12
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F8314: D08A0004  stfs f4, 4(r10)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831F8318: EC64402A  fadds f3, f4, f8
	ctx.f[3].f64 = ((ctx.f[4].f64 + ctx.f[8].f64) as f32) as f64;
	// 831F831C: EC270132  fmuls f1, f7, f4
	ctx.f[1].f64 = (((ctx.f[7].f64 * ctx.f[4].f64) as f32) as f64);
	// 831F8320: EC430032  fmuls f2, f3, f0
	ctx.f[2].f64 = (((ctx.f[3].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F8324: ED0202F2  fmuls f8, f2, f11
	ctx.f[8].f64 = (((ctx.f[2].f64 * ctx.f[11].f64) as f32) as f64);
	// 831F8328: D10B0400  stfs f8, 0x400(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 831F832C: D02B0404  stfs f1, 0x404(r11)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(1028 as u32), tmp.u32 ) };
	// 831F8330: 88890000  lbz r4, 0(r9)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F8334: C0CA0000  lfs f6, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 831F8338: 39290006  addi r9, r9, 6
	ctx.r[9].s64 = ctx.r[9].s64 + 6;
	// 831F833C: F881FFE8  std r4, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[4].u64 ) };
	// 831F8340: C8A1FFE8  lfd f5, -0x18(r1)
	ctx.f[5].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831F8344: FC802E9C  fcfid f4, f5
	ctx.f[4].f64 = (ctx.f[5].s64 as f64);
	// 831F8348: FC602018  frsp f3, f4
	ctx.f[3].f64 = (ctx.f[4].f64 as f32) as f64;
	// 831F834C: EC436828  fsubs f2, f3, f13
	ctx.f[2].f64 = (((ctx.f[3].f64 - ctx.f[13].f64) as f32) as f64);
	// 831F8350: EC220332  fmuls f1, f2, f12
	ctx.f[1].f64 = (((ctx.f[2].f64 * ctx.f[12].f64) as f32) as f64);
	// 831F8354: D02A0000  stfs f1, 0(r10)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F8358: ED01302A  fadds f8, f1, f6
	ctx.f[8].f64 = ((ctx.f[1].f64 + ctx.f[6].f64) as f32) as f64;
	// 831F835C: ECE70072  fmuls f7, f7, f1
	ctx.f[7].f64 = (((ctx.f[7].f64 * ctx.f[1].f64) as f32) as f64);
	// 831F8360: ECC80032  fmuls f6, f8, f0
	ctx.f[6].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F8364: EC09002A  fadds f0, f9, f0
	ctx.f[0].f64 = ((ctx.f[9].f64 + ctx.f[0].f64) as f32) as f64;
	// 831F8368: ECA602F2  fmuls f5, f6, f11
	ctx.f[5].f64 = (((ctx.f[6].f64 * ctx.f[11].f64) as f32) as f64);
	// 831F836C: D0AB0000  stfs f5, 0(r11)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831F8370: D0EB0004  stfs f7, 4(r11)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831F8374: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 831F8378: 4082FE84  bne 0x831f81fc
	if !ctx.cr[0].eq {
	pc = 0x831F81FC; continue 'dispatch;
	}
	// 831F837C: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831F8380: 88E3000D  lbz r7, 0xd(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 831F8384: 7CC84850  subf r6, r8, r9
	ctx.r[6].s64 = ctx.r[9].s64 - ctx.r[8].s64;
	// 831F8388: 81230004  lwz r9, 4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831F838C: 0CC70000  twi 6, r7, 0
	// 831F8390: 7D063B96  divwu r8, r6, r7
	ctx.r[8].u32 = ctx.r[6].u32 / ctx.r[7].u32;
	// 831F8394: 7F084840  cmplw cr6, r8, r9
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831F8398: 41980008  blt cr6, 0x831f83a0
	if ctx.cr[6].lt {
	pc = 0x831F83A0; continue 'dispatch;
	}
	// 831F839C: 7D284B78  mr r8, r9
	ctx.r[8].u64 = ctx.r[9].u64;
	// 831F83A0: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831F83A4: 81230018  lwz r9, 0x18(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831F83A8: 7CC75850  subf r6, r7, r11
	ctx.r[6].s64 = ctx.r[11].s64 - ctx.r[7].s64;
	// 831F83AC: 91030008  stw r8, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 831F83B0: 54CBF0BE  srwi r11, r6, 2
	ctx.r[11].u32 = ctx.r[6].u32.wrapping_shr(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831F83B4: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831F83B8: 41980008  blt cr6, 0x831f83c0
	if ctx.cr[6].lt {
	pc = 0x831F83C0; continue 'dispatch;
	}
	// 831F83BC: 7D2B4B78  mr r11, r9
	ctx.r[11].u64 = ctx.r[9].u64;
	// 831F83C0: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831F83C4: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831F83C8: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 831F83CC: 39200006  li r9, 6
	ctx.r[9].s64 = 6;
	// 831F83D0: 390000FF  li r8, 0xff
	ctx.r[8].s64 = 255;
	// 831F83D4: C00B28A0  lfs f0, 0x28a0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(10400 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831F83D8: C1AA0000  lfs f13, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831F83DC: ED8D0032  fmuls f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 831F83E0: FD60601E  fctiwz f11, f12
	ctx.f[11].s64 = if ctx.f[12].f64 > (i32::MAX as f64) { i32::MAX as i64 } else { ctx.f[12].f64.trunc() as i32 as i64 };
	// 831F83E4: D961FFE8  stfd f11, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.f[11].u64 ) };
	// 831F83E8: 8161FFEC  lwz r11, -0x14(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-20 as u32) ) } as u64;
	// 831F83EC: 216B0080  subfic r11, r11, 0x80
	ctx.xer.ca = ctx.r[11].u32 <= 128 as u32;
	ctx.r[11].s64 = (128 as i64) - ctx.r[11].s64;
	// 831F83F0: 2F0B00FF  cmpwi cr6, r11, 0xff
	ctx.cr[6].compare_i32(ctx.r[11].s32, 255, &mut ctx.xer);
	// 831F83F4: 4198000C  blt cr6, 0x831f8400
	if ctx.cr[6].lt {
	pc = 0x831F8400; continue 'dispatch;
	}
	// 831F83F8: 990A0000  stb r8, 0(r10)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[8].u8 ) };
	// 831F83FC: 48000018  b 0x831f8414
	pc = 0x831F8414; continue 'dispatch;
	// 831F8400: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831F8404: 4199000C  bgt cr6, 0x831f8410
	if ctx.cr[6].gt {
	pc = 0x831F8410; continue 'dispatch;
	}
	// 831F8408: 98AA0000  stb r5, 0(r10)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[5].u8 ) };
	// 831F840C: 48000008  b 0x831f8414
	pc = 0x831F8414; continue 'dispatch;
	// 831F8410: 996A0000  stb r11, 0(r10)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[11].u8 ) };
	// 831F8414: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831F8418: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 831F841C: 4082FFBC  bne 0x831f83d8
	if !ctx.cr[0].eq {
	pc = 0x831F83D8; continue 'dispatch;
	}
	// 831F8420: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831F8424: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


